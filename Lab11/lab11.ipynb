{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78845c72",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f568f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "\n",
    "def build_model(n_hidden, n_neurons, optimizer, learning_rate, momentum=0): \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=X_train.shape[1:]))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = \"relu\"))\n",
    "    if optimizer == 'sgd':\n",
    "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate), loss=\"mse\", metrics=[\"mae\"])\n",
    "    elif optimizer == 'nesterov':\n",
    "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate, nesterov=True), loss=\"mse\", metrics=[\"mae\"])\n",
    "    elif optimizer == 'momentum':\n",
    "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), loss=\"mse\", metrics=[\"mae\"])\n",
    "    elif optimizer == 'adam':\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7255f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                      min_delta=1.0, \n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43c0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "def get_run_logdir(name, value): \n",
    "    import time\n",
    "    ts = int(time.time())\n",
    "    run_id = \"{}_{}_{}\".format(ts, name, value)\n",
    "    return os.path.join(root_logdir, run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee29b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 1070.8545 - mae: 23.2873 - val_loss: 412.8358 - val_mae: 18.7222\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 486.2099 - mae: 19.4476 - val_loss: 444.5895 - val_mae: 19.4031\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 480.0300 - mae: 19.2714 - val_loss: 387.6432 - val_mae: 17.7246\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 474.5277 - mae: 19.0983 - val_loss: 409.8431 - val_mae: 18.4711\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 466.0997 - mae: 18.8093 - val_loss: 384.5089 - val_mae: 17.5943\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 469.7098 - mae: 18.8984 - val_loss: 391.5736 - val_mae: 17.9577\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 457.9530 - mae: 18.5499 - val_loss: 396.7944 - val_mae: 17.9128\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.9962 - mae: 18.8319 - val_loss: 382.0858 - val_mae: 17.4909\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 460.2207 - mae: 18.6356 - val_loss: 379.8502 - val_mae: 17.4731\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 464.2900 - mae: 18.8012 - val_loss: 393.8468 - val_mae: 18.0491\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 466.7433 - mae: 18.8008 - val_loss: 383.5280 - val_mae: 17.5536\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 457.3224 - mae: 18.5066 - val_loss: 377.5269 - val_mae: 17.2517\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 445.7868 - mae: 18.0925 - val_loss: 407.7849 - val_mae: 18.3045\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 467.9200 - mae: 18.7897 - val_loss: 369.8721 - val_mae: 17.0297\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 454.1933 - mae: 18.4367 - val_loss: 405.1762 - val_mae: 18.3166\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 462.7657 - mae: 18.7401 - val_loss: 383.3596 - val_mae: 17.5730\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 453.8543 - mae: 18.3360 - val_loss: 452.1433 - val_mae: 19.8751\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 460.6039 - mae: 18.5927 - val_loss: 385.4105 - val_mae: 17.6994\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 451.7670 - mae: 18.3532 - val_loss: 374.1972 - val_mae: 17.2611\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 448.0216 - mae: 18.1936 - val_loss: 380.7965 - val_mae: 17.4204\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 458.2035 - mae: 18.5387 - val_loss: 412.2907 - val_mae: 18.8684\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 463.3615 - mae: 18.7790 - val_loss: 415.9062 - val_mae: 18.9797\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 450.4361 - mae: 18.3507 - val_loss: 358.5286 - val_mae: 16.3804\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 453.4174 - mae: 18.3732 - val_loss: 390.5814 - val_mae: 17.9436\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 455.5606 - mae: 18.5280 - val_loss: 382.4439 - val_mae: 17.4190\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 464.6059 - mae: 18.7693 - val_loss: 384.4686 - val_mae: 17.5590\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 445.2375 - mae: 18.0552 - val_loss: 391.2924 - val_mae: 17.9068\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 458.1918 - mae: 18.5958 - val_loss: 377.6756 - val_mae: 17.2128\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 449.6842 - mae: 18.2476 - val_loss: 376.5801 - val_mae: 17.2942\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 457.0280 - mae: 18.5553 - val_loss: 382.0728 - val_mae: 17.4836\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 452.2722 - mae: 18.4885 - val_loss: 371.2965 - val_mae: 16.9301\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 447.0318 - mae: 18.1462 - val_loss: 358.7086 - val_mae: 16.3965\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 450.3324 - mae: 18.2975 - val_loss: 406.1079 - val_mae: 18.3076\n",
      "Epoch 33: early stopping\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 499.5125 - mae: 19.8040\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1993.0154 - mae: 30.3000 - val_loss: 594.2615 - val_mae: 20.0506\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 570.8487 - mae: 19.8165 - val_loss: 451.6447 - val_mae: 18.2890\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 508.1488 - mae: 19.0579 - val_loss: 408.8592 - val_mae: 17.7379\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 480.5530 - mae: 18.7433 - val_loss: 382.5505 - val_mae: 17.2408\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 460.3884 - mae: 18.3491 - val_loss: 362.5721 - val_mae: 16.7730\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 444.4633 - mae: 18.0134 - val_loss: 351.9797 - val_mae: 16.4155\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 435.2872 - mae: 17.8013 - val_loss: 347.0573 - val_mae: 16.2626\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 429.8755 - mae: 17.6588 - val_loss: 344.2318 - val_mae: 16.2138\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 424.2115 - mae: 17.5580 - val_loss: 338.3720 - val_mae: 15.9747\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 417.7673 - mae: 17.3687 - val_loss: 331.8737 - val_mae: 15.7839\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 412.1829 - mae: 17.2168 - val_loss: 328.0119 - val_mae: 15.6897\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 408.2149 - mae: 17.1059 - val_loss: 324.9341 - val_mae: 15.5745\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 405.5932 - mae: 17.0080 - val_loss: 322.4258 - val_mae: 15.4663\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 403.2545 - mae: 16.9349 - val_loss: 320.9647 - val_mae: 15.4283\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 401.0925 - mae: 16.8608 - val_loss: 319.0787 - val_mae: 15.3555\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 399.6358 - mae: 16.8195 - val_loss: 316.8612 - val_mae: 15.2647\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 398.1901 - mae: 16.7621 - val_loss: 315.6564 - val_mae: 15.2244\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 397.0845 - mae: 16.7172 - val_loss: 314.9737 - val_mae: 15.2000\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 396.2846 - mae: 16.6875 - val_loss: 313.9113 - val_mae: 15.1728\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 394.9602 - mae: 16.6567 - val_loss: 312.9337 - val_mae: 15.1410\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.7911 - mae: 16.6176 - val_loss: 312.6379 - val_mae: 15.1537\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 392.5716 - mae: 16.5930 - val_loss: 311.4764 - val_mae: 15.1493\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 391.1977 - mae: 16.5703 - val_loss: 308.9881 - val_mae: 15.0302\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.5779 - mae: 16.5032 - val_loss: 307.6643 - val_mae: 14.9858\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 388.5728 - mae: 16.4640 - val_loss: 307.0329 - val_mae: 14.9628\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 387.9777 - mae: 16.4363 - val_loss: 305.8958 - val_mae: 14.9037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 387.0106 - mae: 16.3864 - val_loss: 306.0573 - val_mae: 14.9633\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 385.8705 - mae: 16.3975 - val_loss: 304.9012 - val_mae: 14.8848\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 385.3448 - mae: 16.3602 - val_loss: 304.3870 - val_mae: 14.8412\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 384.7220 - mae: 16.3084 - val_loss: 304.9615 - val_mae: 14.9170\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 384.2014 - mae: 16.3386 - val_loss: 303.2846 - val_mae: 14.7826\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 383.6534 - mae: 16.2653 - val_loss: 303.2025 - val_mae: 14.8421\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 383.0073 - mae: 16.2743 - val_loss: 302.3912 - val_mae: 14.7553\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 382.0412 - mae: 16.2173 - val_loss: 302.5144 - val_mae: 14.7967\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 381.2811 - mae: 16.2191 - val_loss: 301.7465 - val_mae: 14.7380\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 380.6880 - mae: 16.1705 - val_loss: 301.2667 - val_mae: 14.7564\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 380.1343 - mae: 16.1639 - val_loss: 300.9875 - val_mae: 14.6987\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 379.2466 - mae: 16.1349 - val_loss: 300.2887 - val_mae: 14.7198\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 379.4497 - mae: 16.1387 - val_loss: 299.5885 - val_mae: 14.6482\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 378.5128 - mae: 16.0998 - val_loss: 299.5767 - val_mae: 14.6500\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 377.8103 - mae: 16.0851 - val_loss: 298.7175 - val_mae: 14.6204\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 377.5585 - mae: 16.0647 - val_loss: 298.7063 - val_mae: 14.6401\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 377.0016 - mae: 16.0619 - val_loss: 297.9564 - val_mae: 14.5848\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 376.2443 - mae: 16.0127 - val_loss: 300.3509 - val_mae: 14.7512\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 376.2957 - mae: 16.0781 - val_loss: 297.6404 - val_mae: 14.5717\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 375.6649 - mae: 16.0072 - val_loss: 298.7324 - val_mae: 14.6604\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 375.2886 - mae: 16.0063 - val_loss: 300.6776 - val_mae: 14.7784\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 375.1414 - mae: 16.0492 - val_loss: 296.7575 - val_mae: 14.5323\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 374.5215 - mae: 15.9826 - val_loss: 296.5027 - val_mae: 14.5352\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 373.8829 - mae: 15.9476 - val_loss: 296.1791 - val_mae: 14.5661\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 373.2809 - mae: 15.9328 - val_loss: 299.4210 - val_mae: 14.7535\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 373.3171 - mae: 16.0050 - val_loss: 295.4986 - val_mae: 14.5357\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 372.1168 - mae: 15.9065 - val_loss: 294.7307 - val_mae: 14.4776\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 371.4036 - mae: 15.8795 - val_loss: 295.1279 - val_mae: 14.5303\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 371.0936 - mae: 15.8763 - val_loss: 294.7273 - val_mae: 14.4854\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 370.5645 - mae: 15.8585 - val_loss: 294.2335 - val_mae: 14.4788\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 369.9846 - mae: 15.8630 - val_loss: 293.0903 - val_mae: 14.3862\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 369.5675 - mae: 15.8165 - val_loss: 292.6288 - val_mae: 14.3578\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 369.1378 - mae: 15.7974 - val_loss: 293.1707 - val_mae: 14.4365\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 368.9153 - mae: 15.8102 - val_loss: 292.6422 - val_mae: 14.4103\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 368.3427 - mae: 15.8092 - val_loss: 291.1743 - val_mae: 14.2874\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 367.8039 - mae: 15.7524 - val_loss: 291.0043 - val_mae: 14.2963\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 367.5406 - mae: 15.7466 - val_loss: 290.9783 - val_mae: 14.2625\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 367.4330 - mae: 15.7312 - val_loss: 290.7904 - val_mae: 14.2786\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 366.8697 - mae: 15.7418 - val_loss: 290.0206 - val_mae: 14.2451\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 366.5467 - mae: 15.7128 - val_loss: 290.2024 - val_mae: 14.2777\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 366.1660 - mae: 15.6740 - val_loss: 289.8864 - val_mae: 14.2735\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 365.8068 - mae: 15.6877 - val_loss: 290.0054 - val_mae: 14.2749\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.3381 - mae: 15.6858 - val_loss: 289.0220 - val_mae: 14.2063\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.2350 - mae: 15.6687 - val_loss: 288.7689 - val_mae: 14.1865\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.0439 - mae: 15.6508 - val_loss: 289.1214 - val_mae: 14.2193\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 364.7330 - mae: 15.6496 - val_loss: 288.4648 - val_mae: 14.1818\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 364.6290 - mae: 15.6570 - val_loss: 288.2542 - val_mae: 14.1762\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 364.0548 - mae: 15.6252 - val_loss: 288.3055 - val_mae: 14.1933\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 363.5073 - mae: 15.5911 - val_loss: 288.5485 - val_mae: 14.1991\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 363.7577 - mae: 15.6080 - val_loss: 288.6284 - val_mae: 14.2111\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 363.1980 - mae: 15.6279 - val_loss: 287.2487 - val_mae: 14.1261\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 362.9611 - mae: 15.5677 - val_loss: 287.2875 - val_mae: 14.0882\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 362.6532 - mae: 15.5349 - val_loss: 287.1023 - val_mae: 14.1285\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 362.2815 - mae: 15.5613 - val_loss: 287.1769 - val_mae: 14.1384\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 362.1366 - mae: 15.5656 - val_loss: 286.6633 - val_mae: 14.1178\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 361.8914 - mae: 15.5478 - val_loss: 286.4423 - val_mae: 14.0952\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 361.6631 - mae: 15.5252 - val_loss: 288.6574 - val_mae: 14.2491\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 361.6506 - mae: 15.5696 - val_loss: 286.6005 - val_mae: 14.1349\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 361.2004 - mae: 15.5415 - val_loss: 285.4135 - val_mae: 14.0256\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 360.8791 - mae: 15.4888 - val_loss: 285.5738 - val_mae: 14.0461\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 360.6646 - mae: 15.4882 - val_loss: 285.8713 - val_mae: 14.0763\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 360.3745 - mae: 15.5032 - val_loss: 285.6594 - val_mae: 14.0639\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 360.1457 - mae: 15.4943 - val_loss: 285.5785 - val_mae: 14.0830\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 360.2402 - mae: 15.4774 - val_loss: 285.7591 - val_mae: 14.0944\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 359.7631 - mae: 15.4958 - val_loss: 284.6129 - val_mae: 13.9992\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 359.5641 - mae: 15.4544 - val_loss: 284.5630 - val_mae: 13.9968\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 359.2701 - mae: 15.4377 - val_loss: 284.2301 - val_mae: 13.9725\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 359.0334 - mae: 15.4211 - val_loss: 284.2112 - val_mae: 13.9943\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 358.6956 - mae: 15.4142 - val_loss: 284.2276 - val_mae: 13.9957\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 358.3501 - mae: 15.3948 - val_loss: 285.9907 - val_mae: 14.1390\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 358.7354 - mae: 15.4657 - val_loss: 284.4068 - val_mae: 14.0170\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 358.0444 - mae: 15.4409 - val_loss: 283.1697 - val_mae: 13.9341\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 357.6055 - mae: 15.3602 - val_loss: 285.3501 - val_mae: 14.1074\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 357.9038 - mae: 15.4304 - val_loss: 283.0630 - val_mae: 13.9370\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 364.4961 - mae: 15.5909\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 31ms/step - loss: 5536.8311 - mae: 49.0638 - val_loss: 3929.0273 - val_mae: 42.4543\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3393.9807 - mae: 40.2508 - val_loss: 2479.0981 - val_mae: 35.2066\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2186.4680 - mae: 33.7761 - val_loss: 1679.4082 - val_mae: 30.0226\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1520.0265 - mae: 29.2208 - val_loss: 1231.8188 - val_mae: 26.3653\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1147.6835 - mae: 26.0450 - val_loss: 974.5751 - val_mae: 23.8506\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 934.3021 - mae: 23.8755 - val_loss: 822.6340 - val_mae: 22.1635\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 808.9402 - mae: 22.3583 - val_loss: 729.7513 - val_mae: 21.0097\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 733.0526 - mae: 21.3492 - val_loss: 668.6766 - val_mae: 20.1973\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 683.6577 - mae: 20.6765 - val_loss: 626.2471 - val_mae: 19.6538\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 649.6579 - mae: 20.2408 - val_loss: 598.0315 - val_mae: 19.3142\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 627.6953 - mae: 19.9609 - val_loss: 574.8299 - val_mae: 19.0808\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 609.8295 - mae: 19.7741 - val_loss: 556.8318 - val_mae: 18.9097\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 595.7391 - mae: 19.6239 - val_loss: 539.9029 - val_mae: 18.7535\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 582.6967 - mae: 19.4979 - val_loss: 525.7341 - val_mae: 18.6235\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 571.9033 - mae: 19.3981 - val_loss: 512.1995 - val_mae: 18.4910\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 561.9595 - mae: 19.3112 - val_loss: 500.1995 - val_mae: 18.3663\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 552.7952 - mae: 19.2158 - val_loss: 488.6041 - val_mae: 18.2530\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 544.2346 - mae: 19.1446 - val_loss: 479.0016 - val_mae: 18.1484\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 536.7112 - mae: 19.0652 - val_loss: 469.4622 - val_mae: 18.0479\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 529.4979 - mae: 18.9945 - val_loss: 460.6500 - val_mae: 17.9525\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 522.5798 - mae: 18.9290 - val_loss: 451.3927 - val_mae: 17.8489\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 515.2745 - mae: 18.8496 - val_loss: 443.6025 - val_mae: 17.7622\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 509.0986 - mae: 18.7813 - val_loss: 435.7608 - val_mae: 17.6764\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 502.7336 - mae: 18.7060 - val_loss: 429.0441 - val_mae: 17.6015\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 497.1851 - mae: 18.6379 - val_loss: 422.9964 - val_mae: 17.5284\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 492.2609 - mae: 18.5733 - val_loss: 416.9118 - val_mae: 17.4531\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 487.2972 - mae: 18.5076 - val_loss: 411.1975 - val_mae: 17.3783\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 482.5165 - mae: 18.4423 - val_loss: 406.2232 - val_mae: 17.3119\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 478.2567 - mae: 18.3838 - val_loss: 401.4507 - val_mae: 17.2407\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 474.3138 - mae: 18.3263 - val_loss: 396.8586 - val_mae: 17.1709\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 470.4639 - mae: 18.2668 - val_loss: 392.1326 - val_mae: 17.0929\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 466.5244 - mae: 18.2058 - val_loss: 386.6750 - val_mae: 17.0089\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 461.9515 - mae: 18.1408 - val_loss: 382.8871 - val_mae: 16.9388\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 458.6672 - mae: 18.0856 - val_loss: 378.9697 - val_mae: 16.8667\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 455.2587 - mae: 18.0258 - val_loss: 375.4668 - val_mae: 16.8033\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 452.2508 - mae: 17.9760 - val_loss: 371.9986 - val_mae: 16.7378\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 449.2591 - mae: 17.9251 - val_loss: 368.8090 - val_mae: 16.6747\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 446.5298 - mae: 17.8742 - val_loss: 365.7920 - val_mae: 16.6134\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 443.9156 - mae: 17.8262 - val_loss: 362.8738 - val_mae: 16.5504\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 441.2964 - mae: 17.7745 - val_loss: 360.0568 - val_mae: 16.4898\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 438.6288 - mae: 17.7235 - val_loss: 357.1590 - val_mae: 16.4239\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 436.0103 - mae: 17.6698 - val_loss: 354.1189 - val_mae: 16.3544\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 433.3296 - mae: 17.6134 - val_loss: 351.3798 - val_mae: 16.2890\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 430.9377 - mae: 17.5636 - val_loss: 348.8051 - val_mae: 16.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 428.6477 - mae: 17.5140 - val_loss: 346.1329 - val_mae: 16.1682\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 426.2452 - mae: 17.4632 - val_loss: 343.8157 - val_mae: 16.1131\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 424.1829 - mae: 17.4180 - val_loss: 341.4261 - val_mae: 16.0572\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 422.0472 - mae: 17.3715 - val_loss: 339.4732 - val_mae: 16.0093\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 420.2734 - mae: 17.3298 - val_loss: 337.6308 - val_mae: 15.9639\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 418.5770 - mae: 17.2928 - val_loss: 335.6712 - val_mae: 15.9112\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 416.7630 - mae: 17.2479 - val_loss: 333.9646 - val_mae: 15.8661\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 415.1959 - mae: 17.2134 - val_loss: 332.3181 - val_mae: 15.8205\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 413.6790 - mae: 17.1733 - val_loss: 330.8019 - val_mae: 15.7777\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 412.2732 - mae: 17.1404 - val_loss: 329.3175 - val_mae: 15.7355\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 410.8809 - mae: 17.1059 - val_loss: 327.9537 - val_mae: 15.6954\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 409.5580 - mae: 17.0727 - val_loss: 326.6156 - val_mae: 15.6558\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 408.3236 - mae: 17.0412 - val_loss: 325.4155 - val_mae: 15.6223\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 407.1336 - mae: 17.0098 - val_loss: 324.2258 - val_mae: 15.5859\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 405.9854 - mae: 16.9787 - val_loss: 323.1562 - val_mae: 15.5539\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 404.9242 - mae: 16.9496 - val_loss: 322.1117 - val_mae: 15.5192\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 403.9109 - mae: 16.9217 - val_loss: 321.0981 - val_mae: 15.4901\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.9251 - mae: 16.8959 - val_loss: 320.1854 - val_mae: 15.4628\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 402.0216 - mae: 16.8711 - val_loss: 319.3090 - val_mae: 15.4339\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 401.1225 - mae: 16.8460 - val_loss: 318.4855 - val_mae: 15.4084\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 400.2995 - mae: 16.8228 - val_loss: 317.7260 - val_mae: 15.3839\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 399.4648 - mae: 16.7992 - val_loss: 316.9271 - val_mae: 15.3598\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 398.6600 - mae: 16.7759 - val_loss: 316.2095 - val_mae: 15.3374\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 397.8824 - mae: 16.7547 - val_loss: 315.5295 - val_mae: 15.3171\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 397.1967 - mae: 16.7346 - val_loss: 314.9078 - val_mae: 15.2970\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 396.5103 - mae: 16.7123 - val_loss: 314.3000 - val_mae: 15.2783\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 395.8584 - mae: 16.6945 - val_loss: 313.7470 - val_mae: 15.2603\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 395.2415 - mae: 16.6756 - val_loss: 313.1913 - val_mae: 15.2417\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 394.6501 - mae: 16.6582 - val_loss: 312.6703 - val_mae: 15.2243\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 394.0770 - mae: 16.6425 - val_loss: 312.1546 - val_mae: 15.2071\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 393.5258 - mae: 16.6259 - val_loss: 311.5877 - val_mae: 15.1870\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 392.9320 - mae: 16.6088 - val_loss: 311.1217 - val_mae: 15.1695\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 392.4282 - mae: 16.5933 - val_loss: 310.6697 - val_mae: 15.1519\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 391.9339 - mae: 16.5773 - val_loss: 310.1574 - val_mae: 15.1323\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 391.4705 - mae: 16.5635 - val_loss: 309.7779 - val_mae: 15.1160\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 390.9986 - mae: 16.5520 - val_loss: 309.4026 - val_mae: 15.1003\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 390.5982 - mae: 16.5384 - val_loss: 309.0443 - val_mae: 15.0852\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 390.2109 - mae: 16.5262 - val_loss: 308.7037 - val_mae: 15.0704\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.8369 - mae: 16.5142 - val_loss: 308.3688 - val_mae: 15.0563\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 389.4289 - mae: 16.4991 - val_loss: 308.0688 - val_mae: 15.0426\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.0449 - mae: 16.4881 - val_loss: 307.7321 - val_mae: 15.0281\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 388.7090 - mae: 16.4771 - val_loss: 307.3955 - val_mae: 15.0140\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 388.3637 - mae: 16.4647 - val_loss: 307.0724 - val_mae: 15.0000\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 388.0324 - mae: 16.4520 - val_loss: 306.7881 - val_mae: 14.9872\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 387.6986 - mae: 16.4404 - val_loss: 306.5147 - val_mae: 14.9744\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 387.3831 - mae: 16.4305 - val_loss: 306.2543 - val_mae: 14.9622\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 387.1009 - mae: 16.4199 - val_loss: 305.9958 - val_mae: 14.9498\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 386.8058 - mae: 16.4089 - val_loss: 305.7968 - val_mae: 14.9387\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 386.5194 - mae: 16.4016 - val_loss: 305.5674 - val_mae: 14.9266\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 386.2738 - mae: 16.3932 - val_loss: 305.3055 - val_mae: 14.9147\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 386.0058 - mae: 16.3834 - val_loss: 305.0812 - val_mae: 14.9033\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 385.7377 - mae: 16.3722 - val_loss: 304.8907 - val_mae: 14.8921\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 385.4375 - mae: 16.3623 - val_loss: 304.6566 - val_mae: 14.8812\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 385.1826 - mae: 16.3537 - val_loss: 304.4722 - val_mae: 14.8708\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 384.9387 - mae: 16.3444 - val_loss: 304.2854 - val_mae: 14.8607\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 384.7199 - mae: 16.3386 - val_loss: 304.0686 - val_mae: 14.8493\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 394.2807 - mae: 16.7622\n",
      "[(0.0001, 499.51251220703125, 19.804012298583984), (1e-05, 364.4961242675781, 15.590876579284668), (1e-06, 394.28070068359375, 16.762243270874023)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "reslr = []\n",
    "for lr in [10**(-4), 10**(-5), 10**(-6)]:\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(\"lr\", lr))\n",
    "    model = build_model(1, 25, 'sgd', lr)\n",
    "    model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    #print(score[0], score[1])\n",
    "    reslr.append((lr, score[0], score[1]))\n",
    "print(reslr)\n",
    "with open('lr.pkl', 'wb') as fp:\n",
    "    pickle.dump(reslr, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3fe2f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 30ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23378.0215 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23378.0195 - mae: 72.6294 - val_loss: 22248.2461 - val_mae: 69.9812\n",
      "Epoch 11: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 24476.9746 - mae: 74.0003\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 20ms/step - loss: 2344.3972 - mae: 32.5164 - val_loss: 432.7750 - val_mae: 16.7688\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 442.3098 - mae: 16.9222 - val_loss: 341.7025 - val_mae: 15.0815\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 397.1410 - mae: 16.1913 - val_loss: 307.9402 - val_mae: 14.5973\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 373.3690 - mae: 15.8011 - val_loss: 286.4655 - val_mae: 14.1630\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 358.5197 - mae: 15.5113 - val_loss: 275.2707 - val_mae: 13.8519\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 350.3698 - mae: 15.3072 - val_loss: 269.9133 - val_mae: 13.6817\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 345.5272 - mae: 15.1528 - val_loss: 265.7629 - val_mae: 13.5262\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 341.7439 - mae: 15.0161 - val_loss: 263.9464 - val_mae: 13.4318\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 339.5212 - mae: 14.9503 - val_loss: 261.4213 - val_mae: 13.3023\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 337.5934 - mae: 14.8818 - val_loss: 260.5894 - val_mae: 13.2296\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 336.3690 - mae: 14.8316 - val_loss: 258.9969 - val_mae: 13.1609\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 335.3810 - mae: 14.8052 - val_loss: 258.2360 - val_mae: 13.1333\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 334.2325 - mae: 14.7680 - val_loss: 258.1808 - val_mae: 13.1212\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 333.5396 - mae: 14.7448 - val_loss: 257.0454 - val_mae: 13.0783\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 332.8383 - mae: 14.6885 - val_loss: 257.0248 - val_mae: 13.0763\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 332.1114 - mae: 14.6825 - val_loss: 257.0494 - val_mae: 13.0798\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 331.6918 - mae: 14.6435 - val_loss: 256.7450 - val_mae: 13.0587\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 331.0453 - mae: 14.6203 - val_loss: 256.0419 - val_mae: 13.0368\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 330.3973 - mae: 14.6161 - val_loss: 255.6664 - val_mae: 13.0216\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 329.9934 - mae: 14.5819 - val_loss: 255.4308 - val_mae: 13.0076\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 329.5711 - mae: 14.5787 - val_loss: 255.5521 - val_mae: 13.0092\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 329.0019 - mae: 14.5405 - val_loss: 255.1283 - val_mae: 12.9892\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 328.3412 - mae: 14.5304 - val_loss: 254.5765 - val_mae: 12.9629\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 328.0443 - mae: 14.5163 - val_loss: 254.6613 - val_mae: 12.9561\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 327.7582 - mae: 14.5042 - val_loss: 254.2199 - val_mae: 12.9352\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 327.1480 - mae: 14.4642 - val_loss: 254.1121 - val_mae: 12.9484\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.9021 - mae: 14.5079 - val_loss: 253.4404 - val_mae: 12.8994\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 326.2061 - mae: 14.4477 - val_loss: 253.2800 - val_mae: 12.8951\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 325.9603 - mae: 14.4593 - val_loss: 253.6426 - val_mae: 12.9217\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 325.5095 - mae: 14.4009 - val_loss: 252.4171 - val_mae: 12.8505\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 325.0871 - mae: 14.4182 - val_loss: 252.1153 - val_mae: 12.8354\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 324.5421 - mae: 14.3791 - val_loss: 252.7581 - val_mae: 12.8839\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 324.3673 - mae: 14.4278 - val_loss: 251.7142 - val_mae: 12.8187\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 324.1034 - mae: 14.3775 - val_loss: 251.5109 - val_mae: 12.8086\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 323.4406 - mae: 14.3463 - val_loss: 251.6451 - val_mae: 12.8163\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.6746 - mae: 14.3109 - val_loss: 250.6884 - val_mae: 12.7661\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.0944 - mae: 14.3215 - val_loss: 250.5892 - val_mae: 12.7527\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.3559 - mae: 14.2926 - val_loss: 250.3745 - val_mae: 12.7409\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.0581 - mae: 14.3001 - val_loss: 249.7436 - val_mae: 12.7149\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 320.2498 - mae: 14.2500 - val_loss: 249.6317 - val_mae: 12.7176\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 320.0071 - mae: 14.2183 - val_loss: 248.8386 - val_mae: 12.6694\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 319.3248 - mae: 14.2160 - val_loss: 248.7390 - val_mae: 12.6718\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 319.1093 - mae: 14.1881 - val_loss: 248.9035 - val_mae: 12.6830\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 318.4849 - mae: 14.1716 - val_loss: 248.4690 - val_mae: 12.6601\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 318.1135 - mae: 14.1625 - val_loss: 247.9678 - val_mae: 12.6348\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.8408 - mae: 14.1674 - val_loss: 248.1132 - val_mae: 12.6434\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 317.4133 - mae: 14.1426 - val_loss: 247.5586 - val_mae: 12.6120\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 317.4185 - mae: 14.1534 - val_loss: 247.5896 - val_mae: 12.6262\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.9044 - mae: 14.1183 - val_loss: 247.1918 - val_mae: 12.5985\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.5178 - mae: 14.1163 - val_loss: 246.9011 - val_mae: 12.5874\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.1046 - mae: 14.0785 - val_loss: 246.8131 - val_mae: 12.5834\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.0546 - mae: 14.1050 - val_loss: 246.3243 - val_mae: 12.5443\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.5548 - mae: 14.0673 - val_loss: 246.4045 - val_mae: 12.5546\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.0374 - mae: 14.0489 - val_loss: 246.2596 - val_mae: 12.5613\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.9521 - mae: 14.0915 - val_loss: 245.9005 - val_mae: 12.5394\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.3021 - mae: 14.0487 - val_loss: 245.5190 - val_mae: 12.5393\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 313.7539 - mae: 14.0223 - val_loss: 244.8803 - val_mae: 12.4996\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 313.2465 - mae: 14.0038 - val_loss: 244.4688 - val_mae: 12.4775\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.6738 - mae: 13.9696 - val_loss: 244.7498 - val_mae: 12.4852\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.0838 - mae: 13.9595 - val_loss: 244.1679 - val_mae: 12.4661\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.6161 - mae: 13.9341 - val_loss: 243.4981 - val_mae: 12.4244\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.1713 - mae: 13.9122 - val_loss: 243.6648 - val_mae: 12.4463\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.6798 - mae: 13.9512 - val_loss: 242.8019 - val_mae: 12.3918\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.3851 - mae: 13.8865 - val_loss: 242.9276 - val_mae: 12.3999\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.1929 - mae: 13.8797 - val_loss: 242.3667 - val_mae: 12.3734\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 309.8113 - mae: 13.8743 - val_loss: 242.4217 - val_mae: 12.3803\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 309.6542 - mae: 13.8543 - val_loss: 242.0425 - val_mae: 12.3567\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 309.2848 - mae: 13.8472 - val_loss: 241.9417 - val_mae: 12.3418\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 309.2874 - mae: 13.8569 - val_loss: 241.6922 - val_mae: 12.3271\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 308.7401 - mae: 13.8156 - val_loss: 241.5438 - val_mae: 12.3372\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.4988 - mae: 13.8385 - val_loss: 241.7162 - val_mae: 12.3349\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.5636 - mae: 13.7967 - val_loss: 240.8231 - val_mae: 12.2736\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 308.0203 - mae: 13.8088 - val_loss: 241.7052 - val_mae: 12.3296\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.2426 - mae: 13.7710 - val_loss: 240.6412 - val_mae: 12.2723\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 307.8389 - mae: 13.7809 - val_loss: 240.2803 - val_mae: 12.2575\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 307.6215 - mae: 13.8001 - val_loss: 240.6006 - val_mae: 12.2847\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 307.3426 - mae: 13.7522 - val_loss: 240.4036 - val_mae: 12.2816\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 307.3935 - mae: 13.7901 - val_loss: 240.1664 - val_mae: 12.2594\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.9458 - mae: 13.7438 - val_loss: 239.8016 - val_mae: 12.2383\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.8057 - mae: 13.7381 - val_loss: 239.8807 - val_mae: 12.2464\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.5243 - mae: 13.7395 - val_loss: 240.1908 - val_mae: 12.2637\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.3669 - mae: 13.6949 - val_loss: 239.4530 - val_mae: 12.2283\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 305.9952 - mae: 13.7257 - val_loss: 239.3415 - val_mae: 12.2290\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 306.0772 - mae: 13.7191 - val_loss: 238.9678 - val_mae: 12.1985\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 305.6241 - mae: 13.7154 - val_loss: 238.5946 - val_mae: 12.1707\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 305.5551 - mae: 13.7160 - val_loss: 238.6301 - val_mae: 12.1715\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 305.4854 - mae: 13.6845 - val_loss: 238.3508 - val_mae: 12.1565\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 305.1096 - mae: 13.6765 - val_loss: 238.6553 - val_mae: 12.2028\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.7087 - mae: 13.7221 - val_loss: 238.6704 - val_mae: 12.1920\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.7882 - mae: 13.6764 - val_loss: 238.1991 - val_mae: 12.1715\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.2343 - mae: 13.6682 - val_loss: 238.3066 - val_mae: 12.1979\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 303.3954 - mae: 13.6279 - val_loss: 237.4986 - val_mae: 12.1733\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 302.5876 - mae: 13.6330 - val_loss: 237.0444 - val_mae: 12.1388\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 301.7593 - mae: 13.5974 - val_loss: 237.1768 - val_mae: 12.1654\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 301.1009 - mae: 13.6048 - val_loss: 236.0760 - val_mae: 12.0878\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 300.6355 - mae: 13.5501 - val_loss: 235.8609 - val_mae: 12.0803\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 299.8324 - mae: 13.5492 - val_loss: 235.8169 - val_mae: 12.0764\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 299.2816 - mae: 13.4949 - val_loss: 235.9673 - val_mae: 12.0979\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 299.0322 - mae: 13.4900 - val_loss: 234.7928 - val_mae: 12.0246\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 298.5296 - mae: 13.4988 - val_loss: 234.9834 - val_mae: 12.0334\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 306.1444 - mae: 13.7552\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 27ms/step - loss: 1566.3713 - mae: 26.3527 - val_loss: 402.0469 - val_mae: 17.0813\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 425.5120 - mae: 17.2472 - val_loss: 318.8121 - val_mae: 15.2551\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 371.5489 - mae: 15.9460 - val_loss: 279.2000 - val_mae: 14.1264\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 340.9400 - mae: 15.0330 - val_loss: 256.3217 - val_mae: 13.3098\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 323.6366 - mae: 14.4449 - val_loss: 243.6247 - val_mae: 12.8008\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.4056 - mae: 14.0583 - val_loss: 234.2175 - val_mae: 12.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 303.7675 - mae: 13.7637 - val_loss: 226.7474 - val_mae: 12.0219\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 296.7656 - mae: 13.5161 - val_loss: 221.7104 - val_mae: 11.7801\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 291.6916 - mae: 13.3346 - val_loss: 217.8874 - val_mae: 11.6180\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.4201 - mae: 13.1944 - val_loss: 215.2811 - val_mae: 11.5003\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.3701 - mae: 13.0860 - val_loss: 212.4447 - val_mae: 11.3630\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 281.6661 - mae: 12.9726 - val_loss: 210.6732 - val_mae: 11.2980\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.1715 - mae: 12.8960 - val_loss: 208.5197 - val_mae: 11.2045\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 276.9091 - mae: 12.8236 - val_loss: 205.8155 - val_mae: 11.0965\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 274.6917 - mae: 12.7341 - val_loss: 204.4440 - val_mae: 11.0496\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 272.1243 - mae: 12.6584 - val_loss: 203.3065 - val_mae: 11.0147\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 270.1723 - mae: 12.6069 - val_loss: 201.2112 - val_mae: 10.9190\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 268.6214 - mae: 12.5450 - val_loss: 200.3473 - val_mae: 10.8785\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 266.9184 - mae: 12.4841 - val_loss: 200.2851 - val_mae: 10.8816\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 265.7428 - mae: 12.4773 - val_loss: 199.0412 - val_mae: 10.8233\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 264.8315 - mae: 12.4091 - val_loss: 199.2921 - val_mae: 10.8357\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 263.8346 - mae: 12.4205 - val_loss: 197.9008 - val_mae: 10.7793\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 263.1218 - mae: 12.3572 - val_loss: 197.5763 - val_mae: 10.7610\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 262.2617 - mae: 12.3292 - val_loss: 197.2877 - val_mae: 10.7476\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 261.5128 - mae: 12.3091 - val_loss: 196.5062 - val_mae: 10.7068\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 260.9689 - mae: 12.2903 - val_loss: 196.1357 - val_mae: 10.6841\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 260.2338 - mae: 12.2522 - val_loss: 196.1753 - val_mae: 10.6858\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 259.6834 - mae: 12.2669 - val_loss: 195.0665 - val_mae: 10.6420\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 258.8658 - mae: 12.2103 - val_loss: 194.5754 - val_mae: 10.6329\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 258.3687 - mae: 12.2049 - val_loss: 193.8486 - val_mae: 10.6229\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 257.3499 - mae: 12.1181 - val_loss: 193.3302 - val_mae: 10.5845\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 256.4447 - mae: 12.1195 - val_loss: 192.9839 - val_mae: 10.5804\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 255.7589 - mae: 12.1154 - val_loss: 192.9937 - val_mae: 10.5878\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 255.0612 - mae: 12.1066 - val_loss: 192.3098 - val_mae: 10.5557\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 254.6625 - mae: 12.0535 - val_loss: 191.9573 - val_mae: 10.5392\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 254.2958 - mae: 12.0376 - val_loss: 191.3651 - val_mae: 10.5093\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 253.4881 - mae: 12.0071 - val_loss: 191.2779 - val_mae: 10.4882\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 252.8647 - mae: 12.0057 - val_loss: 190.8240 - val_mae: 10.4759\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 252.4898 - mae: 11.9665 - val_loss: 190.7081 - val_mae: 10.4678\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 252.0565 - mae: 11.9615 - val_loss: 190.7447 - val_mae: 10.4631\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 251.3978 - mae: 11.9371 - val_loss: 190.2265 - val_mae: 10.4533\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 251.1792 - mae: 11.9246 - val_loss: 189.5837 - val_mae: 10.4100\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 250.6735 - mae: 11.8801 - val_loss: 189.9813 - val_mae: 10.4302\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 250.1372 - mae: 11.9365 - val_loss: 188.7974 - val_mae: 10.3815\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 249.6925 - mae: 11.8476 - val_loss: 188.5197 - val_mae: 10.3649\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 249.0940 - mae: 11.8502 - val_loss: 188.1504 - val_mae: 10.3508\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 248.3715 - mae: 11.8401 - val_loss: 187.2587 - val_mae: 10.3203\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 247.7521 - mae: 11.8185 - val_loss: 186.5303 - val_mae: 10.3354\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 245.7869 - mae: 11.8113 - val_loss: 184.2365 - val_mae: 10.2612\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 243.6650 - mae: 11.7543 - val_loss: 181.8082 - val_mae: 10.1979\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 240.8020 - mae: 11.6950 - val_loss: 178.7125 - val_mae: 10.0925\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 237.9976 - mae: 11.5858 - val_loss: 176.4885 - val_mae: 10.0020\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 236.1276 - mae: 11.4966 - val_loss: 174.9702 - val_mae: 9.9366\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 234.8669 - mae: 11.4373 - val_loss: 173.8795 - val_mae: 9.8826\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 233.4675 - mae: 11.3996 - val_loss: 173.2325 - val_mae: 9.8596\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 232.7227 - mae: 11.3503 - val_loss: 172.5149 - val_mae: 9.8202\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 231.9141 - mae: 11.3170 - val_loss: 172.1303 - val_mae: 9.8091\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 231.2319 - mae: 11.2458 - val_loss: 171.6428 - val_mae: 9.7762\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 230.7979 - mae: 11.2819 - val_loss: 171.5991 - val_mae: 9.7897\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 229.9102 - mae: 11.2571 - val_loss: 170.9834 - val_mae: 9.7591\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 229.3273 - mae: 11.2569 - val_loss: 169.9980 - val_mae: 9.7005\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 228.4563 - mae: 11.1883 - val_loss: 169.7655 - val_mae: 9.6912\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 228.2171 - mae: 11.1968 - val_loss: 169.0925 - val_mae: 9.6503\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 227.6526 - mae: 11.1802 - val_loss: 168.4083 - val_mae: 9.6146\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 226.9721 - mae: 11.1234 - val_loss: 168.1450 - val_mae: 9.5999\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 226.5475 - mae: 11.0928 - val_loss: 167.6726 - val_mae: 9.5701\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 226.2672 - mae: 11.0746 - val_loss: 167.3635 - val_mae: 9.5559\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 225.7273 - mae: 11.0706 - val_loss: 166.8604 - val_mae: 9.5161\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 225.4214 - mae: 11.0194 - val_loss: 166.7856 - val_mae: 9.5137\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 225.1426 - mae: 11.0472 - val_loss: 166.3954 - val_mae: 9.4997\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 224.5782 - mae: 10.9863 - val_loss: 166.9194 - val_mae: 9.5365\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 224.4877 - mae: 11.0458 - val_loss: 166.0597 - val_mae: 9.4763\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 224.2329 - mae: 10.9619 - val_loss: 165.3751 - val_mae: 9.4341\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 223.7755 - mae: 10.9315 - val_loss: 165.2464 - val_mae: 9.4314\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 223.6308 - mae: 10.9535 - val_loss: 164.9617 - val_mae: 9.4144\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 223.0802 - mae: 10.9217 - val_loss: 164.7826 - val_mae: 9.4028\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 222.7264 - mae: 10.8955 - val_loss: 165.3628 - val_mae: 9.4569\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 220.9435 - mae: 10.9119 - val_loss: 159.7153 - val_mae: 9.2946\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 214.8806 - mae: 10.7858 - val_loss: 154.2502 - val_mae: 9.1133\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 211.0242 - mae: 10.6275 - val_loss: 151.8418 - val_mae: 9.0228\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 208.7356 - mae: 10.5295 - val_loss: 151.2186 - val_mae: 8.9992\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 207.2414 - mae: 10.5218 - val_loss: 149.4032 - val_mae: 8.9172\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 206.3913 - mae: 10.4484 - val_loss: 148.8519 - val_mae: 8.8872\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 205.6136 - mae: 10.4107 - val_loss: 148.5983 - val_mae: 8.8597\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 205.2475 - mae: 10.3986 - val_loss: 147.8188 - val_mae: 8.8185\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 204.6402 - mae: 10.3249 - val_loss: 147.4953 - val_mae: 8.7924\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 204.4404 - mae: 10.3330 - val_loss: 147.2902 - val_mae: 8.7875\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 204.1318 - mae: 10.3073 - val_loss: 147.5146 - val_mae: 8.7962\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 203.9342 - mae: 10.3486 - val_loss: 146.9418 - val_mae: 8.7513\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 203.6122 - mae: 10.2941 - val_loss: 146.8154 - val_mae: 8.7479\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 203.3945 - mae: 10.2883 - val_loss: 146.6492 - val_mae: 8.7355\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 203.2342 - mae: 10.3008 - val_loss: 146.7623 - val_mae: 8.7468\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 203.0825 - mae: 10.2781 - val_loss: 147.3916 - val_mae: 8.7874\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 203.1608 - mae: 10.3444 - val_loss: 146.3817 - val_mae: 8.7227\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.8526 - mae: 10.2589 - val_loss: 146.0418 - val_mae: 8.6898\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.6545 - mae: 10.2576 - val_loss: 145.8884 - val_mae: 8.6742\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.6989 - mae: 10.2457 - val_loss: 145.8264 - val_mae: 8.6832\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.2893 - mae: 10.2094 - val_loss: 146.3160 - val_mae: 8.7196\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.2344 - mae: 10.3031 - val_loss: 145.6128 - val_mae: 8.6644\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 202.1816 - mae: 10.2192 - val_loss: 145.3592 - val_mae: 8.6432\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 205.4791 - mae: 10.5032\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 17ms/step - loss: 503.4771 - mae: 18.8432 - val_loss: 367.7943 - val_mae: 16.4846\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 412.2707 - mae: 16.8715 - val_loss: 332.6093 - val_mae: 15.4663\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 389.3600 - mae: 16.2391 - val_loss: 316.3839 - val_mae: 14.9698\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 378.4278 - mae: 15.9138 - val_loss: 306.6263 - val_mae: 14.6591\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 370.4032 - mae: 15.6694 - val_loss: 292.3705 - val_mae: 14.2820\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 354.2434 - mae: 15.2160 - val_loss: 282.9212 - val_mae: 13.8828\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 346.6468 - mae: 14.9478 - val_loss: 278.5148 - val_mae: 13.6819\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 343.2096 - mae: 14.8173 - val_loss: 275.8346 - val_mae: 13.5876\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 340.9837 - mae: 14.7462 - val_loss: 273.4100 - val_mae: 13.4762\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 339.5194 - mae: 14.6684 - val_loss: 273.2655 - val_mae: 13.4832\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 338.1248 - mae: 14.6454 - val_loss: 271.4195 - val_mae: 13.3943\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 336.5975 - mae: 14.5880 - val_loss: 269.8293 - val_mae: 13.3148\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 335.4487 - mae: 14.5263 - val_loss: 268.9348 - val_mae: 13.2763\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 331.4080 - mae: 14.4105 - val_loss: 261.1202 - val_mae: 13.0900\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 324.0129 - mae: 14.2030 - val_loss: 256.1321 - val_mae: 12.8709\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 320.5556 - mae: 14.0500 - val_loss: 256.0963 - val_mae: 12.9083\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 318.9407 - mae: 14.0461 - val_loss: 252.7417 - val_mae: 12.7306\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.6989 - mae: 13.9827 - val_loss: 252.1191 - val_mae: 12.7127\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.6977 - mae: 13.9474 - val_loss: 251.5018 - val_mae: 12.6968\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.7842 - mae: 13.9278 - val_loss: 249.7410 - val_mae: 12.5850\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.3141 - mae: 13.8753 - val_loss: 251.0982 - val_mae: 12.6993\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.3627 - mae: 13.8975 - val_loss: 248.3297 - val_mae: 12.5012\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 313.9945 - mae: 13.7964 - val_loss: 248.7025 - val_mae: 12.5588\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 313.3580 - mae: 13.8246 - val_loss: 250.7075 - val_mae: 12.7013\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 313.3943 - mae: 13.8440 - val_loss: 247.5325 - val_mae: 12.4914\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.3159 - mae: 13.7716 - val_loss: 249.8647 - val_mae: 12.6678\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.0410 - mae: 13.8426 - val_loss: 246.2720 - val_mae: 12.4122\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.6242 - mae: 13.7290 - val_loss: 246.2989 - val_mae: 12.4264\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.4284 - mae: 13.7487 - val_loss: 245.3805 - val_mae: 12.3493\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 311.0685 - mae: 13.6905 - val_loss: 245.4365 - val_mae: 12.3752\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.1758 - mae: 13.7081 - val_loss: 241.6557 - val_mae: 12.2713\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 297.3351 - mae: 13.3533 - val_loss: 229.9367 - val_mae: 11.9186\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 291.0286 - mae: 13.1244 - val_loss: 228.5454 - val_mae: 11.8386\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 290.0322 - mae: 13.1034 - val_loss: 226.1952 - val_mae: 11.6629\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 289.6754 - mae: 13.0318 - val_loss: 226.6259 - val_mae: 11.7175\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 289.0714 - mae: 13.0233 - val_loss: 225.7681 - val_mae: 11.6461\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 288.8343 - mae: 13.0069 - val_loss: 227.3165 - val_mae: 11.7695\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 288.7906 - mae: 13.0522 - val_loss: 224.9906 - val_mae: 11.5815\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 288.5420 - mae: 12.9776 - val_loss: 226.3860 - val_mae: 11.7007\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 288.5213 - mae: 13.0170 - val_loss: 224.7342 - val_mae: 11.5641\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.8901 - mae: 12.9610 - val_loss: 224.7177 - val_mae: 11.5747\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.7928 - mae: 12.9472 - val_loss: 224.7163 - val_mae: 11.5848\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.6567 - mae: 12.9563 - val_loss: 225.2380 - val_mae: 11.6444\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.2892 - mae: 12.9572 - val_loss: 224.5944 - val_mae: 11.5862\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.1371 - mae: 12.8964 - val_loss: 227.7749 - val_mae: 11.8068\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.7189 - mae: 13.0383 - val_loss: 223.7837 - val_mae: 11.5063\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 286.7750 - mae: 12.8833 - val_loss: 225.5681 - val_mae: 11.6684\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.0497 - mae: 12.9465 - val_loss: 223.7831 - val_mae: 11.5177\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 286.6655 - mae: 12.8849 - val_loss: 224.1650 - val_mae: 11.5670\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 286.3239 - mae: 12.8820 - val_loss: 223.8456 - val_mae: 11.5409\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 286.1877 - mae: 12.8959 - val_loss: 223.1530 - val_mae: 11.4846\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 286.1557 - mae: 12.8755 - val_loss: 223.0843 - val_mae: 11.4749\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.8922 - mae: 12.8462 - val_loss: 223.3136 - val_mae: 11.5092\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.6772 - mae: 12.8550 - val_loss: 222.8923 - val_mae: 11.4646\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.8482 - mae: 12.8674 - val_loss: 222.7472 - val_mae: 11.4411\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 285.4967 - mae: 12.7876 - val_loss: 223.9684 - val_mae: 11.5581\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.3619 - mae: 12.8603 - val_loss: 222.8849 - val_mae: 11.4844\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.0522 - mae: 12.8297 - val_loss: 222.6273 - val_mae: 11.4482\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.9476 - mae: 12.7855 - val_loss: 223.9260 - val_mae: 11.5638\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 284.9889 - mae: 12.8754 - val_loss: 222.2066 - val_mae: 11.4183\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.0404 - mae: 12.8378 - val_loss: 222.0795 - val_mae: 11.3913\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.8939 - mae: 12.7532 - val_loss: 222.3014 - val_mae: 11.4433\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.6184 - mae: 12.8085 - val_loss: 222.2526 - val_mae: 11.4401\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 284.6244 - mae: 12.8214 - val_loss: 221.7694 - val_mae: 11.3948\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 284.7388 - mae: 12.7845 - val_loss: 221.7608 - val_mae: 11.3996\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 290.1710 - mae: 13.0580\n",
      "[(0, 24476.974609375, 74.0003433227539), (1, 306.1444396972656, 13.755215644836426), (2, 205.47911071777344, 10.50320053100586), (3, 290.1710205078125, 13.057953834533691)]\n"
     ]
    }
   ],
   "source": [
    "reshl = []\n",
    "for hl in [0, 1, 2, 3]:\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(\"hl\", hl))\n",
    "    model = build_model(hl, 25, 'sgd', 10**(-5))\n",
    "    #history = model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    #print(score[0], score[1])\n",
    "    #reshl.append((hl, history.history['loss'][-1], history.history['mae'][-1]))\n",
    "    reshl.append((hl, score[0], score[1]))\n",
    "print(reshl)\n",
    "with open('hl.pkl', 'wb') as fp:\n",
    "    pickle.dump(reshl, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5e96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 632.6570 - mae: 22.6622 - val_loss: 452.7329 - val_mae: 19.7959\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 531.4154 - mae: 20.6915 - val_loss: 432.5195 - val_mae: 19.0680\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 524.0264 - mae: 20.5535 - val_loss: 434.0421 - val_mae: 19.2370\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 518.9872 - mae: 20.3517 - val_loss: 433.3725 - val_mae: 19.2160\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 517.0610 - mae: 20.2915 - val_loss: 443.9304 - val_mae: 19.5493\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 515.7249 - mae: 20.2478 - val_loss: 434.6300 - val_mae: 19.2804\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 513.2603 - mae: 20.1950 - val_loss: 429.5931 - val_mae: 19.0748\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 512.0468 - mae: 20.1648 - val_loss: 430.2080 - val_mae: 19.1092\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 509.3084 - mae: 20.0960 - val_loss: 434.1740 - val_mae: 19.2120\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 508.3918 - mae: 20.0396 - val_loss: 425.6219 - val_mae: 18.9172\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 507.3546 - mae: 20.0290 - val_loss: 425.3917 - val_mae: 18.9267\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 505.3399 - mae: 19.9665 - val_loss: 428.5297 - val_mae: 19.0153\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 505.6389 - mae: 19.9885 - val_loss: 423.4316 - val_mae: 18.8469\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 502.1476 - mae: 19.8480 - val_loss: 423.0836 - val_mae: 18.8363\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 501.2680 - mae: 19.7922 - val_loss: 422.7441 - val_mae: 18.8317\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 500.3615 - mae: 19.7909 - val_loss: 424.2527 - val_mae: 18.8592\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 499.5983 - mae: 19.7540 - val_loss: 435.5503 - val_mae: 19.3495\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 499.9019 - mae: 19.7196 - val_loss: 420.6466 - val_mae: 18.7217\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 498.0076 - mae: 19.6794 - val_loss: 421.5793 - val_mae: 18.7444\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 498.2451 - mae: 19.6472 - val_loss: 419.4060 - val_mae: 18.6727\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 497.7952 - mae: 19.6630 - val_loss: 420.6589 - val_mae: 18.7063\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 497.2461 - mae: 19.6458 - val_loss: 418.4075 - val_mae: 18.6279\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 495.6491 - mae: 19.5630 - val_loss: 418.9762 - val_mae: 18.6326\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 495.1367 - mae: 19.5645 - val_loss: 417.8644 - val_mae: 18.5791\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 497.0668 - mae: 19.6178 - val_loss: 418.9177 - val_mae: 18.6310\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 493.9269 - mae: 19.4936 - val_loss: 415.5861 - val_mae: 18.4535\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 493.3466 - mae: 19.4617 - val_loss: 415.5856 - val_mae: 18.4562\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.1135 - mae: 19.4619 - val_loss: 420.2389 - val_mae: 18.7079\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.5959 - mae: 19.4506 - val_loss: 418.8988 - val_mae: 18.5683\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.6447 - mae: 19.4806 - val_loss: 415.0343 - val_mae: 18.4243\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 493.2045 - mae: 19.4463 - val_loss: 414.5687 - val_mae: 18.3977\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 492.5439 - mae: 19.4117 - val_loss: 414.4089 - val_mae: 18.3865\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.5409 - mae: 19.3832 - val_loss: 414.3744 - val_mae: 18.3820\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 493.7586 - mae: 19.4628 - val_loss: 414.7051 - val_mae: 18.3892\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.4382 - mae: 19.3813 - val_loss: 413.6126 - val_mae: 18.3335\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.4896 - mae: 19.3643 - val_loss: 414.2308 - val_mae: 18.3673\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 491.5381 - mae: 19.3642 - val_loss: 412.9289 - val_mae: 18.3015\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 490.9675 - mae: 19.3359 - val_loss: 413.4604 - val_mae: 18.3323\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 490.8322 - mae: 19.3376 - val_loss: 412.9875 - val_mae: 18.2971\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 491.1263 - mae: 19.3456 - val_loss: 413.0627 - val_mae: 18.2911\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.9037 - mae: 19.2754 - val_loss: 413.3209 - val_mae: 18.2982\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 490.1505 - mae: 19.3192 - val_loss: 412.8358 - val_mae: 18.2750\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 490.1443 - mae: 19.3112 - val_loss: 418.0064 - val_mae: 18.6049\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 490.3028 - mae: 19.3179 - val_loss: 412.7843 - val_mae: 18.3015\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.7578 - mae: 19.2826 - val_loss: 412.0311 - val_mae: 18.2381\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 489.6503 - mae: 19.2685 - val_loss: 412.0788 - val_mae: 18.2341\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.7807 - mae: 19.2646 - val_loss: 419.0181 - val_mae: 18.5279\n",
      "Epoch 47: early stopping\n",
      "4/4 [==============================] - 0s 998us/step - loss: 518.1640 - mae: 20.3049\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1397.4592 - mae: 28.3397 - val_loss: 559.3593 - val_mae: 21.1564\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 573.3183 - mae: 20.9414 - val_loss: 471.1091 - val_mae: 19.6819\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 534.4469 - mae: 20.3825 - val_loss: 444.1485 - val_mae: 19.2145\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 516.8597 - mae: 20.0833 - val_loss: 425.5541 - val_mae: 18.8201\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 501.4802 - mae: 19.7623 - val_loss: 410.6299 - val_mae: 18.4187\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 488.6914 - mae: 19.4219 - val_loss: 398.2291 - val_mae: 18.0149\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 478.1511 - mae: 19.1104 - val_loss: 388.5948 - val_mae: 17.7052\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 468.3881 - mae: 18.8159 - val_loss: 379.3538 - val_mae: 17.3800\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 460.6082 - mae: 18.5672 - val_loss: 372.7794 - val_mae: 17.1105\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 455.0697 - mae: 18.3854 - val_loss: 369.8236 - val_mae: 17.0108\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 450.2238 - mae: 18.2466 - val_loss: 367.0563 - val_mae: 16.9542\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 445.7236 - mae: 18.1322 - val_loss: 362.6202 - val_mae: 16.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 441.1282 - mae: 18.0127 - val_loss: 358.4454 - val_mae: 16.7352\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 436.9875 - mae: 17.9124 - val_loss: 354.2236 - val_mae: 16.6024\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 433.4079 - mae: 17.7917 - val_loss: 351.3596 - val_mae: 16.5438\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 430.3953 - mae: 17.7404 - val_loss: 347.8237 - val_mae: 16.4227\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 427.3741 - mae: 17.6467 - val_loss: 345.1505 - val_mae: 16.3211\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 425.5011 - mae: 17.5801 - val_loss: 342.6885 - val_mae: 16.2058\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 423.5131 - mae: 17.5033 - val_loss: 343.2849 - val_mae: 16.2308\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 422.2722 - mae: 17.4886 - val_loss: 340.8937 - val_mae: 16.1319\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 420.8619 - mae: 17.4139 - val_loss: 339.3473 - val_mae: 16.0639\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 420.0026 - mae: 17.3953 - val_loss: 338.8182 - val_mae: 16.0421\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 419.0851 - mae: 17.3450 - val_loss: 338.0049 - val_mae: 16.0114\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 418.5038 - mae: 17.3346 - val_loss: 337.7161 - val_mae: 16.0088\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 417.9357 - mae: 17.3195 - val_loss: 336.9362 - val_mae: 15.9672\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 417.5007 - mae: 17.2963 - val_loss: 336.6474 - val_mae: 15.9684\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 417.1992 - mae: 17.3013 - val_loss: 335.7963 - val_mae: 15.9119\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 416.8680 - mae: 17.2723 - val_loss: 336.2026 - val_mae: 15.9521\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 416.1180 - mae: 17.2477 - val_loss: 336.0839 - val_mae: 15.9575\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 415.8222 - mae: 17.2605 - val_loss: 334.9082 - val_mae: 15.8819\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 415.4616 - mae: 17.2191 - val_loss: 335.4096 - val_mae: 15.9322\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 415.2627 - mae: 17.2449 - val_loss: 334.0744 - val_mae: 15.8330\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 414.8987 - mae: 17.2093 - val_loss: 334.1318 - val_mae: 15.8481\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 414.2913 - mae: 17.1782 - val_loss: 334.9356 - val_mae: 15.9087\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 414.2140 - mae: 17.1966 - val_loss: 334.0563 - val_mae: 15.8593\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.7374 - mae: 17.1662 - val_loss: 334.8037 - val_mae: 15.9047\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.3064 - mae: 17.1645 - val_loss: 333.4035 - val_mae: 15.8313\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.2127 - mae: 17.1535 - val_loss: 333.1323 - val_mae: 15.8050\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 412.7864 - mae: 17.1369 - val_loss: 332.8936 - val_mae: 15.7887\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 412.3072 - mae: 17.1058 - val_loss: 332.6833 - val_mae: 15.7890\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 412.0445 - mae: 17.1148 - val_loss: 332.6976 - val_mae: 15.7827\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 411.5934 - mae: 17.1000 - val_loss: 332.3932 - val_mae: 15.7759\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 411.1250 - mae: 17.0812 - val_loss: 331.9765 - val_mae: 15.7638\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.4481 - mae: 17.0726 - val_loss: 331.2625 - val_mae: 15.7428\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 409.8140 - mae: 17.0415 - val_loss: 330.7173 - val_mae: 15.7068\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 409.2897 - mae: 17.0056 - val_loss: 330.8733 - val_mae: 15.7241\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.6568 - mae: 17.0020 - val_loss: 330.2615 - val_mae: 15.6935\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 408.2085 - mae: 16.9790 - val_loss: 329.8299 - val_mae: 15.6828\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 407.5137 - mae: 16.9673 - val_loss: 329.0572 - val_mae: 15.6527\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 406.4818 - mae: 16.9527 - val_loss: 327.8263 - val_mae: 15.6054\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 405.8476 - mae: 16.9166 - val_loss: 327.3197 - val_mae: 15.5919\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 404.6170 - mae: 16.8725 - val_loss: 327.2136 - val_mae: 15.6049\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 403.7844 - mae: 16.8405 - val_loss: 327.8260 - val_mae: 15.6377\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.9828 - mae: 16.8421 - val_loss: 325.5527 - val_mae: 15.4981\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.0332 - mae: 16.7728 - val_loss: 325.3933 - val_mae: 15.5027\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 401.5716 - mae: 16.7784 - val_loss: 324.9952 - val_mae: 15.4762\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 400.8927 - mae: 16.7307 - val_loss: 324.1346 - val_mae: 15.4311\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 400.4440 - mae: 16.7036 - val_loss: 324.6014 - val_mae: 15.4754\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.8686 - mae: 16.7168 - val_loss: 323.2061 - val_mae: 15.3574\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.4367 - mae: 16.6782 - val_loss: 322.4135 - val_mae: 15.3203\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.1104 - mae: 16.6363 - val_loss: 322.9887 - val_mae: 15.3693\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 398.7520 - mae: 16.6483 - val_loss: 323.1489 - val_mae: 15.3981\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 398.3191 - mae: 16.6271 - val_loss: 324.3459 - val_mae: 15.4961\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 398.1156 - mae: 16.6818 - val_loss: 321.4004 - val_mae: 15.2570\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 397.7912 - mae: 16.5661 - val_loss: 321.8582 - val_mae: 15.3294\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 397.5262 - mae: 16.5996 - val_loss: 321.4958 - val_mae: 15.3183\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 397.1627 - mae: 16.5699 - val_loss: 322.2906 - val_mae: 15.3736\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 397.0085 - mae: 16.6062 - val_loss: 321.1312 - val_mae: 15.2607\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 396.4881 - mae: 16.5675 - val_loss: 320.8314 - val_mae: 15.2517\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 396.1618 - mae: 16.5556 - val_loss: 320.1723 - val_mae: 15.2248\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 395.7787 - mae: 16.5315 - val_loss: 320.4460 - val_mae: 15.2660\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 395.2999 - mae: 16.5234 - val_loss: 319.8101 - val_mae: 15.2228\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 394.7291 - mae: 16.5155 - val_loss: 319.3920 - val_mae: 15.1892\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 394.6223 - mae: 16.5054 - val_loss: 319.9839 - val_mae: 15.2350\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 393.9406 - mae: 16.4859 - val_loss: 320.2309 - val_mae: 15.2682\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.5015 - mae: 16.5060 - val_loss: 318.2819 - val_mae: 15.1394\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 392.9580 - mae: 16.4099 - val_loss: 319.8663 - val_mae: 15.2634\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 393.0234 - mae: 16.4560 - val_loss: 319.4662 - val_mae: 15.2423\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 392.5963 - mae: 16.4469 - val_loss: 318.4307 - val_mae: 15.1855\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 392.1421 - mae: 16.4422 - val_loss: 317.4669 - val_mae: 15.1131\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 391.8712 - mae: 16.4065 - val_loss: 317.1154 - val_mae: 15.0919\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 391.5539 - mae: 16.3984 - val_loss: 316.8263 - val_mae: 15.0621\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 391.3824 - mae: 16.3791 - val_loss: 316.8619 - val_mae: 15.0674\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 391.0500 - mae: 16.3519 - val_loss: 317.5852 - val_mae: 15.1343\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 390.9723 - mae: 16.3800 - val_loss: 316.3216 - val_mae: 15.0457\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 390.6337 - mae: 16.3497 - val_loss: 316.3551 - val_mae: 15.0575\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 390.4635 - mae: 16.3400 - val_loss: 316.2147 - val_mae: 15.0452\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 390.3367 - mae: 16.3409 - val_loss: 316.0284 - val_mae: 15.0430\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 390.3717 - mae: 16.3444 - val_loss: 315.9025 - val_mae: 15.0295\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 390.0685 - mae: 16.3192 - val_loss: 316.0712 - val_mae: 15.0472\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.8072 - mae: 16.3185 - val_loss: 315.9898 - val_mae: 15.0402\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 389.5681 - mae: 16.3041 - val_loss: 315.5174 - val_mae: 15.0210\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.3490 - mae: 16.3043 - val_loss: 314.9140 - val_mae: 14.9664\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.0726 - mae: 16.3001 - val_loss: 314.5641 - val_mae: 14.9359\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 389.1356 - mae: 16.2651 - val_loss: 315.0670 - val_mae: 14.9808\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.8578 - mae: 16.2672 - val_loss: 314.7498 - val_mae: 14.9452\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.7903 - mae: 16.2635 - val_loss: 314.8292 - val_mae: 14.9714\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.4679 - mae: 16.2755 - val_loss: 314.4941 - val_mae: 14.9685\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.3399 - mae: 16.2523 - val_loss: 314.5176 - val_mae: 14.9687\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 388.0295 - mae: 16.2597 - val_loss: 314.6182 - val_mae: 14.9921\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 394.5849 - mae: 16.4854\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 18ms/step - loss: 1320.0343 - mae: 28.0617 - val_loss: 798.2573 - val_mae: 23.1130\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 714.2190 - mae: 22.0284 - val_loss: 515.0153 - val_mae: 19.2293\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 522.2048 - mae: 19.1615 - val_loss: 412.4109 - val_mae: 17.2946\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 452.0193 - mae: 17.7896 - val_loss: 371.2218 - val_mae: 16.3448\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 422.8509 - mae: 17.1210 - val_loss: 350.4323 - val_mae: 15.8232\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 407.8929 - mae: 16.7332 - val_loss: 338.5058 - val_mae: 15.5131\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 398.9643 - mae: 16.4916 - val_loss: 329.7845 - val_mae: 15.2722\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 392.3335 - mae: 16.3092 - val_loss: 323.1476 - val_mae: 15.0979\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 386.8694 - mae: 16.1744 - val_loss: 317.0071 - val_mae: 14.9480\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 382.0500 - mae: 16.0535 - val_loss: 312.4778 - val_mae: 14.8234\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 378.2473 - mae: 15.9524 - val_loss: 308.1642 - val_mae: 14.7175\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 374.4556 - mae: 15.8588 - val_loss: 304.0942 - val_mae: 14.6171\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 370.9683 - mae: 15.7784 - val_loss: 300.2911 - val_mae: 14.5106\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 367.6136 - mae: 15.6942 - val_loss: 296.4094 - val_mae: 14.3972\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 363.9910 - mae: 15.5912 - val_loss: 292.5764 - val_mae: 14.2908\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 360.4821 - mae: 15.5034 - val_loss: 288.9218 - val_mae: 14.1740\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 356.8843 - mae: 15.3922 - val_loss: 285.2441 - val_mae: 14.0564\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 353.0546 - mae: 15.2825 - val_loss: 281.3412 - val_mae: 13.9249\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 349.2912 - mae: 15.1674 - val_loss: 277.8436 - val_mae: 13.8069\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 345.8678 - mae: 15.0707 - val_loss: 275.1364 - val_mae: 13.7178\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 343.0536 - mae: 14.9929 - val_loss: 272.7247 - val_mae: 13.6437\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 340.4888 - mae: 14.9126 - val_loss: 270.5094 - val_mae: 13.5742\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 338.1782 - mae: 14.8473 - val_loss: 268.4748 - val_mae: 13.5033\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 335.9979 - mae: 14.7852 - val_loss: 266.2903 - val_mae: 13.4270\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.9924 - mae: 14.7205 - val_loss: 264.7067 - val_mae: 13.3687\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 332.2778 - mae: 14.6690 - val_loss: 263.0554 - val_mae: 13.3064\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 330.7019 - mae: 14.6192 - val_loss: 261.4575 - val_mae: 13.2428\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 329.3523 - mae: 14.5580 - val_loss: 260.1833 - val_mae: 13.1946\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 327.9419 - mae: 14.5273 - val_loss: 258.7908 - val_mae: 13.1389\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.6456 - mae: 14.4710 - val_loss: 257.7171 - val_mae: 13.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 325.5403 - mae: 14.4393 - val_loss: 256.4646 - val_mae: 13.0416\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 324.3683 - mae: 14.3784 - val_loss: 255.6017 - val_mae: 13.0136\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 323.1949 - mae: 14.3614 - val_loss: 254.3444 - val_mae: 12.9621\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.1323 - mae: 14.3200 - val_loss: 253.2861 - val_mae: 12.9204\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 321.0165 - mae: 14.2788 - val_loss: 252.3291 - val_mae: 12.8834\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 319.9998 - mae: 14.2517 - val_loss: 251.3571 - val_mae: 12.8404\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 319.0999 - mae: 14.2193 - val_loss: 250.5490 - val_mae: 12.8045\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 318.1942 - mae: 14.1840 - val_loss: 249.9331 - val_mae: 12.7829\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 317.3849 - mae: 14.1678 - val_loss: 249.2384 - val_mae: 12.7530\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 316.5623 - mae: 14.1400 - val_loss: 248.5286 - val_mae: 12.7205\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 315.8755 - mae: 14.1026 - val_loss: 247.9223 - val_mae: 12.6954\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 315.1146 - mae: 14.0861 - val_loss: 247.3005 - val_mae: 12.6664\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 314.4926 - mae: 14.0655 - val_loss: 246.7503 - val_mae: 12.6437\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 313.7949 - mae: 14.0446 - val_loss: 246.2491 - val_mae: 12.6218\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 313.1387 - mae: 14.0161 - val_loss: 245.7442 - val_mae: 12.6007\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 312.4451 - mae: 13.9994 - val_loss: 245.1747 - val_mae: 12.5789\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 311.7997 - mae: 13.9746 - val_loss: 244.6163 - val_mae: 12.5591\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 310.9445 - mae: 13.9663 - val_loss: 243.7593 - val_mae: 12.5227\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 309.8483 - mae: 13.9242 - val_loss: 242.9641 - val_mae: 12.5023\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 308.6035 - mae: 13.8905 - val_loss: 241.6072 - val_mae: 12.4613\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 307.1584 - mae: 13.8576 - val_loss: 239.9243 - val_mae: 12.4045\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 305.3469 - mae: 13.8035 - val_loss: 238.2755 - val_mae: 12.3358\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 303.6656 - mae: 13.7280 - val_loss: 237.2233 - val_mae: 12.2902\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 302.7042 - mae: 13.6946 - val_loss: 236.3839 - val_mae: 12.2514\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 301.9091 - mae: 13.6694 - val_loss: 235.7189 - val_mae: 12.2280\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 301.2067 - mae: 13.6409 - val_loss: 235.2620 - val_mae: 12.2143\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 300.6615 - mae: 13.6274 - val_loss: 234.7972 - val_mae: 12.1997\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 300.1024 - mae: 13.6193 - val_loss: 234.3919 - val_mae: 12.1863\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 299.6388 - mae: 13.6140 - val_loss: 233.8847 - val_mae: 12.1672\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 299.1187 - mae: 13.5895 - val_loss: 233.5826 - val_mae: 12.1587\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 298.7218 - mae: 13.5970 - val_loss: 233.0397 - val_mae: 12.1332\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 298.2467 - mae: 13.5619 - val_loss: 232.8251 - val_mae: 12.1300\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 297.7768 - mae: 13.5747 - val_loss: 232.3395 - val_mae: 12.1062\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 297.2865 - mae: 13.5323 - val_loss: 231.9440 - val_mae: 12.0924\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 296.8422 - mae: 13.5296 - val_loss: 231.4051 - val_mae: 12.0704\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 296.2935 - mae: 13.5131 - val_loss: 230.8219 - val_mae: 12.0459\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 295.6602 - mae: 13.4819 - val_loss: 230.3155 - val_mae: 12.0381\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 294.8492 - mae: 13.4654 - val_loss: 229.4308 - val_mae: 12.0077\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 293.8313 - mae: 13.4477 - val_loss: 228.2798 - val_mae: 11.9691\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 292.7611 - mae: 13.4025 - val_loss: 227.3404 - val_mae: 11.9382\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 291.8571 - mae: 13.3708 - val_loss: 226.7913 - val_mae: 11.9254\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 291.1628 - mae: 13.3745 - val_loss: 225.8753 - val_mae: 11.8789\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 290.5838 - mae: 13.3378 - val_loss: 225.4134 - val_mae: 11.8588\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 289.9784 - mae: 13.3308 - val_loss: 224.8290 - val_mae: 11.8294\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 289.4252 - mae: 13.2903 - val_loss: 224.3393 - val_mae: 11.8063\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 288.9431 - mae: 13.2725 - val_loss: 223.8653 - val_mae: 11.7840\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 288.4543 - mae: 13.2373 - val_loss: 223.4666 - val_mae: 11.7765\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.8065 - mae: 13.2441 - val_loss: 222.8095 - val_mae: 11.7528\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.1649 - mae: 13.2168 - val_loss: 222.2822 - val_mae: 11.7371\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 286.6134 - mae: 13.2214 - val_loss: 221.8584 - val_mae: 11.7222\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 286.0725 - mae: 13.1905 - val_loss: 221.3852 - val_mae: 11.7012\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 285.6988 - mae: 13.1700 - val_loss: 221.0407 - val_mae: 11.6884\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 285.2780 - mae: 13.1485 - val_loss: 220.7713 - val_mae: 11.6829\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 284.8761 - mae: 13.1514 - val_loss: 220.4511 - val_mae: 11.6724\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 284.5029 - mae: 13.1531 - val_loss: 220.0023 - val_mae: 11.6494\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.0484 - mae: 13.1210 - val_loss: 219.6551 - val_mae: 11.6408\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 283.4277 - mae: 13.0988 - val_loss: 218.9541 - val_mae: 11.6224\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 282.6433 - mae: 13.0796 - val_loss: 218.3690 - val_mae: 11.6122\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 281.9359 - mae: 13.0722 - val_loss: 217.7736 - val_mae: 11.5893\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 281.4203 - mae: 13.0638 - val_loss: 217.2983 - val_mae: 11.5746\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 280.8607 - mae: 13.0427 - val_loss: 216.8600 - val_mae: 11.5602\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 280.3401 - mae: 13.0299 - val_loss: 216.3154 - val_mae: 11.5373\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.8493 - mae: 13.0166 - val_loss: 215.7943 - val_mae: 11.5162\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.3628 - mae: 12.9859 - val_loss: 215.2906 - val_mae: 11.4992\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 278.7801 - mae: 12.9738 - val_loss: 214.8641 - val_mae: 11.4893\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 278.2498 - mae: 12.9550 - val_loss: 214.2880 - val_mae: 11.4643\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 277.6315 - mae: 12.9351 - val_loss: 213.8508 - val_mae: 11.4509\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 277.1409 - mae: 12.9317 - val_loss: 213.1843 - val_mae: 11.4222\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 276.5724 - mae: 12.9065 - val_loss: 212.5437 - val_mae: 11.3979\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 275.9259 - mae: 12.8795 - val_loss: 211.9418 - val_mae: 11.3777\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 280.0011 - mae: 13.0608\n",
      "[(5, 518.1640014648438, 20.30488395690918), (25, 394.5848693847656, 16.485429763793945), (125, 280.0011291503906, 13.06084156036377)]\n"
     ]
    }
   ],
   "source": [
    "resnn = []\n",
    "for nn in [5, 25, 125]:\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(\"nn\", nn))\n",
    "    model = build_model(1, nn, 'sgd', 10**(-5))\n",
    "    model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    resnn.append((nn, score[0], score[1]))\n",
    "print(resnn)\n",
    "with open('nn.pkl', 'wb') as fp:\n",
    "    pickle.dump(resnn, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76baac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2565.4333 - mae: 34.2976 - val_loss: 490.3812 - val_mae: 18.5628\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 497.6620 - mae: 18.6420 - val_loss: 391.8802 - val_mae: 16.8327\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 448.3875 - mae: 17.7866 - val_loss: 355.0204 - val_mae: 16.1663\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 421.6247 - mae: 17.3019 - val_loss: 329.0876 - val_mae: 15.6220\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 402.9775 - mae: 16.9124 - val_loss: 313.6033 - val_mae: 15.2019\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 391.4340 - mae: 16.6348 - val_loss: 304.0014 - val_mae: 14.9015\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 384.1044 - mae: 16.4209 - val_loss: 298.1527 - val_mae: 14.7032\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 379.0884 - mae: 16.2709 - val_loss: 295.0985 - val_mae: 14.6184\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 375.6971 - mae: 16.2102 - val_loss: 291.8731 - val_mae: 14.4802\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 372.8019 - mae: 16.0971 - val_loss: 290.0328 - val_mae: 14.4574\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 370.9142 - mae: 16.0574 - val_loss: 288.9674 - val_mae: 14.3875\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 369.3530 - mae: 16.0117 - val_loss: 288.0209 - val_mae: 14.3443\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 368.1226 - mae: 15.9648 - val_loss: 287.2094 - val_mae: 14.3220\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 366.8875 - mae: 15.9429 - val_loss: 286.3219 - val_mae: 14.2812\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 366.1678 - mae: 15.9071 - val_loss: 286.3638 - val_mae: 14.3213\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 364.6904 - mae: 15.8870 - val_loss: 284.8653 - val_mae: 14.2353\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 361.6920 - mae: 15.7897 - val_loss: 282.0696 - val_mae: 14.1070\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 353.4373 - mae: 15.5737 - val_loss: 277.1989 - val_mae: 13.9677\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 349.7472 - mae: 15.4556 - val_loss: 274.4788 - val_mae: 13.8923\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 347.6469 - mae: 15.3927 - val_loss: 272.9913 - val_mae: 13.8487\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 345.8777 - mae: 15.3448 - val_loss: 271.0752 - val_mae: 13.7805\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 344.7140 - mae: 15.2945 - val_loss: 269.7520 - val_mae: 13.7211\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 343.5489 - mae: 15.2297 - val_loss: 269.3701 - val_mae: 13.7497\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 342.4478 - mae: 15.2439 - val_loss: 267.8984 - val_mae: 13.6624\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 341.8553 - mae: 15.1658 - val_loss: 267.2996 - val_mae: 13.6625\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 341.2186 - mae: 15.1752 - val_loss: 267.2235 - val_mae: 13.6637\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 340.7879 - mae: 15.1708 - val_loss: 266.1567 - val_mae: 13.5926\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 340.2325 - mae: 15.1306 - val_loss: 266.5786 - val_mae: 13.6120\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 339.5175 - mae: 15.1071 - val_loss: 265.2592 - val_mae: 13.5686\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 339.3203 - mae: 15.1107 - val_loss: 265.1153 - val_mae: 13.5355\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 338.5672 - mae: 15.0708 - val_loss: 264.7981 - val_mae: 13.5390\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 338.2787 - mae: 15.0758 - val_loss: 264.2924 - val_mae: 13.5179\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 337.7234 - mae: 15.0333 - val_loss: 264.6815 - val_mae: 13.5556\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 337.3591 - mae: 15.0248 - val_loss: 264.3932 - val_mae: 13.5540\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 336.8831 - mae: 15.0268 - val_loss: 264.3373 - val_mae: 13.5349\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 336.3198 - mae: 14.9996 - val_loss: 263.8406 - val_mae: 13.5039\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 335.8631 - mae: 14.9678 - val_loss: 263.5129 - val_mae: 13.5167\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 335.1612 - mae: 14.9847 - val_loss: 263.5306 - val_mae: 13.4803\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 334.9957 - mae: 14.9434 - val_loss: 262.2180 - val_mae: 13.4371\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 334.3768 - mae: 14.9254 - val_loss: 261.4027 - val_mae: 13.4104\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.9675 - mae: 14.8927 - val_loss: 263.5189 - val_mae: 13.5218\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 333.4581 - mae: 14.9227 - val_loss: 261.8327 - val_mae: 13.4508\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 332.8704 - mae: 14.8854 - val_loss: 261.0811 - val_mae: 13.3963\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 332.0423 - mae: 14.8346 - val_loss: 260.8510 - val_mae: 13.3661\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 331.4030 - mae: 14.8001 - val_loss: 260.2188 - val_mae: 13.3334\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 330.9915 - mae: 14.7977 - val_loss: 260.2486 - val_mae: 13.3399\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 330.2995 - mae: 14.7571 - val_loss: 258.9701 - val_mae: 13.2966\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 329.8585 - mae: 14.7599 - val_loss: 258.6625 - val_mae: 13.2822\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 329.4105 - mae: 14.7348 - val_loss: 258.4243 - val_mae: 13.2841\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 329.0316 - mae: 14.7280 - val_loss: 258.2087 - val_mae: 13.2676\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 328.5082 - mae: 14.6814 - val_loss: 259.4637 - val_mae: 13.3512\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 328.3180 - mae: 14.7171 - val_loss: 258.8338 - val_mae: 13.2803\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 328.2095 - mae: 14.6702 - val_loss: 258.7912 - val_mae: 13.3069\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 327.5151 - mae: 14.6857 - val_loss: 258.1318 - val_mae: 13.2426\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 327.3002 - mae: 14.6376 - val_loss: 256.5512 - val_mae: 13.1893\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.8994 - mae: 14.6349 - val_loss: 257.7811 - val_mae: 13.2780\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.6925 - mae: 14.6540 - val_loss: 255.8048 - val_mae: 13.1605\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.0567 - mae: 14.5901 - val_loss: 256.3174 - val_mae: 13.1932\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 325.8510 - mae: 14.5880 - val_loss: 257.0646 - val_mae: 13.2573\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 325.7824 - mae: 14.6051 - val_loss: 257.3115 - val_mae: 13.2494\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 325.5276 - mae: 14.5840 - val_loss: 258.6978 - val_mae: 13.3526\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 325.1084 - mae: 14.6113 - val_loss: 255.2417 - val_mae: 13.1321\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 324.6341 - mae: 14.5430 - val_loss: 254.3789 - val_mae: 13.1132\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 324.5744 - mae: 14.5472 - val_loss: 254.6349 - val_mae: 13.1160\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 323.7945 - mae: 14.5068 - val_loss: 253.9652 - val_mae: 13.0806\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 322.7939 - mae: 14.4508 - val_loss: 255.1608 - val_mae: 13.1618\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 322.5661 - mae: 14.4897 - val_loss: 254.1041 - val_mae: 13.0808\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.9455 - mae: 14.4563 - val_loss: 253.3126 - val_mae: 13.0481\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 321.7068 - mae: 14.4327 - val_loss: 253.4754 - val_mae: 13.0521\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.0443 - mae: 14.4169 - val_loss: 252.3300 - val_mae: 12.9945\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 320.4968 - mae: 14.3861 - val_loss: 252.1196 - val_mae: 12.9841\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 320.0720 - mae: 14.3888 - val_loss: 252.2985 - val_mae: 12.9885\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 319.6148 - mae: 14.3428 - val_loss: 252.4507 - val_mae: 13.0134\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 319.2948 - mae: 14.3587 - val_loss: 251.4783 - val_mae: 12.9631\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 318.6442 - mae: 14.3396 - val_loss: 251.5773 - val_mae: 12.9695\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 318.4100 - mae: 14.2798 - val_loss: 251.5246 - val_mae: 12.9767\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.9640 - mae: 14.3072 - val_loss: 250.5730 - val_mae: 12.9223\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 317.8214 - mae: 14.2900 - val_loss: 250.2630 - val_mae: 12.9052\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.4350 - mae: 14.2797 - val_loss: 250.2891 - val_mae: 12.9102\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 317.3648 - mae: 14.2680 - val_loss: 250.2576 - val_mae: 12.9128\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.1362 - mae: 14.2299 - val_loss: 249.1974 - val_mae: 12.8464\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 316.4777 - mae: 14.2298 - val_loss: 250.3984 - val_mae: 12.9193\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 316.5407 - mae: 14.2407 - val_loss: 249.3390 - val_mae: 12.8439\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 316.1777 - mae: 14.1986 - val_loss: 249.2889 - val_mae: 12.8641\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.7413 - mae: 14.1901 - val_loss: 250.5280 - val_mae: 12.9299\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.6703 - mae: 14.2420 - val_loss: 249.6330 - val_mae: 12.8617\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 315.4375 - mae: 14.1934 - val_loss: 249.9151 - val_mae: 12.8944\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 315.2965 - mae: 14.2073 - val_loss: 248.4214 - val_mae: 12.8073\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 314.6051 - mae: 14.1859 - val_loss: 248.6335 - val_mae: 12.8193\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 314.4065 - mae: 14.1102 - val_loss: 250.1103 - val_mae: 12.9322\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.4876 - mae: 14.1879 - val_loss: 248.5044 - val_mae: 12.8654\n",
      "Epoch 91: early stopping\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 318.4300 - mae: 14.3518\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 17ms/step - loss: 1564.3428 - mae: 28.0723 - val_loss: 532.2753 - val_mae: 20.9065\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 575.6218 - mae: 21.3159 - val_loss: 478.8408 - val_mae: 20.1421\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 551.3477 - mae: 20.9347 - val_loss: 462.3895 - val_mae: 19.8807\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 540.6953 - mae: 20.7632 - val_loss: 452.1294 - val_mae: 19.6692\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 533.5319 - mae: 20.6202 - val_loss: 445.9034 - val_mae: 19.5084\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 528.1111 - mae: 20.4971 - val_loss: 442.9031 - val_mae: 19.3639\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 524.0775 - mae: 20.3723 - val_loss: 439.4535 - val_mae: 19.2748\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 518.6346 - mae: 20.2403 - val_loss: 434.7908 - val_mae: 19.1634\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 513.7338 - mae: 20.1070 - val_loss: 430.3531 - val_mae: 19.0469\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 510.2471 - mae: 20.0131 - val_loss: 426.7762 - val_mae: 18.9293\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 507.4153 - mae: 19.9265 - val_loss: 424.7532 - val_mae: 18.8641\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 505.4780 - mae: 19.8688 - val_loss: 422.8971 - val_mae: 18.7934\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 503.8640 - mae: 19.8192 - val_loss: 421.4845 - val_mae: 18.7316\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 502.8360 - mae: 19.7859 - val_loss: 420.2183 - val_mae: 18.6717\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 501.9265 - mae: 19.7643 - val_loss: 418.4067 - val_mae: 18.6219\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 499.9950 - mae: 19.7135 - val_loss: 416.2848 - val_mae: 18.5545\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 497.5718 - mae: 19.6582 - val_loss: 412.5739 - val_mae: 18.4244\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 494.4113 - mae: 19.5496 - val_loss: 409.3514 - val_mae: 18.3168\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 491.8174 - mae: 19.4691 - val_loss: 407.0509 - val_mae: 18.2310\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 489.6803 - mae: 19.3964 - val_loss: 405.3585 - val_mae: 18.1671\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 487.6740 - mae: 19.3443 - val_loss: 404.2250 - val_mae: 18.1344\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 486.4159 - mae: 19.3073 - val_loss: 403.8900 - val_mae: 18.1328\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 484.8484 - mae: 19.2741 - val_loss: 402.7519 - val_mae: 18.0961\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 483.2423 - mae: 19.2253 - val_loss: 401.2659 - val_mae: 18.0681\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 480.9846 - mae: 19.1649 - val_loss: 399.8402 - val_mae: 18.0264\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 478.7646 - mae: 19.1060 - val_loss: 397.2081 - val_mae: 17.9360\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 476.5701 - mae: 19.0342 - val_loss: 393.2147 - val_mae: 17.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 473.9351 - mae: 18.9482 - val_loss: 391.0317 - val_mae: 17.7481\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 472.5178 - mae: 18.9222 - val_loss: 390.3972 - val_mae: 17.7139\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 472.0071 - mae: 18.9039 - val_loss: 390.4291 - val_mae: 17.7192\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 471.3438 - mae: 18.8946 - val_loss: 390.1310 - val_mae: 17.7145\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 470.8359 - mae: 18.8810 - val_loss: 389.6198 - val_mae: 17.6956\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 470.3412 - mae: 18.8419 - val_loss: 389.8377 - val_mae: 17.6905\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 469.8946 - mae: 18.8440 - val_loss: 389.3029 - val_mae: 17.6667\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 469.4478 - mae: 18.8245 - val_loss: 388.6101 - val_mae: 17.6367\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 469.1111 - mae: 18.7998 - val_loss: 388.9776 - val_mae: 17.6407\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 468.7432 - mae: 18.8009 - val_loss: 388.6201 - val_mae: 17.6169\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 468.4798 - mae: 18.7782 - val_loss: 388.4301 - val_mae: 17.6070\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 468.1843 - mae: 18.7686 - val_loss: 387.9795 - val_mae: 17.5844\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 467.8348 - mae: 18.7608 - val_loss: 387.6738 - val_mae: 17.5789\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 467.7609 - mae: 18.7493 - val_loss: 387.5305 - val_mae: 17.5698\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.4706 - mae: 18.7250 - val_loss: 387.8167 - val_mae: 17.5733\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.3585 - mae: 18.7360 - val_loss: 387.3630 - val_mae: 17.5692\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.1349 - mae: 18.7126 - val_loss: 387.1630 - val_mae: 17.5603\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 467.0295 - mae: 18.7102 - val_loss: 387.4099 - val_mae: 17.5577\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.8631 - mae: 18.7108 - val_loss: 387.1500 - val_mae: 17.5427\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 466.6822 - mae: 18.7073 - val_loss: 386.5809 - val_mae: 17.5210\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.4566 - mae: 18.6889 - val_loss: 386.3611 - val_mae: 17.5121\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.4042 - mae: 18.6900 - val_loss: 386.6894 - val_mae: 17.5285\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 466.2824 - mae: 18.6815 - val_loss: 386.5049 - val_mae: 17.5116\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.1275 - mae: 18.6692 - val_loss: 387.3154 - val_mae: 17.5428\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.9894 - mae: 18.6916 - val_loss: 386.5771 - val_mae: 17.5151\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 465.9255 - mae: 18.6727 - val_loss: 386.4314 - val_mae: 17.5167\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 465.8224 - mae: 18.6513 - val_loss: 385.8797 - val_mae: 17.4818\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 465.6490 - mae: 18.6482 - val_loss: 386.1121 - val_mae: 17.4913\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.4686 - mae: 18.6576 - val_loss: 385.8127 - val_mae: 17.4815\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.4919 - mae: 18.6419 - val_loss: 385.9759 - val_mae: 17.4939\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.3988 - mae: 18.6441 - val_loss: 385.5248 - val_mae: 17.4717\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 481.2220 - mae: 19.0947\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2628.7690 - mae: 33.1078 - val_loss: 336.6229 - val_mae: 15.8286\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 380.8676 - mae: 16.4192 - val_loss: 290.0948 - val_mae: 14.5752\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 358.0652 - mae: 15.7940 - val_loss: 272.1270 - val_mae: 14.0217\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 345.9989 - mae: 15.3968 - val_loss: 262.3474 - val_mae: 13.6477\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 338.1930 - mae: 15.1570 - val_loss: 255.4263 - val_mae: 13.3628\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.1571 - mae: 14.9676 - val_loss: 251.1725 - val_mae: 13.1546\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 329.6102 - mae: 14.8458 - val_loss: 248.5488 - val_mae: 13.0295\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 326.4330 - mae: 14.7158 - val_loss: 246.7766 - val_mae: 12.9566\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 324.0908 - mae: 14.6850 - val_loss: 244.2456 - val_mae: 12.8600\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 321.2665 - mae: 14.5971 - val_loss: 241.8945 - val_mae: 12.7463\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 317.2130 - mae: 14.4656 - val_loss: 236.3353 - val_mae: 12.6227\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 310.1999 - mae: 14.2814 - val_loss: 229.0803 - val_mae: 12.3326\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 305.9157 - mae: 14.1167 - val_loss: 226.5152 - val_mae: 12.2355\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.1563 - mae: 14.1064 - val_loss: 224.8291 - val_mae: 12.1472\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 303.0625 - mae: 14.0546 - val_loss: 224.0508 - val_mae: 12.1186\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 302.3069 - mae: 14.0275 - val_loss: 223.3497 - val_mae: 12.0993\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 301.8383 - mae: 14.0046 - val_loss: 222.8565 - val_mae: 12.0855\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 300.8918 - mae: 13.9715 - val_loss: 222.8264 - val_mae: 12.0780\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 299.8599 - mae: 13.9701 - val_loss: 221.9553 - val_mae: 12.0572\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 299.3562 - mae: 13.9347 - val_loss: 222.8233 - val_mae: 12.0886\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 298.4145 - mae: 13.9385 - val_loss: 220.7760 - val_mae: 12.0054\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 297.5885 - mae: 13.8500 - val_loss: 221.3876 - val_mae: 12.0247\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 297.3667 - mae: 13.8664 - val_loss: 221.7786 - val_mae: 12.0512\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 296.5381 - mae: 13.8573 - val_loss: 219.9458 - val_mae: 11.9701\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 295.9000 - mae: 13.8293 - val_loss: 219.0650 - val_mae: 11.9428\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 294.9977 - mae: 13.7798 - val_loss: 219.1691 - val_mae: 11.9451\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 294.7509 - mae: 13.7747 - val_loss: 218.3565 - val_mae: 11.9246\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 294.0052 - mae: 13.7534 - val_loss: 217.5325 - val_mae: 11.8727\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 293.2981 - mae: 13.7179 - val_loss: 217.2652 - val_mae: 11.8670\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 292.6183 - mae: 13.6939 - val_loss: 216.7883 - val_mae: 11.8483\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 292.0332 - mae: 13.6873 - val_loss: 216.1253 - val_mae: 11.8477\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 290.9786 - mae: 13.6573 - val_loss: 216.0317 - val_mae: 11.8310\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 290.1066 - mae: 13.6151 - val_loss: 216.0665 - val_mae: 11.8460\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 288.8936 - mae: 13.5964 - val_loss: 216.0667 - val_mae: 11.8434\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 287.7652 - mae: 13.5878 - val_loss: 214.3555 - val_mae: 11.7626\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 287.1974 - mae: 13.4904 - val_loss: 213.9169 - val_mae: 11.7374\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 286.1664 - mae: 13.4812 - val_loss: 213.5654 - val_mae: 11.7278\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 284.8875 - mae: 13.4341 - val_loss: 216.7142 - val_mae: 11.8686\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 284.8944 - mae: 13.4655 - val_loss: 211.8089 - val_mae: 11.6303\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 283.3493 - mae: 13.3619 - val_loss: 211.6614 - val_mae: 11.6298\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 282.8193 - mae: 13.3700 - val_loss: 210.0689 - val_mae: 11.5514\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 282.4339 - mae: 13.3312 - val_loss: 210.8289 - val_mae: 11.5796\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 281.4868 - mae: 13.3182 - val_loss: 209.9919 - val_mae: 11.5388\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 280.6952 - mae: 13.3087 - val_loss: 209.3181 - val_mae: 11.5101\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 280.4468 - mae: 13.2348 - val_loss: 208.2326 - val_mae: 11.4697\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 279.6637 - mae: 13.2100 - val_loss: 208.0130 - val_mae: 11.4646\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 279.4805 - mae: 13.2333 - val_loss: 208.4044 - val_mae: 11.4827\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 278.5203 - mae: 13.2168 - val_loss: 206.8893 - val_mae: 11.4143\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 278.0602 - mae: 13.1602 - val_loss: 207.1048 - val_mae: 11.4334\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 277.6552 - mae: 13.1768 - val_loss: 206.5703 - val_mae: 11.4068\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 277.3734 - mae: 13.1440 - val_loss: 206.6488 - val_mae: 11.4132\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 276.8075 - mae: 13.1466 - val_loss: 205.5964 - val_mae: 11.3605\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 276.1748 - mae: 13.1131 - val_loss: 205.3263 - val_mae: 11.3487\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 275.8369 - mae: 13.0881 - val_loss: 204.6440 - val_mae: 11.3136\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 275.2349 - mae: 13.0676 - val_loss: 206.1013 - val_mae: 11.3926\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 275.1546 - mae: 13.0711 - val_loss: 206.1680 - val_mae: 11.3995\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 274.8755 - mae: 13.1112 - val_loss: 204.0090 - val_mae: 11.2960\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 273.9482 - mae: 13.0127 - val_loss: 203.6771 - val_mae: 11.2701\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 273.3626 - mae: 13.0007 - val_loss: 204.0480 - val_mae: 11.3104\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 273.1517 - mae: 13.0130 - val_loss: 204.1895 - val_mae: 11.3177\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 272.6913 - mae: 13.0046 - val_loss: 203.4978 - val_mae: 11.2814\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 271.8844 - mae: 12.9728 - val_loss: 203.1504 - val_mae: 11.2829\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 271.5961 - mae: 12.9134 - val_loss: 202.4059 - val_mae: 11.2248\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 271.1692 - mae: 12.9151 - val_loss: 204.1402 - val_mae: 11.3221\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 270.9709 - mae: 12.9483 - val_loss: 201.7084 - val_mae: 11.1857\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 270.2140 - mae: 12.8929 - val_loss: 201.9923 - val_mae: 11.2151\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 269.9694 - mae: 12.9111 - val_loss: 201.3991 - val_mae: 11.1871\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 269.1462 - mae: 12.8652 - val_loss: 200.7542 - val_mae: 11.1619\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 268.4261 - mae: 12.8394 - val_loss: 200.6055 - val_mae: 11.1683\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 267.9096 - mae: 12.8083 - val_loss: 200.5549 - val_mae: 11.1641\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 266.8834 - mae: 12.8057 - val_loss: 198.9953 - val_mae: 11.0763\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 266.3912 - mae: 12.7745 - val_loss: 198.8335 - val_mae: 11.0669\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 265.6687 - mae: 12.7292 - val_loss: 199.6700 - val_mae: 11.1310\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 265.0455 - mae: 12.7694 - val_loss: 198.2775 - val_mae: 11.0420\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 264.7227 - mae: 12.6810 - val_loss: 197.5602 - val_mae: 10.9982\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 264.0632 - mae: 12.6497 - val_loss: 197.2965 - val_mae: 10.9717\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 263.3935 - mae: 12.6751 - val_loss: 196.7545 - val_mae: 10.9586\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 263.5459 - mae: 12.6268 - val_loss: 196.8539 - val_mae: 10.9621\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 262.7689 - mae: 12.6288 - val_loss: 196.4610 - val_mae: 10.9690\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 262.2271 - mae: 12.5895 - val_loss: 196.1970 - val_mae: 10.9308\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 261.9359 - mae: 12.5882 - val_loss: 195.7735 - val_mae: 10.9203\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 261.7328 - mae: 12.5705 - val_loss: 195.4643 - val_mae: 10.9057\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 261.0774 - mae: 12.5382 - val_loss: 195.2415 - val_mae: 10.8857\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 260.6129 - mae: 12.5440 - val_loss: 194.9286 - val_mae: 10.8690\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 260.5882 - mae: 12.5227 - val_loss: 194.6681 - val_mae: 10.8526\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 260.0930 - mae: 12.4664 - val_loss: 194.3685 - val_mae: 10.8364\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 259.8190 - mae: 12.4740 - val_loss: 194.6852 - val_mae: 10.8675\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 259.5334 - mae: 12.5020 - val_loss: 194.3285 - val_mae: 10.8485\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 259.3886 - mae: 12.4489 - val_loss: 193.9249 - val_mae: 10.8049\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 258.8093 - mae: 12.4528 - val_loss: 193.1811 - val_mae: 10.7633\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 258.4299 - mae: 12.4378 - val_loss: 193.3482 - val_mae: 10.7946\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 258.9101 - mae: 12.4343 - val_loss: 192.4156 - val_mae: 10.7201\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 257.9218 - mae: 12.3947 - val_loss: 192.9599 - val_mae: 10.7712\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 257.9092 - mae: 12.3774 - val_loss: 192.6245 - val_mae: 10.7472\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 257.3168 - mae: 12.3917 - val_loss: 192.5401 - val_mae: 10.7531\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 257.1278 - mae: 12.3671 - val_loss: 192.2426 - val_mae: 10.7302\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 256.9705 - mae: 12.3488 - val_loss: 192.5500 - val_mae: 10.7577\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 256.7719 - mae: 12.3269 - val_loss: 192.1189 - val_mae: 10.7423\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 256.5591 - mae: 12.3551 - val_loss: 191.3213 - val_mae: 10.6834\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 255.8981 - mae: 12.3331 - val_loss: 192.6137 - val_mae: 10.7727\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 261.6187 - mae: 12.6152\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 5975.8999 - mae: 51.4001 - val_loss: 5674.4106 - val_mae: 50.1967\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5967.1631 - mae: 51.3559 - val_loss: 5666.0601 - val_mae: 50.1534\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5958.5356 - mae: 51.3127 - val_loss: 5657.7329 - val_mae: 50.1101\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5949.8257 - mae: 51.2689 - val_loss: 5649.4507 - val_mae: 50.0670\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5941.1045 - mae: 51.2255 - val_loss: 5641.2266 - val_mae: 50.0241\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5932.4653 - mae: 51.1818 - val_loss: 5632.8838 - val_mae: 49.9806\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5923.7622 - mae: 51.1384 - val_loss: 5624.6387 - val_mae: 49.9376\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5915.1279 - mae: 51.0949 - val_loss: 5616.3359 - val_mae: 49.8941\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5906.4131 - mae: 51.0513 - val_loss: 5608.0776 - val_mae: 49.8507\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5897.8208 - mae: 51.0078 - val_loss: 5599.7051 - val_mae: 49.8068\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5889.0405 - mae: 50.9642 - val_loss: 5591.3911 - val_mae: 49.7631\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5880.3613 - mae: 50.9207 - val_loss: 5583.1553 - val_mae: 49.7199\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5871.7891 - mae: 50.8780 - val_loss: 5575.0181 - val_mae: 49.6771\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5863.3369 - mae: 50.8354 - val_loss: 5566.8491 - val_mae: 49.6344\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5854.8154 - mae: 50.7928 - val_loss: 5558.6499 - val_mae: 49.5914\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5846.2568 - mae: 50.7498 - val_loss: 5550.5977 - val_mae: 49.5492\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5837.7764 - mae: 50.7073 - val_loss: 5542.4565 - val_mae: 49.5067\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5829.2832 - mae: 50.6645 - val_loss: 5534.3672 - val_mae: 49.4643\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5820.6924 - mae: 50.6217 - val_loss: 5526.2935 - val_mae: 49.4219\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5812.2808 - mae: 50.5789 - val_loss: 5518.1538 - val_mae: 49.3792\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5803.7739 - mae: 50.5361 - val_loss: 5510.1235 - val_mae: 49.3369\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5795.3809 - mae: 50.4937 - val_loss: 5502.1240 - val_mae: 49.2947\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5787.0464 - mae: 50.4513 - val_loss: 5494.0200 - val_mae: 49.2521\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5778.5649 - mae: 50.4088 - val_loss: 5486.0493 - val_mae: 49.2101\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5770.2554 - mae: 50.3669 - val_loss: 5478.0518 - val_mae: 49.1682\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5761.9468 - mae: 50.3247 - val_loss: 5470.0078 - val_mae: 49.1258\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5753.4443 - mae: 50.2822 - val_loss: 5462.1309 - val_mae: 49.0841\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5745.1860 - mae: 50.2404 - val_loss: 5454.1484 - val_mae: 49.0420\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5736.7983 - mae: 50.1981 - val_loss: 5446.2026 - val_mae: 49.0001\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5728.4897 - mae: 50.1561 - val_loss: 5438.1934 - val_mae: 48.9579\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5720.0156 - mae: 50.1137 - val_loss: 5430.2856 - val_mae: 48.9163\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5711.8091 - mae: 50.0718 - val_loss: 5422.1519 - val_mae: 48.8735\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5703.3340 - mae: 50.0291 - val_loss: 5414.2725 - val_mae: 48.8320\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5695.0542 - mae: 49.9873 - val_loss: 5406.3262 - val_mae: 48.7903\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5686.8008 - mae: 49.9455 - val_loss: 5398.4512 - val_mae: 48.7490\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5678.5649 - mae: 49.9039 - val_loss: 5390.6226 - val_mae: 48.7078\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5670.3511 - mae: 49.8622 - val_loss: 5382.7725 - val_mae: 48.6668\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5662.1929 - mae: 49.8208 - val_loss: 5374.9199 - val_mae: 48.6254\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5653.9233 - mae: 49.7794 - val_loss: 5367.1650 - val_mae: 48.5848\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5645.7964 - mae: 49.7385 - val_loss: 5359.4868 - val_mae: 48.5443\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5637.7173 - mae: 49.6977 - val_loss: 5351.7266 - val_mae: 48.5036\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5629.5483 - mae: 49.6565 - val_loss: 5343.8618 - val_mae: 48.4623\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5621.3833 - mae: 49.6153 - val_loss: 5336.0220 - val_mae: 48.4210\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5613.1616 - mae: 49.5740 - val_loss: 5328.3379 - val_mae: 48.3804\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 5605.0835 - mae: 49.5332 - val_loss: 5320.6665 - val_mae: 48.3399\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5597.0400 - mae: 49.4926 - val_loss: 5313.0220 - val_mae: 48.2995\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5589.1074 - mae: 49.4522 - val_loss: 5305.3428 - val_mae: 48.2590\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5581.1367 - mae: 49.4117 - val_loss: 5297.6260 - val_mae: 48.2183\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5572.9771 - mae: 49.3708 - val_loss: 5290.0225 - val_mae: 48.1783\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5564.9634 - mae: 49.3302 - val_loss: 5282.2842 - val_mae: 48.1378\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5556.8638 - mae: 49.2893 - val_loss: 5274.6333 - val_mae: 48.0974\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5548.8252 - mae: 49.2485 - val_loss: 5266.9966 - val_mae: 48.0572\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5540.8398 - mae: 49.2080 - val_loss: 5259.2715 - val_mae: 48.0164\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5532.8125 - mae: 49.1670 - val_loss: 5251.6260 - val_mae: 47.9762\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5524.7695 - mae: 49.1263 - val_loss: 5244.1191 - val_mae: 47.9365\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5516.9292 - mae: 49.0863 - val_loss: 5236.5503 - val_mae: 47.8965\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5508.9351 - mae: 49.0458 - val_loss: 5228.9819 - val_mae: 47.8565\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5501.0342 - mae: 49.0055 - val_loss: 5221.4077 - val_mae: 47.8164\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5493.1167 - mae: 48.9652 - val_loss: 5213.9048 - val_mae: 47.7767\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5485.2109 - mae: 48.9251 - val_loss: 5206.3354 - val_mae: 47.7366\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5477.3057 - mae: 48.8850 - val_loss: 5198.8281 - val_mae: 47.6968\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5469.4233 - mae: 48.8448 - val_loss: 5191.2310 - val_mae: 47.6565\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5461.4946 - mae: 48.8043 - val_loss: 5183.6772 - val_mae: 47.6164\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5453.5669 - mae: 48.7643 - val_loss: 5176.2041 - val_mae: 47.5766\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5445.7378 - mae: 48.7244 - val_loss: 5168.7637 - val_mae: 47.5366\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5437.9102 - mae: 48.6845 - val_loss: 5161.3105 - val_mae: 47.4967\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5430.1562 - mae: 48.6447 - val_loss: 5153.7524 - val_mae: 47.4562\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5422.2461 - mae: 48.6048 - val_loss: 5146.3589 - val_mae: 47.4166\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5414.4526 - mae: 48.5652 - val_loss: 5138.9785 - val_mae: 47.3769\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5406.6836 - mae: 48.5257 - val_loss: 5131.5366 - val_mae: 47.3369\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5398.9126 - mae: 48.4860 - val_loss: 5124.0283 - val_mae: 47.2967\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5391.0693 - mae: 48.4461 - val_loss: 5116.5356 - val_mae: 47.2566\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5383.2363 - mae: 48.4061 - val_loss: 5109.1587 - val_mae: 47.2171\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5375.5132 - mae: 48.3668 - val_loss: 5101.7603 - val_mae: 47.1775\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5367.7539 - mae: 48.3273 - val_loss: 5094.4561 - val_mae: 47.1383\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5360.0869 - mae: 48.2882 - val_loss: 5087.1562 - val_mae: 47.0990\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5352.4653 - mae: 48.2489 - val_loss: 5079.7744 - val_mae: 47.0593\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5344.7305 - mae: 48.2094 - val_loss: 5072.4785 - val_mae: 47.0198\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5337.0190 - mae: 48.1697 - val_loss: 5065.1250 - val_mae: 46.9801\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5329.3325 - mae: 48.1303 - val_loss: 5057.8081 - val_mae: 46.9406\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5321.6284 - mae: 48.0908 - val_loss: 5050.6030 - val_mae: 46.9015\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5314.0088 - mae: 48.0514 - val_loss: 5043.2090 - val_mae: 46.8616\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5306.3062 - mae: 48.0115 - val_loss: 5035.9082 - val_mae: 46.8222\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5298.6743 - mae: 47.9720 - val_loss: 5028.6333 - val_mae: 46.7832\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5291.0229 - mae: 47.9325 - val_loss: 5021.4331 - val_mae: 46.7444\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5283.4282 - mae: 47.8935 - val_loss: 5014.2896 - val_mae: 46.7060\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5275.8662 - mae: 47.8545 - val_loss: 5007.0503 - val_mae: 46.6672\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5268.2925 - mae: 47.8148 - val_loss: 4999.7397 - val_mae: 46.6282\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5260.6572 - mae: 47.7752 - val_loss: 4992.5859 - val_mae: 46.5897\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5253.0635 - mae: 47.7359 - val_loss: 4985.4463 - val_mae: 46.5512\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5245.6382 - mae: 47.6968 - val_loss: 4978.1519 - val_mae: 46.5120\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5238.0068 - mae: 47.6576 - val_loss: 4971.0479 - val_mae: 46.4736\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5230.5171 - mae: 47.6186 - val_loss: 4963.8984 - val_mae: 46.4351\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5223.0039 - mae: 47.5796 - val_loss: 4956.7393 - val_mae: 46.3967\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5215.4385 - mae: 47.5403 - val_loss: 4949.5679 - val_mae: 46.3585\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5207.9541 - mae: 47.5013 - val_loss: 4942.4351 - val_mae: 46.3205\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5200.4297 - mae: 47.4623 - val_loss: 4935.3135 - val_mae: 46.2827\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5192.9014 - mae: 47.4232 - val_loss: 4928.1812 - val_mae: 46.2449\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5185.3833 - mae: 47.3842 - val_loss: 4921.1191 - val_mae: 46.2074\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5178.0176 - mae: 47.3457 - val_loss: 4913.9551 - val_mae: 46.1697\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 5411.9619 - mae: 47.9901\n",
      "[('sgd', 318.4300231933594, 14.351791381835938), ('nesterov', 481.2220153808594, 19.094675064086914), ('momentum', 261.61865234375, 12.615179061889648), ('adam', 5411.9619140625, 47.990142822265625)]\n"
     ]
    }
   ],
   "source": [
    "resopt = []\n",
    "for opt in ['sgd', 'nesterov', 'momentum', 'adam']:\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(\"opt\", opt))\n",
    "    model = build_model(1, 25, opt, 10**(-5))\n",
    "    model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    resopt.append((opt, score[0], score[1]))\n",
    "print(resopt)\n",
    "with open('opt.pkl', 'wb') as fp:\n",
    "    pickle.dump(resopt, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52428df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2332.0325 - mae: 32.5223 - val_loss: 507.6911 - val_mae: 18.4053\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 513.1547 - mae: 18.7304 - val_loss: 394.8939 - val_mae: 16.7538\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 456.6576 - mae: 17.9286 - val_loss: 354.4090 - val_mae: 16.1574\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 428.2428 - mae: 17.4414 - val_loss: 322.7374 - val_mae: 15.4084\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 405.7867 - mae: 16.9164 - val_loss: 304.1937 - val_mae: 14.8770\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 391.4167 - mae: 16.5497 - val_loss: 293.3596 - val_mae: 14.5435\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 381.8440 - mae: 16.2732 - val_loss: 286.7761 - val_mae: 14.2730\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 375.4088 - mae: 16.0520 - val_loss: 282.7144 - val_mae: 14.1396\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 370.3152 - mae: 15.9015 - val_loss: 277.0315 - val_mae: 13.9210\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 359.3824 - mae: 15.6019 - val_loss: 264.9814 - val_mae: 13.5409\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 348.2399 - mae: 15.3077 - val_loss: 257.8023 - val_mae: 13.3027\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 341.9716 - mae: 15.1629 - val_loss: 252.2503 - val_mae: 13.1028\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 337.2894 - mae: 14.9994 - val_loss: 248.6830 - val_mae: 13.0684\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 333.5128 - mae: 14.9245 - val_loss: 245.9638 - val_mae: 12.9905\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 330.6117 - mae: 14.8526 - val_loss: 243.4774 - val_mae: 12.8846\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 328.3780 - mae: 14.7890 - val_loss: 240.9405 - val_mae: 12.7409\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 327.1440 - mae: 14.7064 - val_loss: 239.7736 - val_mae: 12.7092\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 325.4461 - mae: 14.6530 - val_loss: 238.7512 - val_mae: 12.7013\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 323.5264 - mae: 14.6144 - val_loss: 236.7151 - val_mae: 12.5657\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.2892 - mae: 14.5383 - val_loss: 236.6059 - val_mae: 12.6043\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 321.0661 - mae: 14.5042 - val_loss: 235.3681 - val_mae: 12.5506\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 319.9745 - mae: 14.4765 - val_loss: 234.0417 - val_mae: 12.4655\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 319.0003 - mae: 14.4149 - val_loss: 234.9468 - val_mae: 12.5621\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 318.1471 - mae: 14.4254 - val_loss: 233.2558 - val_mae: 12.4415\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 317.0682 - mae: 14.3402 - val_loss: 234.6642 - val_mae: 12.5753\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 317.0989 - mae: 14.3980 - val_loss: 232.5189 - val_mae: 12.4365\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.8448 - mae: 14.3163 - val_loss: 232.2878 - val_mae: 12.4424\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 315.1183 - mae: 14.2979 - val_loss: 231.8683 - val_mae: 12.4326\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.5071 - mae: 14.2832 - val_loss: 231.9441 - val_mae: 12.4238\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 314.4361 - mae: 14.2710 - val_loss: 230.3042 - val_mae: 12.3256\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 313.3825 - mae: 14.2327 - val_loss: 230.6309 - val_mae: 12.3391\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.6310 - mae: 14.1936 - val_loss: 230.5160 - val_mae: 12.3857\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.4018 - mae: 14.2038 - val_loss: 231.5351 - val_mae: 12.4637\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 312.0253 - mae: 14.2493 - val_loss: 229.1714 - val_mae: 12.2853\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 311.0982 - mae: 14.1325 - val_loss: 231.4607 - val_mae: 12.4545\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.9760 - mae: 14.2013 - val_loss: 228.1221 - val_mae: 12.2351\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 310.0640 - mae: 14.1030 - val_loss: 229.1429 - val_mae: 12.3350\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 309.6149 - mae: 14.1174 - val_loss: 228.2823 - val_mae: 12.2692\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.9967 - mae: 14.0977 - val_loss: 227.3643 - val_mae: 12.2144\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.7238 - mae: 14.0804 - val_loss: 227.1396 - val_mae: 12.2074\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 308.0047 - mae: 14.0636 - val_loss: 226.7325 - val_mae: 12.2069\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 307.3929 - mae: 14.0135 - val_loss: 226.7455 - val_mae: 12.2336\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 306.9375 - mae: 14.0375 - val_loss: 226.4955 - val_mae: 12.2363\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 305.7057 - mae: 14.0254 - val_loss: 225.2778 - val_mae: 12.1560\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.9608 - mae: 13.9603 - val_loss: 225.9726 - val_mae: 12.2357\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 304.0653 - mae: 13.9901 - val_loss: 224.7151 - val_mae: 12.1449\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 303.5933 - mae: 13.9087 - val_loss: 224.1408 - val_mae: 12.1185\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 302.7721 - mae: 13.8836 - val_loss: 224.4944 - val_mae: 12.1693\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 302.0929 - mae: 13.9009 - val_loss: 223.1265 - val_mae: 12.0829\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 301.4927 - mae: 13.8653 - val_loss: 222.7420 - val_mae: 12.0636\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 300.6036 - mae: 13.8309 - val_loss: 221.6253 - val_mae: 12.0091\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 299.5484 - mae: 13.7979 - val_loss: 221.0528 - val_mae: 11.9934\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 298.6750 - mae: 13.7715 - val_loss: 220.9460 - val_mae: 12.0056\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 297.6425 - mae: 13.7304 - val_loss: 220.2404 - val_mae: 11.9693\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 296.9576 - mae: 13.7197 - val_loss: 220.2061 - val_mae: 11.9636\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 296.0090 - mae: 13.6702 - val_loss: 219.5686 - val_mae: 11.9233\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 295.2359 - mae: 13.6656 - val_loss: 218.7997 - val_mae: 11.8945\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 294.6189 - mae: 13.5993 - val_loss: 221.0190 - val_mae: 12.0602\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 294.0493 - mae: 13.6749 - val_loss: 218.6802 - val_mae: 11.9067\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 293.4962 - mae: 13.5789 - val_loss: 218.5238 - val_mae: 11.9088\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 292.6443 - mae: 13.5825 - val_loss: 217.5965 - val_mae: 11.8450\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 292.3291 - mae: 13.5371 - val_loss: 217.2938 - val_mae: 11.8568\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 291.4688 - mae: 13.5686 - val_loss: 216.6213 - val_mae: 11.8021\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 290.9176 - mae: 13.4959 - val_loss: 217.2843 - val_mae: 11.8742\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 290.3983 - mae: 13.4972 - val_loss: 216.6873 - val_mae: 11.8404\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 289.7904 - mae: 13.4726 - val_loss: 215.7837 - val_mae: 11.7894\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 289.2891 - mae: 13.4546 - val_loss: 216.0327 - val_mae: 11.8083\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 288.4871 - mae: 13.4389 - val_loss: 215.3877 - val_mae: 11.7537\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.8951 - mae: 13.3746 - val_loss: 216.8459 - val_mae: 11.8939\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 287.6406 - mae: 13.4464 - val_loss: 215.2143 - val_mae: 11.8070\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 286.2256 - mae: 13.3971 - val_loss: 213.7681 - val_mae: 11.7189\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 285.1958 - mae: 13.3468 - val_loss: 214.0253 - val_mae: 11.7595\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 284.1215 - mae: 13.3252 - val_loss: 212.7811 - val_mae: 11.6972\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 283.1304 - mae: 13.2600 - val_loss: 212.9129 - val_mae: 11.7336\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 282.4756 - mae: 13.2776 - val_loss: 211.5904 - val_mae: 11.6698\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 281.5954 - mae: 13.2158 - val_loss: 213.2660 - val_mae: 11.7854\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 280.9759 - mae: 13.2571 - val_loss: 210.9875 - val_mae: 11.6424\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.9006 - mae: 13.1869 - val_loss: 209.3963 - val_mae: 11.5342\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 279.2985 - mae: 13.1023 - val_loss: 210.6266 - val_mae: 11.6455\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 278.3287 - mae: 13.1335 - val_loss: 208.4444 - val_mae: 11.5125\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 277.0369 - mae: 13.0822 - val_loss: 207.0878 - val_mae: 11.4553\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 276.3229 - mae: 13.0574 - val_loss: 206.6117 - val_mae: 11.4270\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 275.8377 - mae: 13.0158 - val_loss: 206.9121 - val_mae: 11.4693\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 274.5141 - mae: 13.0150 - val_loss: 205.6636 - val_mae: 11.3739\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 274.2288 - mae: 12.9202 - val_loss: 205.3178 - val_mae: 11.3760\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 273.1087 - mae: 12.9478 - val_loss: 205.8457 - val_mae: 11.4262\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 272.0991 - mae: 12.9523 - val_loss: 203.7041 - val_mae: 11.3130\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 271.9772 - mae: 12.8994 - val_loss: 202.8730 - val_mae: 11.2667\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 270.8532 - mae: 12.8576 - val_loss: 202.9389 - val_mae: 11.2933\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 270.2045 - mae: 12.8619 - val_loss: 201.8271 - val_mae: 11.2292\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 269.7133 - mae: 12.8078 - val_loss: 203.0044 - val_mae: 11.3130\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 269.3448 - mae: 12.8305 - val_loss: 202.7641 - val_mae: 11.3197\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 268.3466 - mae: 12.8105 - val_loss: 201.1790 - val_mae: 11.2312\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 267.6966 - mae: 12.7747 - val_loss: 201.3281 - val_mae: 11.2614\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 266.9986 - mae: 12.7563 - val_loss: 200.3705 - val_mae: 11.1921\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 266.4745 - mae: 12.7001 - val_loss: 201.7757 - val_mae: 11.3085\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 266.1846 - mae: 12.7702 - val_loss: 199.3167 - val_mae: 11.1555\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 265.4874 - mae: 12.6890 - val_loss: 199.6826 - val_mae: 11.1992\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 264.8547 - mae: 12.6658 - val_loss: 199.4886 - val_mae: 11.1877\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 264.5440 - mae: 12.6623 - val_loss: 199.0171 - val_mae: 11.1773\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 261.3286 - mae: 12.6790\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2304.0669 - mae: 30.3782 - val_loss: 427.4252 - val_mae: 17.6254\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 477.6520 - mae: 18.3834 - val_loss: 359.2526 - val_mae: 16.4378\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 441.5045 - mae: 17.8666 - val_loss: 343.0444 - val_mae: 16.0873\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 431.2741 - mae: 17.6761 - val_loss: 340.0782 - val_mae: 15.9996\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 426.6711 - mae: 17.5584 - val_loss: 338.5714 - val_mae: 15.9436\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 423.0134 - mae: 17.4615 - val_loss: 336.5602 - val_mae: 15.8307\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 420.8512 - mae: 17.3849 - val_loss: 334.2238 - val_mae: 15.7407\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 418.2092 - mae: 17.2922 - val_loss: 332.3880 - val_mae: 15.7131\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 413.8341 - mae: 17.1651 - val_loss: 325.8817 - val_mae: 15.4851\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 409.5861 - mae: 17.0077 - val_loss: 324.3024 - val_mae: 15.4340\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 407.4892 - mae: 16.9613 - val_loss: 323.2451 - val_mae: 15.3949\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 406.4687 - mae: 16.9277 - val_loss: 323.0595 - val_mae: 15.4146\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 405.6956 - mae: 16.9070 - val_loss: 323.0903 - val_mae: 15.4201\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 404.4897 - mae: 16.8895 - val_loss: 321.5951 - val_mae: 15.3455\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 403.8497 - mae: 16.8316 - val_loss: 322.1297 - val_mae: 15.4041\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 403.4056 - mae: 16.8218 - val_loss: 321.9393 - val_mae: 15.3966\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 402.8123 - mae: 16.8105 - val_loss: 320.5436 - val_mae: 15.3148\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 401.8372 - mae: 16.7876 - val_loss: 319.6436 - val_mae: 15.2636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 400.3584 - mae: 16.7370 - val_loss: 318.7774 - val_mae: 15.2290\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 399.6346 - mae: 16.7076 - val_loss: 318.1515 - val_mae: 15.2085\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 398.3507 - mae: 16.6629 - val_loss: 317.2971 - val_mae: 15.1777\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 397.4577 - mae: 16.6235 - val_loss: 318.5783 - val_mae: 15.2650\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 397.0898 - mae: 16.6183 - val_loss: 318.9209 - val_mae: 15.2962\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 396.8123 - mae: 16.6517 - val_loss: 316.3138 - val_mae: 15.1306\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 395.6059 - mae: 16.5703 - val_loss: 315.9983 - val_mae: 15.1189\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 394.8517 - mae: 16.5446 - val_loss: 315.4423 - val_mae: 15.0808\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 394.3899 - mae: 16.5304 - val_loss: 314.9869 - val_mae: 15.0763\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.6851 - mae: 16.5328 - val_loss: 315.7087 - val_mae: 15.1161\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.4202 - mae: 16.4718 - val_loss: 316.2398 - val_mae: 15.1730\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 393.1459 - mae: 16.5188 - val_loss: 314.9513 - val_mae: 15.1000\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 392.1887 - mae: 16.4757 - val_loss: 315.9904 - val_mae: 15.1630\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 391.9826 - mae: 16.5023 - val_loss: 313.7791 - val_mae: 15.0455\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 390.7355 - mae: 16.4323 - val_loss: 312.0201 - val_mae: 14.9378\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 390.1421 - mae: 16.3851 - val_loss: 314.2273 - val_mae: 15.0956\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 390.1059 - mae: 16.4173 - val_loss: 311.1731 - val_mae: 14.9048\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 389.4373 - mae: 16.3893 - val_loss: 310.9065 - val_mae: 14.8979\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 388.6741 - mae: 16.3505 - val_loss: 312.2271 - val_mae: 14.9968\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 388.2073 - mae: 16.3756 - val_loss: 310.1736 - val_mae: 14.8755\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 387.5752 - mae: 16.3236 - val_loss: 310.2510 - val_mae: 14.8836\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 386.8756 - mae: 16.2946 - val_loss: 309.3743 - val_mae: 14.8542\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 386.6147 - mae: 16.2925 - val_loss: 309.5175 - val_mae: 14.8587\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 386.0052 - mae: 16.2988 - val_loss: 309.4135 - val_mae: 14.8657\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 385.4204 - mae: 16.2658 - val_loss: 308.6093 - val_mae: 14.8185\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 385.1380 - mae: 16.2455 - val_loss: 309.6146 - val_mae: 14.8962\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 384.5572 - mae: 16.2471 - val_loss: 308.6529 - val_mae: 14.8486\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 383.7642 - mae: 16.2281 - val_loss: 307.7262 - val_mae: 14.7968\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 383.6124 - mae: 16.2259 - val_loss: 307.1427 - val_mae: 14.7803\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 382.8510 - mae: 16.1821 - val_loss: 306.5251 - val_mae: 14.7476\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 382.4630 - mae: 16.1879 - val_loss: 305.4911 - val_mae: 14.6932\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 381.8774 - mae: 16.1516 - val_loss: 306.2762 - val_mae: 14.7487\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 381.3742 - mae: 16.1492 - val_loss: 305.7925 - val_mae: 14.7233\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 380.8285 - mae: 16.1286 - val_loss: 305.1505 - val_mae: 14.7035\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 380.1093 - mae: 16.1040 - val_loss: 305.2555 - val_mae: 14.7172\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 379.7832 - mae: 16.0997 - val_loss: 305.1511 - val_mae: 14.7184\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 380.0829 - mae: 16.1195 - val_loss: 304.5682 - val_mae: 14.7005\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 378.7505 - mae: 16.0609 - val_loss: 305.4105 - val_mae: 14.7558\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 378.4198 - mae: 16.0766 - val_loss: 304.9428 - val_mae: 14.7352\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 378.0582 - mae: 16.0762 - val_loss: 303.7659 - val_mae: 14.6690\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 377.3925 - mae: 16.0065 - val_loss: 303.7588 - val_mae: 14.6804\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 377.0152 - mae: 16.0320 - val_loss: 302.3135 - val_mae: 14.5921\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 376.3192 - mae: 15.9596 - val_loss: 303.8223 - val_mae: 14.6961\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 375.5750 - mae: 15.9768 - val_loss: 302.4164 - val_mae: 14.6146\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 375.1827 - mae: 15.9742 - val_loss: 301.2279 - val_mae: 14.5480\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 374.8059 - mae: 15.9375 - val_loss: 301.3728 - val_mae: 14.5590\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 373.8301 - mae: 15.8705 - val_loss: 303.2784 - val_mae: 14.6861\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 374.0661 - mae: 15.9631 - val_loss: 301.4106 - val_mae: 14.5864\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 372.7609 - mae: 15.8812 - val_loss: 300.9715 - val_mae: 14.5656\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 371.8452 - mae: 15.8446 - val_loss: 300.7234 - val_mae: 14.5582\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 370.6384 - mae: 15.8297 - val_loss: 299.1799 - val_mae: 14.4769\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 369.6699 - mae: 15.7519 - val_loss: 299.8109 - val_mae: 14.5215\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 369.1912 - mae: 15.7770 - val_loss: 298.7878 - val_mae: 14.4591\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 368.1894 - mae: 15.7577 - val_loss: 297.8363 - val_mae: 14.4025\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 367.7996 - mae: 15.6906 - val_loss: 297.2886 - val_mae: 14.3778\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 366.5844 - mae: 15.6783 - val_loss: 296.5674 - val_mae: 14.3539\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 366.0437 - mae: 15.6611 - val_loss: 295.9497 - val_mae: 14.3144\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.7955 - mae: 15.6360 - val_loss: 295.5825 - val_mae: 14.3094\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 364.8798 - mae: 15.5994 - val_loss: 298.3372 - val_mae: 14.4853\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 365.3061 - mae: 15.6535 - val_loss: 296.7386 - val_mae: 14.4070\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 364.4538 - mae: 15.6120 - val_loss: 294.8013 - val_mae: 14.2847\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 363.8545 - mae: 15.5610 - val_loss: 294.5958 - val_mae: 14.2594\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 363.4570 - mae: 15.5598 - val_loss: 295.4348 - val_mae: 14.3302\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 362.9492 - mae: 15.5795 - val_loss: 292.9756 - val_mae: 14.1723\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 362.8867 - mae: 15.5293 - val_loss: 293.0412 - val_mae: 14.1882\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 362.4549 - mae: 15.5457 - val_loss: 293.5156 - val_mae: 14.2297\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 362.4919 - mae: 15.5044 - val_loss: 292.9740 - val_mae: 14.1930\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 361.8238 - mae: 15.5044 - val_loss: 293.3030 - val_mae: 14.2277\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 361.4578 - mae: 15.4976 - val_loss: 292.5718 - val_mae: 14.1655\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 360.9799 - mae: 15.4387 - val_loss: 293.1080 - val_mae: 14.2191\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 360.6976 - mae: 15.4389 - val_loss: 292.4953 - val_mae: 14.1815\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 361.2583 - mae: 15.4878 - val_loss: 291.9117 - val_mae: 14.1607\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 361.5557 - mae: 15.5134 - val_loss: 291.9260 - val_mae: 14.1632\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 359.9382 - mae: 15.3965 - val_loss: 290.7329 - val_mae: 14.0775\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 359.9298 - mae: 15.3996 - val_loss: 292.1365 - val_mae: 14.1885\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 359.2494 - mae: 15.4056 - val_loss: 290.5075 - val_mae: 14.0861\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 359.2526 - mae: 15.3921 - val_loss: 290.0485 - val_mae: 14.0638\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 358.0795 - mae: 15.3528 - val_loss: 292.4974 - val_mae: 14.2391\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 357.3606 - mae: 15.3605 - val_loss: 290.9402 - val_mae: 14.1545\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 356.4514 - mae: 15.2909 - val_loss: 291.9021 - val_mae: 14.2191\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 355.8090 - mae: 15.3024 - val_loss: 289.4908 - val_mae: 14.0545\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 355.2881 - mae: 15.2364 - val_loss: 288.8510 - val_mae: 14.0205\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 362.3949 - mae: 15.4537\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1715.8156 - mae: 29.2985 - val_loss: 487.8878 - val_mae: 20.9362\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 568.3959 - mae: 21.7339 - val_loss: 477.5808 - val_mae: 20.6392\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 564.4510 - mae: 21.6296 - val_loss: 477.7943 - val_mae: 20.6452\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 563.5005 - mae: 21.5886 - val_loss: 474.9607 - val_mae: 20.5407\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 562.3250 - mae: 21.5461 - val_loss: 474.6534 - val_mae: 20.5254\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 561.6954 - mae: 21.5251 - val_loss: 475.1416 - val_mae: 20.5507\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 561.5892 - mae: 21.5249 - val_loss: 473.9457 - val_mae: 20.4965\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 560.6230 - mae: 21.4895 - val_loss: 472.9985 - val_mae: 20.4541\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 559.7651 - mae: 21.4483 - val_loss: 472.3908 - val_mae: 20.4128\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 558.3817 - mae: 21.4042 - val_loss: 471.0703 - val_mae: 20.3529\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 557.6533 - mae: 21.3568 - val_loss: 470.8382 - val_mae: 20.3451\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.8329 - mae: 21.3314 - val_loss: 471.2141 - val_mae: 20.3702\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 557.6518 - mae: 21.3701 - val_loss: 471.0065 - val_mae: 20.3615\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 557.6401 - mae: 21.3664 - val_loss: 471.6332 - val_mae: 20.3951\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 557.4506 - mae: 21.3738 - val_loss: 470.0924 - val_mae: 20.2966\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.4199 - mae: 21.3457 - val_loss: 469.9448 - val_mae: 20.2906\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.5764 - mae: 21.3201 - val_loss: 469.8509 - val_mae: 20.2851\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.8463 - mae: 21.2966 - val_loss: 469.9243 - val_mae: 20.2895\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 556.1801 - mae: 21.3036 - val_loss: 469.6331 - val_mae: 20.2694\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.8746 - mae: 21.2821 - val_loss: 469.6915 - val_mae: 20.2752\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 555.7375 - mae: 21.2844 - val_loss: 469.9818 - val_mae: 20.3024\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.6363 - mae: 21.2704 - val_loss: 470.4859 - val_mae: 20.3427\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.7469 - mae: 21.2940 - val_loss: 469.4781 - val_mae: 20.2614\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 555.5479 - mae: 21.2868 - val_loss: 469.3374 - val_mae: 20.2529\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.6232 - mae: 21.2726 - val_loss: 469.6331 - val_mae: 20.2785\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 555.5698 - mae: 21.2781 - val_loss: 470.3928 - val_mae: 20.3397\n",
      "Epoch 26: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 574.1872 - mae: 21.8570\n",
      "[(0.1, 261.32855224609375, 12.678954124450684), (0.5, 362.3949279785156, 15.453727722167969), (0.9, 574.1871948242188, 21.856962203979492)]\n"
     ]
    }
   ],
   "source": [
    "resmom = []\n",
    "for mom in [0.1, 0.5, 0.9]:\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir(\"mom\", mom))\n",
    "    model = build_model(1, 25, 'momentum', 10**(-5), mom)\n",
    "    model.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[tensorboard_cb, es])\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    resmom.append((mom, score[0], score[1]))\n",
    "print(resmom)\n",
    "with open('mom.pkl', 'wb') as fp:\n",
    "    pickle.dump(resmom, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bc8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "\"model__n_hidden\": [0, 1, 2, 3],\n",
    "\"model__n_neurons\": [5, 25, 125],\n",
    "\"model__learning_rate\": [10**(-4), 10**(-5), 10**(-6)],\n",
    "\"model__optimizer\": ['sgd', 'nesterov', 'momentum', 'adam'],\n",
    "\"model__momentum\": [0.1, 0.5, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752bbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1.0, verbose=1)\n",
    "keras_reg = KerasRegressor(build_model, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9d11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 7854.1753 - mae: 57.9376 - val_loss: 9690.2520 - val_mae: 63.1724\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7853.4497 - mae: 57.9343 - val_loss: 9689.4473 - val_mae: 63.1691\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7852.7349 - mae: 57.9310 - val_loss: 9688.6260 - val_mae: 63.1658\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7852.0024 - mae: 57.9276 - val_loss: 9687.8076 - val_mae: 63.1625\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7851.2651 - mae: 57.9242 - val_loss: 9687.0000 - val_mae: 63.1592\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7850.5625 - mae: 57.9209 - val_loss: 9686.1748 - val_mae: 63.1559\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7849.8521 - mae: 57.9176 - val_loss: 9685.3457 - val_mae: 63.1526\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7849.1177 - mae: 57.9142 - val_loss: 9684.5225 - val_mae: 63.1492\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7848.3867 - mae: 57.9108 - val_loss: 9683.7168 - val_mae: 63.1460\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7847.6572 - mae: 57.9075 - val_loss: 9682.9072 - val_mae: 63.1427\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7846.9473 - mae: 57.9042 - val_loss: 9682.0879 - val_mae: 63.1394\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7846.2300 - mae: 57.9008 - val_loss: 9681.2637 - val_mae: 63.1360\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7845.5117 - mae: 57.8975 - val_loss: 9680.4326 - val_mae: 63.1327\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7844.7646 - mae: 57.8941 - val_loss: 9679.6162 - val_mae: 63.1294\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7844.0332 - mae: 57.8907 - val_loss: 9678.7959 - val_mae: 63.1261\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7843.3110 - mae: 57.8874 - val_loss: 9677.9678 - val_mae: 63.1227\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7842.5796 - mae: 57.8839 - val_loss: 9677.1426 - val_mae: 63.1194\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7841.8564 - mae: 57.8806 - val_loss: 9676.3232 - val_mae: 63.1161\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7841.1479 - mae: 57.8773 - val_loss: 9675.4922 - val_mae: 63.1128\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7840.4004 - mae: 57.8739 - val_loss: 9674.6895 - val_mae: 63.1095\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7839.7041 - mae: 57.8706 - val_loss: 9673.8594 - val_mae: 63.1061\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7838.9624 - mae: 57.8672 - val_loss: 9673.0537 - val_mae: 63.1029\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7838.2490 - mae: 57.8638 - val_loss: 9672.2393 - val_mae: 63.0996\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7837.5352 - mae: 57.8605 - val_loss: 9671.4248 - val_mae: 63.0963\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7836.8091 - mae: 57.8572 - val_loss: 9670.6221 - val_mae: 63.0930\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7836.0830 - mae: 57.8539 - val_loss: 9669.8057 - val_mae: 63.0897\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7835.3755 - mae: 57.8505 - val_loss: 9668.9707 - val_mae: 63.0863\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7834.6455 - mae: 57.8471 - val_loss: 9668.1553 - val_mae: 63.0831\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7833.9219 - mae: 57.8438 - val_loss: 9667.3369 - val_mae: 63.0797\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7833.1914 - mae: 57.8404 - val_loss: 9666.5205 - val_mae: 63.0764\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7832.4658 - mae: 57.8371 - val_loss: 9665.6963 - val_mae: 63.0731\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7831.7437 - mae: 57.8337 - val_loss: 9664.8711 - val_mae: 63.0698\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7831.0156 - mae: 57.8303 - val_loss: 9664.0479 - val_mae: 63.0665\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7830.2988 - mae: 57.8270 - val_loss: 9663.2314 - val_mae: 63.0631\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7829.5630 - mae: 57.8236 - val_loss: 9662.4199 - val_mae: 63.0599\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7828.8560 - mae: 57.8203 - val_loss: 9661.6055 - val_mae: 63.0566\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7828.1396 - mae: 57.8170 - val_loss: 9660.7949 - val_mae: 63.0533\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7827.4395 - mae: 57.8136 - val_loss: 9659.9697 - val_mae: 63.0499\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7826.6890 - mae: 57.8102 - val_loss: 9659.1699 - val_mae: 63.0467\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7825.9814 - mae: 57.8069 - val_loss: 9658.3457 - val_mae: 63.0433\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7825.2622 - mae: 57.8036 - val_loss: 9657.5215 - val_mae: 63.0400\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7824.5337 - mae: 57.8002 - val_loss: 9656.7109 - val_mae: 63.0367\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7823.8140 - mae: 57.7969 - val_loss: 9655.8945 - val_mae: 63.0334\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7823.1001 - mae: 57.7935 - val_loss: 9655.0713 - val_mae: 63.0301\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7822.3735 - mae: 57.7901 - val_loss: 9654.2520 - val_mae: 63.0268\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7821.6509 - mae: 57.7868 - val_loss: 9653.4404 - val_mae: 63.0235\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7820.9038 - mae: 57.7834 - val_loss: 9652.6455 - val_mae: 63.0202\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7820.2061 - mae: 57.7801 - val_loss: 9651.8213 - val_mae: 63.0169\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7819.4741 - mae: 57.7768 - val_loss: 9651.0049 - val_mae: 63.0136\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7818.7637 - mae: 57.7734 - val_loss: 9650.1777 - val_mae: 63.0103\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7818.0391 - mae: 57.7700 - val_loss: 9649.3486 - val_mae: 63.0069\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7817.3086 - mae: 57.7667 - val_loss: 9648.5352 - val_mae: 63.0036\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7816.5903 - mae: 57.7633 - val_loss: 9647.7051 - val_mae: 63.0003\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7815.8555 - mae: 57.7599 - val_loss: 9646.8955 - val_mae: 62.9970\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7815.1387 - mae: 57.7566 - val_loss: 9646.0811 - val_mae: 62.9937\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7814.4312 - mae: 57.7533 - val_loss: 9645.2549 - val_mae: 62.9903\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7813.6890 - mae: 57.7499 - val_loss: 9644.4502 - val_mae: 62.9871\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7812.9692 - mae: 57.7465 - val_loss: 9643.6455 - val_mae: 62.9838\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7812.2642 - mae: 57.7432 - val_loss: 9642.8301 - val_mae: 62.9805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7811.5522 - mae: 57.7399 - val_loss: 9641.9961 - val_mae: 62.9771\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7810.7886 - mae: 57.7364 - val_loss: 9641.1992 - val_mae: 62.9739\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7810.0884 - mae: 57.7331 - val_loss: 9640.3564 - val_mae: 62.9705\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7809.3569 - mae: 57.7297 - val_loss: 9639.5264 - val_mae: 62.9671\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7808.6362 - mae: 57.7264 - val_loss: 9638.6973 - val_mae: 62.9638\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7807.9033 - mae: 57.7230 - val_loss: 9637.8760 - val_mae: 62.9605\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7807.1548 - mae: 57.7196 - val_loss: 9637.0859 - val_mae: 62.9572\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7806.4702 - mae: 57.7163 - val_loss: 9636.2490 - val_mae: 62.9539\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7805.7363 - mae: 57.7129 - val_loss: 9635.4238 - val_mae: 62.9505\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7805.0059 - mae: 57.7096 - val_loss: 9634.6006 - val_mae: 62.9472\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7804.2856 - mae: 57.7062 - val_loss: 9633.7764 - val_mae: 62.9439\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7803.5659 - mae: 57.7028 - val_loss: 9632.9609 - val_mae: 62.9406\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7802.8462 - mae: 57.6995 - val_loss: 9632.1650 - val_mae: 62.9373\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7802.1528 - mae: 57.6962 - val_loss: 9631.3516 - val_mae: 62.9340\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7801.4219 - mae: 57.6928 - val_loss: 9630.5586 - val_mae: 62.9308\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7800.7280 - mae: 57.6895 - val_loss: 9629.7520 - val_mae: 62.9275\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7799.9990 - mae: 57.6862 - val_loss: 9628.9639 - val_mae: 62.9243\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7799.2983 - mae: 57.6829 - val_loss: 9628.1650 - val_mae: 62.9210\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7798.5991 - mae: 57.6796 - val_loss: 9627.3428 - val_mae: 62.9177\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7797.8833 - mae: 57.6763 - val_loss: 9626.5264 - val_mae: 62.9143\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7797.1538 - mae: 57.6729 - val_loss: 9625.7227 - val_mae: 62.9111\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7796.4502 - mae: 57.6696 - val_loss: 9624.9102 - val_mae: 62.9078\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7795.7280 - mae: 57.6662 - val_loss: 9624.1074 - val_mae: 62.9045\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7795.0215 - mae: 57.6630 - val_loss: 9623.2988 - val_mae: 62.9012\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7794.2969 - mae: 57.6596 - val_loss: 9622.5098 - val_mae: 62.8980\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7793.5996 - mae: 57.6563 - val_loss: 9621.7041 - val_mae: 62.8947\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7792.8965 - mae: 57.6530 - val_loss: 9620.8740 - val_mae: 62.8913\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7792.1572 - mae: 57.6496 - val_loss: 9620.0752 - val_mae: 62.8881\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7791.4399 - mae: 57.6463 - val_loss: 9619.2725 - val_mae: 62.8848\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7790.7397 - mae: 57.6430 - val_loss: 9618.4482 - val_mae: 62.8815\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7789.9971 - mae: 57.6395 - val_loss: 9617.6367 - val_mae: 62.8782\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7789.2881 - mae: 57.6362 - val_loss: 9616.8037 - val_mae: 62.8748\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7788.5664 - mae: 57.6328 - val_loss: 9615.9766 - val_mae: 62.8715\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7787.8325 - mae: 57.6294 - val_loss: 9615.1572 - val_mae: 62.8681\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7787.1035 - mae: 57.6261 - val_loss: 9614.3477 - val_mae: 62.8648\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7786.3901 - mae: 57.6227 - val_loss: 9613.5254 - val_mae: 62.8615\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7785.6719 - mae: 57.6194 - val_loss: 9612.7012 - val_mae: 62.8582\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7784.9468 - mae: 57.6160 - val_loss: 9611.8926 - val_mae: 62.8549\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7784.2212 - mae: 57.6126 - val_loss: 9611.0918 - val_mae: 62.8516\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7783.5137 - mae: 57.6093 - val_loss: 9610.2676 - val_mae: 62.8483\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7782.7871 - mae: 57.6059 - val_loss: 9609.4414 - val_mae: 62.8449\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 36967.1641 - mae: 161.7420 - val_loss: 39735.7031 - val_mae: 169.4037\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36964.7344 - mae: 161.7361 - val_loss: 39733.1328 - val_mae: 169.3975\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36962.3359 - mae: 161.7302 - val_loss: 39730.5508 - val_mae: 169.3912\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36959.8828 - mae: 161.7243 - val_loss: 39727.9844 - val_mae: 169.3850\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36957.4844 - mae: 161.7184 - val_loss: 39725.4102 - val_mae: 169.3787\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36955.0391 - mae: 161.7125 - val_loss: 39722.8555 - val_mae: 169.3725\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36952.6445 - mae: 161.7066 - val_loss: 39720.2773 - val_mae: 169.3663\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36950.2227 - mae: 161.7007 - val_loss: 39717.7188 - val_mae: 169.3601\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36947.8281 - mae: 161.6949 - val_loss: 39715.1602 - val_mae: 169.3539\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36945.4531 - mae: 161.6890 - val_loss: 39712.6055 - val_mae: 169.3477\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36943.0039 - mae: 161.6832 - val_loss: 39710.0977 - val_mae: 169.3416\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36940.6602 - mae: 161.6774 - val_loss: 39707.5430 - val_mae: 169.3354\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36938.2578 - mae: 161.6716 - val_loss: 39704.9922 - val_mae: 169.3292\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36935.8320 - mae: 161.6657 - val_loss: 39702.4414 - val_mae: 169.3231\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36933.4375 - mae: 161.6599 - val_loss: 39699.8906 - val_mae: 169.3169\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36931.0391 - mae: 161.6540 - val_loss: 39697.3516 - val_mae: 169.3107\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36928.6641 - mae: 161.6482 - val_loss: 39694.7930 - val_mae: 169.3045\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36926.2266 - mae: 161.6423 - val_loss: 39692.2461 - val_mae: 169.2983\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36923.8594 - mae: 161.6365 - val_loss: 39689.6719 - val_mae: 169.2921\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36921.4453 - mae: 161.6306 - val_loss: 39687.1211 - val_mae: 169.2859\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36919.0625 - mae: 161.6248 - val_loss: 39684.5820 - val_mae: 169.2797\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36916.6758 - mae: 161.6189 - val_loss: 39682.0312 - val_mae: 169.2735\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36914.2227 - mae: 161.6130 - val_loss: 39679.5039 - val_mae: 169.2674\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36911.8750 - mae: 161.6072 - val_loss: 39676.9258 - val_mae: 169.2612\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36909.4414 - mae: 161.6013 - val_loss: 39674.3672 - val_mae: 169.2550\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36907.0000 - mae: 161.5955 - val_loss: 39671.8281 - val_mae: 169.2488\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36904.6250 - mae: 161.5896 - val_loss: 39669.2578 - val_mae: 169.2426\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36902.1992 - mae: 161.5837 - val_loss: 39666.6914 - val_mae: 169.2363\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36899.8047 - mae: 161.5779 - val_loss: 39664.1211 - val_mae: 169.2301\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36897.4180 - mae: 161.5719 - val_loss: 39661.5469 - val_mae: 169.2238\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36894.9727 - mae: 161.5661 - val_loss: 39659.0195 - val_mae: 169.2177\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36892.5898 - mae: 161.5603 - val_loss: 39656.4805 - val_mae: 169.2115\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36890.2070 - mae: 161.5544 - val_loss: 39653.9219 - val_mae: 169.2053\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36887.7969 - mae: 161.5486 - val_loss: 39651.3594 - val_mae: 169.1991\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36885.3633 - mae: 161.5427 - val_loss: 39648.8086 - val_mae: 169.1930\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36882.9961 - mae: 161.5368 - val_loss: 39646.2344 - val_mae: 169.1867\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36880.5547 - mae: 161.5309 - val_loss: 39643.6914 - val_mae: 169.1806\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36878.2031 - mae: 161.5251 - val_loss: 39641.1094 - val_mae: 169.1743\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36875.7812 - mae: 161.5192 - val_loss: 39638.5742 - val_mae: 169.1682\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36873.3516 - mae: 161.5134 - val_loss: 39636.0469 - val_mae: 169.1620\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36870.9883 - mae: 161.5075 - val_loss: 39633.5000 - val_mae: 169.1559\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36868.5859 - mae: 161.5017 - val_loss: 39630.9805 - val_mae: 169.1497\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36866.2422 - mae: 161.4960 - val_loss: 39628.4102 - val_mae: 169.1435\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36863.7969 - mae: 161.4900 - val_loss: 39625.9023 - val_mae: 169.1374\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36861.4492 - mae: 161.4843 - val_loss: 39623.3555 - val_mae: 169.1312\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36859.0664 - mae: 161.4784 - val_loss: 39620.8203 - val_mae: 169.1251\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36856.6602 - mae: 161.4726 - val_loss: 39618.2930 - val_mae: 169.1189\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36854.2812 - mae: 161.4668 - val_loss: 39615.7539 - val_mae: 169.1127\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36851.9141 - mae: 161.4610 - val_loss: 39613.1758 - val_mae: 169.1065\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36849.4609 - mae: 161.4551 - val_loss: 39610.6523 - val_mae: 169.1004\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36847.0938 - mae: 161.4492 - val_loss: 39608.1055 - val_mae: 169.0942\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36844.6914 - mae: 161.4434 - val_loss: 39605.5781 - val_mae: 169.0880\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36842.3086 - mae: 161.4376 - val_loss: 39603.0352 - val_mae: 169.0819\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36839.9102 - mae: 161.4317 - val_loss: 39600.5039 - val_mae: 169.0757\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36837.5430 - mae: 161.4259 - val_loss: 39597.9414 - val_mae: 169.0695\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36835.1172 - mae: 161.4200 - val_loss: 39595.4062 - val_mae: 169.0634\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36832.7266 - mae: 161.4143 - val_loss: 39592.8789 - val_mae: 169.0572\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36830.3398 - mae: 161.4084 - val_loss: 39590.3398 - val_mae: 169.0510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36827.9727 - mae: 161.4026 - val_loss: 39587.7734 - val_mae: 169.0448\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36825.5781 - mae: 161.3967 - val_loss: 39585.1953 - val_mae: 169.0386\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36823.1523 - mae: 161.3908 - val_loss: 39582.6680 - val_mae: 169.0324\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36820.7695 - mae: 161.3850 - val_loss: 39580.1328 - val_mae: 169.0263\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36818.3711 - mae: 161.3792 - val_loss: 39577.5977 - val_mae: 169.0201\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36815.9609 - mae: 161.3733 - val_loss: 39575.0742 - val_mae: 169.0140\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36813.5781 - mae: 161.3675 - val_loss: 39572.5352 - val_mae: 169.0078\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36811.1992 - mae: 161.3617 - val_loss: 39569.9805 - val_mae: 169.0016\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36808.8125 - mae: 161.3558 - val_loss: 39567.4180 - val_mae: 168.9954\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36806.3984 - mae: 161.3499 - val_loss: 39564.8672 - val_mae: 168.9893\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36804.0039 - mae: 161.3441 - val_loss: 39562.3047 - val_mae: 168.9830\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36801.6016 - mae: 161.3382 - val_loss: 39559.7578 - val_mae: 168.9769\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36799.1992 - mae: 161.3324 - val_loss: 39557.2266 - val_mae: 168.9707\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36796.8398 - mae: 161.3266 - val_loss: 39554.6680 - val_mae: 168.9645\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 36794.3906 - mae: 161.3208 - val_loss: 39552.1758 - val_mae: 168.9584\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36792.0664 - mae: 161.3150 - val_loss: 39549.6211 - val_mae: 168.9522\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36789.6641 - mae: 161.3091 - val_loss: 39547.0703 - val_mae: 168.9460\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36787.2305 - mae: 161.3033 - val_loss: 39544.5547 - val_mae: 168.9398\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36784.8906 - mae: 161.2975 - val_loss: 39542.0039 - val_mae: 168.9337\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36782.4766 - mae: 161.2916 - val_loss: 39539.4688 - val_mae: 168.9275\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36780.1094 - mae: 161.2858 - val_loss: 39536.9102 - val_mae: 168.9213\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36777.7031 - mae: 161.2800 - val_loss: 39534.3750 - val_mae: 168.9151\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36775.2930 - mae: 161.2742 - val_loss: 39531.8516 - val_mae: 168.9090\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36772.9375 - mae: 161.2683 - val_loss: 39529.2773 - val_mae: 168.9028\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36770.5039 - mae: 161.2624 - val_loss: 39526.7266 - val_mae: 168.8966\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36768.1094 - mae: 161.2566 - val_loss: 39524.1719 - val_mae: 168.8904\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36765.6680 - mae: 161.2507 - val_loss: 39521.6523 - val_mae: 168.8842\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36763.3516 - mae: 161.2449 - val_loss: 39519.0703 - val_mae: 168.8780\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36760.9141 - mae: 161.2390 - val_loss: 39516.5078 - val_mae: 168.8718\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36758.5039 - mae: 161.2331 - val_loss: 39513.9531 - val_mae: 168.8655\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36756.0664 - mae: 161.2272 - val_loss: 39511.4219 - val_mae: 168.8593\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36753.7188 - mae: 161.2214 - val_loss: 39508.8320 - val_mae: 168.8531\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36751.2734 - mae: 161.2155 - val_loss: 39506.2969 - val_mae: 168.8469\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36748.8906 - mae: 161.2096 - val_loss: 39503.7539 - val_mae: 168.8407\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36746.4805 - mae: 161.2038 - val_loss: 39501.2227 - val_mae: 168.8345\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36744.0938 - mae: 161.1980 - val_loss: 39498.6602 - val_mae: 168.8283\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36741.7148 - mae: 161.1921 - val_loss: 39496.0938 - val_mae: 168.8221\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36739.2891 - mae: 161.1862 - val_loss: 39493.5703 - val_mae: 168.8159\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36736.8984 - mae: 161.1804 - val_loss: 39491.0352 - val_mae: 168.8098\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36734.5508 - mae: 161.1746 - val_loss: 39488.4570 - val_mae: 168.8035\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36732.0938 - mae: 161.1687 - val_loss: 39485.9336 - val_mae: 168.7974\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36729.7344 - mae: 161.1629 - val_loss: 39483.3828 - val_mae: 168.7912\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 22ms/step - loss: 35421.8867 - mae: 130.5230 - val_loss: 37173.4570 - val_mae: 132.8238\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35420.0430 - mae: 130.5182 - val_loss: 37171.5000 - val_mae: 132.8186\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35418.1953 - mae: 130.5134 - val_loss: 37169.5312 - val_mae: 132.8134\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35416.3398 - mae: 130.5085 - val_loss: 37167.5586 - val_mae: 132.8083\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35414.4883 - mae: 130.5038 - val_loss: 37165.5977 - val_mae: 132.8031\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35412.6562 - mae: 130.4990 - val_loss: 37163.6328 - val_mae: 132.7979\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35410.8008 - mae: 130.4942 - val_loss: 37161.6523 - val_mae: 132.7927\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35408.9336 - mae: 130.4893 - val_loss: 37159.7031 - val_mae: 132.7875\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35407.0898 - mae: 130.4845 - val_loss: 37157.7227 - val_mae: 132.7823\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35405.2539 - mae: 130.4797 - val_loss: 37155.7344 - val_mae: 132.7771\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35403.3789 - mae: 130.4748 - val_loss: 37153.7656 - val_mae: 132.7719\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35401.5156 - mae: 130.4700 - val_loss: 37151.8086 - val_mae: 132.7667\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35399.6680 - mae: 130.4652 - val_loss: 37149.8477 - val_mae: 132.7615\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35397.8359 - mae: 130.4604 - val_loss: 37147.8555 - val_mae: 132.7563\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35395.9805 - mae: 130.4555 - val_loss: 37145.8750 - val_mae: 132.7511\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35394.1133 - mae: 130.4507 - val_loss: 37143.9180 - val_mae: 132.7459\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35392.2617 - mae: 130.4459 - val_loss: 37141.9492 - val_mae: 132.7407\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35390.4414 - mae: 130.4411 - val_loss: 37139.9570 - val_mae: 132.7354\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35388.5391 - mae: 130.4362 - val_loss: 37138.0195 - val_mae: 132.7303\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35386.7227 - mae: 130.4314 - val_loss: 37136.0430 - val_mae: 132.7251\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35384.8711 - mae: 130.4266 - val_loss: 37134.0625 - val_mae: 132.7198\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35383.0039 - mae: 130.4218 - val_loss: 37132.1094 - val_mae: 132.7147\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35381.1797 - mae: 130.4169 - val_loss: 37130.1484 - val_mae: 132.7095\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35379.3359 - mae: 130.4122 - val_loss: 37128.1836 - val_mae: 132.7043\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35377.4727 - mae: 130.4073 - val_loss: 37126.2539 - val_mae: 132.6992\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35375.6562 - mae: 130.4026 - val_loss: 37124.2656 - val_mae: 132.6940\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35373.7969 - mae: 130.3977 - val_loss: 37122.2852 - val_mae: 132.6887\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35371.9336 - mae: 130.3929 - val_loss: 37120.3203 - val_mae: 132.6835\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35370.0938 - mae: 130.3880 - val_loss: 37118.3555 - val_mae: 132.6784\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35368.2656 - mae: 130.3833 - val_loss: 37116.3789 - val_mae: 132.6731\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35366.4023 - mae: 130.3785 - val_loss: 37114.4414 - val_mae: 132.6680\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35364.5703 - mae: 130.3737 - val_loss: 37112.4844 - val_mae: 132.6628\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35362.7383 - mae: 130.3689 - val_loss: 37110.5469 - val_mae: 132.6577\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35360.9258 - mae: 130.3642 - val_loss: 37108.5781 - val_mae: 132.6525\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35359.0664 - mae: 130.3593 - val_loss: 37106.6250 - val_mae: 132.6473\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35357.2148 - mae: 130.3545 - val_loss: 37104.6953 - val_mae: 132.6422\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35355.4141 - mae: 130.3497 - val_loss: 37102.7070 - val_mae: 132.6370\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35353.5391 - mae: 130.3449 - val_loss: 37100.7617 - val_mae: 132.6318\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35351.7148 - mae: 130.3401 - val_loss: 37098.8047 - val_mae: 132.6266\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35349.8711 - mae: 130.3353 - val_loss: 37096.8516 - val_mae: 132.6215\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35348.0234 - mae: 130.3305 - val_loss: 37094.9023 - val_mae: 132.6163\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35346.1992 - mae: 130.3257 - val_loss: 37092.9492 - val_mae: 132.6112\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35344.3555 - mae: 130.3210 - val_loss: 37090.9961 - val_mae: 132.6060\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35342.5430 - mae: 130.3162 - val_loss: 37089.0156 - val_mae: 132.6008\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35340.6719 - mae: 130.3114 - val_loss: 37087.0898 - val_mae: 132.5956\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35338.8398 - mae: 130.3067 - val_loss: 37085.1328 - val_mae: 132.5905\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35337.0234 - mae: 130.3019 - val_loss: 37083.1680 - val_mae: 132.5853\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35335.1797 - mae: 130.2971 - val_loss: 37081.1992 - val_mae: 132.5801\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35333.3203 - mae: 130.2923 - val_loss: 37079.2578 - val_mae: 132.5749\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35331.4883 - mae: 130.2875 - val_loss: 37077.3164 - val_mae: 132.5698\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35329.6641 - mae: 130.2827 - val_loss: 37075.3516 - val_mae: 132.5646\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35327.8203 - mae: 130.2780 - val_loss: 37073.3711 - val_mae: 132.5594\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35325.9688 - mae: 130.2731 - val_loss: 37071.4219 - val_mae: 132.5542\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35324.1133 - mae: 130.2683 - val_loss: 37069.4883 - val_mae: 132.5491\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35322.3008 - mae: 130.2636 - val_loss: 37067.5117 - val_mae: 132.5439\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35320.4648 - mae: 130.2588 - val_loss: 37065.5352 - val_mae: 132.5387\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35318.5938 - mae: 130.2540 - val_loss: 37063.5898 - val_mae: 132.5335\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35316.7656 - mae: 130.2492 - val_loss: 37061.6094 - val_mae: 132.5283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35314.8984 - mae: 130.2444 - val_loss: 37059.6523 - val_mae: 132.5231\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35313.0625 - mae: 130.2397 - val_loss: 37057.6758 - val_mae: 132.5179\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35311.2188 - mae: 130.2348 - val_loss: 37055.7070 - val_mae: 132.5127\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35309.3555 - mae: 130.2300 - val_loss: 37053.7695 - val_mae: 132.5076\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35307.5469 - mae: 130.2253 - val_loss: 37051.8008 - val_mae: 132.5024\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35305.6953 - mae: 130.2205 - val_loss: 37049.8477 - val_mae: 132.4972\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35303.8555 - mae: 130.2157 - val_loss: 37047.9102 - val_mae: 132.4921\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35302.0469 - mae: 130.2110 - val_loss: 37045.9414 - val_mae: 132.4869\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35300.1875 - mae: 130.2062 - val_loss: 37043.9766 - val_mae: 132.4817\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35298.3555 - mae: 130.2014 - val_loss: 37042.0312 - val_mae: 132.4765\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35296.5312 - mae: 130.1966 - val_loss: 37040.0977 - val_mae: 132.4714\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35294.7031 - mae: 130.1918 - val_loss: 37038.1562 - val_mae: 132.4662\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35292.8867 - mae: 130.1871 - val_loss: 37036.1914 - val_mae: 132.4610\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35291.0195 - mae: 130.1823 - val_loss: 37034.2578 - val_mae: 132.4559\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35289.1992 - mae: 130.1775 - val_loss: 37032.3008 - val_mae: 132.4508\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35287.3672 - mae: 130.1727 - val_loss: 37030.3555 - val_mae: 132.4456\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35285.5352 - mae: 130.1680 - val_loss: 37028.3906 - val_mae: 132.4404\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35283.6914 - mae: 130.1632 - val_loss: 37026.4336 - val_mae: 132.4352\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35281.8477 - mae: 130.1584 - val_loss: 37024.5000 - val_mae: 132.4301\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35280.0156 - mae: 130.1536 - val_loss: 37022.5312 - val_mae: 132.4249\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35278.1680 - mae: 130.1488 - val_loss: 37020.5859 - val_mae: 132.4197\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35276.3203 - mae: 130.1440 - val_loss: 37018.6328 - val_mae: 132.4146\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35274.5156 - mae: 130.1393 - val_loss: 37016.6484 - val_mae: 132.4093\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35272.6406 - mae: 130.1344 - val_loss: 37014.6914 - val_mae: 132.4041\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35270.8047 - mae: 130.1297 - val_loss: 37012.7305 - val_mae: 132.3990\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35268.9844 - mae: 130.1249 - val_loss: 37010.7695 - val_mae: 132.3938\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35267.1289 - mae: 130.1201 - val_loss: 37008.8203 - val_mae: 132.3886\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35265.2969 - mae: 130.1153 - val_loss: 37006.8594 - val_mae: 132.3834\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35263.4531 - mae: 130.1105 - val_loss: 37004.9219 - val_mae: 132.3783\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35261.6250 - mae: 130.1058 - val_loss: 37002.9570 - val_mae: 132.3731\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35259.7891 - mae: 130.1010 - val_loss: 37000.9844 - val_mae: 132.3679\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35257.9414 - mae: 130.0962 - val_loss: 36999.0273 - val_mae: 132.3627\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35256.1055 - mae: 130.0914 - val_loss: 36997.0625 - val_mae: 132.3575\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35254.2578 - mae: 130.0867 - val_loss: 36995.1094 - val_mae: 132.3524\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35252.4102 - mae: 130.0818 - val_loss: 36993.1797 - val_mae: 132.3472\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35250.5938 - mae: 130.0771 - val_loss: 36991.2344 - val_mae: 132.3421\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35248.7617 - mae: 130.0723 - val_loss: 36989.2812 - val_mae: 132.3369\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35246.9219 - mae: 130.0676 - val_loss: 36987.3203 - val_mae: 132.3317\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35245.0781 - mae: 130.0628 - val_loss: 36985.3477 - val_mae: 132.3265\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35243.2422 - mae: 130.0579 - val_loss: 36983.3828 - val_mae: 132.3213\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35241.3828 - mae: 130.0531 - val_loss: 36981.4453 - val_mae: 132.3162\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35239.5625 - mae: 130.0484 - val_loss: 36979.5156 - val_mae: 132.3111\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 1719.3008 - mae: 30.5284 - val_loss: 1615.2837 - val_mae: 29.2369\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1534.8593 - mae: 29.3295 - val_loss: 1434.7665 - val_mae: 28.0377\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1371.7544 - mae: 28.1853 - val_loss: 1279.1993 - val_mae: 26.9244\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1232.2872 - mae: 27.1349 - val_loss: 1145.0541 - val_mae: 25.8892\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1113.6516 - mae: 26.1781 - val_loss: 1032.9431 - val_mae: 24.9568\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1012.7225 - mae: 25.3025 - val_loss: 935.6929 - val_mae: 24.0881\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 926.1849 - mae: 24.5021 - val_loss: 852.8185 - val_mae: 23.2922\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 851.9440 - mae: 23.7561 - val_loss: 779.7769 - val_mae: 22.5433\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 788.7297 - mae: 23.0801 - val_loss: 718.8682 - val_mae: 21.8744\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 734.8467 - mae: 22.4655 - val_loss: 666.2496 - val_mae: 21.2572\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.1958 - mae: 21.8981 - val_loss: 619.9491 - val_mae: 20.6811\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.4358 - mae: 21.3841 - val_loss: 581.2155 - val_mae: 20.1667\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.7783 - mae: 20.9097 - val_loss: 546.9351 - val_mae: 19.6854\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.2239 - mae: 20.4839 - val_loss: 517.8970 - val_mae: 19.2497\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 560.1763 - mae: 20.0942 - val_loss: 492.7189 - val_mae: 18.8483\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 538.3877 - mae: 19.7335 - val_loss: 470.3839 - val_mae: 18.4762\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.5640 - mae: 19.4088 - val_loss: 451.2177 - val_mae: 18.1371\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.4991 - mae: 19.1145 - val_loss: 434.3112 - val_mae: 17.8224\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.6814 - mae: 18.8499 - val_loss: 419.9675 - val_mae: 17.5437\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 477.6618 - mae: 18.6069 - val_loss: 407.2952 - val_mae: 17.2863\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.1985 - mae: 18.3880 - val_loss: 396.1077 - val_mae: 17.0503\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.0597 - mae: 18.1893 - val_loss: 386.1854 - val_mae: 16.8325\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.1119 - mae: 18.0115 - val_loss: 377.3792 - val_mae: 16.6354\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.1801 - mae: 17.8512 - val_loss: 369.8171 - val_mae: 16.4564\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.1735 - mae: 17.7045 - val_loss: 363.0620 - val_mae: 16.2941\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.8432 - mae: 17.5709 - val_loss: 357.0781 - val_mae: 16.1473\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.1479 - mae: 17.4513 - val_loss: 351.7959 - val_mae: 16.0115\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.9422 - mae: 17.3429 - val_loss: 346.7105 - val_mae: 15.8825\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.2196 - mae: 17.2427 - val_loss: 342.4322 - val_mae: 15.7696\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.9869 - mae: 17.1526 - val_loss: 338.6569 - val_mae: 15.6699\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.0497 - mae: 17.0698 - val_loss: 335.2083 - val_mae: 15.5775\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.3992 - mae: 16.9951 - val_loss: 331.9955 - val_mae: 15.4924\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.0023 - mae: 16.9259 - val_loss: 328.9941 - val_mae: 15.4123\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.8492 - mae: 16.8628 - val_loss: 326.3480 - val_mae: 15.3411\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.9320 - mae: 16.8050 - val_loss: 323.9838 - val_mae: 15.2767\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.1762 - mae: 16.7532 - val_loss: 321.8292 - val_mae: 15.2182\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.5341 - mae: 16.7051 - val_loss: 319.7097 - val_mae: 15.1618\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.0005 - mae: 16.6598 - val_loss: 317.7305 - val_mae: 15.1112\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.6214 - mae: 16.6187 - val_loss: 315.9041 - val_mae: 15.0631\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.3215 - mae: 16.5789 - val_loss: 314.2922 - val_mae: 15.0204\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.1644 - mae: 16.5441 - val_loss: 312.7392 - val_mae: 14.9800\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.0203 - mae: 16.5101 - val_loss: 311.3153 - val_mae: 14.9421\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.9869 - mae: 16.4794 - val_loss: 310.0000 - val_mae: 14.9076\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.0418 - mae: 16.4506 - val_loss: 308.7603 - val_mae: 14.8749\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.1443 - mae: 16.4231 - val_loss: 307.6293 - val_mae: 14.8438\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.2361 - mae: 16.3966 - val_loss: 306.4881 - val_mae: 14.8142\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.3792 - mae: 16.3720 - val_loss: 305.3162 - val_mae: 14.7846\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.5936 - mae: 16.3485 - val_loss: 304.2370 - val_mae: 14.7567\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.7938 - mae: 16.3251 - val_loss: 303.2067 - val_mae: 14.7310\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.0335 - mae: 16.3053 - val_loss: 302.2515 - val_mae: 14.7078\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.2943 - mae: 16.2843 - val_loss: 301.2840 - val_mae: 14.6830\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.5837 - mae: 16.2654 - val_loss: 300.3076 - val_mae: 14.6599\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.9045 - mae: 16.2462 - val_loss: 299.4566 - val_mae: 14.6384\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.2995 - mae: 16.2296 - val_loss: 298.7086 - val_mae: 14.6200\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.6668 - mae: 16.2116 - val_loss: 297.8645 - val_mae: 14.5995\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.0376 - mae: 16.1946 - val_loss: 297.0427 - val_mae: 14.5796\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.4615 - mae: 16.1788 - val_loss: 296.2662 - val_mae: 14.5604\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.8531 - mae: 16.1627 - val_loss: 295.4906 - val_mae: 14.5420\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.2791 - mae: 16.1463 - val_loss: 294.8420 - val_mae: 14.5258\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.7418 - mae: 16.1324 - val_loss: 294.1173 - val_mae: 14.5088\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 380.1854 - mae: 16.1178 - val_loss: 293.5038 - val_mae: 14.4938\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.6740 - mae: 16.1038 - val_loss: 292.8358 - val_mae: 14.4777\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.1412 - mae: 16.0895 - val_loss: 292.2195 - val_mae: 14.4623\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.6236 - mae: 16.0760 - val_loss: 291.5489 - val_mae: 14.4465\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.1209 - mae: 16.0625 - val_loss: 290.8874 - val_mae: 14.4309\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.6398 - mae: 16.0497 - val_loss: 290.3469 - val_mae: 14.4173\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.1382 - mae: 16.0372 - val_loss: 289.7304 - val_mae: 14.4026\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.6589 - mae: 16.0239 - val_loss: 289.1745 - val_mae: 14.3881\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 376.1840 - mae: 16.0117 - val_loss: 288.5637 - val_mae: 14.3736\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.7044 - mae: 15.9987 - val_loss: 288.0234 - val_mae: 14.3593\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.2466 - mae: 15.9862 - val_loss: 287.4407 - val_mae: 14.3447\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.7527 - mae: 15.9732 - val_loss: 286.8601 - val_mae: 14.3300\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.2912 - mae: 15.9605 - val_loss: 286.2708 - val_mae: 14.3153\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.8031 - mae: 15.9472 - val_loss: 285.7324 - val_mae: 14.3014\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.3607 - mae: 15.9354 - val_loss: 285.1823 - val_mae: 14.2873\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 372.8674 - mae: 15.9227 - val_loss: 284.5994 - val_mae: 14.2728\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.3911 - mae: 15.9116 - val_loss: 284.0460 - val_mae: 14.2593\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.8989 - mae: 15.8984 - val_loss: 283.5006 - val_mae: 14.2449\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.4424 - mae: 15.8849 - val_loss: 282.9659 - val_mae: 14.2303\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.9629 - mae: 15.8721 - val_loss: 282.3995 - val_mae: 14.2159\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.4916 - mae: 15.8599 - val_loss: 281.8901 - val_mae: 14.2021\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.0231 - mae: 15.8474 - val_loss: 281.3781 - val_mae: 14.1881\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.5346 - mae: 15.8346 - val_loss: 280.7978 - val_mae: 14.1726\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.0608 - mae: 15.8211 - val_loss: 280.2694 - val_mae: 14.1575\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.5835 - mae: 15.8077 - val_loss: 279.7548 - val_mae: 14.1430\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.0874 - mae: 15.7946 - val_loss: 279.2687 - val_mae: 14.1296\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.5915 - mae: 15.7810 - val_loss: 278.7319 - val_mae: 14.1146\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.1128 - mae: 15.7674 - val_loss: 278.1960 - val_mae: 14.0994\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 366.6184 - mae: 15.7545 - val_loss: 277.7177 - val_mae: 14.0853\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 366.1472 - mae: 15.7408 - val_loss: 277.2471 - val_mae: 14.0708\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.6563 - mae: 15.7270 - val_loss: 276.7162 - val_mae: 14.0555\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.1675 - mae: 15.7133 - val_loss: 276.2000 - val_mae: 14.0402\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.6851 - mae: 15.6999 - val_loss: 275.6881 - val_mae: 14.0252\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 364.2198 - mae: 15.6856 - val_loss: 275.1649 - val_mae: 14.0090\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.7381 - mae: 15.6719 - val_loss: 274.7047 - val_mae: 13.9948\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.2464 - mae: 15.6574 - val_loss: 274.1870 - val_mae: 13.9789\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.7884 - mae: 15.6440 - val_loss: 273.6961 - val_mae: 13.9636\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.3193 - mae: 15.6312 - val_loss: 273.2280 - val_mae: 13.9495\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.8645 - mae: 15.6168 - val_loss: 272.7388 - val_mae: 13.9340\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.3839 - mae: 15.6040 - val_loss: 272.2618 - val_mae: 13.9199\n",
      "5/5 [==============================] - 0s 996us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   4.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 1702.2878 - mae: 31.7019 - val_loss: 1618.0276 - val_mae: 30.3368\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1531.6154 - mae: 30.4855 - val_loss: 1442.7412 - val_mae: 29.0834\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1380.2249 - mae: 29.3134 - val_loss: 1292.7255 - val_mae: 27.9295\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1250.2646 - mae: 28.2462 - val_loss: 1162.9399 - val_mae: 26.8564\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1139.4166 - mae: 27.2554 - val_loss: 1052.4030 - val_mae: 25.8748\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1044.4867 - mae: 26.3553 - val_loss: 956.5093 - val_mae: 24.9633\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 963.5266 - mae: 25.5358 - val_loss: 875.3719 - val_mae: 24.1361\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 894.2959 - mae: 24.7847 - val_loss: 804.3450 - val_mae: 23.3610\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 834.7309 - mae: 24.0992 - val_loss: 743.9586 - val_mae: 22.6605\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 783.7316 - mae: 23.4927 - val_loss: 692.2277 - val_mae: 22.0213\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 739.9140 - mae: 22.9290 - val_loss: 646.4523 - val_mae: 21.4251\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 702.0204 - mae: 22.4164 - val_loss: 606.8478 - val_mae: 20.8815\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 669.5067 - mae: 21.9498 - val_loss: 572.5073 - val_mae: 20.3855\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 641.4908 - mae: 21.5402 - val_loss: 543.3917 - val_mae: 19.9425\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 617.2227 - mae: 21.1610 - val_loss: 517.4892 - val_mae: 19.5280\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 596.5408 - mae: 20.8166 - val_loss: 495.0137 - val_mae: 19.1530\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 578.5463 - mae: 20.5123 - val_loss: 475.6701 - val_mae: 18.8164\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 562.9705 - mae: 20.2417 - val_loss: 458.9774 - val_mae: 18.5148\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 549.3467 - mae: 19.9895 - val_loss: 443.5535 - val_mae: 18.2265\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 537.3916 - mae: 19.7675 - val_loss: 430.4763 - val_mae: 17.9739\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.2117 - mae: 19.5662 - val_loss: 418.6906 - val_mae: 17.7421\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 518.2443 - mae: 19.3861 - val_loss: 408.6982 - val_mae: 17.5400\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 510.3318 - mae: 19.2242 - val_loss: 399.5650 - val_mae: 17.3528\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 503.4731 - mae: 19.0802 - val_loss: 391.7491 - val_mae: 17.1901\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.4300 - mae: 18.9500 - val_loss: 384.6306 - val_mae: 17.0391\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.0698 - mae: 18.8356 - val_loss: 378.1023 - val_mae: 16.8999\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 487.3130 - mae: 18.7304 - val_loss: 372.4637 - val_mae: 16.7757\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 483.2039 - mae: 18.6380 - val_loss: 367.5292 - val_mae: 16.6653\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.4771 - mae: 18.5523 - val_loss: 362.8062 - val_mae: 16.5588\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 476.1901 - mae: 18.4751 - val_loss: 358.7504 - val_mae: 16.4655\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 473.3059 - mae: 18.4075 - val_loss: 355.1088 - val_mae: 16.3802\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 470.6877 - mae: 18.3433 - val_loss: 351.8205 - val_mae: 16.3021\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.2794 - mae: 18.2834 - val_loss: 348.7545 - val_mae: 16.2283\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.0596 - mae: 18.2297 - val_loss: 345.9528 - val_mae: 16.1622\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.1138 - mae: 18.1803 - val_loss: 343.4271 - val_mae: 16.1013\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.2892 - mae: 18.1355 - val_loss: 340.9944 - val_mae: 16.0430\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.6001 - mae: 18.0926 - val_loss: 338.8367 - val_mae: 15.9896\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 459.0945 - mae: 18.0546 - val_loss: 336.8716 - val_mae: 15.9418\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 457.6581 - mae: 18.0160 - val_loss: 334.9553 - val_mae: 15.8929\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 456.3219 - mae: 17.9805 - val_loss: 333.1448 - val_mae: 15.8466\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 455.0442 - mae: 17.9469 - val_loss: 331.4030 - val_mae: 15.8025\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.8735 - mae: 17.9161 - val_loss: 329.8808 - val_mae: 15.7632\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.7688 - mae: 17.8860 - val_loss: 328.3931 - val_mae: 15.7238\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.7292 - mae: 17.8577 - val_loss: 326.9716 - val_mae: 15.6861\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.7510 - mae: 17.8305 - val_loss: 325.6707 - val_mae: 15.6510\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 449.8374 - mae: 17.8044 - val_loss: 324.4264 - val_mae: 15.6182\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.9733 - mae: 17.7808 - val_loss: 323.3587 - val_mae: 15.5893\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.1479 - mae: 17.7572 - val_loss: 322.2627 - val_mae: 15.5598\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.3736 - mae: 17.7347 - val_loss: 321.2322 - val_mae: 15.5321\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.6308 - mae: 17.7145 - val_loss: 320.3009 - val_mae: 15.5066\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.9198 - mae: 17.6949 - val_loss: 319.3791 - val_mae: 15.4818\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.2672 - mae: 17.6756 - val_loss: 318.4877 - val_mae: 15.4571\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.5464 - mae: 17.6558 - val_loss: 317.5895 - val_mae: 15.4341\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.8671 - mae: 17.6381 - val_loss: 316.7705 - val_mae: 15.4129\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.2350 - mae: 17.6214 - val_loss: 315.9547 - val_mae: 15.3914\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.6213 - mae: 17.6035 - val_loss: 315.2344 - val_mae: 15.3717\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.0219 - mae: 17.5876 - val_loss: 314.4590 - val_mae: 15.3518\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.4377 - mae: 17.5720 - val_loss: 313.7443 - val_mae: 15.3330\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.8750 - mae: 17.5561 - val_loss: 313.0452 - val_mae: 15.3147\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.3441 - mae: 17.5417 - val_loss: 312.4256 - val_mae: 15.2988\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 439.8069 - mae: 17.5278 - val_loss: 311.8663 - val_mae: 15.2842\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.2908 - mae: 17.5147 - val_loss: 311.2393 - val_mae: 15.2680\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.7753 - mae: 17.5008 - val_loss: 310.6217 - val_mae: 15.2518\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 438.2900 - mae: 17.4890 - val_loss: 310.0563 - val_mae: 15.2370\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.7824 - mae: 17.4747 - val_loss: 309.4332 - val_mae: 15.2201\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.3366 - mae: 17.4619 - val_loss: 308.9224 - val_mae: 15.2057\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.8445 - mae: 17.4499 - val_loss: 308.3985 - val_mae: 15.1917\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.3827 - mae: 17.4381 - val_loss: 307.8588 - val_mae: 15.1769\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.9250 - mae: 17.4251 - val_loss: 307.3487 - val_mae: 15.1623\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.4958 - mae: 17.4137 - val_loss: 306.8589 - val_mae: 15.1491\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.0395 - mae: 17.4030 - val_loss: 306.4377 - val_mae: 15.1383\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.6287 - mae: 17.3933 - val_loss: 306.0134 - val_mae: 15.1262\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.1906 - mae: 17.3818 - val_loss: 305.4600 - val_mae: 15.1115\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.7688 - mae: 17.3714 - val_loss: 305.0296 - val_mae: 15.0998\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.3420 - mae: 17.3601 - val_loss: 304.5829 - val_mae: 15.0872\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.9182 - mae: 17.3499 - val_loss: 304.1776 - val_mae: 15.0750\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.5085 - mae: 17.3386 - val_loss: 303.6983 - val_mae: 15.0612\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.1028 - mae: 17.3279 - val_loss: 303.2669 - val_mae: 15.0492\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.6970 - mae: 17.3182 - val_loss: 302.8461 - val_mae: 15.0374\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.3129 - mae: 17.3083 - val_loss: 302.4009 - val_mae: 15.0248\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.9284 - mae: 17.2972 - val_loss: 302.0336 - val_mae: 15.0132\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.5680 - mae: 17.2864 - val_loss: 301.6114 - val_mae: 15.0005\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.1968 - mae: 17.2765 - val_loss: 301.2001 - val_mae: 14.9884\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.8019 - mae: 17.2666 - val_loss: 300.8257 - val_mae: 14.9775\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.4388 - mae: 17.2576 - val_loss: 300.4452 - val_mae: 14.9658\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.0701 - mae: 17.2470 - val_loss: 300.0916 - val_mae: 14.9543\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.7154 - mae: 17.2374 - val_loss: 299.7154 - val_mae: 14.9426\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.3366 - mae: 17.2270 - val_loss: 299.3342 - val_mae: 14.9306\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.9753 - mae: 17.2174 - val_loss: 298.9332 - val_mae: 14.9186\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.6328 - mae: 17.2069 - val_loss: 298.5873 - val_mae: 14.9070\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.2901 - mae: 17.1973 - val_loss: 298.2215 - val_mae: 14.8952\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.9709 - mae: 17.1881 - val_loss: 297.8871 - val_mae: 14.8843\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.6395 - mae: 17.1782 - val_loss: 297.5174 - val_mae: 14.8722\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.3042 - mae: 17.1690 - val_loss: 297.2109 - val_mae: 14.8619\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.9674 - mae: 17.1595 - val_loss: 296.8721 - val_mae: 14.8511\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.6340 - mae: 17.1503 - val_loss: 296.5522 - val_mae: 14.8405\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 425.3119 - mae: 17.1416 - val_loss: 296.2231 - val_mae: 14.8298\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.9941 - mae: 17.1322 - val_loss: 295.9471 - val_mae: 14.8205\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.7007 - mae: 17.1234 - val_loss: 295.6151 - val_mae: 14.8096\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.3636 - mae: 17.1150 - val_loss: 295.3663 - val_mae: 14.8014\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1644.3918 - mae: 30.5804 - val_loss: 1596.2202 - val_mae: 30.1138\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1476.0242 - mae: 29.3568 - val_loss: 1423.4982 - val_mae: 28.8680\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1326.4310 - mae: 28.2048 - val_loss: 1277.3932 - val_mae: 27.7335\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1198.6226 - mae: 27.1563 - val_loss: 1152.6351 - val_mae: 26.6986\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1088.8448 - mae: 26.1865 - val_loss: 1044.8171 - val_mae: 25.7487\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 994.4784 - mae: 25.3078 - val_loss: 952.6460 - val_mae: 24.8800\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 913.3496 - mae: 24.4792 - val_loss: 871.2406 - val_mae: 24.0656\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 843.3988 - mae: 23.7259 - val_loss: 802.6352 - val_mae: 23.3269\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 784.0242 - mae: 23.0417 - val_loss: 744.2139 - val_mae: 22.6564\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 732.8367 - mae: 22.4285 - val_loss: 694.3696 - val_mae: 22.0487\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.7742 - mae: 21.8673 - val_loss: 651.3820 - val_mae: 21.4895\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.6399 - mae: 21.3439 - val_loss: 613.5542 - val_mae: 20.9692\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 617.3994 - mae: 20.8711 - val_loss: 580.6507 - val_mae: 20.4950\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.8418 - mae: 20.4366 - val_loss: 552.2490 - val_mae: 20.0648\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.0766 - mae: 20.0448 - val_loss: 528.2101 - val_mae: 19.6801\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.5682 - mae: 19.6909 - val_loss: 506.9928 - val_mae: 19.3217\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 524.0659 - mae: 19.3703 - val_loss: 489.0945 - val_mae: 19.0033\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 507.9983 - mae: 19.0799 - val_loss: 473.3564 - val_mae: 18.7120\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 493.9103 - mae: 18.8174 - val_loss: 459.5585 - val_mae: 18.4471\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 481.6028 - mae: 18.5784 - val_loss: 447.4744 - val_mae: 18.2061\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 470.6897 - mae: 18.3657 - val_loss: 436.9586 - val_mae: 17.9875\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.0968 - mae: 18.1694 - val_loss: 427.7357 - val_mae: 17.7867\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.6360 - mae: 17.9937 - val_loss: 419.4826 - val_mae: 17.6014\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.2708 - mae: 17.8351 - val_loss: 412.4834 - val_mae: 17.4393\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.8054 - mae: 17.6926 - val_loss: 406.2921 - val_mae: 17.2925\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.0251 - mae: 17.5618 - val_loss: 400.8504 - val_mae: 17.1601\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.8309 - mae: 17.4444 - val_loss: 395.8184 - val_mae: 17.0354\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.1651 - mae: 17.3357 - val_loss: 391.5077 - val_mae: 16.9265\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.9617 - mae: 17.2363 - val_loss: 387.6414 - val_mae: 16.8258\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.0789 - mae: 17.1452 - val_loss: 384.0615 - val_mae: 16.7296\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.6453 - mae: 17.0614 - val_loss: 380.9826 - val_mae: 16.6442\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.4892 - mae: 16.9845 - val_loss: 378.1932 - val_mae: 16.5654\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.6206 - mae: 16.9142 - val_loss: 375.6030 - val_mae: 16.4915\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.9516 - mae: 16.8482 - val_loss: 373.3488 - val_mae: 16.4253\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.5498 - mae: 16.7866 - val_loss: 371.3131 - val_mae: 16.3643\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.2976 - mae: 16.7287 - val_loss: 369.3598 - val_mae: 16.3047\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.2229 - mae: 16.6762 - val_loss: 367.5971 - val_mae: 16.2512\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.2438 - mae: 16.6260 - val_loss: 365.9523 - val_mae: 16.1995\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.3848 - mae: 16.5781 - val_loss: 364.3742 - val_mae: 16.1489\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.6204 - mae: 16.5327 - val_loss: 362.9703 - val_mae: 16.1024\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.0007 - mae: 16.4893 - val_loss: 361.6263 - val_mae: 16.0577\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.4702 - mae: 16.4504 - val_loss: 360.3425 - val_mae: 16.0162\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.0031 - mae: 16.4121 - val_loss: 359.1635 - val_mae: 15.9770\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.6301 - mae: 16.3762 - val_loss: 358.0427 - val_mae: 15.9401\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.3266 - mae: 16.3411 - val_loss: 356.9803 - val_mae: 15.9046\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.0601 - mae: 16.3094 - val_loss: 355.9542 - val_mae: 15.8713\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.8394 - mae: 16.2755 - val_loss: 354.9815 - val_mae: 15.8398\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.6705 - mae: 16.2462 - val_loss: 354.0591 - val_mae: 15.8116\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.5282 - mae: 16.2163 - val_loss: 353.1924 - val_mae: 15.7842\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.4387 - mae: 16.1880 - val_loss: 352.3333 - val_mae: 15.7570\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.3683 - mae: 16.1602 - val_loss: 351.5327 - val_mae: 15.7314\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.3665 - mae: 16.1331 - val_loss: 350.7545 - val_mae: 15.7069\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.3411 - mae: 16.1060 - val_loss: 349.9728 - val_mae: 15.6822\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.3577 - mae: 16.0804 - val_loss: 349.2464 - val_mae: 15.6591\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.4284 - mae: 16.0550 - val_loss: 348.5370 - val_mae: 15.6375\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.5011 - mae: 16.0303 - val_loss: 347.8516 - val_mae: 15.6164\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.6272 - mae: 16.0059 - val_loss: 347.1849 - val_mae: 15.5960\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.7592 - mae: 15.9825 - val_loss: 346.5189 - val_mae: 15.5759\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.8849 - mae: 15.9586 - val_loss: 345.8715 - val_mae: 15.5561\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.0593 - mae: 15.9360 - val_loss: 345.2159 - val_mae: 15.5357\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 367.2387 - mae: 15.9138 - val_loss: 344.5969 - val_mae: 15.5169\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.4523 - mae: 15.8919 - val_loss: 344.0037 - val_mae: 15.4983\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.6776 - mae: 15.8709 - val_loss: 343.4092 - val_mae: 15.4805\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.9107 - mae: 15.8500 - val_loss: 342.8293 - val_mae: 15.4626\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.1888 - mae: 15.8299 - val_loss: 342.2540 - val_mae: 15.4451\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.4440 - mae: 15.8095 - val_loss: 341.6842 - val_mae: 15.4276\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.6958 - mae: 15.7890 - val_loss: 341.1346 - val_mae: 15.4112\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.9232 - mae: 15.7680 - val_loss: 340.5573 - val_mae: 15.3939\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.1832 - mae: 15.7482 - val_loss: 339.9684 - val_mae: 15.3764\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.4176 - mae: 15.7275 - val_loss: 339.3742 - val_mae: 15.3580\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.6747 - mae: 15.7068 - val_loss: 338.7746 - val_mae: 15.3395\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.9015 - mae: 15.6848 - val_loss: 338.1746 - val_mae: 15.3202\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.1490 - mae: 15.6641 - val_loss: 337.5697 - val_mae: 15.3012\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.3851 - mae: 15.6431 - val_loss: 336.9623 - val_mae: 15.2830\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.6171 - mae: 15.6209 - val_loss: 336.3383 - val_mae: 15.2646\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.8828 - mae: 15.5996 - val_loss: 335.7141 - val_mae: 15.2463\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 355.1245 - mae: 15.5784 - val_loss: 335.0723 - val_mae: 15.2265\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.3757 - mae: 15.5575 - val_loss: 334.4608 - val_mae: 15.2077\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.6344 - mae: 15.5359 - val_loss: 333.8624 - val_mae: 15.1889\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.8944 - mae: 15.5142 - val_loss: 333.2888 - val_mae: 15.1708\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.1590 - mae: 15.4933 - val_loss: 332.7121 - val_mae: 15.1528\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.4260 - mae: 15.4722 - val_loss: 332.1285 - val_mae: 15.1349\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.6978 - mae: 15.4507 - val_loss: 331.5365 - val_mae: 15.1162\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.9843 - mae: 15.4304 - val_loss: 330.9625 - val_mae: 15.0982\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.2553 - mae: 15.4096 - val_loss: 330.3818 - val_mae: 15.0793\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.5287 - mae: 15.3899 - val_loss: 329.8014 - val_mae: 15.0610\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.7857 - mae: 15.3678 - val_loss: 329.2385 - val_mae: 15.0422\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.0440 - mae: 15.3464 - val_loss: 328.6483 - val_mae: 15.0230\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.3463 - mae: 15.3267 - val_loss: 328.0999 - val_mae: 15.0043\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 345.6574 - mae: 15.3063 - val_loss: 327.5750 - val_mae: 14.9856\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 345.0219 - mae: 15.2872 - val_loss: 327.0771 - val_mae: 14.9681\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 344.4111 - mae: 15.2692 - val_loss: 326.5957 - val_mae: 14.9510\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.8246 - mae: 15.2508 - val_loss: 326.1584 - val_mae: 14.9349\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.2597 - mae: 15.2333 - val_loss: 325.7337 - val_mae: 14.9204\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.7210 - mae: 15.2178 - val_loss: 325.3220 - val_mae: 14.9072\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.1856 - mae: 15.2012 - val_loss: 324.9303 - val_mae: 14.8944\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.6831 - mae: 15.1857 - val_loss: 324.5606 - val_mae: 14.8818\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.2040 - mae: 15.1718 - val_loss: 324.2159 - val_mae: 14.8708\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.7276 - mae: 15.1575 - val_loss: 323.8732 - val_mae: 14.8593\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 340.2713 - mae: 15.1441 - val_loss: 323.5351 - val_mae: 14.8476\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   4.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 23ms/step - loss: 4176.2578 - mae: 50.2908 - val_loss: 3917.6826 - val_mae: 47.4459\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4108.5659 - mae: 49.9614 - val_loss: 3851.4595 - val_mae: 47.0988\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4040.4658 - mae: 49.6280 - val_loss: 3786.9253 - val_mae: 46.7572\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3973.4727 - mae: 49.2972 - val_loss: 3723.9661 - val_mae: 46.4205\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3909.4792 - mae: 48.9742 - val_loss: 3660.9155 - val_mae: 46.0795\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3843.8354 - mae: 48.6505 - val_loss: 3599.6042 - val_mae: 45.7559\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3780.5750 - mae: 48.3278 - val_loss: 3539.1001 - val_mae: 45.4342\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3719.7737 - mae: 48.0143 - val_loss: 3479.0037 - val_mae: 45.1218\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3657.9832 - mae: 47.6990 - val_loss: 3421.1462 - val_mae: 44.8244\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3597.8403 - mae: 47.3878 - val_loss: 3364.6580 - val_mae: 44.5310\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3538.5686 - mae: 47.0798 - val_loss: 3308.8521 - val_mae: 44.2381\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3481.3848 - mae: 46.7779 - val_loss: 3253.5374 - val_mae: 43.9448\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3423.3042 - mae: 46.4757 - val_loss: 3200.5491 - val_mae: 43.6606\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3368.7329 - mae: 46.1834 - val_loss: 3147.5786 - val_mae: 43.3677\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3313.3447 - mae: 45.8882 - val_loss: 3095.8259 - val_mae: 43.0714\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3259.4851 - mae: 45.5972 - val_loss: 3044.8369 - val_mae: 42.7764\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3207.0105 - mae: 45.3077 - val_loss: 2994.9465 - val_mae: 42.4848\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3155.7603 - mae: 45.0231 - val_loss: 2946.0122 - val_mae: 42.1958\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3105.1548 - mae: 44.7376 - val_loss: 2898.0767 - val_mae: 41.9097\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3055.5884 - mae: 44.4585 - val_loss: 2851.0745 - val_mae: 41.6263\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3006.8000 - mae: 44.1809 - val_loss: 2804.7871 - val_mae: 41.3443\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2958.2190 - mae: 43.8995 - val_loss: 2759.7458 - val_mae: 41.0785\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2910.7312 - mae: 43.6202 - val_loss: 2715.6687 - val_mae: 40.8157\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2865.3438 - mae: 43.3514 - val_loss: 2671.7952 - val_mae: 40.5515\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2819.8477 - mae: 43.0771 - val_loss: 2628.8079 - val_mae: 40.2920\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2774.6816 - mae: 42.8061 - val_loss: 2586.9114 - val_mae: 40.0498\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2730.3613 - mae: 42.5354 - val_loss: 2545.8276 - val_mae: 39.8100\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2688.7319 - mae: 42.2743 - val_loss: 2504.6626 - val_mae: 39.5673\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2644.7061 - mae: 42.0013 - val_loss: 2465.6731 - val_mae: 39.3345\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2604.5579 - mae: 41.7461 - val_loss: 2426.5598 - val_mae: 39.0990\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2563.4724 - mae: 41.4843 - val_loss: 2388.4402 - val_mae: 38.8668\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2523.9543 - mae: 41.2270 - val_loss: 2350.6050 - val_mae: 38.6340\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2484.0874 - mae: 40.9682 - val_loss: 2314.0505 - val_mae: 38.4064\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2445.3521 - mae: 40.7128 - val_loss: 2278.1021 - val_mae: 38.1803\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2407.4280 - mae: 40.4576 - val_loss: 2242.5007 - val_mae: 37.9539\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2369.7229 - mae: 40.2047 - val_loss: 2207.1572 - val_mae: 37.7160\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2332.9187 - mae: 39.9538 - val_loss: 2172.3220 - val_mae: 37.4790\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2297.0276 - mae: 39.7044 - val_loss: 2138.0522 - val_mae: 37.2436\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2261.4539 - mae: 39.4582 - val_loss: 2104.5645 - val_mae: 37.0111\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2226.6394 - mae: 39.2117 - val_loss: 2071.7595 - val_mae: 36.7810\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2192.5520 - mae: 38.9701 - val_loss: 2039.5999 - val_mae: 36.5531\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2158.8313 - mae: 38.7274 - val_loss: 2008.1869 - val_mae: 36.3283\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2126.1736 - mae: 38.4896 - val_loss: 1977.4321 - val_mae: 36.1059\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2093.5876 - mae: 38.2535 - val_loss: 1947.5865 - val_mae: 35.8879\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2062.5574 - mae: 38.0215 - val_loss: 1917.7275 - val_mae: 35.6675\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2031.5338 - mae: 37.7922 - val_loss: 1888.6432 - val_mae: 35.4506\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2001.4370 - mae: 37.5644 - val_loss: 1859.8472 - val_mae: 35.2337\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1971.2853 - mae: 37.3349 - val_loss: 1831.6600 - val_mae: 35.0191\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1941.9968 - mae: 37.1097 - val_loss: 1803.7427 - val_mae: 34.8042\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1913.0000 - mae: 36.8848 - val_loss: 1776.4297 - val_mae: 34.5918\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1884.0773 - mae: 36.6588 - val_loss: 1750.1030 - val_mae: 34.3851\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1856.5579 - mae: 36.4420 - val_loss: 1723.7935 - val_mae: 34.1761\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1829.1841 - mae: 36.2226 - val_loss: 1697.8615 - val_mae: 33.9680\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1801.8781 - mae: 36.0040 - val_loss: 1672.6061 - val_mae: 33.7632\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1775.3826 - mae: 35.7904 - val_loss: 1647.5813 - val_mae: 33.5580\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1749.2067 - mae: 35.5775 - val_loss: 1623.2321 - val_mae: 33.3563\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1723.8324 - mae: 35.3655 - val_loss: 1599.1390 - val_mae: 33.1544\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1698.8716 - mae: 35.1578 - val_loss: 1575.4648 - val_mae: 32.9539\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1673.6827 - mae: 34.9447 - val_loss: 1552.6608 - val_mae: 32.7588\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 1649.6558 - mae: 34.7398 - val_loss: 1529.9912 - val_mae: 32.5628\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1625.9000 - mae: 34.5347 - val_loss: 1507.3279 - val_mae: 32.3652\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1602.4686 - mae: 34.3290 - val_loss: 1485.0455 - val_mae: 32.1687\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1579.5306 - mae: 34.1274 - val_loss: 1463.1915 - val_mae: 31.9737\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1556.8842 - mae: 33.9258 - val_loss: 1441.8844 - val_mae: 31.7816\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1534.6902 - mae: 33.7273 - val_loss: 1421.0214 - val_mae: 31.5913\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1513.3309 - mae: 33.5340 - val_loss: 1400.3330 - val_mae: 31.4004\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1492.0054 - mae: 33.3372 - val_loss: 1380.3196 - val_mae: 31.2138\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1471.5624 - mae: 33.1490 - val_loss: 1360.1421 - val_mae: 31.0242\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1450.7515 - mae: 32.9553 - val_loss: 1340.6202 - val_mae: 30.8391\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1431.1284 - mae: 32.7694 - val_loss: 1321.0819 - val_mae: 30.6516\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1411.3251 - mae: 32.5791 - val_loss: 1301.6190 - val_mae: 30.4657\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1391.9973 - mae: 32.3948 - val_loss: 1282.3817 - val_mae: 30.2867\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1372.4187 - mae: 32.2047 - val_loss: 1263.9297 - val_mae: 30.1130\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1354.3394 - mae: 32.0255 - val_loss: 1245.3038 - val_mae: 29.9354\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1335.5601 - mae: 31.8385 - val_loss: 1227.4070 - val_mae: 29.7629\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1317.4620 - mae: 31.6580 - val_loss: 1209.8058 - val_mae: 29.5911\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1300.1277 - mae: 31.4805 - val_loss: 1192.2990 - val_mae: 29.4182\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1282.3972 - mae: 31.3011 - val_loss: 1175.4126 - val_mae: 29.2492\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1265.5444 - mae: 31.1253 - val_loss: 1158.8387 - val_mae: 29.0827\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1248.8467 - mae: 30.9505 - val_loss: 1142.6237 - val_mae: 28.9287\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1232.8264 - mae: 30.7779 - val_loss: 1126.5198 - val_mae: 28.7740\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1216.5227 - mae: 30.6045 - val_loss: 1111.0673 - val_mae: 28.6236\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1201.0643 - mae: 30.4353 - val_loss: 1095.8820 - val_mae: 28.4740\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1186.0867 - mae: 30.2689 - val_loss: 1080.8668 - val_mae: 28.3243\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1170.9398 - mae: 30.1003 - val_loss: 1066.3688 - val_mae: 28.1780\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1156.2798 - mae: 29.9371 - val_loss: 1052.2296 - val_mae: 28.0335\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1142.1375 - mae: 29.7776 - val_loss: 1038.2267 - val_mae: 27.8886\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1127.9799 - mae: 29.6182 - val_loss: 1024.5636 - val_mae: 27.7455\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1114.2089 - mae: 29.4599 - val_loss: 1011.1844 - val_mae: 27.6036\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1100.8755 - mae: 29.3032 - val_loss: 998.0732 - val_mae: 27.4629\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1087.5801 - mae: 29.1483 - val_loss: 985.1984 - val_mae: 27.3228\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1074.5016 - mae: 28.9921 - val_loss: 972.6581 - val_mae: 27.1848\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1061.8319 - mae: 28.8405 - val_loss: 960.3239 - val_mae: 27.0516\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1049.4502 - mae: 28.6885 - val_loss: 948.1367 - val_mae: 26.9195\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1037.0441 - mae: 28.5351 - val_loss: 936.3997 - val_mae: 26.7907\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1025.0311 - mae: 28.3888 - val_loss: 924.9144 - val_mae: 26.6630\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1013.3292 - mae: 28.2409 - val_loss: 913.5991 - val_mae: 26.5355\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1001.9594 - mae: 28.0969 - val_loss: 902.3484 - val_mae: 26.4071\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 990.4813 - mae: 27.9527 - val_loss: 891.5331 - val_mae: 26.2820\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 979.4494 - mae: 27.8117 - val_loss: 880.9390 - val_mae: 26.1579\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 1477.5596 - mae: 31.4140 - val_loss: 1477.4314 - val_mae: 31.0622\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1433.0734 - mae: 30.9237 - val_loss: 1428.9592 - val_mae: 30.5322\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1389.1772 - mae: 30.4513 - val_loss: 1382.3264 - val_mae: 30.0218\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1347.3051 - mae: 29.9896 - val_loss: 1337.7845 - val_mae: 29.5345\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1308.8066 - mae: 29.5460 - val_loss: 1294.9438 - val_mae: 29.0532\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1269.7632 - mae: 29.1183 - val_loss: 1254.8950 - val_mae: 28.6041\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1234.5447 - mae: 28.7300 - val_loss: 1215.8940 - val_mae: 28.1609\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1199.5886 - mae: 28.3426 - val_loss: 1179.3452 - val_mae: 27.7496\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1167.3948 - mae: 27.9841 - val_loss: 1143.9525 - val_mae: 27.3627\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1136.7706 - mae: 27.6285 - val_loss: 1110.0018 - val_mae: 27.0027\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1106.6227 - mae: 27.2837 - val_loss: 1078.2505 - val_mae: 26.6614\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1079.2273 - mae: 26.9600 - val_loss: 1047.6984 - val_mae: 26.3302\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1052.5193 - mae: 26.6505 - val_loss: 1018.8406 - val_mae: 26.0166\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1026.7687 - mae: 26.3508 - val_loss: 991.6387 - val_mae: 25.7178\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1003.2352 - mae: 26.0694 - val_loss: 965.5165 - val_mae: 25.4249\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 980.7725 - mae: 25.8037 - val_loss: 940.3041 - val_mae: 25.1436\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 958.8082 - mae: 25.5412 - val_loss: 916.4095 - val_mae: 24.8734\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 938.3325 - mae: 25.3017 - val_loss: 893.3458 - val_mae: 24.6056\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 918.5613 - mae: 25.0724 - val_loss: 871.2402 - val_mae: 24.3412\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 899.7446 - mae: 24.8514 - val_loss: 849.8301 - val_mae: 24.0788\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 881.7028 - mae: 24.6381 - val_loss: 829.5082 - val_mae: 23.8255\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 864.0987 - mae: 24.4305 - val_loss: 810.3992 - val_mae: 23.5980\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 848.0148 - mae: 24.2296 - val_loss: 791.6837 - val_mae: 23.3739\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 832.2169 - mae: 24.0365 - val_loss: 773.8929 - val_mae: 23.1622\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 817.4288 - mae: 23.8480 - val_loss: 756.6429 - val_mae: 22.9495\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 802.6291 - mae: 23.6570 - val_loss: 740.7426 - val_mae: 22.7537\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 789.5752 - mae: 23.4840 - val_loss: 725.0863 - val_mae: 22.5563\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 776.4589 - mae: 23.3093 - val_loss: 710.1562 - val_mae: 22.3621\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 764.0811 - mae: 23.1406 - val_loss: 696.1967 - val_mae: 22.1755\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 752.4343 - mae: 22.9782 - val_loss: 682.7271 - val_mae: 21.9939\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 741.0236 - mae: 22.8129 - val_loss: 669.8444 - val_mae: 21.8152\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 730.0424 - mae: 22.6562 - val_loss: 657.3554 - val_mae: 21.6389\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 719.4304 - mae: 22.5051 - val_loss: 645.3187 - val_mae: 21.4663\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 708.8773 - mae: 22.3562 - val_loss: 633.8202 - val_mae: 21.2986\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 699.3596 - mae: 22.2121 - val_loss: 622.4129 - val_mae: 21.1270\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5897 - mae: 22.0673 - val_loss: 611.5812 - val_mae: 20.9575\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3246 - mae: 21.9240 - val_loss: 601.1948 - val_mae: 20.7911\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 671.3853 - mae: 21.7896 - val_loss: 591.3516 - val_mae: 20.6304\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7464 - mae: 21.6527 - val_loss: 581.7854 - val_mae: 20.4714\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 654.6377 - mae: 21.5218 - val_loss: 572.3505 - val_mae: 20.3113\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 646.4426 - mae: 21.3942 - val_loss: 563.5840 - val_mae: 20.1611\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.3865 - mae: 21.2760 - val_loss: 554.7276 - val_mae: 20.0101\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 631.9969 - mae: 21.1601 - val_loss: 546.3999 - val_mae: 19.8717\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 624.7410 - mae: 21.0473 - val_loss: 538.6730 - val_mae: 19.7433\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 618.3387 - mae: 20.9376 - val_loss: 531.0460 - val_mae: 19.6159\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 611.9935 - mae: 20.8345 - val_loss: 523.6613 - val_mae: 19.4937\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 605.8734 - mae: 20.7360 - val_loss: 516.6805 - val_mae: 19.3737\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.1516 - mae: 20.6422 - val_loss: 509.7239 - val_mae: 19.2535\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 594.3190 - mae: 20.5531 - val_loss: 503.2888 - val_mae: 19.1434\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.8689 - mae: 20.4650 - val_loss: 497.1159 - val_mae: 19.0385\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.6732 - mae: 20.3832 - val_loss: 491.0923 - val_mae: 18.9340\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.7535 - mae: 20.3025 - val_loss: 485.0155 - val_mae: 18.8271\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8683 - mae: 20.2235 - val_loss: 479.0895 - val_mae: 18.7202\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.1426 - mae: 20.1460 - val_loss: 473.3073 - val_mae: 18.6130\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.4633 - mae: 20.0711 - val_loss: 467.9218 - val_mae: 18.5101\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.8237 - mae: 19.9965 - val_loss: 462.9863 - val_mae: 18.4137\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 555.8687 - mae: 19.9290 - val_loss: 457.6747 - val_mae: 18.3090\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 551.6060 - mae: 19.8562 - val_loss: 452.6707 - val_mae: 18.2080\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.5410 - mae: 19.7876 - val_loss: 447.8694 - val_mae: 18.1094\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.6204 - mae: 19.7204 - val_loss: 443.2998 - val_mae: 18.0133\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 539.8164 - mae: 19.6570 - val_loss: 438.9390 - val_mae: 17.9202\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.4216 - mae: 19.5940 - val_loss: 434.4443 - val_mae: 17.8252\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.8710 - mae: 19.5314 - val_loss: 430.1190 - val_mae: 17.7340\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 529.1363 - mae: 19.4641 - val_loss: 426.1987 - val_mae: 17.6506\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.8765 - mae: 19.4005 - val_loss: 422.1721 - val_mae: 17.5651\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 522.4968 - mae: 19.3367 - val_loss: 418.2438 - val_mae: 17.4822\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.9619 - mae: 19.2654 - val_loss: 414.0795 - val_mae: 17.3921\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 515.2392 - mae: 19.1871 - val_loss: 409.7925 - val_mae: 17.2975\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 510.9532 - mae: 19.0979 - val_loss: 405.0598 - val_mae: 17.1918\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.3612 - mae: 18.9988 - val_loss: 399.0148 - val_mae: 17.0593\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 500.9416 - mae: 18.8808 - val_loss: 392.8006 - val_mae: 16.9178\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 494.8776 - mae: 18.7517 - val_loss: 386.2203 - val_mae: 16.7675\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.3875 - mae: 18.6140 - val_loss: 379.2923 - val_mae: 16.6224\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 481.2129 - mae: 18.4534 - val_loss: 371.5104 - val_mae: 16.4610\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 473.1146 - mae: 18.2734 - val_loss: 363.8027 - val_mae: 16.2989\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.7767 - mae: 18.0832 - val_loss: 356.7475 - val_mae: 16.1423\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.3265 - mae: 17.9018 - val_loss: 350.3498 - val_mae: 15.9897\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.2961 - mae: 17.7322 - val_loss: 344.5175 - val_mae: 15.8390\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.0687 - mae: 17.5827 - val_loss: 339.4304 - val_mae: 15.6953\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.4465 - mae: 17.4437 - val_loss: 334.8004 - val_mae: 15.5620\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.7069 - mae: 17.3223 - val_loss: 330.5989 - val_mae: 15.4398\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.5107 - mae: 17.2066 - val_loss: 326.9362 - val_mae: 15.3362\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 425.8457 - mae: 17.1063 - val_loss: 323.5482 - val_mae: 15.2418\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.6567 - mae: 17.0186 - val_loss: 320.3836 - val_mae: 15.1443\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.5507 - mae: 16.9390 - val_loss: 317.5871 - val_mae: 15.0577\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.7740 - mae: 16.8689 - val_loss: 314.8957 - val_mae: 14.9808\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.9978 - mae: 16.8008 - val_loss: 312.3823 - val_mae: 14.9031\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.4162 - mae: 16.7366 - val_loss: 310.0079 - val_mae: 14.8215\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.1060 - mae: 16.6774 - val_loss: 307.7658 - val_mae: 14.7391\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.6010 - mae: 16.6133 - val_loss: 305.2877 - val_mae: 14.6451\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.2729 - mae: 16.5559 - val_loss: 302.8253 - val_mae: 14.5534\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.0053 - mae: 16.5022 - val_loss: 300.4183 - val_mae: 14.4676\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.6936 - mae: 16.4486 - val_loss: 297.9748 - val_mae: 14.3739\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.4580 - mae: 16.3929 - val_loss: 295.5693 - val_mae: 14.2889\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.3340 - mae: 16.3388 - val_loss: 293.3905 - val_mae: 14.2087\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 393.4659 - mae: 16.2888 - val_loss: 290.9865 - val_mae: 14.1220\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 391.4130 - mae: 16.2363 - val_loss: 288.6626 - val_mae: 14.0348\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.4822 - mae: 16.1813 - val_loss: 286.5490 - val_mae: 13.9512\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.3922 - mae: 16.1276 - val_loss: 284.3105 - val_mae: 13.8651\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.0878 - mae: 16.0708 - val_loss: 282.3462 - val_mae: 13.7950\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 29ms/step - loss: 929.3903 - mae: 24.5496 - val_loss: 992.3738 - val_mae: 25.1605\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 915.6960 - mae: 24.3831 - val_loss: 977.2689 - val_mae: 24.9884\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 901.9403 - mae: 24.2198 - val_loss: 962.8953 - val_mae: 24.8226\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 888.7017 - mae: 24.0568 - val_loss: 948.5269 - val_mae: 24.6569\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 875.8196 - mae: 23.8945 - val_loss: 934.3974 - val_mae: 24.4924\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 862.9464 - mae: 23.7337 - val_loss: 920.5347 - val_mae: 24.3292\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 850.4913 - mae: 23.5754 - val_loss: 907.0234 - val_mae: 24.1680\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 838.3162 - mae: 23.4199 - val_loss: 893.7273 - val_mae: 24.0070\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 826.1486 - mae: 23.2653 - val_loss: 880.8566 - val_mae: 23.8499\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 814.6559 - mae: 23.1159 - val_loss: 868.1418 - val_mae: 23.6960\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 803.1782 - mae: 22.9667 - val_loss: 855.6597 - val_mae: 23.5435\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 792.0586 - mae: 22.8193 - val_loss: 843.4356 - val_mae: 23.3924\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 781.1741 - mae: 22.6747 - val_loss: 831.5500 - val_mae: 23.2441\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 770.1870 - mae: 22.5314 - val_loss: 820.1449 - val_mae: 23.1014\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 759.8299 - mae: 22.3922 - val_loss: 808.8738 - val_mae: 22.9587\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 749.7890 - mae: 22.2530 - val_loss: 797.6224 - val_mae: 22.8141\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 739.6530 - mae: 22.1147 - val_loss: 786.6505 - val_mae: 22.6720\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 729.8897 - mae: 21.9796 - val_loss: 775.9796 - val_mae: 22.5320\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 720.2532 - mae: 21.8446 - val_loss: 765.4996 - val_mae: 22.3932\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 710.9338 - mae: 21.7152 - val_loss: 755.1688 - val_mae: 22.2540\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 701.8424 - mae: 21.5864 - val_loss: 744.9396 - val_mae: 22.1143\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 692.7495 - mae: 21.4579 - val_loss: 735.1238 - val_mae: 21.9794\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.8129 - mae: 21.3332 - val_loss: 725.7396 - val_mae: 21.8487\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.4587 - mae: 21.2101 - val_loss: 716.2423 - val_mae: 21.7168\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 667.0019 - mae: 21.0882 - val_loss: 706.9636 - val_mae: 21.5876\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 658.6580 - mae: 20.9665 - val_loss: 697.8376 - val_mae: 21.4609\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 650.7264 - mae: 20.8484 - val_loss: 689.0164 - val_mae: 21.3385\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 642.6945 - mae: 20.7291 - val_loss: 680.4579 - val_mae: 21.2194\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 634.9473 - mae: 20.6137 - val_loss: 672.1082 - val_mae: 21.1019\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 627.4222 - mae: 20.4993 - val_loss: 663.9891 - val_mae: 20.9859\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 620.0831 - mae: 20.3874 - val_loss: 655.8467 - val_mae: 20.8679\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 613.0261 - mae: 20.2778 - val_loss: 647.7466 - val_mae: 20.7498\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 605.8541 - mae: 20.1671 - val_loss: 640.0837 - val_mae: 20.6406\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 598.8596 - mae: 20.0575 - val_loss: 632.5757 - val_mae: 20.5326\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 592.2185 - mae: 19.9533 - val_loss: 625.2204 - val_mae: 20.4255\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 585.5355 - mae: 19.8485 - val_loss: 618.0406 - val_mae: 20.3202\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 579.2211 - mae: 19.7462 - val_loss: 610.7792 - val_mae: 20.2120\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 572.6758 - mae: 19.6429 - val_loss: 603.9662 - val_mae: 20.1092\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 566.5491 - mae: 19.5433 - val_loss: 597.1809 - val_mae: 20.0058\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 560.5789 - mae: 19.4452 - val_loss: 590.3940 - val_mae: 19.9010\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 554.5913 - mae: 19.3461 - val_loss: 583.7940 - val_mae: 19.7978\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 548.7681 - mae: 19.2503 - val_loss: 577.4731 - val_mae: 19.6983\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 543.0339 - mae: 19.1543 - val_loss: 571.2405 - val_mae: 19.5989\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 537.5618 - mae: 19.0605 - val_loss: 564.9916 - val_mae: 19.4980\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.9537 - mae: 18.9660 - val_loss: 558.9503 - val_mae: 19.3993\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 526.5827 - mae: 18.8747 - val_loss: 552.9907 - val_mae: 19.2998\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 521.3029 - mae: 18.7833 - val_loss: 547.1671 - val_mae: 19.2020\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 516.2380 - mae: 18.6946 - val_loss: 541.4083 - val_mae: 19.1034\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 511.0422 - mae: 18.6049 - val_loss: 535.8777 - val_mae: 19.0081\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 506.2075 - mae: 18.5177 - val_loss: 530.2978 - val_mae: 18.9106\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 501.3360 - mae: 18.4305 - val_loss: 524.9267 - val_mae: 18.8161\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 496.5102 - mae: 18.3459 - val_loss: 519.7045 - val_mae: 18.7230\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 491.9185 - mae: 18.2627 - val_loss: 514.4031 - val_mae: 18.6274\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 487.2805 - mae: 18.1803 - val_loss: 509.2894 - val_mae: 18.5344\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 482.8940 - mae: 18.1004 - val_loss: 504.2969 - val_mae: 18.4422\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 478.4456 - mae: 18.0209 - val_loss: 499.3902 - val_mae: 18.3515\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.1879 - mae: 17.9435 - val_loss: 494.6104 - val_mae: 18.2621\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.9771 - mae: 17.8657 - val_loss: 489.9409 - val_mae: 18.1753\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.9898 - mae: 17.7916 - val_loss: 485.2966 - val_mae: 18.0889\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 461.9297 - mae: 17.7163 - val_loss: 480.8092 - val_mae: 18.0064\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 458.0214 - mae: 17.6439 - val_loss: 476.4357 - val_mae: 17.9290\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 454.1040 - mae: 17.5722 - val_loss: 472.2635 - val_mae: 17.8561\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 450.4584 - mae: 17.5028 - val_loss: 468.0109 - val_mae: 17.7796\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 446.6950 - mae: 17.4328 - val_loss: 463.9229 - val_mae: 17.7057\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.1860 - mae: 17.3658 - val_loss: 459.7891 - val_mae: 17.6301\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 439.5638 - mae: 17.2976 - val_loss: 455.8854 - val_mae: 17.5582\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 436.1468 - mae: 17.2313 - val_loss: 451.9495 - val_mae: 17.4842\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.7060 - mae: 17.1653 - val_loss: 448.1924 - val_mae: 17.4145\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.3682 - mae: 17.1001 - val_loss: 444.5956 - val_mae: 17.3474\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.1803 - mae: 17.0362 - val_loss: 440.9750 - val_mae: 17.2795\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.9043 - mae: 16.9719 - val_loss: 437.5198 - val_mae: 17.2144\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.7776 - mae: 16.9099 - val_loss: 434.0764 - val_mae: 17.1482\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.7640 - mae: 16.8493 - val_loss: 430.4893 - val_mae: 17.0785\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.7145 - mae: 16.7887 - val_loss: 427.0972 - val_mae: 17.0116\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.7004 - mae: 16.7288 - val_loss: 423.8664 - val_mae: 16.9490\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 407.8135 - mae: 16.6701 - val_loss: 420.6853 - val_mae: 16.8877\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 405.0540 - mae: 16.6139 - val_loss: 417.4896 - val_mae: 16.8260\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 402.2382 - mae: 16.5562 - val_loss: 414.4144 - val_mae: 16.7667\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.5459 - mae: 16.4996 - val_loss: 411.3191 - val_mae: 16.7057\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.7151 - mae: 16.4414 - val_loss: 408.4672 - val_mae: 16.6504\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.1778 - mae: 16.3869 - val_loss: 405.5228 - val_mae: 16.5930\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.4217 - mae: 16.3284 - val_loss: 402.7832 - val_mae: 16.5413\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.8749 - mae: 16.2750 - val_loss: 399.9510 - val_mae: 16.4858\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.2471 - mae: 16.2201 - val_loss: 397.1892 - val_mae: 16.4327\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.7066 - mae: 16.1648 - val_loss: 394.4856 - val_mae: 16.3797\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 381.1860 - mae: 16.1109 - val_loss: 391.7840 - val_mae: 16.3281\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.7287 - mae: 16.0585 - val_loss: 389.0981 - val_mae: 16.2763\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.1735 - mae: 16.0045 - val_loss: 386.5511 - val_mae: 16.2296\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 373.7598 - mae: 15.9525 - val_loss: 384.0389 - val_mae: 16.1827\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.2520 - mae: 15.8987 - val_loss: 381.6129 - val_mae: 16.1391\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.7797 - mae: 15.8470 - val_loss: 379.0776 - val_mae: 16.0933\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.1581 - mae: 15.7899 - val_loss: 376.4772 - val_mae: 16.0445\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 363.5494 - mae: 15.7358 - val_loss: 373.5647 - val_mae: 15.9905\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.6888 - mae: 15.6741 - val_loss: 370.7092 - val_mae: 15.9349\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.6510 - mae: 15.6085 - val_loss: 367.6742 - val_mae: 15.8791\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.4272 - mae: 15.5436 - val_loss: 364.2430 - val_mae: 15.8172\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.0829 - mae: 15.4728 - val_loss: 360.2182 - val_mae: 15.7410\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.9395 - mae: 15.3878 - val_loss: 355.7674 - val_mae: 15.6583\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.6583 - mae: 15.2937 - val_loss: 350.5361 - val_mae: 15.5547\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.9165 - mae: 15.1921 - val_loss: 344.3702 - val_mae: 15.4232\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   5.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 817.6626 - mae: 22.8530 - val_loss: 679.8055 - val_mae: 20.7850\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 645.6907 - mae: 20.5367 - val_loss: 547.3342 - val_mae: 18.9279\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 541.3621 - mae: 18.9763 - val_loss: 462.7517 - val_mae: 17.5726\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.2931 - mae: 17.8495 - val_loss: 405.5770 - val_mae: 16.5342\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.8820 - mae: 17.0102 - val_loss: 364.9207 - val_mae: 15.7510\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.5092 - mae: 16.3614 - val_loss: 335.0504 - val_mae: 15.1316\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.8542 - mae: 15.8444 - val_loss: 312.2838 - val_mae: 14.6294\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 354.8475 - mae: 15.4227 - val_loss: 294.6746 - val_mae: 14.2222\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.0508 - mae: 15.0831 - val_loss: 280.6035 - val_mae: 13.8811\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.1625 - mae: 14.7969 - val_loss: 269.2889 - val_mae: 13.5900\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 321.3487 - mae: 14.5551 - val_loss: 259.9966 - val_mae: 13.3414\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.0785 - mae: 14.3504 - val_loss: 252.2921 - val_mae: 13.1314\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.0748 - mae: 14.1782 - val_loss: 245.8619 - val_mae: 12.9516\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 303.0056 - mae: 14.0282 - val_loss: 240.1429 - val_mae: 12.7898\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.5285 - mae: 13.8954 - val_loss: 235.1008 - val_mae: 12.6407\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.5681 - mae: 13.7706 - val_loss: 230.6050 - val_mae: 12.5065\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.0150 - mae: 13.6563 - val_loss: 226.5871 - val_mae: 12.3818\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.8611 - mae: 13.5555 - val_loss: 222.9778 - val_mae: 12.2654\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.0468 - mae: 13.4603 - val_loss: 219.6589 - val_mae: 12.1536\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.3965 - mae: 13.3714 - val_loss: 216.4941 - val_mae: 12.0442\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.9324 - mae: 13.2885 - val_loss: 213.5611 - val_mae: 11.9411\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.7069 - mae: 13.2122 - val_loss: 210.9716 - val_mae: 11.8472\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275.6139 - mae: 13.1420 - val_loss: 208.5070 - val_mae: 11.7586\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.7098 - mae: 13.0743 - val_loss: 206.3406 - val_mae: 11.6792\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.9510 - mae: 13.0156 - val_loss: 204.2460 - val_mae: 11.6010\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270.3074 - mae: 12.9580 - val_loss: 202.1729 - val_mae: 11.5237\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 268.7740 - mae: 12.9014 - val_loss: 200.3413 - val_mae: 11.4551\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.2706 - mae: 12.8510 - val_loss: 198.5704 - val_mae: 11.3877\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 265.8794 - mae: 12.8010 - val_loss: 196.8430 - val_mae: 11.3211\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.5342 - mae: 12.7519 - val_loss: 195.2588 - val_mae: 11.2593\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.2891 - mae: 12.7100 - val_loss: 193.7090 - val_mae: 11.1990\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.0608 - mae: 12.6661 - val_loss: 192.1901 - val_mae: 11.1404\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.9195 - mae: 12.6280 - val_loss: 190.7231 - val_mae: 11.0830\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.7736 - mae: 12.5868 - val_loss: 189.3535 - val_mae: 11.0297\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.7017 - mae: 12.5507 - val_loss: 188.0096 - val_mae: 10.9767\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.6547 - mae: 12.5130 - val_loss: 186.7379 - val_mae: 10.9274\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.6337 - mae: 12.4792 - val_loss: 185.4972 - val_mae: 10.8779\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.6075 - mae: 12.4473 - val_loss: 184.2947 - val_mae: 10.8287\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.6373 - mae: 12.4109 - val_loss: 183.1730 - val_mae: 10.7827\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.7095 - mae: 12.3814 - val_loss: 182.0516 - val_mae: 10.7360\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252.7313 - mae: 12.3528 - val_loss: 180.9522 - val_mae: 10.6911\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.7844 - mae: 12.3207 - val_loss: 179.8869 - val_mae: 10.6496\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250.7964 - mae: 12.2880 - val_loss: 178.8815 - val_mae: 10.6130\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.8078 - mae: 12.2611 - val_loss: 177.7980 - val_mae: 10.5725\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.8628 - mae: 12.2278 - val_loss: 176.7841 - val_mae: 10.5359\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 247.8665 - mae: 12.2018 - val_loss: 175.7417 - val_mae: 10.4990\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 246.9030 - mae: 12.1716 - val_loss: 174.7564 - val_mae: 10.4643\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 245.9064 - mae: 12.1451 - val_loss: 173.7505 - val_mae: 10.4306\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.7186 - mae: 12.1136 - val_loss: 172.6962 - val_mae: 10.3957\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.5711 - mae: 12.0812 - val_loss: 171.6595 - val_mae: 10.3621\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 242.3330 - mae: 12.0504 - val_loss: 170.6570 - val_mae: 10.3306\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.0680 - mae: 12.0184 - val_loss: 169.5423 - val_mae: 10.2996\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.6917 - mae: 11.9892 - val_loss: 168.2737 - val_mae: 10.2630\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 238.2883 - mae: 11.9478 - val_loss: 167.0726 - val_mae: 10.2321\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 236.7671 - mae: 11.9149 - val_loss: 165.8616 - val_mae: 10.1996\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235.1320 - mae: 11.8735 - val_loss: 164.5725 - val_mae: 10.1636\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 233.3874 - mae: 11.8303 - val_loss: 163.1906 - val_mae: 10.1254\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 231.3683 - mae: 11.7767 - val_loss: 161.4913 - val_mae: 10.0780\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 229.4139 - mae: 11.7257 - val_loss: 159.7480 - val_mae: 10.0260\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.5182 - mae: 11.6702 - val_loss: 158.1328 - val_mae: 9.9775\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 225.7387 - mae: 11.6173 - val_loss: 156.4875 - val_mae: 9.9273\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 223.9432 - mae: 11.5636 - val_loss: 154.8899 - val_mae: 9.8775\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.2994 - mae: 11.5118 - val_loss: 153.4721 - val_mae: 9.8336\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220.5900 - mae: 11.4608 - val_loss: 152.1716 - val_mae: 9.7903\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.1984 - mae: 11.4148 - val_loss: 150.9466 - val_mae: 9.7468\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.8766 - mae: 11.3706 - val_loss: 149.7980 - val_mae: 9.7039\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.7015 - mae: 11.3269 - val_loss: 148.8445 - val_mae: 9.6680\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.6093 - mae: 11.2914 - val_loss: 147.8432 - val_mae: 9.6276\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.6134 - mae: 11.2540 - val_loss: 146.9451 - val_mae: 9.5903\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.6852 - mae: 11.2195 - val_loss: 146.1323 - val_mae: 9.5556\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212.8461 - mae: 11.1870 - val_loss: 145.3354 - val_mae: 9.5214\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212.0315 - mae: 11.1527 - val_loss: 144.5753 - val_mae: 9.4884\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.2473 - mae: 11.1219 - val_loss: 143.8689 - val_mae: 9.4569\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 210.5195 - mae: 11.0919 - val_loss: 143.1677 - val_mae: 9.4252\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.8544 - mae: 11.0649 - val_loss: 142.4610 - val_mae: 9.3923\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.1635 - mae: 11.0365 - val_loss: 141.8160 - val_mae: 9.3617\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.4787 - mae: 11.0079 - val_loss: 141.2141 - val_mae: 9.3333\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 207.8728 - mae: 10.9855 - val_loss: 140.5863 - val_mae: 9.3047\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.2454 - mae: 10.9589 - val_loss: 140.0205 - val_mae: 9.2778\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.6680 - mae: 10.9330 - val_loss: 139.5009 - val_mae: 9.2534\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 206.1275 - mae: 10.9107 - val_loss: 139.0113 - val_mae: 9.2299\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 205.5842 - mae: 10.8915 - val_loss: 138.4412 - val_mae: 9.2039\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 205.0254 - mae: 10.8642 - val_loss: 137.9357 - val_mae: 9.1794\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.5174 - mae: 10.8437 - val_loss: 137.4159 - val_mae: 9.1545\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.0085 - mae: 10.8237 - val_loss: 136.8411 - val_mae: 9.1281\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.5091 - mae: 10.8000 - val_loss: 136.4032 - val_mae: 9.1061\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 203.0029 - mae: 10.7792 - val_loss: 135.9008 - val_mae: 9.0822\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 202.5578 - mae: 10.7600 - val_loss: 135.3967 - val_mae: 9.0585\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.1117 - mae: 10.7394 - val_loss: 134.9849 - val_mae: 9.0379\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.6312 - mae: 10.7191 - val_loss: 134.5349 - val_mae: 9.0157\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.2383 - mae: 10.7023 - val_loss: 134.0635 - val_mae: 8.9921\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.7629 - mae: 10.6824 - val_loss: 133.6738 - val_mae: 8.9722\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 200.3266 - mae: 10.6636 - val_loss: 133.2088 - val_mae: 8.9493\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 199.8864 - mae: 10.6445 - val_loss: 132.7592 - val_mae: 8.9271\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 199.5140 - mae: 10.6296 - val_loss: 132.3291 - val_mae: 8.9057\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.1120 - mae: 10.6110 - val_loss: 131.9334 - val_mae: 8.8860\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 198.6816 - mae: 10.5956 - val_loss: 131.4722 - val_mae: 8.8642\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 198.3122 - mae: 10.5766 - val_loss: 131.0665 - val_mae: 8.8445\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.8674 - mae: 10.5576 - val_loss: 130.6701 - val_mae: 8.8245\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.4678 - mae: 10.5397 - val_loss: 130.3330 - val_mae: 8.8067\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   4.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 1072.6304 - mae: 26.6236 - val_loss: 866.8906 - val_mae: 23.9500\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 859.5612 - mae: 24.3431 - val_loss: 704.4769 - val_mae: 22.0350\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 736.8017 - mae: 22.8072 - val_loss: 604.0822 - val_mae: 20.6488\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 660.0100 - mae: 21.6733 - val_loss: 537.6474 - val_mae: 19.6158\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 609.3506 - mae: 20.8509 - val_loss: 490.8531 - val_mae: 18.8213\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 573.7289 - mae: 20.2301 - val_loss: 457.8207 - val_mae: 18.2051\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 549.0964 - mae: 19.7684 - val_loss: 433.8035 - val_mae: 17.7365\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 531.1368 - mae: 19.4215 - val_loss: 415.5639 - val_mae: 17.3660\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 517.2422 - mae: 19.1423 - val_loss: 400.7878 - val_mae: 17.0583\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.0776 - mae: 18.9164 - val_loss: 389.1461 - val_mae: 16.8003\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 497.3556 - mae: 18.7310 - val_loss: 379.7486 - val_mae: 16.5908\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 490.2068 - mae: 18.5752 - val_loss: 371.7627 - val_mae: 16.4067\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 484.0065 - mae: 18.4316 - val_loss: 364.9037 - val_mae: 16.2460\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.4717 - mae: 18.2994 - val_loss: 358.7709 - val_mae: 16.1026\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 473.4882 - mae: 18.1814 - val_loss: 353.2032 - val_mae: 15.9700\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.8297 - mae: 18.0685 - val_loss: 347.6264 - val_mae: 15.8316\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 463.6806 - mae: 17.9373 - val_loss: 341.5801 - val_mae: 15.6753\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 458.1196 - mae: 17.7981 - val_loss: 336.1207 - val_mae: 15.5283\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 453.0022 - mae: 17.6699 - val_loss: 331.0652 - val_mae: 15.3876\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 447.7672 - mae: 17.5397 - val_loss: 325.4976 - val_mae: 15.2324\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 441.8632 - mae: 17.3849 - val_loss: 319.5380 - val_mae: 15.0664\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.2301 - mae: 17.2358 - val_loss: 314.1148 - val_mae: 14.9066\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.1781 - mae: 17.0943 - val_loss: 309.5321 - val_mae: 14.7627\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.9032 - mae: 16.9697 - val_loss: 305.6234 - val_mae: 14.6318\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.1226 - mae: 16.8574 - val_loss: 302.1146 - val_mae: 14.5169\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.8588 - mae: 16.7605 - val_loss: 298.9388 - val_mae: 14.4147\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.9394 - mae: 16.6778 - val_loss: 296.1584 - val_mae: 14.3277\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.3751 - mae: 16.6012 - val_loss: 293.7807 - val_mae: 14.2485\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 412.1252 - mae: 16.5344 - val_loss: 291.5839 - val_mae: 14.1770\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.0289 - mae: 16.4690 - val_loss: 289.6502 - val_mae: 14.1118\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.2262 - mae: 16.4135 - val_loss: 287.9651 - val_mae: 14.0539\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.5213 - mae: 16.3636 - val_loss: 286.4212 - val_mae: 14.0020\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 404.9187 - mae: 16.3160 - val_loss: 284.8885 - val_mae: 13.9521\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 403.4615 - mae: 16.2726 - val_loss: 283.5164 - val_mae: 13.9053\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 402.1488 - mae: 16.2342 - val_loss: 282.2537 - val_mae: 13.8618\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 400.8792 - mae: 16.1983 - val_loss: 281.0285 - val_mae: 13.8216\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.7137 - mae: 16.1668 - val_loss: 279.8409 - val_mae: 13.7849\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.6106 - mae: 16.1349 - val_loss: 278.7689 - val_mae: 13.7536\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.5823 - mae: 16.1085 - val_loss: 277.7250 - val_mae: 13.7243\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.6411 - mae: 16.0818 - val_loss: 276.7193 - val_mae: 13.6967\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.6899 - mae: 16.0567 - val_loss: 275.7765 - val_mae: 13.6702\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.8286 - mae: 16.0345 - val_loss: 274.8782 - val_mae: 13.6449\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.9895 - mae: 16.0112 - val_loss: 274.0671 - val_mae: 13.6230\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.1843 - mae: 15.9919 - val_loss: 273.2968 - val_mae: 13.6025\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.4145 - mae: 15.9755 - val_loss: 272.5376 - val_mae: 13.5815\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.6957 - mae: 15.9591 - val_loss: 271.7995 - val_mae: 13.5614\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.9977 - mae: 15.9401 - val_loss: 271.1028 - val_mae: 13.5419\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.3405 - mae: 15.9227 - val_loss: 270.3918 - val_mae: 13.5227\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.7071 - mae: 15.9098 - val_loss: 269.6973 - val_mae: 13.5033\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.0732 - mae: 15.8920 - val_loss: 269.0405 - val_mae: 13.4865\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.5080 - mae: 15.8805 - val_loss: 268.3405 - val_mae: 13.4674\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.9427 - mae: 15.8632 - val_loss: 267.6736 - val_mae: 13.4483\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.3951 - mae: 15.8495 - val_loss: 267.0948 - val_mae: 13.4328\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 386.8584 - mae: 15.8373 - val_loss: 266.5509 - val_mae: 13.4173\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.3645 - mae: 15.8243 - val_loss: 266.0276 - val_mae: 13.4018\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.8667 - mae: 15.8144 - val_loss: 265.4818 - val_mae: 13.3859\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.4091 - mae: 15.8007 - val_loss: 264.9133 - val_mae: 13.3703\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.9492 - mae: 15.7935 - val_loss: 264.3990 - val_mae: 13.3558\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 384.4733 - mae: 15.7782 - val_loss: 263.9283 - val_mae: 13.3432\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.0525 - mae: 15.7734 - val_loss: 263.4010 - val_mae: 13.3273\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 383.6097 - mae: 15.7573 - val_loss: 262.9027 - val_mae: 13.3130\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 383.2163 - mae: 15.7474 - val_loss: 262.5110 - val_mae: 13.3022\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.7888 - mae: 15.7409 - val_loss: 262.0413 - val_mae: 13.2888\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.3816 - mae: 15.7284 - val_loss: 261.6479 - val_mae: 13.2787\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.0043 - mae: 15.7222 - val_loss: 261.2693 - val_mae: 13.2684\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.6543 - mae: 15.7138 - val_loss: 260.8748 - val_mae: 13.2578\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.2853 - mae: 15.7048 - val_loss: 260.4797 - val_mae: 13.2467\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.9312 - mae: 15.6960 - val_loss: 260.0952 - val_mae: 13.2366\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.5828 - mae: 15.6866 - val_loss: 259.7804 - val_mae: 13.2295\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.2741 - mae: 15.6860 - val_loss: 259.4294 - val_mae: 13.2198\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.9296 - mae: 15.6772 - val_loss: 259.0392 - val_mae: 13.2079\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.6319 - mae: 15.6690 - val_loss: 258.6698 - val_mae: 13.1968\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.2913 - mae: 15.6567 - val_loss: 258.3693 - val_mae: 13.1889\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.0085 - mae: 15.6534 - val_loss: 258.0326 - val_mae: 13.1793\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.7046 - mae: 15.6448 - val_loss: 257.7004 - val_mae: 13.1690\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.4382 - mae: 15.6371 - val_loss: 257.3193 - val_mae: 13.1575\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 378.1459 - mae: 15.6278 - val_loss: 256.9655 - val_mae: 13.1471\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.8792 - mae: 15.6216 - val_loss: 256.6599 - val_mae: 13.1381\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.6039 - mae: 15.6133 - val_loss: 256.3669 - val_mae: 13.1295\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.3247 - mae: 15.6077 - val_loss: 256.0721 - val_mae: 13.1206\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 377.0933 - mae: 15.6024 - val_loss: 255.8104 - val_mae: 13.1134\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.8084 - mae: 15.5953 - val_loss: 255.5391 - val_mae: 13.1046\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.5742 - mae: 15.5889 - val_loss: 255.2518 - val_mae: 13.0948\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.3225 - mae: 15.5825 - val_loss: 254.9700 - val_mae: 13.0862\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.0797 - mae: 15.5762 - val_loss: 254.6951 - val_mae: 13.0782\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.8568 - mae: 15.5736 - val_loss: 254.4021 - val_mae: 13.0680\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.6151 - mae: 15.5669 - val_loss: 254.0900 - val_mae: 13.0574\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.3871 - mae: 15.5579 - val_loss: 253.8153 - val_mae: 13.0489\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 375.1710 - mae: 15.5510 - val_loss: 253.5791 - val_mae: 13.0416\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.9538 - mae: 15.5477 - val_loss: 253.2988 - val_mae: 13.0322\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.7669 - mae: 15.5411 - val_loss: 253.0661 - val_mae: 13.0252\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.5374 - mae: 15.5340 - val_loss: 252.8723 - val_mae: 13.0192\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 374.3556 - mae: 15.5322 - val_loss: 252.6544 - val_mae: 13.0123\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 374.1447 - mae: 15.5235 - val_loss: 252.4944 - val_mae: 13.0080\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.9558 - mae: 15.5228 - val_loss: 252.2677 - val_mae: 12.9999\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.7638 - mae: 15.5154 - val_loss: 252.0429 - val_mae: 12.9916\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.5663 - mae: 15.5123 - val_loss: 251.8070 - val_mae: 12.9832\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 373.3902 - mae: 15.5061 - val_loss: 251.5930 - val_mae: 12.9756\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.2089 - mae: 15.5008 - val_loss: 251.3941 - val_mae: 12.9690\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.0295 - mae: 15.4969 - val_loss: 251.1733 - val_mae: 12.9616\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   4.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 1915.4344 - mae: 32.6874 - val_loss: 1514.0377 - val_mae: 29.4923\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1227.1846 - mae: 27.0415 - val_loss: 1047.4921 - val_mae: 25.1547\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 889.4261 - mae: 23.4873 - val_loss: 798.8809 - val_mae: 22.3956\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 702.4113 - mae: 21.1890 - val_loss: 651.9792 - val_mae: 20.5292\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 588.3054 - mae: 19.5631 - val_loss: 558.5913 - val_mae: 19.1884\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.3136 - mae: 18.3829 - val_loss: 497.4927 - val_mae: 18.2049\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.8170 - mae: 17.5277 - val_loss: 453.2863 - val_mae: 17.4350\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.2421 - mae: 16.8337 - val_loss: 419.8173 - val_mae: 16.8054\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.5698 - mae: 16.2801 - val_loss: 393.6848 - val_mae: 16.2655\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.0836 - mae: 15.8234 - val_loss: 373.2715 - val_mae: 15.8140\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2364 - mae: 15.4503 - val_loss: 357.0640 - val_mae: 15.4364\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 348.6252 - mae: 15.1321 - val_loss: 343.5581 - val_mae: 15.1000\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.2843 - mae: 14.8565 - val_loss: 332.3829 - val_mae: 14.8088\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.7668 - mae: 14.6204 - val_loss: 323.0348 - val_mae: 14.5553\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.8099 - mae: 14.4109 - val_loss: 315.2883 - val_mae: 14.3417\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.0646 - mae: 14.2239 - val_loss: 308.9236 - val_mae: 14.1686\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.4292 - mae: 14.0638 - val_loss: 303.5592 - val_mae: 14.0204\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.6463 - mae: 13.9239 - val_loss: 299.0364 - val_mae: 13.8901\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.5464 - mae: 13.8013 - val_loss: 295.0831 - val_mae: 13.7725\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 294.9348 - mae: 13.6898 - val_loss: 291.6266 - val_mae: 13.6687\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 291.7984 - mae: 13.5906 - val_loss: 288.6309 - val_mae: 13.5765\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.0404 - mae: 13.5037 - val_loss: 285.9242 - val_mae: 13.4935\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286.5549 - mae: 13.4215 - val_loss: 283.5349 - val_mae: 13.4212\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.3707 - mae: 13.3478 - val_loss: 281.3992 - val_mae: 13.3546\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.3946 - mae: 13.2815 - val_loss: 279.4660 - val_mae: 13.2921\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 280.6480 - mae: 13.2203 - val_loss: 277.7195 - val_mae: 13.2339\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 279.0125 - mae: 13.1631 - val_loss: 276.1030 - val_mae: 13.1791\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.5123 - mae: 13.1106 - val_loss: 274.5935 - val_mae: 13.1275\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.0915 - mae: 13.0589 - val_loss: 273.2076 - val_mae: 13.0795\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.8231 - mae: 13.0134 - val_loss: 271.9094 - val_mae: 13.0337\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273.6158 - mae: 12.9675 - val_loss: 270.7109 - val_mae: 12.9914\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.4893 - mae: 12.9249 - val_loss: 269.5761 - val_mae: 12.9508\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 271.4325 - mae: 12.8842 - val_loss: 268.5085 - val_mae: 12.9120\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270.4536 - mae: 12.8474 - val_loss: 267.4897 - val_mae: 12.8745\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 269.5318 - mae: 12.8107 - val_loss: 266.5353 - val_mae: 12.8392\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.6503 - mae: 12.7762 - val_loss: 265.6219 - val_mae: 12.8054\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.8209 - mae: 12.7441 - val_loss: 264.7681 - val_mae: 12.7741\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.0243 - mae: 12.7115 - val_loss: 263.9571 - val_mae: 12.7439\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 266.3124 - mae: 12.6834 - val_loss: 263.1905 - val_mae: 12.7151\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 265.5684 - mae: 12.6553 - val_loss: 262.4238 - val_mae: 12.6860\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 264.8893 - mae: 12.6277 - val_loss: 261.6924 - val_mae: 12.6582\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 264.2237 - mae: 12.6030 - val_loss: 260.9914 - val_mae: 12.6314\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.6004 - mae: 12.5766 - val_loss: 260.2981 - val_mae: 12.6050\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.9514 - mae: 12.5521 - val_loss: 259.6342 - val_mae: 12.5802\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.3405 - mae: 12.5292 - val_loss: 258.9864 - val_mae: 12.5552\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 261.7546 - mae: 12.5055 - val_loss: 258.3481 - val_mae: 12.5308\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 261.1788 - mae: 12.4833 - val_loss: 257.7203 - val_mae: 12.5066\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.6176 - mae: 12.4629 - val_loss: 257.1102 - val_mae: 12.4828\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 260.0446 - mae: 12.4394 - val_loss: 256.5122 - val_mae: 12.4596\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.5128 - mae: 12.4196 - val_loss: 255.9341 - val_mae: 12.4371\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258.9619 - mae: 12.3985 - val_loss: 255.3718 - val_mae: 12.4148\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258.4347 - mae: 12.3788 - val_loss: 254.8020 - val_mae: 12.3924\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.9262 - mae: 12.3611 - val_loss: 254.2438 - val_mae: 12.3702\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.3894 - mae: 12.3381 - val_loss: 253.6901 - val_mae: 12.3485\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.8559 - mae: 12.3176 - val_loss: 253.1343 - val_mae: 12.3262\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.3122 - mae: 12.3023 - val_loss: 252.5528 - val_mae: 12.3031\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.7476 - mae: 12.2788 - val_loss: 251.9736 - val_mae: 12.2812\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.1594 - mae: 12.2616 - val_loss: 251.3778 - val_mae: 12.2597\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.5596 - mae: 12.2394 - val_loss: 250.7749 - val_mae: 12.2382\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.9762 - mae: 12.2194 - val_loss: 250.1925 - val_mae: 12.2169\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 253.4189 - mae: 12.2007 - val_loss: 249.6099 - val_mae: 12.1954\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.8528 - mae: 12.1816 - val_loss: 249.0552 - val_mae: 12.1751\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.3080 - mae: 12.1636 - val_loss: 248.5149 - val_mae: 12.1554\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.7881 - mae: 12.1464 - val_loss: 247.9732 - val_mae: 12.1349\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.2549 - mae: 12.1286 - val_loss: 247.4349 - val_mae: 12.1146\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250.7607 - mae: 12.1109 - val_loss: 246.8995 - val_mae: 12.0941\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 250.2947 - mae: 12.0947 - val_loss: 246.3799 - val_mae: 12.0749\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 249.8132 - mae: 12.0748 - val_loss: 245.8723 - val_mae: 12.0561\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.3313 - mae: 12.0580 - val_loss: 245.3713 - val_mae: 12.0376\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.8631 - mae: 12.0427 - val_loss: 244.8785 - val_mae: 12.0191\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.4119 - mae: 12.0243 - val_loss: 244.3994 - val_mae: 12.0017\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247.9734 - mae: 12.0100 - val_loss: 243.9302 - val_mae: 11.9842\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247.5294 - mae: 11.9951 - val_loss: 243.4705 - val_mae: 11.9678\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 247.1114 - mae: 11.9806 - val_loss: 243.0127 - val_mae: 11.9506\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.6905 - mae: 11.9683 - val_loss: 242.5525 - val_mae: 11.9338\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 246.2804 - mae: 11.9527 - val_loss: 242.0988 - val_mae: 11.9176\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 245.8854 - mae: 11.9366 - val_loss: 241.6652 - val_mae: 11.9023\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 245.5023 - mae: 11.9226 - val_loss: 241.2468 - val_mae: 11.8880\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 245.1057 - mae: 11.9095 - val_loss: 240.8339 - val_mae: 11.8740\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244.7308 - mae: 11.8974 - val_loss: 240.4181 - val_mae: 11.8600\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244.3576 - mae: 11.8830 - val_loss: 240.0130 - val_mae: 11.8460\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244.0009 - mae: 11.8696 - val_loss: 239.6181 - val_mae: 11.8333\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.6289 - mae: 11.8553 - val_loss: 239.2238 - val_mae: 11.8202\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.2752 - mae: 11.8439 - val_loss: 238.8215 - val_mae: 11.8068\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 242.9187 - mae: 11.8313 - val_loss: 238.4036 - val_mae: 11.7931\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 242.5530 - mae: 11.8179 - val_loss: 237.9897 - val_mae: 11.7787\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 242.2074 - mae: 11.8031 - val_loss: 237.5698 - val_mae: 11.7647\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241.8462 - mae: 11.7891 - val_loss: 237.1677 - val_mae: 11.7526\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241.4818 - mae: 11.7782 - val_loss: 236.7687 - val_mae: 11.7401\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241.1275 - mae: 11.7678 - val_loss: 236.3791 - val_mae: 11.7271\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 240.7779 - mae: 11.7548 - val_loss: 236.0006 - val_mae: 11.7148\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 240.4317 - mae: 11.7415 - val_loss: 235.6214 - val_mae: 11.7020\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 240.0931 - mae: 11.7284 - val_loss: 235.2529 - val_mae: 11.6909\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 239.7487 - mae: 11.7185 - val_loss: 234.8851 - val_mae: 11.6798\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 239.4202 - mae: 11.7058 - val_loss: 234.5277 - val_mae: 11.6689\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 239.0870 - mae: 11.6974 - val_loss: 234.1447 - val_mae: 11.6554\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 238.7298 - mae: 11.6839 - val_loss: 233.7723 - val_mae: 11.6420\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 238.4097 - mae: 11.6706 - val_loss: 233.4081 - val_mae: 11.6286\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 238.0684 - mae: 11.6577 - val_loss: 233.0526 - val_mae: 11.6158\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 237.7564 - mae: 11.6457 - val_loss: 232.7031 - val_mae: 11.6029\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 3349.1514 - mae: 40.0633 - val_loss: 447.9789 - val_mae: 20.2537\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 597.3427 - mae: 22.6850 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 4478.5991 - mae: 43.1511 - val_loss: 691.1063 - val_mae: 22.8955\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 648.0733 - mae: 22.5314 - val_loss: 417.5453 - val_mae: 19.0325\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.0032 - mae: 20.8651 - val_loss: 385.6530 - val_mae: 18.0425\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 535.7869 - mae: 20.2383 - val_loss: 371.8580 - val_mae: 17.5353\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 534.4511 - mae: 20.2933 - val_loss: 370.0795 - val_mae: 17.4470\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.8817 - mae: 20.2151 - val_loss: 370.5975 - val_mae: 17.4741\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 533.4303 - mae: 20.2222 - val_loss: 369.6892 - val_mae: 17.4246\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.2658 - mae: 20.2099 - val_loss: 371.2306 - val_mae: 17.5037\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 532.2384 - mae: 20.1664 - val_loss: 370.3568 - val_mae: 17.4596\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.5811 - mae: 20.1346 - val_loss: 371.4373 - val_mae: 17.5133\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.4796 - mae: 20.0992 - val_loss: 370.7514 - val_mae: 17.4806\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 531.4188 - mae: 20.1480 - val_loss: 370.5314 - val_mae: 17.4715\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 531.5013 - mae: 20.1022 - val_loss: 370.8316 - val_mae: 17.4888\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.2177 - mae: 20.1568 - val_loss: 370.1740 - val_mae: 17.4457\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 530.9705 - mae: 20.0906 - val_loss: 370.5397 - val_mae: 17.4756\n",
      "Epoch 15: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1526.6985 - mae: 26.4552 - val_loss: 515.5135 - val_mae: 20.9202\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 567.3957 - mae: 21.3605 - val_loss: 506.1983 - val_mae: 20.8375\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.6179 - mae: 21.1177 - val_loss: 505.8621 - val_mae: 20.8169\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 524.6892 - mae: 21.0248 - val_loss: 505.1042 - val_mae: 20.7444\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 520.1050 - mae: 20.8653 - val_loss: 509.1092 - val_mae: 20.8507\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 518.3448 - mae: 20.7787 - val_loss: 512.0654 - val_mae: 20.9043\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 517.5351 - mae: 20.7416 - val_loss: 508.2391 - val_mae: 20.8326\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 516.3279 - mae: 20.7353 - val_loss: 508.4267 - val_mae: 20.8367\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 515.8685 - mae: 20.7236 - val_loss: 508.0269 - val_mae: 20.8282\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 515.1820 - mae: 20.7093 - val_loss: 506.8266 - val_mae: 20.8015\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 514.9083 - mae: 20.7023 - val_loss: 506.9381 - val_mae: 20.8038\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.1589 - mae: 20.6892 - val_loss: 505.2066 - val_mae: 20.7649\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 513.5753 - mae: 20.6773 - val_loss: 504.7723 - val_mae: 20.7563\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 513.0966 - mae: 20.6644 - val_loss: 504.3323 - val_mae: 20.7466\n",
      "Epoch 14: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=5, model__optimizer=momentum; total time=   1.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2188 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=momentum; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=momentum; total time=   0.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 43ms/step - loss: 1231.5804 - mae: 25.7852 - val_loss: 396.1639 - val_mae: 16.8342\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.2897 - mae: 17.8390 - val_loss: 339.0719 - val_mae: 15.6231\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.6759 - mae: 17.3488 - val_loss: 322.7430 - val_mae: 15.3427\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.7817 - mae: 17.1637 - val_loss: 310.5430 - val_mae: 15.0836\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.1451 - mae: 16.9561 - val_loss: 300.4461 - val_mae: 14.8233\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.9525 - mae: 16.7980 - val_loss: 295.5759 - val_mae: 14.6945\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.7204 - mae: 16.6425 - val_loss: 290.6162 - val_mae: 14.5360\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.8941 - mae: 16.5179 - val_loss: 286.2946 - val_mae: 14.3851\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.6444 - mae: 16.3952 - val_loss: 283.6762 - val_mae: 14.2813\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.0866 - mae: 16.3080 - val_loss: 281.9061 - val_mae: 14.1943\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.0744 - mae: 16.2478 - val_loss: 278.8058 - val_mae: 14.0445\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.3555 - mae: 16.1630 - val_loss: 277.3631 - val_mae: 13.9755\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.6454 - mae: 16.1066 - val_loss: 276.6141 - val_mae: 13.9358\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.3202 - mae: 16.0383 - val_loss: 276.0502 - val_mae: 13.9268\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.3634 - mae: 16.0448 - val_loss: 274.9206 - val_mae: 13.8124\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.5909 - mae: 15.9846 - val_loss: 273.9345 - val_mae: 13.7752\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.0227 - mae: 15.9713 - val_loss: 273.5892 - val_mae: 13.7481\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.2100 - mae: 15.9267 - val_loss: 273.9668 - val_mae: 13.8121\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.2609 - mae: 15.9396 - val_loss: 271.5220 - val_mae: 13.6749\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.4119 - mae: 15.8729 - val_loss: 269.7284 - val_mae: 13.6184\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 374.2042 - mae: 15.7855 - val_loss: 267.8435 - val_mae: 13.5961\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 372.1540 - mae: 15.7582 - val_loss: 264.7928 - val_mae: 13.4696\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.8866 - mae: 15.6747 - val_loss: 263.8763 - val_mae: 13.4464\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.8958 - mae: 15.6144 - val_loss: 262.9830 - val_mae: 13.4413\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.6698 - mae: 15.6091 - val_loss: 260.7162 - val_mae: 13.3207\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.5909 - mae: 15.5229 - val_loss: 259.3865 - val_mae: 13.2798\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.4736 - mae: 15.4945 - val_loss: 259.1048 - val_mae: 13.2911\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.5739 - mae: 15.5111 - val_loss: 257.1448 - val_mae: 13.1760\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.1346 - mae: 15.4064 - val_loss: 258.6980 - val_mae: 13.2977\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2296 - mae: 15.4672 - val_loss: 256.3483 - val_mae: 13.1464\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2369 - mae: 15.3965 - val_loss: 256.5829 - val_mae: 13.1853\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.6000 - mae: 15.3950 - val_loss: 256.7645 - val_mae: 13.1920\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.9759 - mae: 15.3945 - val_loss: 255.1465 - val_mae: 13.0707\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.8850 - mae: 15.3401 - val_loss: 255.8237 - val_mae: 13.1460\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.1966 - mae: 15.3326 - val_loss: 255.4433 - val_mae: 13.1153\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.9112 - mae: 15.3151 - val_loss: 256.6335 - val_mae: 13.2069\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.8755 - mae: 15.3417 - val_loss: 256.8732 - val_mae: 13.2197\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.3519 - mae: 15.3356 - val_loss: 255.4328 - val_mae: 13.1106\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.8677 - mae: 15.3258 - val_loss: 254.2118 - val_mae: 13.0215\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.6476 - mae: 15.2753 - val_loss: 253.4551 - val_mae: 12.9567\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.3626 - mae: 15.2198 - val_loss: 253.9763 - val_mae: 13.0044\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.0647 - mae: 15.2637 - val_loss: 253.8885 - val_mae: 12.9955\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.2554 - mae: 15.2312 - val_loss: 254.2695 - val_mae: 13.0324\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.7048 - mae: 15.2514 - val_loss: 253.4409 - val_mae: 12.9540\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.6144 - mae: 15.2132 - val_loss: 253.1868 - val_mae: 12.9394\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.4727 - mae: 15.1934 - val_loss: 254.2144 - val_mae: 13.0261\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.4903 - mae: 15.2231 - val_loss: 253.6424 - val_mae: 12.9807\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.5454 - mae: 15.2103 - val_loss: 255.5882 - val_mae: 13.1484\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.1294 - mae: 15.2542 - val_loss: 252.6361 - val_mae: 12.8911\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.4271 - mae: 15.1744 - val_loss: 252.9150 - val_mae: 12.9185\n",
      "Epoch 50: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   2.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 1447.6879 - mae: 28.1658 - val_loss: 544.3884 - val_mae: 19.6075\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.5149 - mae: 19.4962 - val_loss: 360.6201 - val_mae: 16.3516\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.6635 - mae: 17.6546 - val_loss: 310.6895 - val_mae: 14.9663\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.1747 - mae: 16.6905 - val_loss: 284.5666 - val_mae: 14.1763\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.2678 - mae: 16.0729 - val_loss: 268.4966 - val_mae: 13.6964\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.3126 - mae: 15.6637 - val_loss: 257.3660 - val_mae: 13.3257\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.4399 - mae: 15.3553 - val_loss: 247.3536 - val_mae: 13.0095\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.9214 - mae: 15.1072 - val_loss: 243.4551 - val_mae: 12.8578\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.9302 - mae: 14.9457 - val_loss: 237.9898 - val_mae: 12.6591\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.0540 - mae: 14.7954 - val_loss: 233.8424 - val_mae: 12.4841\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.2342 - mae: 14.6549 - val_loss: 230.2092 - val_mae: 12.3546\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.5152 - mae: 14.5538 - val_loss: 227.4072 - val_mae: 12.2528\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 335.3456 - mae: 14.5014 - val_loss: 223.2558 - val_mae: 12.1151\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.4568 - mae: 14.3823 - val_loss: 219.6694 - val_mae: 12.0035\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.4519 - mae: 14.2556 - val_loss: 216.9831 - val_mae: 11.9641\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.8267 - mae: 14.1672 - val_loss: 211.5873 - val_mae: 11.8351\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.3210 - mae: 14.0071 - val_loss: 204.6718 - val_mae: 11.6001\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 309.0836 - mae: 13.8086 - val_loss: 198.6671 - val_mae: 11.3744\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.8788 - mae: 13.5549 - val_loss: 195.6034 - val_mae: 11.2402\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.1317 - mae: 13.4180 - val_loss: 193.4489 - val_mae: 11.1507\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.2544 - mae: 13.3335 - val_loss: 191.2042 - val_mae: 11.0460\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.1312 - mae: 13.2690 - val_loss: 188.7813 - val_mae: 10.9449\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.1400 - mae: 13.2308 - val_loss: 185.4444 - val_mae: 10.7452\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.5090 - mae: 13.0962 - val_loss: 184.4441 - val_mae: 10.7081\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.8423 - mae: 13.0842 - val_loss: 183.5119 - val_mae: 10.6673\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.3919 - mae: 13.0176 - val_loss: 183.0339 - val_mae: 10.6418\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.4386 - mae: 12.9935 - val_loss: 182.3748 - val_mae: 10.6240\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.4073 - mae: 12.9823 - val_loss: 181.2905 - val_mae: 10.5495\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 283.5522 - mae: 12.9259 - val_loss: 180.6964 - val_mae: 10.5275\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 283.0686 - mae: 12.9144 - val_loss: 180.1485 - val_mae: 10.4993\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.0153 - mae: 12.8654 - val_loss: 181.0543 - val_mae: 10.5549\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.6940 - mae: 12.8695 - val_loss: 179.9069 - val_mae: 10.4860\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.8000 - mae: 12.8377 - val_loss: 178.0371 - val_mae: 10.3664\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.4554 - mae: 12.8042 - val_loss: 178.3913 - val_mae: 10.3869\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.7539 - mae: 12.7968 - val_loss: 177.4796 - val_mae: 10.3286\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.0676 - mae: 12.7699 - val_loss: 177.0978 - val_mae: 10.3052\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.7126 - mae: 12.7845 - val_loss: 176.1801 - val_mae: 10.2528\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.7498 - mae: 12.7209 - val_loss: 175.8866 - val_mae: 10.2479\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.0891 - mae: 12.7056 - val_loss: 174.9395 - val_mae: 10.1929\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.6073 - mae: 12.7043 - val_loss: 172.7977 - val_mae: 10.0854\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275.3646 - mae: 12.6108 - val_loss: 172.0036 - val_mae: 10.0982\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273.8498 - mae: 12.6140 - val_loss: 169.6378 - val_mae: 9.9952\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 271.7369 - mae: 12.5631 - val_loss: 167.1354 - val_mae: 9.9014\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 267.8222 - mae: 12.4122 - val_loss: 165.4128 - val_mae: 9.8612\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 264.4415 - mae: 12.3006 - val_loss: 164.6865 - val_mae: 9.8596\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 261.7300 - mae: 12.2591 - val_loss: 162.2104 - val_mae: 9.7226\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.8289 - mae: 12.1625 - val_loss: 161.6767 - val_mae: 9.7240\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.0515 - mae: 12.1544 - val_loss: 160.4109 - val_mae: 9.6569\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258.1949 - mae: 12.1219 - val_loss: 159.5836 - val_mae: 9.5998\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.7491 - mae: 12.1015 - val_loss: 158.9760 - val_mae: 9.5599\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.9345 - mae: 12.0064 - val_loss: 161.2430 - val_mae: 9.7481\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 256.9288 - mae: 12.1451 - val_loss: 158.3965 - val_mae: 9.5285\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 256.6058 - mae: 12.0588 - val_loss: 158.2925 - val_mae: 9.5326\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.3023 - mae: 12.0232 - val_loss: 159.4912 - val_mae: 9.6286\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.1295 - mae: 12.0667 - val_loss: 158.0698 - val_mae: 9.5202\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.8225 - mae: 12.0104 - val_loss: 158.7482 - val_mae: 9.5849\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.6863 - mae: 12.0268 - val_loss: 159.1101 - val_mae: 9.6188\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.3700 - mae: 12.0425 - val_loss: 158.8304 - val_mae: 9.5913\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.3620 - mae: 12.0421 - val_loss: 156.9315 - val_mae: 9.4373\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 255.3616 - mae: 12.0118 - val_loss: 156.9991 - val_mae: 9.4587\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 254.8489 - mae: 11.9348 - val_loss: 159.6807 - val_mae: 9.6692\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.8529 - mae: 12.0391 - val_loss: 157.6291 - val_mae: 9.5133\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.4316 - mae: 11.9973 - val_loss: 157.0683 - val_mae: 9.4713\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.6337 - mae: 11.9845 - val_loss: 157.1187 - val_mae: 9.4890\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.2068 - mae: 11.9398 - val_loss: 158.0529 - val_mae: 9.5519\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.1164 - mae: 12.0306 - val_loss: 155.6954 - val_mae: 9.3597\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 254.2076 - mae: 11.9485 - val_loss: 156.1082 - val_mae: 9.4093\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.9528 - mae: 11.9606 - val_loss: 155.9715 - val_mae: 9.3931\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.6148 - mae: 11.9234 - val_loss: 156.7213 - val_mae: 9.4713\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.4772 - mae: 11.9681 - val_loss: 155.8971 - val_mae: 9.4010\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.5757 - mae: 11.9333 - val_loss: 156.5842 - val_mae: 9.4636\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.2379 - mae: 11.9461 - val_loss: 156.9034 - val_mae: 9.4856\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.2063 - mae: 11.9863 - val_loss: 155.1986 - val_mae: 9.3504\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.3988 - mae: 11.9236 - val_loss: 156.1523 - val_mae: 9.4407\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.8495 - mae: 11.9908 - val_loss: 154.6198 - val_mae: 9.3030\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252.8576 - mae: 11.9146 - val_loss: 154.4006 - val_mae: 9.2960\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.7801 - mae: 11.8912 - val_loss: 155.0121 - val_mae: 9.3583\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.7254 - mae: 11.9234 - val_loss: 155.3628 - val_mae: 9.3795\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252.6276 - mae: 11.9303 - val_loss: 155.2273 - val_mae: 9.3789\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252.5071 - mae: 11.9152 - val_loss: 155.7299 - val_mae: 9.4304\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.4048 - mae: 11.9147 - val_loss: 155.4718 - val_mae: 9.4065\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.2701 - mae: 11.9503 - val_loss: 154.2320 - val_mae: 9.3110\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.9060 - mae: 11.8924 - val_loss: 154.4079 - val_mae: 9.3427\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.1078 - mae: 11.9143 - val_loss: 154.8029 - val_mae: 9.3919\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.7346 - mae: 11.9462 - val_loss: 153.3524 - val_mae: 9.2730\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.4981 - mae: 11.8256 - val_loss: 154.9166 - val_mae: 9.4170\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.1748 - mae: 11.8921 - val_loss: 154.6508 - val_mae: 9.4063\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.2566 - mae: 11.9297 - val_loss: 153.4533 - val_mae: 9.3238\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.0596 - mae: 11.8649 - val_loss: 154.3398 - val_mae: 9.4035\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250.6478 - mae: 11.9016 - val_loss: 152.9067 - val_mae: 9.2915\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250.4040 - mae: 11.8823 - val_loss: 151.9798 - val_mae: 9.2249\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 250.3766 - mae: 11.8626 - val_loss: 151.3754 - val_mae: 9.1780\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.9469 - mae: 11.7924 - val_loss: 152.3161 - val_mae: 9.2644\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.8548 - mae: 11.8932 - val_loss: 151.1440 - val_mae: 9.1730\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.5045 - mae: 11.8000 - val_loss: 151.6143 - val_mae: 9.2209\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 249.1799 - mae: 11.8173 - val_loss: 151.4519 - val_mae: 9.2131\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.9689 - mae: 11.8260 - val_loss: 151.4945 - val_mae: 9.2205\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 248.6637 - mae: 11.7526 - val_loss: 154.8088 - val_mae: 9.4676\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 248.4644 - mae: 11.9303 - val_loss: 150.9302 - val_mae: 9.1764\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.3279 - mae: 11.7278 - val_loss: 153.2532 - val_mae: 9.3611\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1174.4714 - mae: 24.8022 - val_loss: 393.6978 - val_mae: 16.8998\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.9160 - mae: 17.1077 - val_loss: 343.4518 - val_mae: 15.4240\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.9427 - mae: 16.0711 - val_loss: 329.1730 - val_mae: 15.0031\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.6210 - mae: 15.6094 - val_loss: 321.0103 - val_mae: 14.7551\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 343.9188 - mae: 15.1371 - val_loss: 307.2890 - val_mae: 14.3406\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 328.5058 - mae: 14.7291 - val_loss: 301.7308 - val_mae: 14.1612\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 320.3833 - mae: 14.5294 - val_loss: 296.6630 - val_mae: 13.9662\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 315.1643 - mae: 14.3814 - val_loss: 294.1906 - val_mae: 13.8955\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 311.0576 - mae: 14.2438 - val_loss: 293.0406 - val_mae: 13.8405\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 307.9079 - mae: 14.1409 - val_loss: 291.2519 - val_mae: 13.7764\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.0275 - mae: 14.0707 - val_loss: 289.6338 - val_mae: 13.6897\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.9104 - mae: 13.9760 - val_loss: 288.5290 - val_mae: 13.6842\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 302.6583 - mae: 13.9769 - val_loss: 287.6159 - val_mae: 13.6004\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 301.3506 - mae: 13.8782 - val_loss: 286.7339 - val_mae: 13.5851\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 300.4731 - mae: 13.8615 - val_loss: 285.9737 - val_mae: 13.5451\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 299.7454 - mae: 13.8197 - val_loss: 285.9885 - val_mae: 13.5888\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.2454 - mae: 13.8286 - val_loss: 285.7960 - val_mae: 13.5436\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 299.0123 - mae: 13.8068 - val_loss: 285.5638 - val_mae: 13.5517\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.3021 - mae: 13.7681 - val_loss: 285.4304 - val_mae: 13.5922\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.1089 - mae: 13.8056 - val_loss: 284.4261 - val_mae: 13.5114\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 296.9866 - mae: 13.7304 - val_loss: 283.8797 - val_mae: 13.4744\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.6689 - mae: 13.7115 - val_loss: 283.6596 - val_mae: 13.4652\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.3648 - mae: 13.6867 - val_loss: 283.6197 - val_mae: 13.4720\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.2474 - mae: 13.7032 - val_loss: 282.8643 - val_mae: 13.4163\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.8587 - mae: 13.6752 - val_loss: 282.6488 - val_mae: 13.4124\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.4931 - mae: 13.6489 - val_loss: 282.7031 - val_mae: 13.4221\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.4129 - mae: 13.6704 - val_loss: 282.4154 - val_mae: 13.4041\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.0282 - mae: 13.6504 - val_loss: 282.4321 - val_mae: 13.4069\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 294.8233 - mae: 13.6236 - val_loss: 282.2003 - val_mae: 13.4082\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 294.9311 - mae: 13.6660 - val_loss: 281.7971 - val_mae: 13.3677\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 294.3839 - mae: 13.5780 - val_loss: 281.9910 - val_mae: 13.4121\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 294.2152 - mae: 13.6437 - val_loss: 281.3404 - val_mae: 13.3571\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 293.9069 - mae: 13.5982 - val_loss: 281.0391 - val_mae: 13.3288\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 293.7935 - mae: 13.5573 - val_loss: 281.3869 - val_mae: 13.3614\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 293.7714 - mae: 13.5727 - val_loss: 280.8964 - val_mae: 13.3466\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 293.5639 - mae: 13.5692 - val_loss: 280.8082 - val_mae: 13.3426\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 293.4286 - mae: 13.5861 - val_loss: 280.2969 - val_mae: 13.3082\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 293.1543 - mae: 13.5539 - val_loss: 280.4672 - val_mae: 13.3120\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 293.0916 - mae: 13.5469 - val_loss: 280.1564 - val_mae: 13.3018\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.9883 - mae: 13.5434 - val_loss: 280.2412 - val_mae: 13.3008\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.6606 - mae: 13.5213 - val_loss: 279.8062 - val_mae: 13.2852\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 292.6234 - mae: 13.5356 - val_loss: 279.6777 - val_mae: 13.2731\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 292.4426 - mae: 13.4946 - val_loss: 279.7596 - val_mae: 13.2885\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.2484 - mae: 13.5258 - val_loss: 279.6033 - val_mae: 13.2663\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.2377 - mae: 13.4959 - val_loss: 279.2822 - val_mae: 13.2633\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.3394 - mae: 13.4978 - val_loss: 279.4477 - val_mae: 13.2897\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 291.8186 - mae: 13.5442 - val_loss: 279.2394 - val_mae: 13.2504\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.9769 - mae: 13.5032 - val_loss: 278.9551 - val_mae: 13.2325\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.9557 - mae: 13.4960 - val_loss: 279.0436 - val_mae: 13.2330\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.8835 - mae: 13.4736 - val_loss: 278.6448 - val_mae: 13.2371\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.7091 - mae: 13.4863 - val_loss: 278.5455 - val_mae: 13.2359\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.5107 - mae: 13.4875 - val_loss: 278.8497 - val_mae: 13.2419\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.2810 - mae: 13.4802 - val_loss: 278.3719 - val_mae: 13.2226\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.2220 - mae: 13.4694 - val_loss: 278.5944 - val_mae: 13.2150\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 291.2795 - mae: 13.4400 - val_loss: 278.4189 - val_mae: 13.2196\n",
      "Epoch 55: early stopping\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   3.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 32ms/step - loss: 9316.7656 - mae: 64.1915 - val_loss: 9661.6074 - val_mae: 64.7824\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9308.6748 - mae: 64.1560 - val_loss: 9653.3789 - val_mae: 64.7468\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9300.6387 - mae: 64.1207 - val_loss: 9645.1113 - val_mae: 64.7109\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9292.5811 - mae: 64.0852 - val_loss: 9636.8379 - val_mae: 64.6751\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9284.6807 - mae: 64.0502 - val_loss: 9628.4824 - val_mae: 64.6391\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9276.5674 - mae: 64.0147 - val_loss: 9620.2354 - val_mae: 64.6034\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9268.6582 - mae: 63.9796 - val_loss: 9611.9854 - val_mae: 64.5678\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9260.6270 - mae: 63.9443 - val_loss: 9603.7900 - val_mae: 64.5323\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9252.6279 - mae: 63.9092 - val_loss: 9595.6113 - val_mae: 64.4969\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9244.7158 - mae: 63.8741 - val_loss: 9587.4141 - val_mae: 64.4615\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9236.7178 - mae: 63.8389 - val_loss: 9579.2168 - val_mae: 64.4260\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9228.7969 - mae: 63.8039 - val_loss: 9570.9863 - val_mae: 64.3903\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9220.8447 - mae: 63.7689 - val_loss: 9562.8369 - val_mae: 64.3550\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9212.8447 - mae: 63.7337 - val_loss: 9554.7041 - val_mae: 64.3197\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9204.9727 - mae: 63.6989 - val_loss: 9546.5488 - val_mae: 64.2844\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9197.1387 - mae: 63.6641 - val_loss: 9538.3428 - val_mae: 64.2488\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9189.1523 - mae: 63.6290 - val_loss: 9530.2422 - val_mae: 64.2136\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9181.3604 - mae: 63.5943 - val_loss: 9522.0400 - val_mae: 64.1780\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9173.3896 - mae: 63.5591 - val_loss: 9513.9131 - val_mae: 64.1428\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9165.4902 - mae: 63.5244 - val_loss: 9505.7773 - val_mae: 64.1074\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9157.5771 - mae: 63.4895 - val_loss: 9497.6387 - val_mae: 64.0721\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9149.6836 - mae: 63.4547 - val_loss: 9489.5742 - val_mae: 64.0370\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9141.8555 - mae: 63.4201 - val_loss: 9481.4990 - val_mae: 64.0018\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9133.9854 - mae: 63.3854 - val_loss: 9473.3916 - val_mae: 63.9666\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9126.1816 - mae: 63.3509 - val_loss: 9465.2295 - val_mae: 63.9311\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9118.2168 - mae: 63.3160 - val_loss: 9457.1514 - val_mae: 63.8959\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9110.5127 - mae: 63.2816 - val_loss: 9449.0117 - val_mae: 63.8603\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9102.6748 - mae: 63.2469 - val_loss: 9440.9883 - val_mae: 63.8253\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9094.8105 - mae: 63.2123 - val_loss: 9433.0244 - val_mae: 63.7905\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9087.0508 - mae: 63.1779 - val_loss: 9425.0059 - val_mae: 63.7556\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9079.2432 - mae: 63.1436 - val_loss: 9417.0381 - val_mae: 63.7207\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9071.5566 - mae: 63.1094 - val_loss: 9409.0303 - val_mae: 63.6856\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9063.7842 - mae: 63.0751 - val_loss: 9400.9893 - val_mae: 63.6507\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9055.9004 - mae: 63.0407 - val_loss: 9393.1074 - val_mae: 63.6165\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9048.3750 - mae: 63.0070 - val_loss: 9385.0586 - val_mae: 63.5815\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9040.5176 - mae: 62.9725 - val_loss: 9377.1064 - val_mae: 63.5468\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9032.7842 - mae: 62.9383 - val_loss: 9369.1133 - val_mae: 63.5119\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9025.0742 - mae: 62.9040 - val_loss: 9361.0869 - val_mae: 63.4771\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9017.2188 - mae: 62.8696 - val_loss: 9353.1445 - val_mae: 63.4425\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9009.5811 - mae: 62.8357 - val_loss: 9345.1729 - val_mae: 63.4077\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9001.9307 - mae: 62.8018 - val_loss: 9337.2012 - val_mae: 63.3729\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8994.1660 - mae: 62.7676 - val_loss: 9329.3105 - val_mae: 63.3386\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8986.4717 - mae: 62.7336 - val_loss: 9321.4082 - val_mae: 63.3040\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8978.8271 - mae: 62.6997 - val_loss: 9313.4395 - val_mae: 63.2692\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8971.1279 - mae: 62.6656 - val_loss: 9305.5332 - val_mae: 63.2347\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8963.4600 - mae: 62.6317 - val_loss: 9297.6523 - val_mae: 63.2004\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8955.7656 - mae: 62.5976 - val_loss: 9289.7861 - val_mae: 63.1661\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8948.0947 - mae: 62.5637 - val_loss: 9281.9307 - val_mae: 63.1319\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8940.4434 - mae: 62.5298 - val_loss: 9274.0898 - val_mae: 63.0978\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8932.8320 - mae: 62.4960 - val_loss: 9266.1719 - val_mae: 63.0633\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8925.1680 - mae: 62.4619 - val_loss: 9258.2822 - val_mae: 63.0290\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8917.5293 - mae: 62.4281 - val_loss: 9250.3896 - val_mae: 62.9946\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8909.9277 - mae: 62.3944 - val_loss: 9242.5166 - val_mae: 62.9603\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8902.2344 - mae: 62.3605 - val_loss: 9234.7588 - val_mae: 62.9263\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8894.7275 - mae: 62.3270 - val_loss: 9226.9453 - val_mae: 62.8922\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8887.1914 - mae: 62.2935 - val_loss: 9219.0771 - val_mae: 62.8578\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8879.5312 - mae: 62.2596 - val_loss: 9211.2871 - val_mae: 62.8237\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8872.0254 - mae: 62.2262 - val_loss: 9203.4932 - val_mae: 62.7896\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8864.4590 - mae: 62.1927 - val_loss: 9195.7354 - val_mae: 62.7556\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 8857.0049 - mae: 62.1593 - val_loss: 9187.9141 - val_mae: 62.7214\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8849.3701 - mae: 62.1253 - val_loss: 9180.1309 - val_mae: 62.6874\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8841.8789 - mae: 62.0921 - val_loss: 9172.2900 - val_mae: 62.6533\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8834.2871 - mae: 62.0584 - val_loss: 9164.5635 - val_mae: 62.6195\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8826.7959 - mae: 62.0251 - val_loss: 9156.7812 - val_mae: 62.5855\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8819.1748 - mae: 61.9914 - val_loss: 9149.1006 - val_mae: 62.5520\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8811.7979 - mae: 61.9583 - val_loss: 9141.2588 - val_mae: 62.5180\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8804.1729 - mae: 61.9246 - val_loss: 9133.5254 - val_mae: 62.4844\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8796.6797 - mae: 61.8914 - val_loss: 9125.8018 - val_mae: 62.4508\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8789.2080 - mae: 61.8581 - val_loss: 9118.0703 - val_mae: 62.4173\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8781.6797 - mae: 61.8248 - val_loss: 9110.3770 - val_mae: 62.3840\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8774.2441 - mae: 61.7916 - val_loss: 9102.6836 - val_mae: 62.3508\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8766.8389 - mae: 61.7585 - val_loss: 9094.9541 - val_mae: 62.3175\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8759.2344 - mae: 61.7253 - val_loss: 9087.3945 - val_mae: 62.2848\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8751.8477 - mae: 61.6925 - val_loss: 9079.7422 - val_mae: 62.2517\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8744.4648 - mae: 61.6595 - val_loss: 9071.9854 - val_mae: 62.2181\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8737.0000 - mae: 61.6262 - val_loss: 9064.2227 - val_mae: 62.1845\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8729.4619 - mae: 61.5930 - val_loss: 9056.5771 - val_mae: 62.1514\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8722.1289 - mae: 61.5602 - val_loss: 9048.8789 - val_mae: 62.1181\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8714.6445 - mae: 61.5272 - val_loss: 9041.2246 - val_mae: 62.0849\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8707.2559 - mae: 61.4943 - val_loss: 9033.5762 - val_mae: 62.0517\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8699.8232 - mae: 61.4613 - val_loss: 9025.9570 - val_mae: 62.0187\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8692.4727 - mae: 61.4285 - val_loss: 9018.2803 - val_mae: 61.9853\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8684.9727 - mae: 61.3954 - val_loss: 9010.6514 - val_mae: 61.9522\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8677.5605 - mae: 61.3624 - val_loss: 9003.0488 - val_mae: 61.9192\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8670.2090 - mae: 61.3297 - val_loss: 8995.3945 - val_mae: 61.8859\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8662.7871 - mae: 61.2966 - val_loss: 8987.8018 - val_mae: 61.8528\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8655.4209 - mae: 61.2640 - val_loss: 8980.2070 - val_mae: 61.8198\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8648.0352 - mae: 61.2311 - val_loss: 8972.6396 - val_mae: 61.7871\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8640.7969 - mae: 61.1986 - val_loss: 8964.9912 - val_mae: 61.7539\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8633.3652 - mae: 61.1657 - val_loss: 8957.4609 - val_mae: 61.7213\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8626.0615 - mae: 61.1331 - val_loss: 8949.8730 - val_mae: 61.6883\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8618.6436 - mae: 61.1002 - val_loss: 8942.3711 - val_mae: 61.6558\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8611.4932 - mae: 61.0680 - val_loss: 8934.6797 - val_mae: 61.6224\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8604.0195 - mae: 61.0350 - val_loss: 8927.1514 - val_mae: 61.5899\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8596.6777 - mae: 61.0025 - val_loss: 8919.6260 - val_mae: 61.5573\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8589.4648 - mae: 60.9700 - val_loss: 8912.0088 - val_mae: 61.5243\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8582.1348 - mae: 60.9374 - val_loss: 8904.4863 - val_mae: 61.4917\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8574.8584 - mae: 60.9049 - val_loss: 8896.9785 - val_mae: 61.4591\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8567.4961 - mae: 60.8722 - val_loss: 8889.5479 - val_mae: 61.4268\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8560.3203 - mae: 60.8401 - val_loss: 8882.0117 - val_mae: 61.3941\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   5.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 32ms/step - loss: 11188.2119 - mae: 74.7366 - val_loss: 12020.4756 - val_mae: 77.0282\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11178.2334 - mae: 74.6982 - val_loss: 12009.9521 - val_mae: 76.9885\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11168.4648 - mae: 74.6599 - val_loss: 11999.3809 - val_mae: 76.9485\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11158.8193 - mae: 74.6220 - val_loss: 11988.8379 - val_mae: 76.9087\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11148.7852 - mae: 74.5836 - val_loss: 11978.4482 - val_mae: 76.8694\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11138.9248 - mae: 74.5456 - val_loss: 11968.0371 - val_mae: 76.8298\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11129.2344 - mae: 74.5076 - val_loss: 11957.5186 - val_mae: 76.7900\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11119.4463 - mae: 74.4694 - val_loss: 11947.0127 - val_mae: 76.7501\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11109.6543 - mae: 74.4312 - val_loss: 11936.5303 - val_mae: 76.7103\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11099.7021 - mae: 74.3930 - val_loss: 11926.1885 - val_mae: 76.6709\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11090.1260 - mae: 74.3552 - val_loss: 11915.7324 - val_mae: 76.6311\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11080.3555 - mae: 74.3173 - val_loss: 11905.3955 - val_mae: 76.5919\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11070.6680 - mae: 74.2796 - val_loss: 11894.9951 - val_mae: 76.5524\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11060.9463 - mae: 74.2419 - val_loss: 11884.6729 - val_mae: 76.5132\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11051.4209 - mae: 74.2042 - val_loss: 11874.2002 - val_mae: 76.4735\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11041.5762 - mae: 74.1661 - val_loss: 11863.8799 - val_mae: 76.4348\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11031.8447 - mae: 74.1284 - val_loss: 11853.5889 - val_mae: 76.3961\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11022.1572 - mae: 74.0908 - val_loss: 11843.2568 - val_mae: 76.3571\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11012.5498 - mae: 74.0530 - val_loss: 11832.8701 - val_mae: 76.3181\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11002.8926 - mae: 74.0153 - val_loss: 11822.4883 - val_mae: 76.2789\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10993.0654 - mae: 73.9774 - val_loss: 11812.2832 - val_mae: 76.2407\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10983.5811 - mae: 73.9400 - val_loss: 11801.9102 - val_mae: 76.2018\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10974.0361 - mae: 73.9024 - val_loss: 11791.5146 - val_mae: 76.1627\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10964.2148 - mae: 73.8646 - val_loss: 11781.3193 - val_mae: 76.1246\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10954.6758 - mae: 73.8271 - val_loss: 11771.0273 - val_mae: 76.0861\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10945.0947 - mae: 73.7892 - val_loss: 11760.6553 - val_mae: 76.0472\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10935.3545 - mae: 73.7515 - val_loss: 11750.4521 - val_mae: 76.0091\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10925.7559 - mae: 73.7141 - val_loss: 11740.2139 - val_mae: 75.9708\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10916.0771 - mae: 73.6765 - val_loss: 11730.0508 - val_mae: 75.9327\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10906.5996 - mae: 73.6394 - val_loss: 11719.8193 - val_mae: 75.8946\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10897.1465 - mae: 73.6019 - val_loss: 11709.4893 - val_mae: 75.8561\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10887.5645 - mae: 73.5643 - val_loss: 11699.1514 - val_mae: 75.8176\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10877.8818 - mae: 73.5266 - val_loss: 11688.9814 - val_mae: 75.7796\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10868.2969 - mae: 73.4893 - val_loss: 11678.8311 - val_mae: 75.7418\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10858.7109 - mae: 73.4519 - val_loss: 11668.6396 - val_mae: 75.7036\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10849.3145 - mae: 73.4147 - val_loss: 11658.2637 - val_mae: 75.6647\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10839.5059 - mae: 73.3768 - val_loss: 11648.1338 - val_mae: 75.6268\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10830.0205 - mae: 73.3396 - val_loss: 11637.9980 - val_mae: 75.5890\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10820.5137 - mae: 73.3025 - val_loss: 11627.7734 - val_mae: 75.5507\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10810.8701 - mae: 73.2649 - val_loss: 11617.7002 - val_mae: 75.5129\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10801.4453 - mae: 73.2278 - val_loss: 11607.4131 - val_mae: 75.4743\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10791.7900 - mae: 73.1902 - val_loss: 11597.2070 - val_mae: 75.4361\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10782.3955 - mae: 73.1529 - val_loss: 11586.8242 - val_mae: 75.3972\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10772.6299 - mae: 73.1148 - val_loss: 11576.6260 - val_mae: 75.3588\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10763.1025 - mae: 73.0776 - val_loss: 11566.4805 - val_mae: 75.3208\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10753.6816 - mae: 73.0403 - val_loss: 11556.3291 - val_mae: 75.2827\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10744.0059 - mae: 73.0031 - val_loss: 11546.3359 - val_mae: 75.2451\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10734.7656 - mae: 72.9663 - val_loss: 11536.1611 - val_mae: 75.2068\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10725.2725 - mae: 72.9290 - val_loss: 11526.0889 - val_mae: 75.1689\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10715.9111 - mae: 72.8919 - val_loss: 11515.8857 - val_mae: 75.1305\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10706.2900 - mae: 72.8546 - val_loss: 11505.8447 - val_mae: 75.0927\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10696.8740 - mae: 72.8177 - val_loss: 11495.7764 - val_mae: 75.0549\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10687.5293 - mae: 72.7807 - val_loss: 11485.6357 - val_mae: 75.0169\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10677.9951 - mae: 72.7435 - val_loss: 11475.5645 - val_mae: 74.9791\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10668.4863 - mae: 72.7064 - val_loss: 11465.5391 - val_mae: 74.9416\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10659.2686 - mae: 72.6699 - val_loss: 11455.4189 - val_mae: 74.9035\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10649.7705 - mae: 72.6328 - val_loss: 11445.4893 - val_mae: 74.8662\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10640.5381 - mae: 72.5963 - val_loss: 11435.4170 - val_mae: 74.8283\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10631.0527 - mae: 72.5593 - val_loss: 11425.4893 - val_mae: 74.7909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10621.7812 - mae: 72.5227 - val_loss: 11415.4854 - val_mae: 74.7533\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10612.4229 - mae: 72.4859 - val_loss: 11405.5205 - val_mae: 74.7157\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10603.1465 - mae: 72.4494 - val_loss: 11395.5352 - val_mae: 74.6781\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10593.7256 - mae: 72.4125 - val_loss: 11385.6553 - val_mae: 74.6408\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10584.5273 - mae: 72.3763 - val_loss: 11375.6865 - val_mae: 74.6032\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10575.1318 - mae: 72.3395 - val_loss: 11365.8125 - val_mae: 74.5661\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10565.7539 - mae: 72.3028 - val_loss: 11355.9111 - val_mae: 74.5287\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10556.6436 - mae: 72.2663 - val_loss: 11345.7363 - val_mae: 74.4903\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10547.1016 - mae: 72.2289 - val_loss: 11335.7500 - val_mae: 74.4526\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10537.8096 - mae: 72.1922 - val_loss: 11325.7959 - val_mae: 74.4150\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10528.5098 - mae: 72.1556 - val_loss: 11315.8916 - val_mae: 74.3776\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10519.2871 - mae: 72.1192 - val_loss: 11306.0293 - val_mae: 74.3403\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10510.0781 - mae: 72.0829 - val_loss: 11296.1387 - val_mae: 74.3030\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10500.8467 - mae: 72.0464 - val_loss: 11286.2412 - val_mae: 74.2655\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10491.5176 - mae: 72.0097 - val_loss: 11276.4072 - val_mae: 74.2283\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10482.3389 - mae: 71.9735 - val_loss: 11266.5498 - val_mae: 74.1912\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10473.0889 - mae: 71.9371 - val_loss: 11256.7451 - val_mae: 74.1541\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10463.9512 - mae: 71.9008 - val_loss: 11246.8916 - val_mae: 74.1169\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10454.8066 - mae: 71.8644 - val_loss: 11236.9609 - val_mae: 74.0794\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10445.3975 - mae: 71.8278 - val_loss: 11227.2334 - val_mae: 74.0426\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10436.3232 - mae: 71.7916 - val_loss: 11217.3174 - val_mae: 74.0050\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10427.0908 - mae: 71.7551 - val_loss: 11207.4639 - val_mae: 73.9677\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10417.8623 - mae: 71.7187 - val_loss: 11197.7139 - val_mae: 73.9308\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10408.7451 - mae: 71.6827 - val_loss: 11187.8936 - val_mae: 73.8936\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10399.4980 - mae: 71.6464 - val_loss: 11178.1113 - val_mae: 73.8565\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10390.2812 - mae: 71.6100 - val_loss: 11168.3037 - val_mae: 73.8192\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10381.1641 - mae: 71.5736 - val_loss: 11158.3486 - val_mae: 73.7814\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10371.8613 - mae: 71.5369 - val_loss: 11148.4912 - val_mae: 73.7441\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10362.6885 - mae: 71.5006 - val_loss: 11138.6611 - val_mae: 73.7067\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10353.4229 - mae: 71.4643 - val_loss: 11128.9287 - val_mae: 73.6698\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10344.3779 - mae: 71.4282 - val_loss: 11119.1113 - val_mae: 73.6324\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10335.0889 - mae: 71.3918 - val_loss: 11109.4229 - val_mae: 73.5956\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10326.1201 - mae: 71.3559 - val_loss: 11099.4814 - val_mae: 73.5576\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10316.9072 - mae: 71.3192 - val_loss: 11089.6797 - val_mae: 73.5204\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10307.8613 - mae: 71.2831 - val_loss: 11079.8584 - val_mae: 73.4831\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10298.6201 - mae: 71.2468 - val_loss: 11070.2109 - val_mae: 73.4464\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10289.5498 - mae: 71.2110 - val_loss: 11060.5547 - val_mae: 73.4098\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10280.5352 - mae: 71.1751 - val_loss: 11050.7607 - val_mae: 73.3726\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10271.3984 - mae: 71.1389 - val_loss: 11041.0449 - val_mae: 73.3357\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10262.3506 - mae: 71.1030 - val_loss: 11031.3691 - val_mae: 73.2990\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10253.2568 - mae: 71.0670 - val_loss: 11021.7383 - val_mae: 73.2623\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   5.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 8714.2100 - mae: 63.9078 - val_loss: 9041.6006 - val_mae: 64.7136\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8706.5439 - mae: 63.8780 - val_loss: 9033.4873 - val_mae: 64.6814\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8698.8008 - mae: 63.8479 - val_loss: 9025.3564 - val_mae: 64.6489\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8691.3135 - mae: 63.8185 - val_loss: 9017.1367 - val_mae: 64.6161\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8683.5342 - mae: 63.7884 - val_loss: 9009.0576 - val_mae: 64.5838\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8676.0332 - mae: 63.7587 - val_loss: 9000.8770 - val_mae: 64.5511\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8668.3418 - mae: 63.7289 - val_loss: 8992.7734 - val_mae: 64.5189\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8660.6973 - mae: 63.6990 - val_loss: 8984.7061 - val_mae: 64.4868\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8653.1426 - mae: 63.6694 - val_loss: 8976.6201 - val_mae: 64.4546\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8645.5508 - mae: 63.6396 - val_loss: 8968.5352 - val_mae: 64.4225\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8637.9854 - mae: 63.6100 - val_loss: 8960.4297 - val_mae: 64.3902\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8630.3809 - mae: 63.5803 - val_loss: 8952.3740 - val_mae: 64.3581\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8622.8418 - mae: 63.5507 - val_loss: 8944.3428 - val_mae: 64.3260\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8615.2305 - mae: 63.5209 - val_loss: 8936.3477 - val_mae: 64.2941\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8607.7539 - mae: 63.4915 - val_loss: 8928.3145 - val_mae: 64.2620\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8600.1504 - mae: 63.4618 - val_loss: 8920.2852 - val_mae: 64.2300\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8592.7051 - mae: 63.4324 - val_loss: 8912.2061 - val_mae: 64.1976\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8585.1660 - mae: 63.4027 - val_loss: 8904.1885 - val_mae: 64.1655\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8577.5400 - mae: 63.3728 - val_loss: 8896.2617 - val_mae: 64.1338\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8570.1377 - mae: 63.3436 - val_loss: 8888.2490 - val_mae: 64.1016\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8562.5312 - mae: 63.3138 - val_loss: 8880.2939 - val_mae: 64.0696\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8555.1562 - mae: 63.2845 - val_loss: 8872.2178 - val_mae: 64.0374\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8547.5518 - mae: 63.2547 - val_loss: 8864.2178 - val_mae: 64.0054\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8540.0371 - mae: 63.2250 - val_loss: 8856.2471 - val_mae: 63.9735\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8532.5498 - mae: 63.1954 - val_loss: 8848.2803 - val_mae: 63.9416\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8525.1025 - mae: 63.1660 - val_loss: 8840.2588 - val_mae: 63.9096\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8517.5664 - mae: 63.1363 - val_loss: 8832.2490 - val_mae: 63.8775\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8510.1260 - mae: 63.1068 - val_loss: 8824.2393 - val_mae: 63.8454\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8502.5625 - mae: 63.0772 - val_loss: 8816.3193 - val_mae: 63.8136\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8495.0068 - mae: 63.0476 - val_loss: 8808.4561 - val_mae: 63.7821\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8487.7168 - mae: 63.0186 - val_loss: 8800.4082 - val_mae: 63.7498\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8480.1875 - mae: 62.9890 - val_loss: 8792.4551 - val_mae: 63.7179\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8472.7051 - mae: 62.9595 - val_loss: 8784.5488 - val_mae: 63.6861\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8465.2891 - mae: 62.9302 - val_loss: 8776.6396 - val_mae: 63.6544\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8457.8340 - mae: 62.9007 - val_loss: 8768.7236 - val_mae: 63.6224\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8450.3584 - mae: 62.8712 - val_loss: 8760.8105 - val_mae: 63.5905\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8443.0078 - mae: 62.8419 - val_loss: 8752.8545 - val_mae: 63.5584\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8435.5312 - mae: 62.8125 - val_loss: 8744.9648 - val_mae: 63.5265\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8428.1543 - mae: 62.7832 - val_loss: 8737.0361 - val_mae: 63.4944\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8420.7373 - mae: 62.7538 - val_loss: 8729.1416 - val_mae: 63.4624\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8413.2715 - mae: 62.7243 - val_loss: 8721.3389 - val_mae: 63.4308\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8406.0107 - mae: 62.6954 - val_loss: 8713.4355 - val_mae: 63.3987\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8398.5068 - mae: 62.6658 - val_loss: 8705.6680 - val_mae: 63.3671\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8391.2061 - mae: 62.6369 - val_loss: 8697.8115 - val_mae: 63.3351\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8383.9277 - mae: 62.6078 - val_loss: 8689.8447 - val_mae: 63.3028\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8376.4297 - mae: 62.5782 - val_loss: 8681.9932 - val_mae: 63.2709\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8369.1426 - mae: 62.5491 - val_loss: 8674.0898 - val_mae: 63.2387\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8361.7285 - mae: 62.5199 - val_loss: 8666.2734 - val_mae: 63.2068\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8354.4385 - mae: 62.4908 - val_loss: 8658.4355 - val_mae: 63.1748\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8347.0244 - mae: 62.4615 - val_loss: 8650.6631 - val_mae: 63.1431\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8339.6963 - mae: 62.4325 - val_loss: 8642.9053 - val_mae: 63.1114\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8332.3887 - mae: 62.4034 - val_loss: 8635.1025 - val_mae: 63.0795\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8325.0547 - mae: 62.3742 - val_loss: 8627.3184 - val_mae: 63.0477\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8317.7568 - mae: 62.3450 - val_loss: 8619.4551 - val_mae: 63.0155\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8310.3447 - mae: 62.3155 - val_loss: 8611.6611 - val_mae: 62.9835\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8302.9629 - mae: 62.2862 - val_loss: 8603.8838 - val_mae: 62.9516\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8295.6973 - mae: 62.2570 - val_loss: 8596.0820 - val_mae: 62.9196\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8288.4385 - mae: 62.2279 - val_loss: 8588.2568 - val_mae: 62.8875\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8281.0225 - mae: 62.1984 - val_loss: 8580.5469 - val_mae: 62.8556\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 8273.8662 - mae: 62.1696 - val_loss: 8572.7334 - val_mae: 62.8234\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8266.5283 - mae: 62.1402 - val_loss: 8564.9570 - val_mae: 62.7912\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8259.1875 - mae: 62.1110 - val_loss: 8557.2627 - val_mae: 62.7594\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8251.9531 - mae: 62.0820 - val_loss: 8549.5645 - val_mae: 62.7275\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8244.7451 - mae: 62.0529 - val_loss: 8541.7725 - val_mae: 62.6952\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8237.4082 - mae: 62.0234 - val_loss: 8534.0264 - val_mae: 62.6631\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8230.0840 - mae: 61.9940 - val_loss: 8526.3086 - val_mae: 62.6311\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8222.8984 - mae: 61.9651 - val_loss: 8518.5605 - val_mae: 62.5989\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8215.6104 - mae: 61.9357 - val_loss: 8510.8047 - val_mae: 62.5667\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8208.3564 - mae: 61.9063 - val_loss: 8503.0352 - val_mae: 62.5346\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8201.1025 - mae: 61.8769 - val_loss: 8495.3340 - val_mae: 62.5028\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8193.8516 - mae: 61.8475 - val_loss: 8487.6768 - val_mae: 62.4711\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8186.5781 - mae: 61.8182 - val_loss: 8480.0498 - val_mae: 62.4396\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8179.4023 - mae: 61.7891 - val_loss: 8472.3740 - val_mae: 62.4079\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8172.2471 - mae: 61.7598 - val_loss: 8464.6416 - val_mae: 62.3759\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8164.9658 - mae: 61.7304 - val_loss: 8457.0029 - val_mae: 62.3445\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8157.7485 - mae: 61.7012 - val_loss: 8449.3604 - val_mae: 62.3130\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8150.6147 - mae: 61.6721 - val_loss: 8441.6924 - val_mae: 62.2815\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8143.4121 - mae: 61.6428 - val_loss: 8434.0479 - val_mae: 62.2500\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8136.2891 - mae: 61.6137 - val_loss: 8426.3643 - val_mae: 62.2183\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8128.9365 - mae: 61.5842 - val_loss: 8418.8516 - val_mae: 62.1870\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8121.9023 - mae: 61.5553 - val_loss: 8411.1953 - val_mae: 62.1554\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8114.7896 - mae: 61.5262 - val_loss: 8403.5137 - val_mae: 62.1235\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8107.5493 - mae: 61.4969 - val_loss: 8395.9229 - val_mae: 62.0921\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8100.3428 - mae: 61.4675 - val_loss: 8388.3584 - val_mae: 62.0607\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8093.3047 - mae: 61.4387 - val_loss: 8380.6953 - val_mae: 62.0287\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8086.0854 - mae: 61.4093 - val_loss: 8373.1250 - val_mae: 61.9971\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8079.0244 - mae: 61.3804 - val_loss: 8365.4980 - val_mae: 61.9652\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8071.8394 - mae: 61.3510 - val_loss: 8357.9580 - val_mae: 61.9337\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8064.7563 - mae: 61.3218 - val_loss: 8350.4053 - val_mae: 61.9021\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8057.6841 - mae: 61.2927 - val_loss: 8342.8350 - val_mae: 61.8705\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8050.4600 - mae: 61.2633 - val_loss: 8335.3711 - val_mae: 61.8394\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8043.5088 - mae: 61.2345 - val_loss: 8327.7012 - val_mae: 61.8075\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8036.2344 - mae: 61.2047 - val_loss: 8320.1738 - val_mae: 61.7764\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8029.1050 - mae: 61.1755 - val_loss: 8312.6670 - val_mae: 61.7451\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8022.1914 - mae: 61.1468 - val_loss: 8304.9629 - val_mae: 61.7130\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8015.0039 - mae: 61.1172 - val_loss: 8297.3711 - val_mae: 61.6814\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8007.8281 - mae: 61.0877 - val_loss: 8289.8447 - val_mae: 61.6500\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8000.7090 - mae: 61.0584 - val_loss: 8282.3730 - val_mae: 61.6188\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7993.6611 - mae: 61.0293 - val_loss: 8274.9033 - val_mae: 61.5876\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7986.7026 - mae: 61.0004 - val_loss: 8267.3633 - val_mae: 61.5560\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   4.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2188 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2188 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   1.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 989.7880 - mae: 24.8544 - val_loss: 896.1489 - val_mae: 23.3933\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 906.7639 - mae: 24.0137 - val_loss: 818.8457 - val_mae: 22.5747\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 837.4891 - mae: 23.2699 - val_loss: 754.2288 - val_mae: 21.8438\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 779.4498 - mae: 22.6037 - val_loss: 698.5731 - val_mae: 21.1743\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 729.5573 - mae: 21.9922 - val_loss: 651.4003 - val_mae: 20.5793\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.3311 - mae: 21.4522 - val_loss: 611.0817 - val_mae: 20.0443\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.2055 - mae: 20.9706 - val_loss: 575.9835 - val_mae: 19.5551\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.8662 - mae: 20.5294 - val_loss: 545.8041 - val_mae: 19.1204\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.8380 - mae: 20.1280 - val_loss: 519.2852 - val_mae: 18.7232\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.1902 - mae: 19.7684 - val_loss: 496.4652 - val_mae: 18.3679\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.7266 - mae: 19.4430 - val_loss: 475.7867 - val_mae: 18.0350\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.3102 - mae: 19.1373 - val_loss: 457.6670 - val_mae: 17.7355\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.1308 - mae: 18.8625 - val_loss: 441.3859 - val_mae: 17.4586\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 499.6305 - mae: 18.6085 - val_loss: 427.0815 - val_mae: 17.2050\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.8656 - mae: 18.3765 - val_loss: 414.1519 - val_mae: 16.9670\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 475.2747 - mae: 18.1591 - val_loss: 402.5536 - val_mae: 16.7456\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.8320 - mae: 17.9547 - val_loss: 391.8755 - val_mae: 16.5344\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.3463 - mae: 17.7660 - val_loss: 382.3609 - val_mae: 16.3404\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.8102 - mae: 17.5905 - val_loss: 373.7028 - val_mae: 16.1589\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.0198 - mae: 17.4251 - val_loss: 365.6516 - val_mae: 15.9868\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.8419 - mae: 17.2683 - val_loss: 358.4299 - val_mae: 15.8292\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.3541 - mae: 17.1234 - val_loss: 351.8527 - val_mae: 15.6816\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.3678 - mae: 16.9856 - val_loss: 345.8199 - val_mae: 15.5433\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.8974 - mae: 16.8560 - val_loss: 340.2541 - val_mae: 15.4157\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.8549 - mae: 16.7376 - val_loss: 335.0214 - val_mae: 15.2940\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.1560 - mae: 16.6230 - val_loss: 330.1219 - val_mae: 15.1770\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.8037 - mae: 16.5142 - val_loss: 325.6469 - val_mae: 15.0677\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.7861 - mae: 16.4131 - val_loss: 321.5219 - val_mae: 14.9645\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.0955 - mae: 16.3183 - val_loss: 317.6199 - val_mae: 14.8658\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.6523 - mae: 16.2288 - val_loss: 314.0179 - val_mae: 14.7733\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.4316 - mae: 16.1424 - val_loss: 310.6573 - val_mae: 14.6859\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.4486 - mae: 16.0618 - val_loss: 307.5190 - val_mae: 14.6022\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.6468 - mae: 15.9861 - val_loss: 304.5765 - val_mae: 14.5227\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.0301 - mae: 15.9126 - val_loss: 301.8195 - val_mae: 14.4486\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.5712 - mae: 15.8438 - val_loss: 299.2641 - val_mae: 14.3789\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.2849 - mae: 15.7784 - val_loss: 296.7637 - val_mae: 14.3116\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.0827 - mae: 15.7146 - val_loss: 294.4883 - val_mae: 14.2486\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.0692 - mae: 15.6577 - val_loss: 292.3003 - val_mae: 14.1877\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.1588 - mae: 15.6021 - val_loss: 290.2541 - val_mae: 14.1304\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 364.3644 - mae: 15.5494 - val_loss: 288.4053 - val_mae: 14.0779\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.6842 - mae: 15.4987 - val_loss: 286.5972 - val_mae: 14.0272\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.0820 - mae: 15.4521 - val_loss: 284.9041 - val_mae: 13.9784\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.5869 - mae: 15.4063 - val_loss: 283.3149 - val_mae: 13.9327\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 358.1900 - mae: 15.3635 - val_loss: 281.8152 - val_mae: 13.8891\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 356.8494 - mae: 15.3230 - val_loss: 280.3994 - val_mae: 13.8481\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 355.5913 - mae: 15.2849 - val_loss: 278.9734 - val_mae: 13.8075\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 354.3668 - mae: 15.2487 - val_loss: 277.6341 - val_mae: 13.7689\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.1994 - mae: 15.2122 - val_loss: 276.3825 - val_mae: 13.7329\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.1308 - mae: 15.1794 - val_loss: 275.1184 - val_mae: 13.6981\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.0806 - mae: 15.1476 - val_loss: 274.0174 - val_mae: 13.6671\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.1000 - mae: 15.1185 - val_loss: 272.9229 - val_mae: 13.6365\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.1680 - mae: 15.0889 - val_loss: 271.9064 - val_mae: 13.6075\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.2943 - mae: 15.0616 - val_loss: 270.9244 - val_mae: 13.5802\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.4359 - mae: 15.0359 - val_loss: 269.9398 - val_mae: 13.5538\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.6024 - mae: 15.0117 - val_loss: 269.0146 - val_mae: 13.5280\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.8324 - mae: 14.9874 - val_loss: 268.1673 - val_mae: 13.5032\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.0807 - mae: 14.9643 - val_loss: 267.2975 - val_mae: 13.4791\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.3605 - mae: 14.9424 - val_loss: 266.4824 - val_mae: 13.4560\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.6617 - mae: 14.9219 - val_loss: 265.6581 - val_mae: 13.4325\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.9949 - mae: 14.9010 - val_loss: 264.8937 - val_mae: 13.4100\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 342.3412 - mae: 14.8811 - val_loss: 264.1904 - val_mae: 13.3891\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.7081 - mae: 14.8620 - val_loss: 263.4758 - val_mae: 13.3678\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.1083 - mae: 14.8437 - val_loss: 262.7472 - val_mae: 13.3469\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.4937 - mae: 14.8251 - val_loss: 262.0473 - val_mae: 13.3269\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.9318 - mae: 14.8076 - val_loss: 261.3543 - val_mae: 13.3074\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.3192 - mae: 14.7898 - val_loss: 260.6761 - val_mae: 13.2880\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.6891 - mae: 14.7720 - val_loss: 259.9812 - val_mae: 13.2686\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.0603 - mae: 14.7547 - val_loss: 259.2745 - val_mae: 13.2489\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.4193 - mae: 14.7366 - val_loss: 258.6036 - val_mae: 13.2295\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.7809 - mae: 14.7189 - val_loss: 257.9388 - val_mae: 13.2106\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.1670 - mae: 14.7023 - val_loss: 257.3402 - val_mae: 13.1931\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.5630 - mae: 14.6853 - val_loss: 256.6957 - val_mae: 13.1751\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.9825 - mae: 14.6688 - val_loss: 256.0888 - val_mae: 13.1583\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 334.4089 - mae: 14.6537 - val_loss: 255.4306 - val_mae: 13.1407\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.8694 - mae: 14.6389 - val_loss: 254.8468 - val_mae: 13.1243\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.3529 - mae: 14.6254 - val_loss: 254.2342 - val_mae: 13.1071\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.8341 - mae: 14.6089 - val_loss: 253.7345 - val_mae: 13.0925\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.3626 - mae: 14.5975 - val_loss: 253.1646 - val_mae: 13.0763\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.8437 - mae: 14.5813 - val_loss: 252.6137 - val_mae: 13.0610\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.3623 - mae: 14.5671 - val_loss: 252.0932 - val_mae: 13.0461\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.8772 - mae: 14.5539 - val_loss: 251.5770 - val_mae: 13.0308\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.4090 - mae: 14.5402 - val_loss: 251.0106 - val_mae: 13.0150\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.9426 - mae: 14.5263 - val_loss: 250.4831 - val_mae: 12.9996\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.4666 - mae: 14.5130 - val_loss: 249.9643 - val_mae: 12.9844\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 329.0098 - mae: 14.5004 - val_loss: 249.4025 - val_mae: 12.9686\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.5547 - mae: 14.4872 - val_loss: 248.8937 - val_mae: 12.9537\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.1033 - mae: 14.4747 - val_loss: 248.4022 - val_mae: 12.9388\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.6777 - mae: 14.4621 - val_loss: 247.9131 - val_mae: 12.9240\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.2503 - mae: 14.4492 - val_loss: 247.4075 - val_mae: 12.9087\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 326.8188 - mae: 14.4361 - val_loss: 246.8972 - val_mae: 12.8933\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 326.3850 - mae: 14.4230 - val_loss: 246.3926 - val_mae: 12.8781\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.9477 - mae: 14.4101 - val_loss: 245.8861 - val_mae: 12.8632\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.5089 - mae: 14.3969 - val_loss: 245.4056 - val_mae: 12.8484\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.0688 - mae: 14.3847 - val_loss: 244.8908 - val_mae: 12.8327\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.6405 - mae: 14.3717 - val_loss: 244.3933 - val_mae: 12.8172\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.1760 - mae: 14.3575 - val_loss: 243.8953 - val_mae: 12.8022\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 323.6993 - mae: 14.3440 - val_loss: 243.3661 - val_mae: 12.7858\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.2339 - mae: 14.3297 - val_loss: 242.8656 - val_mae: 12.7705\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.7602 - mae: 14.3166 - val_loss: 242.3359 - val_mae: 12.7543\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322.2904 - mae: 14.3025 - val_loss: 241.8265 - val_mae: 12.7383\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 791.1227 - mae: 23.0939 - val_loss: 691.3050 - val_mae: 21.3739\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 757.5225 - mae: 22.7256 - val_loss: 655.7338 - val_mae: 20.9846\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 727.8262 - mae: 22.3911 - val_loss: 624.3831 - val_mae: 20.6241\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 701.7410 - mae: 22.0815 - val_loss: 596.9799 - val_mae: 20.2965\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.0505 - mae: 21.7983 - val_loss: 573.1397 - val_mae: 19.9989\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.0668 - mae: 21.5438 - val_loss: 551.2758 - val_mae: 19.7152\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 640.9313 - mae: 21.3002 - val_loss: 531.5297 - val_mae: 19.4532\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 624.6603 - mae: 21.0729 - val_loss: 514.7509 - val_mae: 19.2199\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 610.7542 - mae: 20.8744 - val_loss: 499.6573 - val_mae: 19.0017\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.1588 - mae: 20.6848 - val_loss: 485.7325 - val_mae: 18.7942\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 586.6785 - mae: 20.5091 - val_loss: 472.9371 - val_mae: 18.5983\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 576.1864 - mae: 20.3439 - val_loss: 461.7304 - val_mae: 18.4180\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 566.8926 - mae: 20.1924 - val_loss: 451.5192 - val_mae: 18.2480\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 558.4236 - mae: 20.0487 - val_loss: 442.0969 - val_mae: 18.0865\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.6962 - mae: 19.9140 - val_loss: 433.2787 - val_mae: 17.9326\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.4790 - mae: 19.7902 - val_loss: 425.3718 - val_mae: 17.7907\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 536.9316 - mae: 19.6740 - val_loss: 418.0893 - val_mae: 17.6577\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 530.9193 - mae: 19.5630 - val_loss: 411.2719 - val_mae: 17.5309\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.2726 - mae: 19.4582 - val_loss: 404.8350 - val_mae: 17.4097\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.9376 - mae: 19.3581 - val_loss: 399.0169 - val_mae: 17.2960\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.0897 - mae: 19.2612 - val_loss: 393.6349 - val_mae: 17.1886\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.6055 - mae: 19.1706 - val_loss: 388.5951 - val_mae: 17.0872\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.3985 - mae: 19.0848 - val_loss: 384.0745 - val_mae: 16.9953\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 502.5421 - mae: 19.0045 - val_loss: 379.6233 - val_mae: 16.9054\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 498.8251 - mae: 18.9289 - val_loss: 375.6235 - val_mae: 16.8207\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 495.4101 - mae: 18.8561 - val_loss: 371.8499 - val_mae: 16.7398\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.2039 - mae: 18.7859 - val_loss: 368.1412 - val_mae: 16.6592\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.0738 - mae: 18.7201 - val_loss: 364.7132 - val_mae: 16.5819\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 486.1315 - mae: 18.6551 - val_loss: 361.3840 - val_mae: 16.5070\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 483.3206 - mae: 18.5919 - val_loss: 358.1982 - val_mae: 16.4341\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 480.6435 - mae: 18.5339 - val_loss: 355.3196 - val_mae: 16.3661\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.1436 - mae: 18.4749 - val_loss: 352.5808 - val_mae: 16.3014\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 475.7550 - mae: 18.4188 - val_loss: 349.9184 - val_mae: 16.2378\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 473.4688 - mae: 18.3643 - val_loss: 347.3885 - val_mae: 16.1757\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 471.2577 - mae: 18.3100 - val_loss: 344.9477 - val_mae: 16.1162\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 469.1318 - mae: 18.2584 - val_loss: 342.6484 - val_mae: 16.0587\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 467.0996 - mae: 18.2088 - val_loss: 340.3843 - val_mae: 16.0018\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 465.1262 - mae: 18.1606 - val_loss: 338.2131 - val_mae: 15.9475\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 463.2281 - mae: 18.1139 - val_loss: 336.2073 - val_mae: 15.8957\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 461.4250 - mae: 18.0692 - val_loss: 334.1850 - val_mae: 15.8449\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.6357 - mae: 18.0263 - val_loss: 332.2470 - val_mae: 15.7954\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.9372 - mae: 17.9856 - val_loss: 330.4665 - val_mae: 15.7491\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.2817 - mae: 17.9442 - val_loss: 328.7646 - val_mae: 15.7042\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.7053 - mae: 17.9027 - val_loss: 327.0481 - val_mae: 15.6601\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 453.1511 - mae: 17.8655 - val_loss: 325.4581 - val_mae: 15.6175\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.6838 - mae: 17.8275 - val_loss: 323.8416 - val_mae: 15.5754\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 450.2375 - mae: 17.7905 - val_loss: 322.3113 - val_mae: 15.5349\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.8398 - mae: 17.7549 - val_loss: 320.8317 - val_mae: 15.4961\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 447.4908 - mae: 17.7212 - val_loss: 319.4093 - val_mae: 15.4588\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.1364 - mae: 17.6859 - val_loss: 317.9929 - val_mae: 15.4222\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.8103 - mae: 17.6526 - val_loss: 316.7120 - val_mae: 15.3876\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 443.5597 - mae: 17.6196 - val_loss: 315.4156 - val_mae: 15.3530\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.2934 - mae: 17.5864 - val_loss: 314.1552 - val_mae: 15.3187\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 441.0790 - mae: 17.5545 - val_loss: 312.9357 - val_mae: 15.2848\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 439.8822 - mae: 17.5228 - val_loss: 311.7646 - val_mae: 15.2518\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.7242 - mae: 17.4916 - val_loss: 310.6270 - val_mae: 15.2194\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.5414 - mae: 17.4607 - val_loss: 309.5268 - val_mae: 15.1873\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 436.4049 - mae: 17.4298 - val_loss: 308.3707 - val_mae: 15.1543\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 435.2753 - mae: 17.3992 - val_loss: 307.2191 - val_mae: 15.1211\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 434.1441 - mae: 17.3690 - val_loss: 306.1416 - val_mae: 15.0889\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 433.0321 - mae: 17.3390 - val_loss: 305.0462 - val_mae: 15.0567\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 431.9193 - mae: 17.3093 - val_loss: 303.9736 - val_mae: 15.0248\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.8334 - mae: 17.2792 - val_loss: 302.9258 - val_mae: 14.9931\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.7603 - mae: 17.2496 - val_loss: 301.9030 - val_mae: 14.9617\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.7026 - mae: 17.2203 - val_loss: 300.8663 - val_mae: 14.9300\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 427.6259 - mae: 17.1904 - val_loss: 299.8501 - val_mae: 14.8985\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.5829 - mae: 17.1613 - val_loss: 298.8184 - val_mae: 14.8668\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 425.5288 - mae: 17.1320 - val_loss: 297.8108 - val_mae: 14.8355\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 424.4937 - mae: 17.1025 - val_loss: 296.8464 - val_mae: 14.8052\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 423.4865 - mae: 17.0739 - val_loss: 295.8404 - val_mae: 14.7742\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.4783 - mae: 17.0454 - val_loss: 294.9142 - val_mae: 14.7449\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.4719 - mae: 17.0165 - val_loss: 293.9662 - val_mae: 14.7151\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 420.4842 - mae: 16.9886 - val_loss: 293.0309 - val_mae: 14.6850\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 419.4888 - mae: 16.9600 - val_loss: 292.1041 - val_mae: 14.6551\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.5043 - mae: 16.9318 - val_loss: 291.2138 - val_mae: 14.6257\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.5157 - mae: 16.9031 - val_loss: 290.3190 - val_mae: 14.5958\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.5161 - mae: 16.8741 - val_loss: 289.3936 - val_mae: 14.5653\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 415.5158 - mae: 16.8449 - val_loss: 288.4906 - val_mae: 14.5355\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.5363 - mae: 16.8161 - val_loss: 287.5880 - val_mae: 14.5056\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.5410 - mae: 16.7872 - val_loss: 286.6894 - val_mae: 14.4758\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 412.5646 - mae: 16.7582 - val_loss: 285.8236 - val_mae: 14.4469\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 411.5956 - mae: 16.7293 - val_loss: 284.9326 - val_mae: 14.4173\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.5927 - mae: 16.6999 - val_loss: 284.0699 - val_mae: 14.3880\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.6175 - mae: 16.6708 - val_loss: 283.1636 - val_mae: 14.3578\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.5958 - mae: 16.6411 - val_loss: 282.2447 - val_mae: 14.3270\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.5762 - mae: 16.6116 - val_loss: 281.3159 - val_mae: 14.2960\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 406.5680 - mae: 16.5815 - val_loss: 280.4099 - val_mae: 14.2652\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 405.5742 - mae: 16.5525 - val_loss: 279.5220 - val_mae: 14.2347\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 404.6060 - mae: 16.5236 - val_loss: 278.6531 - val_mae: 14.2048\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.6538 - mae: 16.4958 - val_loss: 277.7928 - val_mae: 14.1750\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.7001 - mae: 16.4679 - val_loss: 276.9579 - val_mae: 14.1459\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.7457 - mae: 16.4404 - val_loss: 276.1484 - val_mae: 14.1175\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.8275 - mae: 16.4131 - val_loss: 275.3501 - val_mae: 14.0895\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.9085 - mae: 16.3864 - val_loss: 274.5638 - val_mae: 14.0621\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 398.9879 - mae: 16.3603 - val_loss: 273.8031 - val_mae: 14.0356\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 398.0776 - mae: 16.3343 - val_loss: 273.0615 - val_mae: 14.0099\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.1970 - mae: 16.3092 - val_loss: 272.3139 - val_mae: 13.9844\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.3417 - mae: 16.2847 - val_loss: 271.5777 - val_mae: 13.9597\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.4861 - mae: 16.2600 - val_loss: 270.9103 - val_mae: 13.9368\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 394.6665 - mae: 16.2367 - val_loss: 270.2086 - val_mae: 13.9132\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 1155.1010 - mae: 25.5361 - val_loss: 1126.4014 - val_mae: 25.2753\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1048.3774 - mae: 24.6741 - val_loss: 1024.1002 - val_mae: 24.4469\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 959.9524 - mae: 23.9166 - val_loss: 937.3488 - val_mae: 23.7068\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 884.7994 - mae: 23.2316 - val_loss: 865.0058 - val_mae: 23.0502\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 822.1948 - mae: 22.6224 - val_loss: 804.2277 - val_mae: 22.4662\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 769.4532 - mae: 22.0847 - val_loss: 752.4755 - val_mae: 21.9372\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 724.4255 - mae: 21.6050 - val_loss: 708.0509 - val_mae: 21.4578\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 685.7153 - mae: 21.1756 - val_loss: 669.0446 - val_mae: 21.0189\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 651.6915 - mae: 20.7762 - val_loss: 635.2784 - val_mae: 20.6210\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 622.2059 - mae: 20.4137 - val_loss: 606.8728 - val_mae: 20.2689\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 597.2639 - mae: 20.0973 - val_loss: 581.7401 - val_mae: 19.9463\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.2422 - mae: 19.8043 - val_loss: 560.0676 - val_mae: 19.6593\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.1052 - mae: 19.5411 - val_loss: 540.5620 - val_mae: 19.3909\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 538.8777 - mae: 19.3024 - val_loss: 523.3055 - val_mae: 19.1457\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 523.5717 - mae: 19.0765 - val_loss: 508.0115 - val_mae: 18.9196\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 509.9711 - mae: 18.8728 - val_loss: 494.4128 - val_mae: 18.7127\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.8485 - mae: 18.6807 - val_loss: 482.3252 - val_mae: 18.5206\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 487.0184 - mae: 18.5040 - val_loss: 471.4297 - val_mae: 18.3415\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 477.1900 - mae: 18.3387 - val_loss: 461.7508 - val_mae: 18.1763\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.4335 - mae: 18.1840 - val_loss: 452.7810 - val_mae: 18.0178\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 460.3056 - mae: 18.0364 - val_loss: 444.6611 - val_mae: 17.8676\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.9295 - mae: 17.8976 - val_loss: 437.2565 - val_mae: 17.7250\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.1863 - mae: 17.7685 - val_loss: 430.4106 - val_mae: 17.5888\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.9547 - mae: 17.6463 - val_loss: 424.2281 - val_mae: 17.4612\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.3003 - mae: 17.5309 - val_loss: 418.5152 - val_mae: 17.3388\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.0622 - mae: 17.4195 - val_loss: 413.2736 - val_mae: 17.2229\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.1660 - mae: 17.3147 - val_loss: 408.3659 - val_mae: 17.1115\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 419.6072 - mae: 17.2152 - val_loss: 403.8160 - val_mae: 17.0052\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.3707 - mae: 17.1207 - val_loss: 399.7321 - val_mae: 16.9074\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.5059 - mae: 17.0322 - val_loss: 395.7967 - val_mae: 16.8130\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.7621 - mae: 16.9447 - val_loss: 392.1359 - val_mae: 16.7238\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.3004 - mae: 16.8609 - val_loss: 388.7612 - val_mae: 16.6401\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.0716 - mae: 16.7820 - val_loss: 385.5828 - val_mae: 16.5601\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.0454 - mae: 16.7082 - val_loss: 382.5998 - val_mae: 16.4837\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.1803 - mae: 16.6348 - val_loss: 379.7605 - val_mae: 16.4111\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.4544 - mae: 16.5652 - val_loss: 377.0902 - val_mae: 16.3425\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.8434 - mae: 16.4983 - val_loss: 374.5674 - val_mae: 16.2759\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.3694 - mae: 16.4331 - val_loss: 372.2050 - val_mae: 16.2120\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.0698 - mae: 16.3715 - val_loss: 369.9865 - val_mae: 16.1510\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.8476 - mae: 16.3118 - val_loss: 367.8574 - val_mae: 16.0921\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.6980 - mae: 16.2532 - val_loss: 365.8267 - val_mae: 16.0348\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.6811 - mae: 16.1975 - val_loss: 363.9240 - val_mae: 15.9796\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.7639 - mae: 16.1433 - val_loss: 362.1035 - val_mae: 15.9264\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.9343 - mae: 16.0912 - val_loss: 360.3385 - val_mae: 15.8749\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 373.1483 - mae: 16.0409 - val_loss: 358.6618 - val_mae: 15.8255\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.4443 - mae: 15.9913 - val_loss: 357.0443 - val_mae: 15.7779\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.7867 - mae: 15.9420 - val_loss: 355.5030 - val_mae: 15.7317\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.2144 - mae: 15.8957 - val_loss: 354.0358 - val_mae: 15.6869\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.7317 - mae: 15.8508 - val_loss: 352.6465 - val_mae: 15.6441\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.2976 - mae: 15.8088 - val_loss: 351.3158 - val_mae: 15.6023\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 363.9393 - mae: 15.7673 - val_loss: 350.0512 - val_mae: 15.5621\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.6274 - mae: 15.7269 - val_loss: 348.8423 - val_mae: 15.5227\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.3988 - mae: 15.6899 - val_loss: 347.6981 - val_mae: 15.4854\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.2041 - mae: 15.6535 - val_loss: 346.5936 - val_mae: 15.4488\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.0630 - mae: 15.6183 - val_loss: 345.5496 - val_mae: 15.4139\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.9922 - mae: 15.5851 - val_loss: 344.5524 - val_mae: 15.3804\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 356.9580 - mae: 15.5528 - val_loss: 343.6201 - val_mae: 15.3488\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 355.9966 - mae: 15.5213 - val_loss: 342.7278 - val_mae: 15.3183\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 355.0479 - mae: 15.4922 - val_loss: 341.8755 - val_mae: 15.2890\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 354.1618 - mae: 15.4625 - val_loss: 341.0254 - val_mae: 15.2599\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 353.2984 - mae: 15.4362 - val_loss: 340.2346 - val_mae: 15.2329\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.4628 - mae: 15.4090 - val_loss: 339.4821 - val_mae: 15.2070\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 351.6635 - mae: 15.3826 - val_loss: 338.7561 - val_mae: 15.1820\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 350.8883 - mae: 15.3580 - val_loss: 338.0375 - val_mae: 15.1570\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 350.1187 - mae: 15.3334 - val_loss: 337.3386 - val_mae: 15.1327\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 349.3592 - mae: 15.3090 - val_loss: 336.6472 - val_mae: 15.1090\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.6186 - mae: 15.2843 - val_loss: 335.9555 - val_mae: 15.0855\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.8934 - mae: 15.2607 - val_loss: 335.2859 - val_mae: 15.0629\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.1723 - mae: 15.2366 - val_loss: 334.6164 - val_mae: 15.0405\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.4579 - mae: 15.2140 - val_loss: 333.9655 - val_mae: 15.0186\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 345.7496 - mae: 15.1905 - val_loss: 333.3032 - val_mae: 14.9965\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.0650 - mae: 15.1682 - val_loss: 332.6758 - val_mae: 14.9755\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 344.3868 - mae: 15.1457 - val_loss: 332.0585 - val_mae: 14.9544\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.7340 - mae: 15.1236 - val_loss: 331.4486 - val_mae: 14.9337\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.0944 - mae: 15.1037 - val_loss: 330.8772 - val_mae: 14.9144\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.4879 - mae: 15.0843 - val_loss: 330.3272 - val_mae: 14.8959\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 341.8976 - mae: 15.0644 - val_loss: 329.7941 - val_mae: 14.8781\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.2998 - mae: 15.0453 - val_loss: 329.2811 - val_mae: 14.8612\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 340.7266 - mae: 15.0272 - val_loss: 328.7863 - val_mae: 14.8446\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 340.1752 - mae: 15.0098 - val_loss: 328.3079 - val_mae: 14.8284\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.6375 - mae: 14.9927 - val_loss: 327.8524 - val_mae: 14.8127\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.1162 - mae: 14.9756 - val_loss: 327.3957 - val_mae: 14.7967\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.6363 - mae: 14.9608 - val_loss: 326.9563 - val_mae: 14.7819\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.1185 - mae: 14.9438 - val_loss: 326.5010 - val_mae: 14.7663\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.6416 - mae: 14.9298 - val_loss: 326.0681 - val_mae: 14.7516\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.1463 - mae: 14.9142 - val_loss: 325.6585 - val_mae: 14.7378\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.6899 - mae: 14.8995 - val_loss: 325.2550 - val_mae: 14.7241\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.2351 - mae: 14.8850 - val_loss: 324.8629 - val_mae: 14.7109\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 335.7801 - mae: 14.8709 - val_loss: 324.4872 - val_mae: 14.6985\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.3498 - mae: 14.8569 - val_loss: 324.1167 - val_mae: 14.6861\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.9255 - mae: 14.8436 - val_loss: 323.7590 - val_mae: 14.6746\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.4944 - mae: 14.8307 - val_loss: 323.3936 - val_mae: 14.6623\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.0830 - mae: 14.8176 - val_loss: 323.0182 - val_mae: 14.6499\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.6661 - mae: 14.8051 - val_loss: 322.6520 - val_mae: 14.6382\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.2572 - mae: 14.7924 - val_loss: 322.2969 - val_mae: 14.6267\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.8558 - mae: 14.7802 - val_loss: 321.9297 - val_mae: 14.6151\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.4514 - mae: 14.7674 - val_loss: 321.5607 - val_mae: 14.6032\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.0449 - mae: 14.7551 - val_loss: 321.2014 - val_mae: 14.5921\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.6398 - mae: 14.7431 - val_loss: 320.8466 - val_mae: 14.5810\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.2372 - mae: 14.7312 - val_loss: 320.5021 - val_mae: 14.5701\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 1278.8318 - mae: 30.8569 - val_loss: 706.8450 - val_mae: 23.6751\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 616.4806 - mae: 22.2328 - val_loss: 449.0999 - val_mae: 18.7296\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.0284 - mae: 19.2275 - val_loss: 378.8532 - val_mae: 16.9866\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.3657 - mae: 18.1236 - val_loss: 354.9655 - val_mae: 16.3813\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.9210 - mae: 17.7031 - val_loss: 343.7059 - val_mae: 16.0475\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.8234 - mae: 17.5251 - val_loss: 339.5052 - val_mae: 15.8770\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.3926 - mae: 17.4204 - val_loss: 337.7172 - val_mae: 15.8014\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.6027 - mae: 17.3789 - val_loss: 336.5936 - val_mae: 15.7461\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.1029 - mae: 17.3473 - val_loss: 335.7234 - val_mae: 15.7098\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.7555 - mae: 17.3344 - val_loss: 335.4406 - val_mae: 15.6798\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.2408 - mae: 17.3104 - val_loss: 334.4199 - val_mae: 15.6564\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.9139 - mae: 17.2994 - val_loss: 333.7149 - val_mae: 15.6435\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.5627 - mae: 17.2984 - val_loss: 334.0094 - val_mae: 15.6413\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.2220 - mae: 17.2917 - val_loss: 334.0026 - val_mae: 15.6244\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.9176 - mae: 17.2777 - val_loss: 332.3814 - val_mae: 15.5932\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.4826 - mae: 17.2590 - val_loss: 331.5553 - val_mae: 15.5898\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.2617 - mae: 17.2696 - val_loss: 331.4586 - val_mae: 15.5826\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.9716 - mae: 17.2625 - val_loss: 330.4851 - val_mae: 15.5634\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 419.6744 - mae: 17.2600 - val_loss: 330.1790 - val_mae: 15.5507\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.2663 - mae: 17.2505 - val_loss: 329.2745 - val_mae: 15.5260\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.1485 - mae: 17.2451 - val_loss: 328.0966 - val_mae: 15.4978\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.5931 - mae: 17.2325 - val_loss: 327.5791 - val_mae: 15.4852\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.2604 - mae: 17.2289 - val_loss: 327.9420 - val_mae: 15.4888\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.0596 - mae: 17.2226 - val_loss: 327.2742 - val_mae: 15.4745\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.7756 - mae: 17.2120 - val_loss: 326.8943 - val_mae: 15.4627\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.4111 - mae: 17.2086 - val_loss: 326.5654 - val_mae: 15.4534\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.1885 - mae: 17.1992 - val_loss: 325.8424 - val_mae: 15.4380\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.0093 - mae: 17.1975 - val_loss: 325.3703 - val_mae: 15.4287\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.7560 - mae: 17.1862 - val_loss: 324.6888 - val_mae: 15.4184\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.4225 - mae: 17.1840 - val_loss: 325.4965 - val_mae: 15.4287\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.2756 - mae: 17.1829 - val_loss: 325.0498 - val_mae: 15.4195\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.1713 - mae: 17.1798 - val_loss: 324.3765 - val_mae: 15.4009\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.6902 - mae: 17.1711 - val_loss: 324.4727 - val_mae: 15.4005\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.4123 - mae: 17.1627 - val_loss: 323.6043 - val_mae: 15.3838\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 415.3525 - mae: 17.1648 - val_loss: 323.1960 - val_mae: 15.3737\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 414.9901 - mae: 17.1519 - val_loss: 323.3744 - val_mae: 15.3760\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 414.7770 - mae: 17.1485 - val_loss: 322.9036 - val_mae: 15.3654\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.5252 - mae: 17.1425 - val_loss: 321.9608 - val_mae: 15.3424\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.3042 - mae: 17.1295 - val_loss: 321.8499 - val_mae: 15.3374\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.0936 - mae: 17.1270 - val_loss: 320.8896 - val_mae: 15.3217\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.9572 - mae: 17.1219 - val_loss: 320.3125 - val_mae: 15.3096\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.7691 - mae: 17.1149 - val_loss: 320.6341 - val_mae: 15.3102\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.7897 - mae: 17.1278 - val_loss: 320.5395 - val_mae: 15.3027\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.3048 - mae: 17.1043 - val_loss: 320.1311 - val_mae: 15.2954\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.1053 - mae: 17.0986 - val_loss: 320.5252 - val_mae: 15.2991\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.0703 - mae: 17.1024 - val_loss: 320.6161 - val_mae: 15.3031\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 412.6881 - mae: 17.0930 - val_loss: 319.8541 - val_mae: 15.2918\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 412.5201 - mae: 17.0910 - val_loss: 319.5234 - val_mae: 15.2796\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.4133 - mae: 17.0900 - val_loss: 319.0429 - val_mae: 15.2701\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 412.2077 - mae: 17.0880 - val_loss: 318.5176 - val_mae: 15.2572\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 412.0788 - mae: 17.0788 - val_loss: 318.6250 - val_mae: 15.2548\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 411.8309 - mae: 17.0725 - val_loss: 318.2582 - val_mae: 15.2452\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 411.6602 - mae: 17.0621 - val_loss: 318.5920 - val_mae: 15.2490\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.5160 - mae: 17.0643 - val_loss: 317.9872 - val_mae: 15.2345\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 411.4150 - mae: 17.0570 - val_loss: 318.1905 - val_mae: 15.2385\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.2357 - mae: 17.0592 - val_loss: 317.0884 - val_mae: 15.2182\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.0396 - mae: 17.0488 - val_loss: 316.9274 - val_mae: 15.2088\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.9870 - mae: 17.0438 - val_loss: 317.1357 - val_mae: 15.2147\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.7121 - mae: 17.0361 - val_loss: 317.1109 - val_mae: 15.2156\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.5216 - mae: 17.0346 - val_loss: 316.6621 - val_mae: 15.2098\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 410.4661 - mae: 17.0322 - val_loss: 316.6526 - val_mae: 15.2101\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.2868 - mae: 17.0373 - val_loss: 316.0053 - val_mae: 15.1923\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.2420 - mae: 17.0285 - val_loss: 315.8270 - val_mae: 15.1867\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.2371 - mae: 17.0339 - val_loss: 315.2515 - val_mae: 15.1670\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.9591 - mae: 17.0181 - val_loss: 314.8305 - val_mae: 15.1555\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.7000 - mae: 17.0063 - val_loss: 314.6672 - val_mae: 15.1515\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.5485 - mae: 17.0038 - val_loss: 314.3097 - val_mae: 15.1422\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.5420 - mae: 17.0015 - val_loss: 313.7267 - val_mae: 15.1309\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.4095 - mae: 16.9880 - val_loss: 314.5289 - val_mae: 15.1595\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.1976 - mae: 17.0013 - val_loss: 313.8275 - val_mae: 15.1424\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.1371 - mae: 16.9879 - val_loss: 313.6364 - val_mae: 15.1377\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.9328 - mae: 16.9902 - val_loss: 313.3150 - val_mae: 15.1269\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.9176 - mae: 16.9944 - val_loss: 312.6808 - val_mae: 15.1028\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.7868 - mae: 16.9720 - val_loss: 312.8701 - val_mae: 15.1132\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.6122 - mae: 16.9766 - val_loss: 312.7156 - val_mae: 15.1132\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 408.4423 - mae: 16.9652 - val_loss: 313.2043 - val_mae: 15.1279\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.4814 - mae: 16.9717 - val_loss: 312.6931 - val_mae: 15.1123\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.2878 - mae: 16.9716 - val_loss: 311.7133 - val_mae: 15.0832\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 408.1479 - mae: 16.9552 - val_loss: 312.0320 - val_mae: 15.0985\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.0123 - mae: 16.9623 - val_loss: 311.4471 - val_mae: 15.0799\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.9017 - mae: 16.9435 - val_loss: 311.9172 - val_mae: 15.0995\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.7776 - mae: 16.9591 - val_loss: 311.3398 - val_mae: 15.0791\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.7218 - mae: 16.9365 - val_loss: 311.6882 - val_mae: 15.0950\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.6731 - mae: 16.9522 - val_loss: 311.0910 - val_mae: 15.0765\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.5255 - mae: 16.9417 - val_loss: 310.8952 - val_mae: 15.0729\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.4260 - mae: 16.9363 - val_loss: 310.5501 - val_mae: 15.0603\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.3396 - mae: 16.9298 - val_loss: 310.6772 - val_mae: 15.0644\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.2097 - mae: 16.9341 - val_loss: 309.7339 - val_mae: 15.0360\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.1935 - mae: 16.9180 - val_loss: 310.0811 - val_mae: 15.0497\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.1120 - mae: 16.9116 - val_loss: 310.0391 - val_mae: 15.0475\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.9597 - mae: 16.9247 - val_loss: 309.4847 - val_mae: 15.0280\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.7716 - mae: 16.9062 - val_loss: 309.4050 - val_mae: 15.0256\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.7468 - mae: 16.9132 - val_loss: 309.0229 - val_mae: 15.0170\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.5551 - mae: 16.8979 - val_loss: 308.9948 - val_mae: 15.0204\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.5384 - mae: 16.9071 - val_loss: 308.5238 - val_mae: 15.0056\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.5308 - mae: 16.9053 - val_loss: 307.9146 - val_mae: 14.9889\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.3995 - mae: 16.8858 - val_loss: 308.3406 - val_mae: 15.0022\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.2436 - mae: 16.8862 - val_loss: 308.6419 - val_mae: 15.0154\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.1684 - mae: 16.8976 - val_loss: 308.1603 - val_mae: 15.0010\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.1599 - mae: 16.8877 - val_loss: 308.0569 - val_mae: 14.9991\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 25ms/step - loss: 1286.0052 - mae: 27.3702 - val_loss: 957.8246 - val_mae: 23.6376\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 866.9863 - mae: 23.6786 - val_loss: 678.9096 - val_mae: 20.8786\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.9564 - mae: 21.4921 - val_loss: 537.5455 - val_mae: 19.0515\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 589.4227 - mae: 20.1716 - val_loss: 459.0979 - val_mae: 17.7818\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 537.4191 - mae: 19.2954 - val_loss: 412.2292 - val_mae: 16.9228\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.9527 - mae: 18.7792 - val_loss: 382.7278 - val_mae: 16.3615\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488.3043 - mae: 18.4381 - val_loss: 363.7888 - val_mae: 16.0424\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 476.5708 - mae: 18.2191 - val_loss: 349.8100 - val_mae: 15.8751\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.3515 - mae: 18.0478 - val_loss: 340.8239 - val_mae: 15.7628\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 463.2008 - mae: 17.9556 - val_loss: 334.3548 - val_mae: 15.6809\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.6962 - mae: 17.8968 - val_loss: 330.1536 - val_mae: 15.6235\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 457.3492 - mae: 17.8547 - val_loss: 326.5353 - val_mae: 15.5805\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 455.3745 - mae: 17.8244 - val_loss: 323.7927 - val_mae: 15.5438\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 453.8475 - mae: 17.8048 - val_loss: 321.4698 - val_mae: 15.5089\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.6344 - mae: 17.7891 - val_loss: 319.5943 - val_mae: 15.4751\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.5757 - mae: 17.7659 - val_loss: 318.1037 - val_mae: 15.4478\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.7682 - mae: 17.7507 - val_loss: 317.0845 - val_mae: 15.4311\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.9124 - mae: 17.7384 - val_loss: 315.9226 - val_mae: 15.4080\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.2104 - mae: 17.7252 - val_loss: 315.0352 - val_mae: 15.3922\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.4722 - mae: 17.7174 - val_loss: 314.0336 - val_mae: 15.3698\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 447.8380 - mae: 17.7015 - val_loss: 312.8748 - val_mae: 15.3424\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.1637 - mae: 17.6830 - val_loss: 312.1867 - val_mae: 15.3272\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.5135 - mae: 17.6732 - val_loss: 311.3594 - val_mae: 15.3040\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.0444 - mae: 17.6590 - val_loss: 310.6481 - val_mae: 15.2840\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.4793 - mae: 17.6481 - val_loss: 309.9496 - val_mae: 15.2643\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 444.9491 - mae: 17.6359 - val_loss: 309.1593 - val_mae: 15.2417\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.3743 - mae: 17.6191 - val_loss: 308.4537 - val_mae: 15.2203\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.8659 - mae: 17.6045 - val_loss: 307.5740 - val_mae: 15.1945\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4984 - mae: 17.5934 - val_loss: 306.8703 - val_mae: 15.1728\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.9322 - mae: 17.5804 - val_loss: 306.4259 - val_mae: 15.1596\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.4151 - mae: 17.5649 - val_loss: 305.9110 - val_mae: 15.1438\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.9728 - mae: 17.5478 - val_loss: 305.4201 - val_mae: 15.1310\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.5150 - mae: 17.5375 - val_loss: 304.8809 - val_mae: 15.1162\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.0789 - mae: 17.5282 - val_loss: 304.2438 - val_mae: 15.0977\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.6389 - mae: 17.5165 - val_loss: 303.8193 - val_mae: 15.0848\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.2436 - mae: 17.5063 - val_loss: 303.4356 - val_mae: 15.0735\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.8333 - mae: 17.4924 - val_loss: 302.9800 - val_mae: 15.0586\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.4660 - mae: 17.4764 - val_loss: 302.6758 - val_mae: 15.0511\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.0743 - mae: 17.4738 - val_loss: 302.1766 - val_mae: 15.0360\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.7066 - mae: 17.4671 - val_loss: 301.7288 - val_mae: 15.0203\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.3135 - mae: 17.4498 - val_loss: 301.2667 - val_mae: 15.0060\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.9952 - mae: 17.4403 - val_loss: 300.8900 - val_mae: 14.9935\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.6939 - mae: 17.4322 - val_loss: 300.5352 - val_mae: 14.9805\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.3698 - mae: 17.4274 - val_loss: 300.1397 - val_mae: 14.9677\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.0006 - mae: 17.4114 - val_loss: 299.9005 - val_mae: 14.9591\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.7180 - mae: 17.4022 - val_loss: 299.5929 - val_mae: 14.9494\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.4164 - mae: 17.4022 - val_loss: 299.1370 - val_mae: 14.9334\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.0950 - mae: 17.3863 - val_loss: 298.8056 - val_mae: 14.9214\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.8450 - mae: 17.3832 - val_loss: 298.3336 - val_mae: 14.9055\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.5235 - mae: 17.3696 - val_loss: 298.0267 - val_mae: 14.8943\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.2498 - mae: 17.3600 - val_loss: 297.8300 - val_mae: 14.8871\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.0168 - mae: 17.3524 - val_loss: 297.6882 - val_mae: 14.8816\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.7211 - mae: 17.3501 - val_loss: 297.4523 - val_mae: 14.8732\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.4992 - mae: 17.3447 - val_loss: 297.1877 - val_mae: 14.8637\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.2192 - mae: 17.3416 - val_loss: 296.7938 - val_mae: 14.8489\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 433.9935 - mae: 17.3307 - val_loss: 296.5017 - val_mae: 14.8360\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 433.8385 - mae: 17.3229 - val_loss: 296.2395 - val_mae: 14.8261\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 433.5705 - mae: 17.3182 - val_loss: 295.9063 - val_mae: 14.8124\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 433.3165 - mae: 17.3033 - val_loss: 295.7462 - val_mae: 14.8066\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.1396 - mae: 17.3041 - val_loss: 295.3893 - val_mae: 14.7924\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 432.8824 - mae: 17.2902 - val_loss: 295.0848 - val_mae: 14.7810\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.6935 - mae: 17.2853 - val_loss: 294.9172 - val_mae: 14.7735\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.4945 - mae: 17.2768 - val_loss: 294.8059 - val_mae: 14.7681\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.2747 - mae: 17.2767 - val_loss: 294.5745 - val_mae: 14.7574\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.1137 - mae: 17.2704 - val_loss: 294.3745 - val_mae: 14.7493\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.9001 - mae: 17.2627 - val_loss: 294.1745 - val_mae: 14.7408\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.7410 - mae: 17.2584 - val_loss: 294.0100 - val_mae: 14.7334\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.5379 - mae: 17.2547 - val_loss: 293.8683 - val_mae: 14.7286\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.3840 - mae: 17.2495 - val_loss: 293.6442 - val_mae: 14.7196\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.2067 - mae: 17.2491 - val_loss: 293.4506 - val_mae: 14.7111\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.0502 - mae: 17.2409 - val_loss: 293.3019 - val_mae: 14.7043\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.8785 - mae: 17.2419 - val_loss: 293.1032 - val_mae: 14.6955\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.7204 - mae: 17.2313 - val_loss: 292.8952 - val_mae: 14.6873\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.5763 - mae: 17.2267 - val_loss: 292.8853 - val_mae: 14.6891\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.4159 - mae: 17.2320 - val_loss: 292.6913 - val_mae: 14.6776\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.2756 - mae: 17.2236 - val_loss: 292.4555 - val_mae: 14.6656\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.1166 - mae: 17.2181 - val_loss: 292.1395 - val_mae: 14.6523\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.0074 - mae: 17.2112 - val_loss: 292.0240 - val_mae: 14.6466\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.8660 - mae: 17.2050 - val_loss: 291.7846 - val_mae: 14.6353\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.7370 - mae: 17.2011 - val_loss: 291.5480 - val_mae: 14.6232\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.6125 - mae: 17.1978 - val_loss: 291.3864 - val_mae: 14.6153\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.4480 - mae: 17.1886 - val_loss: 291.2576 - val_mae: 14.6079\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.3145 - mae: 17.1815 - val_loss: 291.1057 - val_mae: 14.5994\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.2122 - mae: 17.1788 - val_loss: 291.0289 - val_mae: 14.5944\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.0659 - mae: 17.1757 - val_loss: 290.8819 - val_mae: 14.5857\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.9963 - mae: 17.1657 - val_loss: 290.7533 - val_mae: 14.5796\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.8305 - mae: 17.1638 - val_loss: 290.5952 - val_mae: 14.5721\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.7253 - mae: 17.1587 - val_loss: 290.5103 - val_mae: 14.5666\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.6081 - mae: 17.1553 - val_loss: 290.4090 - val_mae: 14.5630\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.5275 - mae: 17.1497 - val_loss: 290.3754 - val_mae: 14.5604\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.4428 - mae: 17.1477 - val_loss: 290.3438 - val_mae: 14.5589\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.3058 - mae: 17.1597 - val_loss: 290.1067 - val_mae: 14.5467\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.2659 - mae: 17.1540 - val_loss: 289.9346 - val_mae: 14.5389\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.1118 - mae: 17.1373 - val_loss: 289.9263 - val_mae: 14.5390\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.0115 - mae: 17.1431 - val_loss: 289.7876 - val_mae: 14.5298\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.8934 - mae: 17.1360 - val_loss: 289.6786 - val_mae: 14.5217\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.7971 - mae: 17.1354 - val_loss: 289.5494 - val_mae: 14.5157\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.7244 - mae: 17.1299 - val_loss: 289.5367 - val_mae: 14.5172\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.6184 - mae: 17.1287 - val_loss: 289.4570 - val_mae: 14.5136\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.5546 - mae: 17.1318 - val_loss: 289.3669 - val_mae: 14.5090\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 62ms/step - loss: 2634.9492 - mae: 31.1624 - val_loss: 1054.1554 - val_mae: 23.0975\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1021.7496 - mae: 21.8669 - val_loss: 566.7183 - val_mae: 18.9695\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 682.8625 - mae: 19.2385 - val_loss: 447.6873 - val_mae: 17.4417\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 578.2261 - mae: 18.3061 - val_loss: 412.6509 - val_mae: 16.8345\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 522.4518 - mae: 17.7613 - val_loss: 393.7047 - val_mae: 16.4616\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 486.0569 - mae: 17.4027 - val_loss: 380.6774 - val_mae: 16.1835\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.2537 - mae: 17.1294 - val_loss: 370.8566 - val_mae: 15.9767\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.1354 - mae: 16.8796 - val_loss: 362.5102 - val_mae: 15.7952\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.7043 - mae: 16.6617 - val_loss: 355.9020 - val_mae: 15.6139\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.9948 - mae: 16.4032 - val_loss: 348.5273 - val_mae: 15.4017\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.2823 - mae: 16.1596 - val_loss: 341.6434 - val_mae: 15.1983\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.5156 - mae: 15.9335 - val_loss: 334.6089 - val_mae: 15.0240\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.1290 - mae: 15.7045 - val_loss: 327.9199 - val_mae: 14.8624\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 358.0384 - mae: 15.4910 - val_loss: 322.1201 - val_mae: 14.7332\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.7206 - mae: 15.2950 - val_loss: 316.7381 - val_mae: 14.6100\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.4922 - mae: 15.1327 - val_loss: 311.6205 - val_mae: 14.4842\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.7648 - mae: 14.9699 - val_loss: 307.0331 - val_mae: 14.3698\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.7172 - mae: 14.8278 - val_loss: 302.7616 - val_mae: 14.2572\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.6884 - mae: 14.6876 - val_loss: 298.7095 - val_mae: 14.1492\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 314.0649 - mae: 14.5665 - val_loss: 294.9829 - val_mae: 14.0468\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.2858 - mae: 14.4671 - val_loss: 292.0334 - val_mae: 13.9609\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.9646 - mae: 14.3529 - val_loss: 289.2762 - val_mae: 13.8784\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.0875 - mae: 14.2604 - val_loss: 287.2019 - val_mae: 13.8099\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 297.7164 - mae: 14.1716 - val_loss: 285.1520 - val_mae: 13.7432\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 294.6029 - mae: 14.0800 - val_loss: 283.2058 - val_mae: 13.6889\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 291.7870 - mae: 14.0035 - val_loss: 281.3826 - val_mae: 13.6364\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 288.9618 - mae: 13.9273 - val_loss: 279.6092 - val_mae: 13.5843\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 286.4200 - mae: 13.8545 - val_loss: 277.9799 - val_mae: 13.5339\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.0146 - mae: 13.7793 - val_loss: 276.1299 - val_mae: 13.4832\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 281.7201 - mae: 13.7250 - val_loss: 274.6985 - val_mae: 13.4321\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 279.5765 - mae: 13.6517 - val_loss: 273.1827 - val_mae: 13.3831\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 277.4609 - mae: 13.5891 - val_loss: 271.7483 - val_mae: 13.3347\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275.4616 - mae: 13.5244 - val_loss: 270.1762 - val_mae: 13.2866\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273.5307 - mae: 13.4688 - val_loss: 268.6770 - val_mae: 13.2414\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 271.7417 - mae: 13.4090 - val_loss: 267.2172 - val_mae: 13.1965\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 270.0061 - mae: 13.3531 - val_loss: 265.9574 - val_mae: 13.1521\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.3677 - mae: 13.2981 - val_loss: 264.6008 - val_mae: 13.1104\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 266.6929 - mae: 13.2478 - val_loss: 263.6728 - val_mae: 13.0768\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 265.2403 - mae: 13.1923 - val_loss: 262.5263 - val_mae: 13.0433\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.7857 - mae: 13.1544 - val_loss: 261.7994 - val_mae: 13.0100\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.3331 - mae: 13.1002 - val_loss: 260.9419 - val_mae: 12.9767\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.9597 - mae: 13.0498 - val_loss: 259.9658 - val_mae: 12.9453\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 259.6509 - mae: 13.0040 - val_loss: 259.0064 - val_mae: 12.9140\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258.4423 - mae: 12.9669 - val_loss: 258.1985 - val_mae: 12.8839\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.1843 - mae: 12.9227 - val_loss: 257.3823 - val_mae: 12.8538\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 255.9962 - mae: 12.8786 - val_loss: 256.3907 - val_mae: 12.8221\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 254.9957 - mae: 12.8477 - val_loss: 255.5724 - val_mae: 12.7922\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253.7145 - mae: 12.8007 - val_loss: 254.7342 - val_mae: 12.7627\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 252.5586 - mae: 12.7594 - val_loss: 253.8348 - val_mae: 12.7326\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.4458 - mae: 12.7220 - val_loss: 253.0620 - val_mae: 12.7038\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 250.3910 - mae: 12.6807 - val_loss: 252.0849 - val_mae: 12.6729\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 249.4382 - mae: 12.6475 - val_loss: 251.2402 - val_mae: 12.6439\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.3186 - mae: 12.6131 - val_loss: 250.3806 - val_mae: 12.6147\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.2731 - mae: 12.5783 - val_loss: 249.6527 - val_mae: 12.5897\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.3299 - mae: 12.5403 - val_loss: 248.7430 - val_mae: 12.5605\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 245.3089 - mae: 12.5054 - val_loss: 247.9090 - val_mae: 12.5329\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.3821 - mae: 12.4744 - val_loss: 247.1573 - val_mae: 12.5071\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.5203 - mae: 12.4418 - val_loss: 246.4154 - val_mae: 12.4819\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 242.6222 - mae: 12.4092 - val_loss: 245.4995 - val_mae: 12.4520\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 241.7903 - mae: 12.3802 - val_loss: 244.6961 - val_mae: 12.4251\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 240.8779 - mae: 12.3469 - val_loss: 243.9622 - val_mae: 12.3997\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 240.0656 - mae: 12.3153 - val_loss: 242.9844 - val_mae: 12.3678\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 239.1507 - mae: 12.2874 - val_loss: 242.4319 - val_mae: 12.3473\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 238.3148 - mae: 12.2519 - val_loss: 241.5339 - val_mae: 12.3176\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 237.6428 - mae: 12.2257 - val_loss: 240.9645 - val_mae: 12.2965\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 236.7185 - mae: 12.1912 - val_loss: 240.1224 - val_mae: 12.2683\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235.8935 - mae: 12.1630 - val_loss: 239.6027 - val_mae: 12.2508\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 235.2239 - mae: 12.1369 - val_loss: 239.0335 - val_mae: 12.2323\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 234.3492 - mae: 12.0994 - val_loss: 238.1948 - val_mae: 12.2049\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 233.7097 - mae: 12.0741 - val_loss: 237.6831 - val_mae: 12.1875\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 232.8684 - mae: 12.0416 - val_loss: 236.8496 - val_mae: 12.1601\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 232.1207 - mae: 12.0143 - val_loss: 236.2829 - val_mae: 12.1405\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 231.3517 - mae: 11.9857 - val_loss: 235.7844 - val_mae: 12.1225\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 230.6233 - mae: 11.9552 - val_loss: 235.0560 - val_mae: 12.0977\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 229.9207 - mae: 11.9249 - val_loss: 234.0895 - val_mae: 12.0660\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 229.1909 - mae: 11.9047 - val_loss: 233.7567 - val_mae: 12.0534\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 228.5963 - mae: 11.8777 - val_loss: 233.0826 - val_mae: 12.0303\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 227.8206 - mae: 11.8481 - val_loss: 232.4507 - val_mae: 12.0084\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 227.1080 - mae: 11.8192 - val_loss: 231.6799 - val_mae: 11.9819\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226.5226 - mae: 11.7977 - val_loss: 231.1177 - val_mae: 11.9625\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 225.8203 - mae: 11.7706 - val_loss: 230.4817 - val_mae: 11.9406\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 225.1867 - mae: 11.7486 - val_loss: 230.0471 - val_mae: 11.9269\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 224.5577 - mae: 11.7183 - val_loss: 229.2486 - val_mae: 11.8983\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 223.9308 - mae: 11.6997 - val_loss: 228.5816 - val_mae: 11.8752\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 223.2729 - mae: 11.6750 - val_loss: 228.0184 - val_mae: 11.8563\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.6688 - mae: 11.6511 - val_loss: 227.3703 - val_mae: 11.8335\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 222.0475 - mae: 11.6272 - val_loss: 226.8763 - val_mae: 11.8173\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 221.5958 - mae: 11.6025 - val_loss: 226.1829 - val_mae: 11.7922\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 220.9521 - mae: 11.5841 - val_loss: 225.7220 - val_mae: 11.7768\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 220.3678 - mae: 11.5604 - val_loss: 225.1496 - val_mae: 11.7565\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 219.9081 - mae: 11.5427 - val_loss: 224.7126 - val_mae: 11.7414\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 219.2805 - mae: 11.5159 - val_loss: 223.9348 - val_mae: 11.7123\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 218.6718 - mae: 11.4939 - val_loss: 223.4383 - val_mae: 11.6945\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 218.0866 - mae: 11.4696 - val_loss: 222.8767 - val_mae: 11.6738\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217.5590 - mae: 11.4481 - val_loss: 222.2913 - val_mae: 11.6520\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217.0935 - mae: 11.4294 - val_loss: 221.5818 - val_mae: 11.6249\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.5085 - mae: 11.4089 - val_loss: 221.0837 - val_mae: 11.6063\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.0462 - mae: 11.3911 - val_loss: 220.6237 - val_mae: 11.5892\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 215.4770 - mae: 11.3690 - val_loss: 220.0384 - val_mae: 11.5668\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 214.9986 - mae: 11.3501 - val_loss: 219.8099 - val_mae: 11.5582\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   5.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 25ms/step - loss: 1462.7548 - mae: 31.0521 - val_loss: 1307.0331 - val_mae: 29.1626\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1171.8743 - mae: 28.2521 - val_loss: 1078.9011 - val_mae: 26.7002\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 986.9359 - mae: 26.1732 - val_loss: 925.3290 - val_mae: 24.7876\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 861.8916 - mae: 24.6166 - val_loss: 817.5199 - val_mae: 23.3404\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 773.9958 - mae: 23.4251 - val_loss: 739.3132 - val_mae: 22.2145\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 709.9730 - mae: 22.4835 - val_loss: 680.1005 - val_mae: 21.3250\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.4932 - mae: 21.7299 - val_loss: 634.5357 - val_mae: 20.6224\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 623.9136 - mae: 21.1022 - val_loss: 596.5450 - val_mae: 20.0333\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.7363 - mae: 20.5787 - val_loss: 566.5281 - val_mae: 19.5419\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 569.7537 - mae: 20.1392 - val_loss: 542.1098 - val_mae: 19.1228\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.4355 - mae: 19.7646 - val_loss: 521.2236 - val_mae: 18.7474\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 534.3098 - mae: 19.4483 - val_loss: 503.8893 - val_mae: 18.4139\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 520.7786 - mae: 19.1678 - val_loss: 488.2900 - val_mae: 18.1178\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 509.0975 - mae: 18.9255 - val_loss: 474.9969 - val_mae: 17.8619\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 498.9562 - mae: 18.7071 - val_loss: 463.2039 - val_mae: 17.6363\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 490.3149 - mae: 18.5184 - val_loss: 451.9722 - val_mae: 17.4364\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 482.3144 - mae: 18.3500 - val_loss: 442.7082 - val_mae: 17.2689\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 475.5939 - mae: 18.1986 - val_loss: 434.3144 - val_mae: 17.1152\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.6233 - mae: 18.0670 - val_loss: 426.4724 - val_mae: 16.9741\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.1368 - mae: 17.9463 - val_loss: 419.6406 - val_mae: 16.8476\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.2049 - mae: 17.8364 - val_loss: 412.7968 - val_mae: 16.7270\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.5740 - mae: 17.7348 - val_loss: 407.0122 - val_mae: 16.6271\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.5513 - mae: 17.6419 - val_loss: 401.2649 - val_mae: 16.5348\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.5697 - mae: 17.5566 - val_loss: 396.1486 - val_mae: 16.4485\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.8993 - mae: 17.4734 - val_loss: 391.1930 - val_mae: 16.3671\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.3394 - mae: 17.3947 - val_loss: 386.6685 - val_mae: 16.2915\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.9740 - mae: 17.3216 - val_loss: 381.9475 - val_mae: 16.2154\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.5716 - mae: 17.2502 - val_loss: 377.0869 - val_mae: 16.1393\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.9558 - mae: 17.1791 - val_loss: 372.9674 - val_mae: 16.0669\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.7485 - mae: 17.1101 - val_loss: 368.8254 - val_mae: 15.9945\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.7255 - mae: 17.0468 - val_loss: 364.9350 - val_mae: 15.9255\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.0096 - mae: 16.9883 - val_loss: 361.3823 - val_mae: 15.8599\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.4604 - mae: 16.9314 - val_loss: 357.8191 - val_mae: 15.7940\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.0828 - mae: 16.8809 - val_loss: 354.6145 - val_mae: 15.7330\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.8252 - mae: 16.8308 - val_loss: 351.3701 - val_mae: 15.6693\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.6324 - mae: 16.7804 - val_loss: 348.3385 - val_mae: 15.6102\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.6391 - mae: 16.7331 - val_loss: 345.5027 - val_mae: 15.5538\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.6842 - mae: 16.6883 - val_loss: 342.5602 - val_mae: 15.4967\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.7812 - mae: 16.6428 - val_loss: 339.9547 - val_mae: 15.4431\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.0217 - mae: 16.6008 - val_loss: 337.3245 - val_mae: 15.3902\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.2325 - mae: 16.5575 - val_loss: 334.8640 - val_mae: 15.3412\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 399.5518 - mae: 16.5155 - val_loss: 332.3422 - val_mae: 15.2928\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 397.8545 - mae: 16.4752 - val_loss: 330.1465 - val_mae: 15.2477\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.2601 - mae: 16.4364 - val_loss: 327.9471 - val_mae: 15.2007\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 394.6786 - mae: 16.3958 - val_loss: 325.5928 - val_mae: 15.1539\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 393.1057 - mae: 16.3586 - val_loss: 323.5654 - val_mae: 15.1082\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.6182 - mae: 16.3198 - val_loss: 321.3324 - val_mae: 15.0608\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 390.1093 - mae: 16.2821 - val_loss: 319.1169 - val_mae: 15.0126\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.5667 - mae: 16.2452 - val_loss: 317.0809 - val_mae: 14.9653\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.0431 - mae: 16.2058 - val_loss: 315.1794 - val_mae: 14.9192\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.5891 - mae: 16.1670 - val_loss: 313.2452 - val_mae: 14.8730\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.0931 - mae: 16.1270 - val_loss: 311.3756 - val_mae: 14.8263\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.6691 - mae: 16.0881 - val_loss: 309.4499 - val_mae: 14.7788\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.2357 - mae: 16.0491 - val_loss: 307.5836 - val_mae: 14.7316\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.8283 - mae: 16.0106 - val_loss: 305.6527 - val_mae: 14.6842\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.4240 - mae: 15.9726 - val_loss: 303.7457 - val_mae: 14.6371\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 377.0507 - mae: 15.9336 - val_loss: 301.7862 - val_mae: 14.5891\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.6752 - mae: 15.8954 - val_loss: 300.0387 - val_mae: 14.5430\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 374.3180 - mae: 15.8568 - val_loss: 298.1899 - val_mae: 14.4964\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 372.9230 - mae: 15.8168 - val_loss: 296.4903 - val_mae: 14.4522\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 371.6174 - mae: 15.7789 - val_loss: 294.9143 - val_mae: 14.4103\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.3267 - mae: 15.7415 - val_loss: 293.3324 - val_mae: 14.3676\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.0847 - mae: 15.7053 - val_loss: 291.7832 - val_mae: 14.3258\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.9040 - mae: 15.6692 - val_loss: 290.3250 - val_mae: 14.2854\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.7061 - mae: 15.6326 - val_loss: 288.8549 - val_mae: 14.2453\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.5614 - mae: 15.5979 - val_loss: 287.4726 - val_mae: 14.2044\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.4235 - mae: 15.5633 - val_loss: 286.0845 - val_mae: 14.1655\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.3571 - mae: 15.5308 - val_loss: 284.6943 - val_mae: 14.1273\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.3242 - mae: 15.4997 - val_loss: 283.4277 - val_mae: 14.0910\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.3407 - mae: 15.4703 - val_loss: 282.2195 - val_mae: 14.0543\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.4000 - mae: 15.4414 - val_loss: 281.0375 - val_mae: 14.0188\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.4972 - mae: 15.4138 - val_loss: 279.8385 - val_mae: 13.9826\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.5739 - mae: 15.3860 - val_loss: 278.7618 - val_mae: 13.9507\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.7314 - mae: 15.3604 - val_loss: 277.7409 - val_mae: 13.9192\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.9125 - mae: 15.3356 - val_loss: 276.6326 - val_mae: 13.8867\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 356.0763 - mae: 15.3115 - val_loss: 275.6600 - val_mae: 13.8591\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 355.3280 - mae: 15.2890 - val_loss: 274.6782 - val_mae: 13.8326\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 354.6099 - mae: 15.2674 - val_loss: 273.7050 - val_mae: 13.8067\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 353.8528 - mae: 15.2448 - val_loss: 272.7215 - val_mae: 13.7814\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 353.1127 - mae: 15.2230 - val_loss: 271.7430 - val_mae: 13.7556\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.4003 - mae: 15.2019 - val_loss: 270.8918 - val_mae: 13.7309\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.7093 - mae: 15.1814 - val_loss: 270.0198 - val_mae: 13.7074\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.0265 - mae: 15.1611 - val_loss: 269.1988 - val_mae: 13.6841\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.3798 - mae: 15.1421 - val_loss: 268.3880 - val_mae: 13.6618\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.7610 - mae: 15.1237 - val_loss: 267.5633 - val_mae: 13.6383\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 349.1093 - mae: 15.1029 - val_loss: 266.7909 - val_mae: 13.6162\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 348.5155 - mae: 15.0848 - val_loss: 266.0125 - val_mae: 13.5946\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.9092 - mae: 15.0675 - val_loss: 265.2418 - val_mae: 13.5730\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.3365 - mae: 15.0501 - val_loss: 264.5200 - val_mae: 13.5518\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.7871 - mae: 15.0347 - val_loss: 263.7680 - val_mae: 13.5298\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.2096 - mae: 15.0170 - val_loss: 263.0768 - val_mae: 13.5085\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.6576 - mae: 15.0007 - val_loss: 262.3285 - val_mae: 13.4867\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.1257 - mae: 14.9855 - val_loss: 261.6022 - val_mae: 13.4662\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.6010 - mae: 14.9702 - val_loss: 260.8894 - val_mae: 13.4448\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.0690 - mae: 14.9556 - val_loss: 260.1423 - val_mae: 13.4238\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.5377 - mae: 14.9398 - val_loss: 259.4304 - val_mae: 13.4035\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.0272 - mae: 14.9253 - val_loss: 258.7689 - val_mae: 13.3840\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.5376 - mae: 14.9116 - val_loss: 258.1155 - val_mae: 13.3658\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.0588 - mae: 14.8968 - val_loss: 257.4385 - val_mae: 13.3472\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.6006 - mae: 14.8845 - val_loss: 256.7950 - val_mae: 13.3295\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   4.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 2669.2744 - mae: 37.6553 - val_loss: 2283.7781 - val_mae: 34.0839\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1830.2014 - mae: 31.5470 - val_loss: 1638.7620 - val_mae: 29.0486\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1384.9940 - mae: 27.7106 - val_loss: 1271.6036 - val_mae: 25.9808\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1126.7692 - mae: 25.3800 - val_loss: 1038.5939 - val_mae: 24.0008\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 961.2988 - mae: 23.8437 - val_loss: 881.9284 - val_mae: 22.5913\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 850.0533 - mae: 22.7590 - val_loss: 777.0997 - val_mae: 21.5355\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 775.1104 - mae: 21.9824 - val_loss: 699.8941 - val_mae: 20.7134\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 719.2496 - mae: 21.3834 - val_loss: 640.9094 - val_mae: 20.0446\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.4692 - mae: 20.9016 - val_loss: 595.2831 - val_mae: 19.4865\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.2117 - mae: 20.4934 - val_loss: 557.7600 - val_mae: 19.0171\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 615.9635 - mae: 20.1717 - val_loss: 528.6584 - val_mae: 18.6219\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.4416 - mae: 19.8817 - val_loss: 503.5965 - val_mae: 18.2814\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 576.3394 - mae: 19.6505 - val_loss: 483.5717 - val_mae: 18.0103\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.5245 - mae: 19.4467 - val_loss: 466.1035 - val_mae: 17.7745\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.6537 - mae: 19.2715 - val_loss: 451.1519 - val_mae: 17.5564\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.7285 - mae: 19.1135 - val_loss: 438.0746 - val_mae: 17.3627\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.0117 - mae: 18.9740 - val_loss: 426.8434 - val_mae: 17.1891\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.6320 - mae: 18.8452 - val_loss: 416.8831 - val_mae: 17.0316\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 512.0435 - mae: 18.7230 - val_loss: 408.2473 - val_mae: 16.8949\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 505.3063 - mae: 18.6136 - val_loss: 400.5862 - val_mae: 16.7726\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 499.2291 - mae: 18.5108 - val_loss: 393.2098 - val_mae: 16.6585\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 493.2704 - mae: 18.4117 - val_loss: 386.2343 - val_mae: 16.5514\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 487.6733 - mae: 18.3220 - val_loss: 380.3355 - val_mae: 16.4579\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 482.7203 - mae: 18.2395 - val_loss: 374.6211 - val_mae: 16.3654\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.1017 - mae: 18.1563 - val_loss: 369.5431 - val_mae: 16.2811\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 473.8677 - mae: 18.0798 - val_loss: 364.3631 - val_mae: 16.1966\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.7064 - mae: 18.0085 - val_loss: 359.7505 - val_mae: 16.1169\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.0010 - mae: 17.9388 - val_loss: 355.4356 - val_mae: 16.0442\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.4994 - mae: 17.8743 - val_loss: 351.1165 - val_mae: 15.9688\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 459.0414 - mae: 17.8074 - val_loss: 347.1895 - val_mae: 15.8963\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 455.8767 - mae: 17.7460 - val_loss: 343.3185 - val_mae: 15.8254\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.7907 - mae: 17.6865 - val_loss: 339.6627 - val_mae: 15.7548\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.8669 - mae: 17.6292 - val_loss: 336.3413 - val_mae: 15.6907\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.0988 - mae: 17.5716 - val_loss: 333.1538 - val_mae: 15.6295\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.4541 - mae: 17.5172 - val_loss: 330.0804 - val_mae: 15.5690\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.9025 - mae: 17.4638 - val_loss: 327.2126 - val_mae: 15.5106\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 439.5777 - mae: 17.4155 - val_loss: 324.4008 - val_mae: 15.4524\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.2157 - mae: 17.3656 - val_loss: 321.7537 - val_mae: 15.3962\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.9688 - mae: 17.3176 - val_loss: 319.0780 - val_mae: 15.3406\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.7379 - mae: 17.2716 - val_loss: 316.3610 - val_mae: 15.2810\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.4767 - mae: 17.2216 - val_loss: 313.9088 - val_mae: 15.2264\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.3203 - mae: 17.1754 - val_loss: 311.4264 - val_mae: 15.1695\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.2150 - mae: 17.1312 - val_loss: 309.2830 - val_mae: 15.1152\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.2909 - mae: 17.0855 - val_loss: 307.1833 - val_mae: 15.0629\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 422.3662 - mae: 17.0408 - val_loss: 305.1246 - val_mae: 15.0141\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 420.4275 - mae: 16.9970 - val_loss: 303.2216 - val_mae: 14.9696\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 418.5273 - mae: 16.9536 - val_loss: 301.4480 - val_mae: 14.9261\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.7468 - mae: 16.9135 - val_loss: 299.6775 - val_mae: 14.8800\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.9904 - mae: 16.8700 - val_loss: 297.9984 - val_mae: 14.8369\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.2521 - mae: 16.8294 - val_loss: 296.4059 - val_mae: 14.7951\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.6097 - mae: 16.7877 - val_loss: 294.7831 - val_mae: 14.7538\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.9363 - mae: 16.7472 - val_loss: 293.1499 - val_mae: 14.7123\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 408.2660 - mae: 16.7069 - val_loss: 291.5436 - val_mae: 14.6677\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.6774 - mae: 16.6645 - val_loss: 289.9583 - val_mae: 14.6230\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.0717 - mae: 16.6231 - val_loss: 288.2267 - val_mae: 14.5727\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.3842 - mae: 16.5787 - val_loss: 286.6229 - val_mae: 14.5222\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 401.6999 - mae: 16.5318 - val_loss: 285.0336 - val_mae: 14.4721\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 400.0417 - mae: 16.4857 - val_loss: 283.4965 - val_mae: 14.4219\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 398.4391 - mae: 16.4430 - val_loss: 282.0779 - val_mae: 14.3746\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 396.9274 - mae: 16.4004 - val_loss: 280.7082 - val_mae: 14.3284\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 395.4819 - mae: 16.3576 - val_loss: 279.3506 - val_mae: 14.2816\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 394.1404 - mae: 16.3180 - val_loss: 278.1565 - val_mae: 14.2409\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.8414 - mae: 16.2781 - val_loss: 276.9571 - val_mae: 14.1986\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.6326 - mae: 16.2434 - val_loss: 275.7416 - val_mae: 14.1526\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 390.4582 - mae: 16.2041 - val_loss: 274.6494 - val_mae: 14.1113\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.3299 - mae: 16.1708 - val_loss: 273.6202 - val_mae: 14.0704\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.2830 - mae: 16.1348 - val_loss: 272.6494 - val_mae: 14.0327\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.3299 - mae: 16.1058 - val_loss: 271.6821 - val_mae: 13.9955\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.3720 - mae: 16.0760 - val_loss: 270.7789 - val_mae: 13.9596\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.4498 - mae: 16.0458 - val_loss: 269.9674 - val_mae: 13.9283\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 384.6000 - mae: 16.0190 - val_loss: 269.1195 - val_mae: 13.8966\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 383.7682 - mae: 15.9911 - val_loss: 268.3500 - val_mae: 13.8665\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 382.9767 - mae: 15.9669 - val_loss: 267.6059 - val_mae: 13.8376\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 382.2604 - mae: 15.9449 - val_loss: 266.8308 - val_mae: 13.8064\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.5214 - mae: 15.9179 - val_loss: 266.1720 - val_mae: 13.7817\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.7864 - mae: 15.8977 - val_loss: 265.4836 - val_mae: 13.7550\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.1167 - mae: 15.8780 - val_loss: 264.8200 - val_mae: 13.7287\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.4588 - mae: 15.8563 - val_loss: 264.1765 - val_mae: 13.7040\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.8427 - mae: 15.8342 - val_loss: 263.6134 - val_mae: 13.6826\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.2143 - mae: 15.8181 - val_loss: 263.0194 - val_mae: 13.6598\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.6171 - mae: 15.7993 - val_loss: 262.4497 - val_mae: 13.6386\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.0336 - mae: 15.7845 - val_loss: 261.8737 - val_mae: 13.6174\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 376.4630 - mae: 15.7673 - val_loss: 261.3315 - val_mae: 13.5983\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.9048 - mae: 15.7520 - val_loss: 260.7534 - val_mae: 13.5760\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 375.3771 - mae: 15.7348 - val_loss: 260.1804 - val_mae: 13.5537\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.8598 - mae: 15.7141 - val_loss: 259.6732 - val_mae: 13.5355\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.3820 - mae: 15.7008 - val_loss: 259.1459 - val_mae: 13.5160\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.8925 - mae: 15.6843 - val_loss: 258.6436 - val_mae: 13.4978\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.3845 - mae: 15.6696 - val_loss: 258.1322 - val_mae: 13.4779\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.9276 - mae: 15.6547 - val_loss: 257.6042 - val_mae: 13.4581\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 372.4522 - mae: 15.6396 - val_loss: 257.1367 - val_mae: 13.4413\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.9921 - mae: 15.6239 - val_loss: 256.6942 - val_mae: 13.4254\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.5482 - mae: 15.6136 - val_loss: 256.2050 - val_mae: 13.4061\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.1058 - mae: 15.6019 - val_loss: 255.7372 - val_mae: 13.3885\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.6855 - mae: 15.5887 - val_loss: 255.2770 - val_mae: 13.3704\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.2589 - mae: 15.5738 - val_loss: 254.8905 - val_mae: 13.3555\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.8520 - mae: 15.5645 - val_loss: 254.4543 - val_mae: 13.3369\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.4823 - mae: 15.5510 - val_loss: 254.0296 - val_mae: 13.3206\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.0741 - mae: 15.5387 - val_loss: 253.6460 - val_mae: 13.3050\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.7222 - mae: 15.5292 - val_loss: 253.2614 - val_mae: 13.2901\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   4.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 3746.6558 - mae: 43.6666 - val_loss: 2786.3093 - val_mae: 38.8384\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2373.3574 - mae: 36.1391 - val_loss: 1857.1163 - val_mae: 32.9878\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1670.2451 - mae: 31.3984 - val_loss: 1346.1775 - val_mae: 29.0537\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1268.8466 - mae: 28.1477 - val_loss: 1044.9587 - val_mae: 26.3111\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1023.6133 - mae: 25.7729 - val_loss: 855.0932 - val_mae: 24.3036\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 863.9275 - mae: 24.0002 - val_loss: 728.2946 - val_mae: 22.7165\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 754.1355 - mae: 22.6317 - val_loss: 640.1200 - val_mae: 21.4737\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.5637 - mae: 21.5455 - val_loss: 575.1196 - val_mae: 20.4893\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 616.3093 - mae: 20.6517 - val_loss: 528.4406 - val_mae: 19.7056\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.8856 - mae: 19.9151 - val_loss: 492.9669 - val_mae: 19.0480\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 537.1964 - mae: 19.3058 - val_loss: 465.9544 - val_mae: 18.5279\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 509.9251 - mae: 18.7981 - val_loss: 444.9538 - val_mae: 18.1068\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 487.7907 - mae: 18.3961 - val_loss: 427.7337 - val_mae: 17.7495\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.8636 - mae: 18.0539 - val_loss: 414.0797 - val_mae: 17.4661\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.2810 - mae: 17.7798 - val_loss: 403.1559 - val_mae: 17.2330\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.5179 - mae: 17.5414 - val_loss: 394.4799 - val_mae: 17.0327\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 434.0766 - mae: 17.3435 - val_loss: 387.4890 - val_mae: 16.8652\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.9641 - mae: 17.1774 - val_loss: 381.8025 - val_mae: 16.7190\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.2219 - mae: 17.0302 - val_loss: 376.9504 - val_mae: 16.5954\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.5802 - mae: 16.9073 - val_loss: 372.8369 - val_mae: 16.4870\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.6787 - mae: 16.8052 - val_loss: 369.4524 - val_mae: 16.3948\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.4464 - mae: 16.7141 - val_loss: 366.5630 - val_mae: 16.3158\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.8107 - mae: 16.6386 - val_loss: 364.0342 - val_mae: 16.2463\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.5660 - mae: 16.5702 - val_loss: 361.7164 - val_mae: 16.1872\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.5546 - mae: 16.5099 - val_loss: 359.8517 - val_mae: 16.1351\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.9882 - mae: 16.4562 - val_loss: 358.1148 - val_mae: 16.0860\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.7206 - mae: 16.4074 - val_loss: 356.5603 - val_mae: 16.0417\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.6112 - mae: 16.3617 - val_loss: 355.1824 - val_mae: 16.0035\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.6858 - mae: 16.3206 - val_loss: 353.8574 - val_mae: 15.9678\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.9088 - mae: 16.2820 - val_loss: 352.6825 - val_mae: 15.9361\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.2718 - mae: 16.2479 - val_loss: 351.6027 - val_mae: 15.9063\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.6795 - mae: 16.2153 - val_loss: 350.6270 - val_mae: 15.8779\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.2908 - mae: 16.1817 - val_loss: 349.7023 - val_mae: 15.8521\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.8767 - mae: 16.1535 - val_loss: 348.8253 - val_mae: 15.8268\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 376.6201 - mae: 16.1249 - val_loss: 347.9873 - val_mae: 15.8030\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.4263 - mae: 16.1018 - val_loss: 347.1928 - val_mae: 15.7786\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.2710 - mae: 16.0759 - val_loss: 346.3127 - val_mae: 15.7537\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 373.1446 - mae: 16.0496 - val_loss: 345.5748 - val_mae: 15.7315\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.0908 - mae: 16.0254 - val_loss: 344.8949 - val_mae: 15.7105\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.1060 - mae: 16.0039 - val_loss: 344.2396 - val_mae: 15.6910\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.0612 - mae: 15.9805 - val_loss: 343.6088 - val_mae: 15.6718\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.0764 - mae: 15.9590 - val_loss: 343.0504 - val_mae: 15.6542\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.1938 - mae: 15.9375 - val_loss: 342.4913 - val_mae: 15.6374\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.2540 - mae: 15.9143 - val_loss: 342.0102 - val_mae: 15.6227\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.3638 - mae: 15.8953 - val_loss: 341.4833 - val_mae: 15.6072\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.5084 - mae: 15.8755 - val_loss: 340.9824 - val_mae: 15.5916\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.6546 - mae: 15.8547 - val_loss: 340.4191 - val_mae: 15.5748\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.8228 - mae: 15.8358 - val_loss: 339.8957 - val_mae: 15.5574\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.9466 - mae: 15.8142 - val_loss: 339.3137 - val_mae: 15.5383\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.0820 - mae: 15.7917 - val_loss: 338.8443 - val_mae: 15.5207\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.1285 - mae: 15.7701 - val_loss: 338.2719 - val_mae: 15.5006\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.1888 - mae: 15.7472 - val_loss: 337.6194 - val_mae: 15.4775\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.3273 - mae: 15.7235 - val_loss: 337.0289 - val_mae: 15.4555\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 358.5055 - mae: 15.7030 - val_loss: 336.4936 - val_mae: 15.4349\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 357.6713 - mae: 15.6799 - val_loss: 336.0160 - val_mae: 15.4161\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.8419 - mae: 15.6602 - val_loss: 335.4265 - val_mae: 15.3944\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.0074 - mae: 15.6391 - val_loss: 334.8336 - val_mae: 15.3720\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.2498 - mae: 15.6194 - val_loss: 334.2557 - val_mae: 15.3496\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.4900 - mae: 15.5993 - val_loss: 333.7170 - val_mae: 15.3295\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.7784 - mae: 15.5818 - val_loss: 333.2284 - val_mae: 15.3099\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 352.9939 - mae: 15.5598 - val_loss: 332.7546 - val_mae: 15.2912\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.2919 - mae: 15.5407 - val_loss: 332.2929 - val_mae: 15.2726\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.5662 - mae: 15.5213 - val_loss: 331.8326 - val_mae: 15.2555\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.8684 - mae: 15.5024 - val_loss: 331.3929 - val_mae: 15.2389\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.1730 - mae: 15.4826 - val_loss: 330.9875 - val_mae: 15.2237\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.5103 - mae: 15.4647 - val_loss: 330.5774 - val_mae: 15.2084\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.8186 - mae: 15.4460 - val_loss: 330.1666 - val_mae: 15.1942\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.1785 - mae: 15.4302 - val_loss: 329.8506 - val_mae: 15.1823\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.5146 - mae: 15.4125 - val_loss: 329.4836 - val_mae: 15.1702\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 346.9374 - mae: 15.3976 - val_loss: 329.0794 - val_mae: 15.1574\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.3404 - mae: 15.3836 - val_loss: 328.7018 - val_mae: 15.1443\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.7372 - mae: 15.3663 - val_loss: 328.2787 - val_mae: 15.1310\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.1272 - mae: 15.3517 - val_loss: 327.9037 - val_mae: 15.1181\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 344.5493 - mae: 15.3360 - val_loss: 327.5200 - val_mae: 15.1048\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 343.9863 - mae: 15.3209 - val_loss: 327.2125 - val_mae: 15.0935\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 343.4027 - mae: 15.3047 - val_loss: 326.8410 - val_mae: 15.0815\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.8294 - mae: 15.2907 - val_loss: 326.4622 - val_mae: 15.0709\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.2754 - mae: 15.2769 - val_loss: 326.0813 - val_mae: 15.0599\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.7230 - mae: 15.2611 - val_loss: 325.7385 - val_mae: 15.0496\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.1934 - mae: 15.2467 - val_loss: 325.4172 - val_mae: 15.0401\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.6756 - mae: 15.2345 - val_loss: 325.0630 - val_mae: 15.0273\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.1808 - mae: 15.2185 - val_loss: 324.6658 - val_mae: 15.0166\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.6429 - mae: 15.2065 - val_loss: 324.2953 - val_mae: 15.0051\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 339.1077 - mae: 15.1920 - val_loss: 324.0197 - val_mae: 14.9954\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 338.5955 - mae: 15.1769 - val_loss: 323.6461 - val_mae: 14.9839\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 338.1089 - mae: 15.1648 - val_loss: 323.3824 - val_mae: 14.9739\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.6023 - mae: 15.1494 - val_loss: 322.9919 - val_mae: 14.9623\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.1177 - mae: 15.1372 - val_loss: 322.6467 - val_mae: 14.9518\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.6609 - mae: 15.1252 - val_loss: 322.3239 - val_mae: 14.9402\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.1913 - mae: 15.1127 - val_loss: 321.9682 - val_mae: 14.9271\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.6903 - mae: 15.0981 - val_loss: 321.6513 - val_mae: 14.9158\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.2380 - mae: 15.0851 - val_loss: 321.2866 - val_mae: 14.9037\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.7821 - mae: 15.0714 - val_loss: 320.9990 - val_mae: 14.8932\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.3058 - mae: 15.0592 - val_loss: 320.7063 - val_mae: 14.8832\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.8389 - mae: 15.0463 - val_loss: 320.4284 - val_mae: 14.8727\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.3766 - mae: 15.0321 - val_loss: 320.0902 - val_mae: 14.8615\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.9455 - mae: 15.0194 - val_loss: 319.7585 - val_mae: 14.8505\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.4884 - mae: 15.0075 - val_loss: 319.4090 - val_mae: 14.8392\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.0517 - mae: 14.9959 - val_loss: 319.1053 - val_mae: 14.8286\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.6418 - mae: 14.9828 - val_loss: 318.7719 - val_mae: 14.8186\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2188 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2188 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.6s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23996.0195 - mae: 72.7370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 24ms/step - loss: 3013.4224 - mae: 31.7954 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 598.7145 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   1.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 26ms/step - loss: 1074.9644 - mae: 26.5460 - val_loss: 449.2481 - val_mae: 20.2765\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 637.2542 - mae: 23.1212 - val_loss: 449.1884 - val_mae: 20.2750\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 637.1861 - mae: 23.1198 - val_loss: 449.1279 - val_mae: 20.2735\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 637.1172 - mae: 23.1182 - val_loss: 449.0681 - val_mae: 20.2720\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 637.0491 - mae: 23.1168 - val_loss: 449.0082 - val_mae: 20.2706\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.9808 - mae: 23.1153 - val_loss: 448.9483 - val_mae: 20.2691\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.9123 - mae: 23.1138 - val_loss: 448.8881 - val_mae: 20.2676\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.8437 - mae: 23.1124 - val_loss: 448.8283 - val_mae: 20.2661\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.7756 - mae: 23.1109 - val_loss: 448.7688 - val_mae: 20.2646\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.7076 - mae: 23.1094 - val_loss: 448.7087 - val_mae: 20.2631\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 636.6392 - mae: 23.1079 - val_loss: 448.6495 - val_mae: 20.2617\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 4072.5117 - mae: 34.1754 - val_loss: 383.2448 - val_mae: 16.9771\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.9840 - mae: 17.4923 - val_loss: 348.4752 - val_mae: 15.3104\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 366.0190 - mae: 15.8133 - val_loss: 370.4543 - val_mae: 16.5992\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 372.3799 - mae: 16.2718 - val_loss: 346.0265 - val_mae: 14.9888\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 361.7562 - mae: 15.5852 - val_loss: 346.5779 - val_mae: 15.0948\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 363.3294 - mae: 15.6509 - val_loss: 349.1786 - val_mae: 15.2192\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.2372 - mae: 15.5747 - val_loss: 347.7281 - val_mae: 15.1624\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.4961 - mae: 15.4732 - val_loss: 350.9879 - val_mae: 15.4118\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.0363 - mae: 15.6582 - val_loss: 347.1517 - val_mae: 15.1251\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.4827 - mae: 15.4588 - val_loss: 380.8256 - val_mae: 17.0572\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.9058 - mae: 15.8335 - val_loss: 351.1468 - val_mae: 15.3874\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.4020 - mae: 15.7503 - val_loss: 345.7965 - val_mae: 15.0058\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.0285 - mae: 15.4375 - val_loss: 353.2339 - val_mae: 15.4737\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 360.6328 - mae: 15.5353 - val_loss: 349.9903 - val_mae: 15.2315\n",
      "Epoch 14: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 19ms/step - loss: 7473.1948 - mae: 55.4892 - val_loss: 7814.4160 - val_mae: 55.8179\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7472.5571 - mae: 55.4867 - val_loss: 7813.7661 - val_mae: 55.8153\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7471.9385 - mae: 55.4842 - val_loss: 7813.1118 - val_mae: 55.8127\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7471.3071 - mae: 55.4817 - val_loss: 7812.4570 - val_mae: 55.8102\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7470.6934 - mae: 55.4792 - val_loss: 7811.7925 - val_mae: 55.8075\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7470.0483 - mae: 55.4766 - val_loss: 7811.1377 - val_mae: 55.8049\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7469.4233 - mae: 55.4741 - val_loss: 7810.4746 - val_mae: 55.8023\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7468.7871 - mae: 55.4716 - val_loss: 7809.8145 - val_mae: 55.7997\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7468.1567 - mae: 55.4690 - val_loss: 7809.1494 - val_mae: 55.7971\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7467.5249 - mae: 55.4665 - val_loss: 7808.4849 - val_mae: 55.7945\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7466.8921 - mae: 55.4640 - val_loss: 7807.8276 - val_mae: 55.7919\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7466.2666 - mae: 55.4615 - val_loss: 7807.1646 - val_mae: 55.7893\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7465.6348 - mae: 55.4589 - val_loss: 7806.5068 - val_mae: 55.7867\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7465.0063 - mae: 55.4564 - val_loss: 7805.8496 - val_mae: 55.7841\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7464.3799 - mae: 55.4539 - val_loss: 7805.1855 - val_mae: 55.7815\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7463.7393 - mae: 55.4513 - val_loss: 7804.5278 - val_mae: 55.7789\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7463.1094 - mae: 55.4488 - val_loss: 7803.8667 - val_mae: 55.7763\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7462.4873 - mae: 55.4463 - val_loss: 7803.1968 - val_mae: 55.7737\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7461.8486 - mae: 55.4437 - val_loss: 7802.5342 - val_mae: 55.7710\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7461.2085 - mae: 55.4412 - val_loss: 7801.8818 - val_mae: 55.7685\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7460.5820 - mae: 55.4386 - val_loss: 7801.2222 - val_mae: 55.7659\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7459.9556 - mae: 55.4361 - val_loss: 7800.5591 - val_mae: 55.7633\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7459.3281 - mae: 55.4336 - val_loss: 7799.9019 - val_mae: 55.7607\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7458.7026 - mae: 55.4311 - val_loss: 7799.2363 - val_mae: 55.7581\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7458.0640 - mae: 55.4285 - val_loss: 7798.5737 - val_mae: 55.7554\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7457.4336 - mae: 55.4260 - val_loss: 7797.9082 - val_mae: 55.7528\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7456.8037 - mae: 55.4234 - val_loss: 7797.2461 - val_mae: 55.7502\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7456.1636 - mae: 55.4209 - val_loss: 7796.5913 - val_mae: 55.7476\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7455.5459 - mae: 55.4184 - val_loss: 7795.9189 - val_mae: 55.7450\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7454.9004 - mae: 55.4158 - val_loss: 7795.2617 - val_mae: 55.7424\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7454.2764 - mae: 55.4133 - val_loss: 7794.5991 - val_mae: 55.7398\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7453.6445 - mae: 55.4107 - val_loss: 7793.9375 - val_mae: 55.7372\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7453.0039 - mae: 55.4082 - val_loss: 7793.2822 - val_mae: 55.7346\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7452.3765 - mae: 55.4056 - val_loss: 7792.6196 - val_mae: 55.7320\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7451.7476 - mae: 55.4031 - val_loss: 7791.9536 - val_mae: 55.7294\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7451.1113 - mae: 55.4006 - val_loss: 7791.2910 - val_mae: 55.7268\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7450.4834 - mae: 55.3980 - val_loss: 7790.6304 - val_mae: 55.7242\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7449.8506 - mae: 55.3955 - val_loss: 7789.9722 - val_mae: 55.7216\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7449.2256 - mae: 55.3930 - val_loss: 7789.3169 - val_mae: 55.7190\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7448.5947 - mae: 55.3904 - val_loss: 7788.6621 - val_mae: 55.7164\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7447.9707 - mae: 55.3879 - val_loss: 7787.9995 - val_mae: 55.7138\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7447.3345 - mae: 55.3854 - val_loss: 7787.3447 - val_mae: 55.7113\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7446.7144 - mae: 55.3829 - val_loss: 7786.6846 - val_mae: 55.7087\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7446.0879 - mae: 55.3803 - val_loss: 7786.0303 - val_mae: 55.7061\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7445.4644 - mae: 55.3778 - val_loss: 7785.3779 - val_mae: 55.7035\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7444.8384 - mae: 55.3753 - val_loss: 7784.7261 - val_mae: 55.7009\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7444.2139 - mae: 55.3728 - val_loss: 7784.0728 - val_mae: 55.6984\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7443.5918 - mae: 55.3703 - val_loss: 7783.4155 - val_mae: 55.6958\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7442.9546 - mae: 55.3677 - val_loss: 7782.7637 - val_mae: 55.6932\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7442.3301 - mae: 55.3652 - val_loss: 7782.1069 - val_mae: 55.6906\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7441.7021 - mae: 55.3627 - val_loss: 7781.4434 - val_mae: 55.6880\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7441.0732 - mae: 55.3602 - val_loss: 7780.7783 - val_mae: 55.6854\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7440.4478 - mae: 55.3576 - val_loss: 7780.1157 - val_mae: 55.6828\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7439.8110 - mae: 55.3551 - val_loss: 7779.4600 - val_mae: 55.6802\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7439.1841 - mae: 55.3526 - val_loss: 7778.8032 - val_mae: 55.6776\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7438.5620 - mae: 55.3500 - val_loss: 7778.1382 - val_mae: 55.6750\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7437.9302 - mae: 55.3475 - val_loss: 7777.4761 - val_mae: 55.6724\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7437.2861 - mae: 55.3449 - val_loss: 7776.8311 - val_mae: 55.6699\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7436.6675 - mae: 55.3424 - val_loss: 7776.1685 - val_mae: 55.6673\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 7436.0449 - mae: 55.3399 - val_loss: 7775.5034 - val_mae: 55.6647\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7435.4067 - mae: 55.3374 - val_loss: 7774.8462 - val_mae: 55.6621\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7434.7866 - mae: 55.3349 - val_loss: 7774.1846 - val_mae: 55.6595\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7434.1499 - mae: 55.3323 - val_loss: 7773.5317 - val_mae: 55.6570\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7433.5205 - mae: 55.3298 - val_loss: 7772.8774 - val_mae: 55.6544\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7432.8911 - mae: 55.3273 - val_loss: 7772.2188 - val_mae: 55.6518\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7432.2705 - mae: 55.3248 - val_loss: 7771.5532 - val_mae: 55.6492\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7431.6367 - mae: 55.3223 - val_loss: 7770.8931 - val_mae: 55.6466\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7430.9980 - mae: 55.3197 - val_loss: 7770.2461 - val_mae: 55.6441\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7430.3804 - mae: 55.3172 - val_loss: 7769.5874 - val_mae: 55.6415\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7429.7515 - mae: 55.3147 - val_loss: 7768.9224 - val_mae: 55.6389\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7429.1138 - mae: 55.3122 - val_loss: 7768.2681 - val_mae: 55.6363\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7428.4897 - mae: 55.3096 - val_loss: 7767.6064 - val_mae: 55.6338\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7427.8608 - mae: 55.3071 - val_loss: 7766.9414 - val_mae: 55.6311\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7427.2314 - mae: 55.3046 - val_loss: 7766.2788 - val_mae: 55.6285\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7426.5952 - mae: 55.3020 - val_loss: 7765.6226 - val_mae: 55.6260\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7425.9604 - mae: 55.2995 - val_loss: 7764.9722 - val_mae: 55.6234\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7425.3442 - mae: 55.2970 - val_loss: 7764.3086 - val_mae: 55.6208\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7424.7061 - mae: 55.2944 - val_loss: 7763.6509 - val_mae: 55.6182\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7424.0674 - mae: 55.2919 - val_loss: 7762.9941 - val_mae: 55.6157\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7423.4438 - mae: 55.2894 - val_loss: 7762.3271 - val_mae: 55.6131\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7422.8135 - mae: 55.2868 - val_loss: 7761.6636 - val_mae: 55.6105\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7422.1909 - mae: 55.2843 - val_loss: 7760.9980 - val_mae: 55.6078\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7421.5630 - mae: 55.2818 - val_loss: 7760.3418 - val_mae: 55.6053\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7420.9229 - mae: 55.2792 - val_loss: 7759.6978 - val_mae: 55.6027\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7420.3057 - mae: 55.2767 - val_loss: 7759.0410 - val_mae: 55.6001\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7419.6733 - mae: 55.2742 - val_loss: 7758.3887 - val_mae: 55.5976\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7419.0503 - mae: 55.2717 - val_loss: 7757.7314 - val_mae: 55.5950\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7418.4302 - mae: 55.2692 - val_loss: 7757.0654 - val_mae: 55.5924\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7417.7915 - mae: 55.2666 - val_loss: 7756.4023 - val_mae: 55.5897\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7417.1602 - mae: 55.2641 - val_loss: 7755.7446 - val_mae: 55.5871\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7416.5361 - mae: 55.2616 - val_loss: 7755.0864 - val_mae: 55.5846\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 7415.9028 - mae: 55.2590 - val_loss: 7754.4316 - val_mae: 55.5820\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7415.2793 - mae: 55.2565 - val_loss: 7753.7725 - val_mae: 55.5794\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7414.6509 - mae: 55.2540 - val_loss: 7753.1157 - val_mae: 55.5768\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7414.0273 - mae: 55.2515 - val_loss: 7752.4619 - val_mae: 55.5742\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7413.3970 - mae: 55.2489 - val_loss: 7751.8130 - val_mae: 55.5716\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7412.7837 - mae: 55.2464 - val_loss: 7751.1489 - val_mae: 55.5690\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7412.1440 - mae: 55.2439 - val_loss: 7750.4932 - val_mae: 55.5664\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7411.5142 - mae: 55.2413 - val_loss: 7749.8354 - val_mae: 55.5639\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7410.8906 - mae: 55.2388 - val_loss: 7749.1777 - val_mae: 55.5613\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   6.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 26ms/step - loss: 6394.4194 - mae: 52.5483 - val_loss: 6761.5874 - val_mae: 52.7957\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6393.8389 - mae: 52.5458 - val_loss: 6760.9780 - val_mae: 52.7931\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6393.2656 - mae: 52.5432 - val_loss: 6760.3657 - val_mae: 52.7905\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6392.6943 - mae: 52.5407 - val_loss: 6759.7495 - val_mae: 52.7879\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6392.1167 - mae: 52.5382 - val_loss: 6759.1333 - val_mae: 52.7854\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6391.5449 - mae: 52.5357 - val_loss: 6758.5146 - val_mae: 52.7828\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6390.9673 - mae: 52.5332 - val_loss: 6757.8999 - val_mae: 52.7802\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6390.3857 - mae: 52.5307 - val_loss: 6757.2900 - val_mae: 52.7776\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6389.8184 - mae: 52.5282 - val_loss: 6756.6738 - val_mae: 52.7750\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6389.2480 - mae: 52.5257 - val_loss: 6756.0537 - val_mae: 52.7724\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6388.6626 - mae: 52.5231 - val_loss: 6755.4443 - val_mae: 52.7699\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6388.0986 - mae: 52.5207 - val_loss: 6754.8242 - val_mae: 52.7673\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6387.5239 - mae: 52.5181 - val_loss: 6754.2041 - val_mae: 52.7647\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6386.9390 - mae: 52.5156 - val_loss: 6753.5938 - val_mae: 52.7621\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6386.3677 - mae: 52.5131 - val_loss: 6752.9780 - val_mae: 52.7595\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6385.8052 - mae: 52.5106 - val_loss: 6752.3555 - val_mae: 52.7569\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6385.2139 - mae: 52.5081 - val_loss: 6751.7524 - val_mae: 52.7543\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6384.6489 - mae: 52.5056 - val_loss: 6751.1367 - val_mae: 52.7517\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6384.0742 - mae: 52.5031 - val_loss: 6750.5283 - val_mae: 52.7491\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6383.5103 - mae: 52.5006 - val_loss: 6749.9121 - val_mae: 52.7465\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6382.9292 - mae: 52.4981 - val_loss: 6749.3008 - val_mae: 52.7440\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6382.3535 - mae: 52.4956 - val_loss: 6748.6919 - val_mae: 52.7414\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6381.7832 - mae: 52.4931 - val_loss: 6748.0742 - val_mae: 52.7388\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6381.2119 - mae: 52.4905 - val_loss: 6747.4526 - val_mae: 52.7362\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6380.6289 - mae: 52.4880 - val_loss: 6746.8413 - val_mae: 52.7336\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6380.0566 - mae: 52.4855 - val_loss: 6746.2241 - val_mae: 52.7310\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6379.4824 - mae: 52.4830 - val_loss: 6745.6055 - val_mae: 52.7284\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6378.9019 - mae: 52.4805 - val_loss: 6744.9907 - val_mae: 52.7258\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 6378.3335 - mae: 52.4780 - val_loss: 6744.3745 - val_mae: 52.7232\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6377.7646 - mae: 52.4755 - val_loss: 6743.7534 - val_mae: 52.7205\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6377.1748 - mae: 52.4729 - val_loss: 6743.1460 - val_mae: 52.7180\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6376.6030 - mae: 52.4704 - val_loss: 6742.5293 - val_mae: 52.7154\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6376.0361 - mae: 52.4679 - val_loss: 6741.9067 - val_mae: 52.7127\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6375.4575 - mae: 52.4654 - val_loss: 6741.2852 - val_mae: 52.7101\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6374.8877 - mae: 52.4629 - val_loss: 6740.6665 - val_mae: 52.7075\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6374.3032 - mae: 52.4603 - val_loss: 6740.0591 - val_mae: 52.7049\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6373.7339 - mae: 52.4578 - val_loss: 6739.4458 - val_mae: 52.7023\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6373.1621 - mae: 52.4554 - val_loss: 6738.8335 - val_mae: 52.6997\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6372.5903 - mae: 52.4528 - val_loss: 6738.2222 - val_mae: 52.6971\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6372.0156 - mae: 52.4504 - val_loss: 6737.6147 - val_mae: 52.6945\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6371.4487 - mae: 52.4479 - val_loss: 6736.9990 - val_mae: 52.6919\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6370.8726 - mae: 52.4453 - val_loss: 6736.3862 - val_mae: 52.6893\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6370.3022 - mae: 52.4429 - val_loss: 6735.7710 - val_mae: 52.6867\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6369.7290 - mae: 52.4404 - val_loss: 6735.1558 - val_mae: 52.6841\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6369.1538 - mae: 52.4378 - val_loss: 6734.5479 - val_mae: 52.6815\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6368.5820 - mae: 52.4353 - val_loss: 6733.9404 - val_mae: 52.6790\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6368.0229 - mae: 52.4329 - val_loss: 6733.3169 - val_mae: 52.6763\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6367.4341 - mae: 52.4303 - val_loss: 6732.7129 - val_mae: 52.6738\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6366.8740 - mae: 52.4278 - val_loss: 6732.0957 - val_mae: 52.6712\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6366.2959 - mae: 52.4253 - val_loss: 6731.4844 - val_mae: 52.6686\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6365.7295 - mae: 52.4228 - val_loss: 6730.8667 - val_mae: 52.6659\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6365.1504 - mae: 52.4203 - val_loss: 6730.2520 - val_mae: 52.6633\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6364.5723 - mae: 52.4178 - val_loss: 6729.6440 - val_mae: 52.6608\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6364.0088 - mae: 52.4153 - val_loss: 6729.0303 - val_mae: 52.6582\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6363.4302 - mae: 52.4128 - val_loss: 6728.4229 - val_mae: 52.6556\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6362.8740 - mae: 52.4103 - val_loss: 6727.8022 - val_mae: 52.6530\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6362.2891 - mae: 52.4078 - val_loss: 6727.1943 - val_mae: 52.6504\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6361.7251 - mae: 52.4053 - val_loss: 6726.5806 - val_mae: 52.6478\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6361.1406 - mae: 52.4028 - val_loss: 6725.9756 - val_mae: 52.6452\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 6360.5830 - mae: 52.4003 - val_loss: 6725.3540 - val_mae: 52.6426\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6360.0015 - mae: 52.3978 - val_loss: 6724.7432 - val_mae: 52.6400\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6359.4292 - mae: 52.3953 - val_loss: 6724.1260 - val_mae: 52.6374\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6358.8589 - mae: 52.3928 - val_loss: 6723.5068 - val_mae: 52.6347\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6358.2764 - mae: 52.3903 - val_loss: 6722.8994 - val_mae: 52.6322\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6357.7134 - mae: 52.3878 - val_loss: 6722.2871 - val_mae: 52.6296\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6357.1411 - mae: 52.3853 - val_loss: 6721.6748 - val_mae: 52.6270\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6356.5718 - mae: 52.3828 - val_loss: 6721.0625 - val_mae: 52.6244\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6356.0024 - mae: 52.3803 - val_loss: 6720.4526 - val_mae: 52.6218\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6355.4302 - mae: 52.3778 - val_loss: 6719.8481 - val_mae: 52.6192\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6354.8662 - mae: 52.3754 - val_loss: 6719.2417 - val_mae: 52.6166\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6354.3027 - mae: 52.3729 - val_loss: 6718.6333 - val_mae: 52.6140\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6353.7329 - mae: 52.3704 - val_loss: 6718.0288 - val_mae: 52.6115\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6353.1606 - mae: 52.3679 - val_loss: 6717.4243 - val_mae: 52.6089\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6352.6011 - mae: 52.3654 - val_loss: 6716.8071 - val_mae: 52.6063\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6352.0239 - mae: 52.3629 - val_loss: 6716.2012 - val_mae: 52.6037\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6351.4604 - mae: 52.3605 - val_loss: 6715.5913 - val_mae: 52.6011\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6350.8848 - mae: 52.3580 - val_loss: 6714.9878 - val_mae: 52.5985\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6350.3242 - mae: 52.3555 - val_loss: 6714.3740 - val_mae: 52.5959\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6349.7480 - mae: 52.3530 - val_loss: 6713.7690 - val_mae: 52.5934\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6349.1826 - mae: 52.3505 - val_loss: 6713.1621 - val_mae: 52.5908\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6348.6182 - mae: 52.3480 - val_loss: 6712.5508 - val_mae: 52.5882\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6348.0552 - mae: 52.3456 - val_loss: 6711.9331 - val_mae: 52.5856\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6347.4771 - mae: 52.3430 - val_loss: 6711.3276 - val_mae: 52.5830\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6346.9126 - mae: 52.3406 - val_loss: 6710.7183 - val_mae: 52.5804\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6346.3379 - mae: 52.3381 - val_loss: 6710.1128 - val_mae: 52.5778\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6345.7715 - mae: 52.3356 - val_loss: 6709.4990 - val_mae: 52.5752\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6345.2026 - mae: 52.3331 - val_loss: 6708.8843 - val_mae: 52.5726\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6344.6196 - mae: 52.3306 - val_loss: 6708.2788 - val_mae: 52.5700\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6344.0522 - mae: 52.3281 - val_loss: 6707.6646 - val_mae: 52.5674\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6343.4800 - mae: 52.3256 - val_loss: 6707.0464 - val_mae: 52.5648\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6342.9038 - mae: 52.3231 - val_loss: 6706.4351 - val_mae: 52.5622\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6342.3369 - mae: 52.3206 - val_loss: 6705.8193 - val_mae: 52.5596\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6341.7603 - mae: 52.3181 - val_loss: 6705.2144 - val_mae: 52.5570\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6341.2036 - mae: 52.3156 - val_loss: 6704.5991 - val_mae: 52.5544\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6340.6279 - mae: 52.3131 - val_loss: 6703.9937 - val_mae: 52.5518\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6340.0591 - mae: 52.3106 - val_loss: 6703.3950 - val_mae: 52.5493\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6339.4971 - mae: 52.3081 - val_loss: 6702.7832 - val_mae: 52.5467\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6338.9292 - mae: 52.3057 - val_loss: 6702.1714 - val_mae: 52.5441\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6338.3545 - mae: 52.3031 - val_loss: 6701.5645 - val_mae: 52.5415\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6337.7852 - mae: 52.3007 - val_loss: 6700.9644 - val_mae: 52.5389\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   5.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 12719.9717 - mae: 73.9979 - val_loss: 13360.8789 - val_mae: 75.1646\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12719.0264 - mae: 73.9943 - val_loss: 13359.8447 - val_mae: 75.1608\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12718.0410 - mae: 73.9906 - val_loss: 13358.8262 - val_mae: 75.1571\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12717.0889 - mae: 73.9870 - val_loss: 13357.7979 - val_mae: 75.1534\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12716.1328 - mae: 73.9834 - val_loss: 13356.7695 - val_mae: 75.1496\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12715.1650 - mae: 73.9798 - val_loss: 13355.7451 - val_mae: 75.1459\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12714.2080 - mae: 73.9761 - val_loss: 13354.7168 - val_mae: 75.1422\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12713.2500 - mae: 73.9725 - val_loss: 13353.6885 - val_mae: 75.1385\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12712.2939 - mae: 73.9689 - val_loss: 13352.6631 - val_mae: 75.1348\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12711.3135 - mae: 73.9653 - val_loss: 13351.6436 - val_mae: 75.1311\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12710.3662 - mae: 73.9617 - val_loss: 13350.6084 - val_mae: 75.1273\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12709.4033 - mae: 73.9580 - val_loss: 13349.5850 - val_mae: 75.1236\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12708.4375 - mae: 73.9544 - val_loss: 13348.5674 - val_mae: 75.1200\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12707.4746 - mae: 73.9508 - val_loss: 13347.5488 - val_mae: 75.1163\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12706.5195 - mae: 73.9472 - val_loss: 13346.5264 - val_mae: 75.1126\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12705.5596 - mae: 73.9436 - val_loss: 13345.4980 - val_mae: 75.1089\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12704.5859 - mae: 73.9399 - val_loss: 13344.4756 - val_mae: 75.1052\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12703.6260 - mae: 73.9363 - val_loss: 13343.4424 - val_mae: 75.1014\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12702.6650 - mae: 73.9327 - val_loss: 13342.4062 - val_mae: 75.0977\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12701.7002 - mae: 73.9290 - val_loss: 13341.3799 - val_mae: 75.0940\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12700.7324 - mae: 73.9254 - val_loss: 13340.3564 - val_mae: 75.0903\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12699.7754 - mae: 73.9218 - val_loss: 13339.3330 - val_mae: 75.0866\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12698.8115 - mae: 73.9182 - val_loss: 13338.3125 - val_mae: 75.0829\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12697.8486 - mae: 73.9146 - val_loss: 13337.2822 - val_mae: 75.0792\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12696.8975 - mae: 73.9109 - val_loss: 13336.2451 - val_mae: 75.0754\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12695.9141 - mae: 73.9073 - val_loss: 13335.2305 - val_mae: 75.0718\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12694.9531 - mae: 73.9036 - val_loss: 13334.2041 - val_mae: 75.0681\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12693.9834 - mae: 73.9000 - val_loss: 13333.1787 - val_mae: 75.0644\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12693.0322 - mae: 73.8964 - val_loss: 13332.1396 - val_mae: 75.0606\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12692.0762 - mae: 73.8928 - val_loss: 13331.0947 - val_mae: 75.0568\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12691.0908 - mae: 73.8891 - val_loss: 13330.0752 - val_mae: 75.0531\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12690.1270 - mae: 73.8855 - val_loss: 13329.0615 - val_mae: 75.0495\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12689.1719 - mae: 73.8819 - val_loss: 13328.0391 - val_mae: 75.0458\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12688.2158 - mae: 73.8783 - val_loss: 13327.0088 - val_mae: 75.0421\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12687.2588 - mae: 73.8747 - val_loss: 13325.9805 - val_mae: 75.0383\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12686.2930 - mae: 73.8711 - val_loss: 13324.9639 - val_mae: 75.0347\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12685.3516 - mae: 73.8675 - val_loss: 13323.9287 - val_mae: 75.0309\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12684.3701 - mae: 73.8638 - val_loss: 13322.9062 - val_mae: 75.0272\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12683.4102 - mae: 73.8602 - val_loss: 13321.8857 - val_mae: 75.0235\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12682.4551 - mae: 73.8566 - val_loss: 13320.8613 - val_mae: 75.0198\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12681.4961 - mae: 73.8530 - val_loss: 13319.8369 - val_mae: 75.0161\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12680.5391 - mae: 73.8494 - val_loss: 13318.8164 - val_mae: 75.0124\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12679.5664 - mae: 73.8458 - val_loss: 13317.8066 - val_mae: 75.0088\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12678.6357 - mae: 73.8422 - val_loss: 13316.7744 - val_mae: 75.0051\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12677.6533 - mae: 73.8386 - val_loss: 13315.7627 - val_mae: 75.0014\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12676.7041 - mae: 73.8350 - val_loss: 13314.7295 - val_mae: 74.9977\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12675.7295 - mae: 73.8314 - val_loss: 13313.7129 - val_mae: 74.9940\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12674.7832 - mae: 73.8278 - val_loss: 13312.6865 - val_mae: 74.9903\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12673.8271 - mae: 73.8242 - val_loss: 13311.6562 - val_mae: 74.9865\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12672.8516 - mae: 73.8205 - val_loss: 13310.6416 - val_mae: 74.9829\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12671.9092 - mae: 73.8170 - val_loss: 13309.6162 - val_mae: 74.9792\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12670.9297 - mae: 73.8133 - val_loss: 13308.6025 - val_mae: 74.9755\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12669.9883 - mae: 73.8097 - val_loss: 13307.5713 - val_mae: 74.9718\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12669.0176 - mae: 73.8061 - val_loss: 13306.5537 - val_mae: 74.9681\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12668.0703 - mae: 73.8025 - val_loss: 13305.5264 - val_mae: 74.9644\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12667.0957 - mae: 73.7989 - val_loss: 13304.5078 - val_mae: 74.9607\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12666.1484 - mae: 73.7953 - val_loss: 13303.4795 - val_mae: 74.9569\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12665.1807 - mae: 73.7916 - val_loss: 13302.4453 - val_mae: 74.9532\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 12664.2070 - mae: 73.7880 - val_loss: 13301.4229 - val_mae: 74.9495\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12663.2422 - mae: 73.7844 - val_loss: 13300.4053 - val_mae: 74.9458\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12662.3105 - mae: 73.7808 - val_loss: 13299.3682 - val_mae: 74.9421\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12661.3359 - mae: 73.7772 - val_loss: 13298.3516 - val_mae: 74.9384\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12660.3779 - mae: 73.7736 - val_loss: 13297.3359 - val_mae: 74.9347\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12659.4199 - mae: 73.7700 - val_loss: 13296.3164 - val_mae: 74.9310\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12658.4629 - mae: 73.7664 - val_loss: 13295.3008 - val_mae: 74.9273\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12657.4961 - mae: 73.7628 - val_loss: 13294.2852 - val_mae: 74.9236\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12656.5508 - mae: 73.7592 - val_loss: 13293.2480 - val_mae: 74.9199\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12655.5762 - mae: 73.7556 - val_loss: 13292.2256 - val_mae: 74.9162\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12654.6074 - mae: 73.7519 - val_loss: 13291.2021 - val_mae: 74.9125\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12653.6514 - mae: 73.7484 - val_loss: 13290.1641 - val_mae: 74.9087\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 12652.6729 - mae: 73.7447 - val_loss: 13289.1338 - val_mae: 74.9050\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 12651.7197 - mae: 73.7411 - val_loss: 13288.0947 - val_mae: 74.9012\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12650.7461 - mae: 73.7374 - val_loss: 13287.0713 - val_mae: 74.8975\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12649.7920 - mae: 73.7339 - val_loss: 13286.0479 - val_mae: 74.8938\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12648.8203 - mae: 73.7302 - val_loss: 13285.0273 - val_mae: 74.8901\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12647.8643 - mae: 73.7266 - val_loss: 13284.0049 - val_mae: 74.8864\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12646.9043 - mae: 73.7230 - val_loss: 13282.9756 - val_mae: 74.8827\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12645.9531 - mae: 73.7194 - val_loss: 13281.9395 - val_mae: 74.8789\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12644.9727 - mae: 73.7158 - val_loss: 13280.9189 - val_mae: 74.8752\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12644.0195 - mae: 73.7122 - val_loss: 13279.8975 - val_mae: 74.8715\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12643.0635 - mae: 73.7086 - val_loss: 13278.8799 - val_mae: 74.8678\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12642.0986 - mae: 73.7049 - val_loss: 13277.8662 - val_mae: 74.8641\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12641.1426 - mae: 73.7014 - val_loss: 13276.8438 - val_mae: 74.8604\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12640.1943 - mae: 73.6978 - val_loss: 13275.8203 - val_mae: 74.8567\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12639.2305 - mae: 73.6942 - val_loss: 13274.8066 - val_mae: 74.8530\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12638.2930 - mae: 73.6906 - val_loss: 13273.7764 - val_mae: 74.8493\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12637.3262 - mae: 73.6870 - val_loss: 13272.7559 - val_mae: 74.8456\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12636.3672 - mae: 73.6834 - val_loss: 13271.7432 - val_mae: 74.8419\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12635.3965 - mae: 73.6798 - val_loss: 13270.7324 - val_mae: 74.8383\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12634.4463 - mae: 73.6763 - val_loss: 13269.7119 - val_mae: 74.8346\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12633.4980 - mae: 73.6727 - val_loss: 13268.6768 - val_mae: 74.8308\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12632.5342 - mae: 73.6690 - val_loss: 13267.6494 - val_mae: 74.8271\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12631.5752 - mae: 73.6654 - val_loss: 13266.6289 - val_mae: 74.8234\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12630.6133 - mae: 73.6618 - val_loss: 13265.6123 - val_mae: 74.8197\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12629.6641 - mae: 73.6582 - val_loss: 13264.5850 - val_mae: 74.8160\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12628.6865 - mae: 73.6546 - val_loss: 13263.5791 - val_mae: 74.8123\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12627.7451 - mae: 73.6510 - val_loss: 13262.5605 - val_mae: 74.8086\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12626.7881 - mae: 73.6474 - val_loss: 13261.5391 - val_mae: 74.8049\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12625.8330 - mae: 73.6439 - val_loss: 13260.5127 - val_mae: 74.8012\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12624.8740 - mae: 73.6403 - val_loss: 13259.4961 - val_mae: 74.7975\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=1, model__n_neurons=25, model__optimizer=adam; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2167.8064 - mae: 30.9506 - val_loss: 407.5484 - val_mae: 17.0173\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 461.3684 - mae: 18.0716 - val_loss: 360.0084 - val_mae: 16.3903\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.6760 - mae: 17.8247 - val_loss: 339.9633 - val_mae: 16.1298\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 434.0361 - mae: 17.6621 - val_loss: 324.7101 - val_mae: 15.8149\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.8078 - mae: 17.5032 - val_loss: 317.6093 - val_mae: 15.6350\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.8772 - mae: 17.3952 - val_loss: 312.7020 - val_mae: 15.4400\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.1379 - mae: 17.2152 - val_loss: 308.9504 - val_mae: 15.3261\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 411.9577 - mae: 17.1223 - val_loss: 302.8478 - val_mae: 15.1279\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.2198 - mae: 16.9414 - val_loss: 297.6096 - val_mae: 14.9538\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 400.7249 - mae: 16.7875 - val_loss: 293.7816 - val_mae: 14.8674\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 397.9770 - mae: 16.7155 - val_loss: 290.9933 - val_mae: 14.7395\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.9205 - mae: 16.6267 - val_loss: 289.5212 - val_mae: 14.6323\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.3386 - mae: 16.5530 - val_loss: 289.6091 - val_mae: 14.6512\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.1832 - mae: 16.5324 - val_loss: 288.1362 - val_mae: 14.5501\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.3489 - mae: 16.5076 - val_loss: 286.2352 - val_mae: 14.4674\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.1693 - mae: 16.4578 - val_loss: 284.9308 - val_mae: 14.4142\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.3781 - mae: 16.4309 - val_loss: 283.6219 - val_mae: 14.4168\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.0300 - mae: 16.3611 - val_loss: 279.0331 - val_mae: 14.2442\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 382.3762 - mae: 16.2221 - val_loss: 274.1349 - val_mae: 14.0729\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.2211 - mae: 16.0997 - val_loss: 271.2841 - val_mae: 13.9413\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 375.6725 - mae: 15.9796 - val_loss: 270.6367 - val_mae: 13.9178\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.6918 - mae: 15.9334 - val_loss: 270.8180 - val_mae: 13.9287\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.2448 - mae: 15.9244 - val_loss: 268.4802 - val_mae: 13.8147\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.3070 - mae: 15.8645 - val_loss: 268.4275 - val_mae: 13.8362\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.2745 - mae: 15.8507 - val_loss: 267.5686 - val_mae: 13.8175\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.2767 - mae: 15.8057 - val_loss: 268.1223 - val_mae: 13.8747\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.7049 - mae: 15.7946 - val_loss: 265.3987 - val_mae: 13.8220\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.4306 - mae: 15.7476 - val_loss: 260.0959 - val_mae: 13.6211\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.2433 - mae: 15.6426 - val_loss: 256.6483 - val_mae: 13.4341\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 359.4750 - mae: 15.4949 - val_loss: 256.4063 - val_mae: 13.4474\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 357.3150 - mae: 15.4667 - val_loss: 253.8119 - val_mae: 13.3422\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 354.8638 - mae: 15.3965 - val_loss: 252.1131 - val_mae: 13.2289\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 353.2110 - mae: 15.2999 - val_loss: 250.7328 - val_mae: 13.1850\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 351.9069 - mae: 15.2635 - val_loss: 250.2264 - val_mae: 13.1663\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 350.8848 - mae: 15.2155 - val_loss: 250.8247 - val_mae: 13.2437\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 349.3722 - mae: 15.1990 - val_loss: 249.5343 - val_mae: 13.1706\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 348.6041 - mae: 15.1750 - val_loss: 248.7680 - val_mae: 13.1474\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 347.6292 - mae: 15.1109 - val_loss: 248.6982 - val_mae: 13.1655\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 347.0241 - mae: 15.1408 - val_loss: 248.3212 - val_mae: 13.1571\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 345.9881 - mae: 15.0907 - val_loss: 248.1278 - val_mae: 13.1814\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.9663 - mae: 15.0745 - val_loss: 247.2405 - val_mae: 13.1357\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 343.5393 - mae: 15.0207 - val_loss: 246.4043 - val_mae: 13.0904\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 342.8250 - mae: 14.9974 - val_loss: 245.1449 - val_mae: 12.9987\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 341.7426 - mae: 14.9455 - val_loss: 244.8360 - val_mae: 13.0001\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 341.0848 - mae: 14.8996 - val_loss: 244.4527 - val_mae: 12.9871\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 340.7083 - mae: 14.8682 - val_loss: 245.4345 - val_mae: 13.0666\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.2751 - mae: 14.9044 - val_loss: 244.0439 - val_mae: 12.9825\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.5498 - mae: 14.8388 - val_loss: 244.3355 - val_mae: 13.0001\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 338.8105 - mae: 14.8602 - val_loss: 242.6444 - val_mae: 12.8903\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 338.2704 - mae: 14.7642 - val_loss: 244.1799 - val_mae: 13.0273\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.0294 - mae: 14.8273 - val_loss: 242.4027 - val_mae: 12.9075\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 337.4437 - mae: 14.7803 - val_loss: 241.6947 - val_mae: 12.8590\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.7565 - mae: 14.7279 - val_loss: 240.7834 - val_mae: 12.8017\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.6510 - mae: 14.6912 - val_loss: 242.0291 - val_mae: 12.9114\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.2190 - mae: 14.7255 - val_loss: 240.8867 - val_mae: 12.8233\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.7284 - mae: 14.6757 - val_loss: 240.6204 - val_mae: 12.8210\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.1002 - mae: 14.6669 - val_loss: 240.4997 - val_mae: 12.8340\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.1062 - mae: 14.6899 - val_loss: 239.0563 - val_mae: 12.7162\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.7958 - mae: 14.6546 - val_loss: 238.9101 - val_mae: 12.7118\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.0229 - mae: 14.6450 - val_loss: 238.7275 - val_mae: 12.6953\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 333.8478 - mae: 14.6140 - val_loss: 237.9185 - val_mae: 12.6430\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.7978 - mae: 14.5956 - val_loss: 238.4304 - val_mae: 12.6997\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.1821 - mae: 14.5625 - val_loss: 239.2945 - val_mae: 12.7888\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.0188 - mae: 14.6499 - val_loss: 237.6744 - val_mae: 12.6630\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.5934 - mae: 14.6232 - val_loss: 236.5365 - val_mae: 12.5569\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 332.8880 - mae: 14.5279 - val_loss: 236.4065 - val_mae: 12.5738\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.7660 - mae: 14.5136 - val_loss: 237.2769 - val_mae: 12.6479\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.8980 - mae: 14.5294 - val_loss: 236.9741 - val_mae: 12.6364\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 331.1869 - mae: 14.4990 - val_loss: 237.0431 - val_mae: 12.6477\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.7995 - mae: 14.4838 - val_loss: 236.7330 - val_mae: 12.6441\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.5774 - mae: 14.5397 - val_loss: 235.1552 - val_mae: 12.5124\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.4427 - mae: 14.4195 - val_loss: 236.8961 - val_mae: 12.6700\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.7068 - mae: 14.5622 - val_loss: 234.6646 - val_mae: 12.4868\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.5874 - mae: 14.4571 - val_loss: 234.6371 - val_mae: 12.5060\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.2810 - mae: 14.4123 - val_loss: 234.1014 - val_mae: 12.4678\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 329.1235 - mae: 14.4292 - val_loss: 233.7219 - val_mae: 12.4385\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.8891 - mae: 14.4048 - val_loss: 233.2810 - val_mae: 12.4085\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.7831 - mae: 14.4164 - val_loss: 233.0838 - val_mae: 12.4025\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.1141 - mae: 14.3582 - val_loss: 233.3057 - val_mae: 12.4277\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.7479 - mae: 14.3674 - val_loss: 233.3728 - val_mae: 12.4595\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 327.1132 - mae: 14.3264 - val_loss: 233.0999 - val_mae: 12.4526\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 327.1193 - mae: 14.3599 - val_loss: 231.9516 - val_mae: 12.4004\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 325.8369 - mae: 14.3611 - val_loss: 230.5034 - val_mae: 12.2827\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 325.2569 - mae: 14.2259 - val_loss: 230.9931 - val_mae: 12.3674\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 323.8762 - mae: 14.2325 - val_loss: 229.8856 - val_mae: 12.2932\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 323.2039 - mae: 14.1838 - val_loss: 231.0067 - val_mae: 12.4073\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.1842 - mae: 14.2678 - val_loss: 227.4254 - val_mae: 12.1610\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 321.0140 - mae: 14.1087 - val_loss: 227.8920 - val_mae: 12.2362\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 320.0735 - mae: 14.1394 - val_loss: 226.4034 - val_mae: 12.1192\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 319.0695 - mae: 14.0604 - val_loss: 225.7196 - val_mae: 12.0759\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 318.7668 - mae: 14.0092 - val_loss: 225.7872 - val_mae: 12.0891\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 317.8490 - mae: 14.0276 - val_loss: 224.6212 - val_mae: 12.0022\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.7443 - mae: 13.9992 - val_loss: 224.1760 - val_mae: 11.9735\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.1944 - mae: 13.9309 - val_loss: 225.4563 - val_mae: 12.0830\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.9665 - mae: 13.9943 - val_loss: 224.5161 - val_mae: 12.0349\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.5992 - mae: 13.9236 - val_loss: 223.2136 - val_mae: 11.9470\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 315.1273 - mae: 13.8858 - val_loss: 222.9003 - val_mae: 11.9017\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 314.5909 - mae: 13.9056 - val_loss: 221.4688 - val_mae: 11.8201\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 314.7232 - mae: 13.8402 - val_loss: 221.4644 - val_mae: 11.8225\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.8765 - mae: 13.8790 - val_loss: 220.7017 - val_mae: 11.7751\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=25, model__optimizer=momentum; total time=   5.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 26ms/step - loss: 1652.9387 - mae: 27.8295 - val_loss: 407.0950 - val_mae: 18.0073\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 534.7963 - mae: 19.9766 - val_loss: 356.4160 - val_mae: 17.0185\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 498.7390 - mae: 19.2390 - val_loss: 339.6915 - val_mae: 16.4738\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 487.4741 - mae: 18.9146 - val_loss: 334.1252 - val_mae: 16.2774\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 482.7223 - mae: 18.7791 - val_loss: 332.0727 - val_mae: 16.1753\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 478.9079 - mae: 18.6764 - val_loss: 329.1507 - val_mae: 16.0410\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 475.9865 - mae: 18.5679 - val_loss: 327.3393 - val_mae: 16.0323\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 469.2435 - mae: 18.4341 - val_loss: 322.5417 - val_mae: 15.8353\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 461.6187 - mae: 18.2032 - val_loss: 316.2780 - val_mae: 15.6739\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 456.8229 - mae: 18.0758 - val_loss: 312.5377 - val_mae: 15.5013\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 455.0354 - mae: 17.9830 - val_loss: 312.1993 - val_mae: 15.4792\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.3601 - mae: 17.8838 - val_loss: 311.4856 - val_mae: 15.4453\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 451.3120 - mae: 17.8495 - val_loss: 311.6623 - val_mae: 15.4375\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.6176 - mae: 17.8273 - val_loss: 311.1535 - val_mae: 15.4264\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 449.5228 - mae: 17.8202 - val_loss: 308.6076 - val_mae: 15.3088\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.5354 - mae: 17.7570 - val_loss: 309.9205 - val_mae: 15.3828\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.9822 - mae: 17.7351 - val_loss: 309.2823 - val_mae: 15.3623\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.0444 - mae: 17.7561 - val_loss: 306.7415 - val_mae: 15.2334\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 446.6201 - mae: 17.6755 - val_loss: 307.6915 - val_mae: 15.3061\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 446.4296 - mae: 17.6986 - val_loss: 306.8540 - val_mae: 15.2547\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 445.4088 - mae: 17.6654 - val_loss: 305.9738 - val_mae: 15.2158\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 445.1762 - mae: 17.6618 - val_loss: 305.3698 - val_mae: 15.1948\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 444.5087 - mae: 17.6404 - val_loss: 304.9302 - val_mae: 15.1796\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4092 - mae: 17.6309 - val_loss: 303.2683 - val_mae: 15.0781\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.5500 - mae: 17.5655 - val_loss: 304.6711 - val_mae: 15.1768\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.4199 - mae: 17.5828 - val_loss: 303.8658 - val_mae: 15.1457\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 442.3734 - mae: 17.5358 - val_loss: 305.5248 - val_mae: 15.2468\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 441.9174 - mae: 17.6470 - val_loss: 301.9173 - val_mae: 15.0252\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.2834 - mae: 17.4892 - val_loss: 303.3407 - val_mae: 15.1320\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.6199 - mae: 17.5013 - val_loss: 302.4208 - val_mae: 15.1027\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.0154 - mae: 17.5071 - val_loss: 301.1093 - val_mae: 15.0035\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.5740 - mae: 17.4589 - val_loss: 300.8133 - val_mae: 15.0019\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.1494 - mae: 17.4425 - val_loss: 301.1346 - val_mae: 15.0475\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.6080 - mae: 17.4547 - val_loss: 300.2142 - val_mae: 14.9986\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.5861 - mae: 17.4078 - val_loss: 302.0244 - val_mae: 15.1104\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.7423 - mae: 17.4544 - val_loss: 299.1737 - val_mae: 14.9196\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.9519 - mae: 17.4027 - val_loss: 298.6096 - val_mae: 14.9173\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.7627 - mae: 17.3694 - val_loss: 298.1441 - val_mae: 14.9204\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.8131 - mae: 17.1564 - val_loss: 291.4719 - val_mae: 14.7579\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 419.5856 - mae: 16.9366 - val_loss: 287.8417 - val_mae: 14.6447\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 416.7170 - mae: 16.8946 - val_loss: 283.1841 - val_mae: 14.3918\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 416.3048 - mae: 16.7786 - val_loss: 283.3637 - val_mae: 14.4229\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 414.6493 - mae: 16.7974 - val_loss: 282.1717 - val_mae: 14.3621\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.8608 - mae: 16.7681 - val_loss: 280.9628 - val_mae: 14.3196\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 412.3246 - mae: 16.7185 - val_loss: 279.1712 - val_mae: 14.2562\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.6016 - mae: 16.6586 - val_loss: 279.1629 - val_mae: 14.2817\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 409.2456 - mae: 16.6562 - val_loss: 277.9984 - val_mae: 14.2104\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 408.0897 - mae: 16.6110 - val_loss: 277.2052 - val_mae: 14.1571\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 406.8577 - mae: 16.5028 - val_loss: 278.5084 - val_mae: 14.2759\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 406.3439 - mae: 16.5748 - val_loss: 275.4762 - val_mae: 14.0683\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.1811 - mae: 16.5031 - val_loss: 274.7153 - val_mae: 14.0393\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.3388 - mae: 16.4315 - val_loss: 275.3329 - val_mae: 14.0946\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.5079 - mae: 16.4713 - val_loss: 274.1137 - val_mae: 14.0208\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.0850 - mae: 16.4082 - val_loss: 274.5001 - val_mae: 14.0599\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 402.3616 - mae: 16.4396 - val_loss: 272.7300 - val_mae: 13.9484\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.6701 - mae: 16.3811 - val_loss: 272.4562 - val_mae: 13.9451\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.6698 - mae: 16.3648 - val_loss: 271.8741 - val_mae: 13.9108\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.2475 - mae: 16.3513 - val_loss: 271.6180 - val_mae: 13.9012\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.1269 - mae: 16.3048 - val_loss: 272.6156 - val_mae: 14.0019\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.6812 - mae: 16.3633 - val_loss: 269.7061 - val_mae: 13.7859\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 399.3289 - mae: 16.2770 - val_loss: 269.6823 - val_mae: 13.8025\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 398.6346 - mae: 16.2523 - val_loss: 269.8984 - val_mae: 13.8382\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 398.7130 - mae: 16.2686 - val_loss: 270.1708 - val_mae: 13.8747\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.5090 - mae: 16.3102 - val_loss: 268.8889 - val_mae: 13.7773\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 397.5560 - mae: 16.2161 - val_loss: 269.9959 - val_mae: 13.8971\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 397.3230 - mae: 16.2498 - val_loss: 267.9304 - val_mae: 13.7554\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.9273 - mae: 16.1832 - val_loss: 269.1751 - val_mae: 13.8467\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.5422 - mae: 16.2405 - val_loss: 267.1535 - val_mae: 13.7144\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.3826 - mae: 16.2340 - val_loss: 265.4836 - val_mae: 13.5922\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.3723 - mae: 16.1496 - val_loss: 265.9633 - val_mae: 13.6426\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.6746 - mae: 16.1952 - val_loss: 264.6818 - val_mae: 13.5559\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.8313 - mae: 16.1324 - val_loss: 264.8767 - val_mae: 13.5928\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.3014 - mae: 16.1231 - val_loss: 265.8535 - val_mae: 13.6845\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 394.6679 - mae: 16.1589 - val_loss: 264.8789 - val_mae: 13.6146\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 394.1333 - mae: 16.0923 - val_loss: 266.4456 - val_mae: 13.7337\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 394.1304 - mae: 16.1554 - val_loss: 263.5449 - val_mae: 13.5210\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 393.6239 - mae: 16.0908 - val_loss: 263.0874 - val_mae: 13.4998\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.8055 - mae: 16.0513 - val_loss: 263.8271 - val_mae: 13.5451\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 393.2734 - mae: 16.0606 - val_loss: 264.2633 - val_mae: 13.6009\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.7899 - mae: 16.0735 - val_loss: 263.2967 - val_mae: 13.5303\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.2041 - mae: 16.0204 - val_loss: 264.9763 - val_mae: 13.6526\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.1070 - mae: 16.0499 - val_loss: 263.3043 - val_mae: 13.5547\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.7873 - mae: 16.0666 - val_loss: 261.4663 - val_mae: 13.4137\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.7764 - mae: 16.0199 - val_loss: 261.0101 - val_mae: 13.3997\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.5447 - mae: 15.9909 - val_loss: 260.8883 - val_mae: 13.3859\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 391.1772 - mae: 15.9493 - val_loss: 261.6885 - val_mae: 13.4734\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 390.2272 - mae: 15.9256 - val_loss: 263.0751 - val_mae: 13.5414\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.1978 - mae: 16.0655 - val_loss: 259.4220 - val_mae: 13.2774\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.5058 - mae: 15.8981 - val_loss: 259.7308 - val_mae: 13.3365\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 389.0333 - mae: 15.9228 - val_loss: 258.9641 - val_mae: 13.2690\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 388.2976 - mae: 15.8684 - val_loss: 259.8690 - val_mae: 13.3565\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 387.8132 - mae: 15.8809 - val_loss: 261.1374 - val_mae: 13.4415\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 387.5220 - mae: 15.9746 - val_loss: 257.4907 - val_mae: 13.1810\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 386.6905 - mae: 15.8146 - val_loss: 258.9796 - val_mae: 13.2945\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 386.1571 - mae: 15.8361 - val_loss: 257.4616 - val_mae: 13.2237\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 385.2126 - mae: 15.7941 - val_loss: 259.2961 - val_mae: 13.3735\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 384.8167 - mae: 15.8246 - val_loss: 257.5667 - val_mae: 13.2718\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 384.2437 - mae: 15.8004 - val_loss: 256.9605 - val_mae: 13.2427\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 383.2941 - mae: 15.8230 - val_loss: 254.8742 - val_mae: 13.1056\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 382.3518 - mae: 15.7468 - val_loss: 255.1698 - val_mae: 13.1367\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=25, model__optimizer=momentum; total time=   5.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 41ms/step - loss: 2583.1826 - mae: 31.9975 - val_loss: 383.9960 - val_mae: 16.9806\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 389.7073 - mae: 16.8930 - val_loss: 340.4446 - val_mae: 15.5531\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 345.6757 - mae: 15.5331 - val_loss: 328.0099 - val_mae: 15.2374\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 337.0294 - mae: 15.3282 - val_loss: 323.9070 - val_mae: 15.0690\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 333.1300 - mae: 15.1630 - val_loss: 321.7166 - val_mae: 15.0189\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 330.5326 - mae: 15.0706 - val_loss: 320.4223 - val_mae: 15.0041\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 328.7795 - mae: 15.0492 - val_loss: 318.3374 - val_mae: 14.9089\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 327.2097 - mae: 14.9846 - val_loss: 316.9816 - val_mae: 14.8733\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 326.2272 - mae: 14.9704 - val_loss: 316.1288 - val_mae: 14.8116\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 325.5098 - mae: 14.9122 - val_loss: 314.7895 - val_mae: 14.7871\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 324.2300 - mae: 14.8774 - val_loss: 313.5523 - val_mae: 14.7345\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 323.2129 - mae: 14.8266 - val_loss: 312.1974 - val_mae: 14.7090\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.5717 - mae: 14.8273 - val_loss: 312.2143 - val_mae: 14.7230\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 321.7368 - mae: 14.8148 - val_loss: 311.1936 - val_mae: 14.6677\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 320.7662 - mae: 14.7400 - val_loss: 309.7383 - val_mae: 14.6119\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 320.0887 - mae: 14.7172 - val_loss: 309.2485 - val_mae: 14.6021\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 319.7048 - mae: 14.7114 - val_loss: 308.0421 - val_mae: 14.5444\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 318.6317 - mae: 14.6767 - val_loss: 307.4970 - val_mae: 14.5184\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 317.9311 - mae: 14.6657 - val_loss: 306.6401 - val_mae: 14.4866\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 317.1158 - mae: 14.6465 - val_loss: 305.7813 - val_mae: 14.4318\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 316.2823 - mae: 14.5680 - val_loss: 305.0653 - val_mae: 14.4699\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 315.2312 - mae: 14.6223 - val_loss: 302.9339 - val_mae: 14.3298\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.4117 - mae: 14.5259 - val_loss: 301.3707 - val_mae: 14.2985\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 311.7699 - mae: 14.4564 - val_loss: 299.6457 - val_mae: 14.2683\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 310.1276 - mae: 14.4288 - val_loss: 299.1152 - val_mae: 14.2330\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 308.5830 - mae: 14.3417 - val_loss: 297.8319 - val_mae: 14.1877\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 307.4857 - mae: 14.2901 - val_loss: 295.8227 - val_mae: 14.0987\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 306.3530 - mae: 14.2584 - val_loss: 295.1178 - val_mae: 14.0519\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 305.3493 - mae: 14.1913 - val_loss: 294.0141 - val_mae: 14.0148\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.4496 - mae: 14.1638 - val_loss: 293.6032 - val_mae: 13.9917\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.6841 - mae: 14.0732 - val_loss: 292.8663 - val_mae: 13.9886\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 302.8435 - mae: 14.1065 - val_loss: 291.7757 - val_mae: 13.9128\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 302.1604 - mae: 14.0579 - val_loss: 291.3482 - val_mae: 13.8783\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 301.6368 - mae: 14.0400 - val_loss: 290.9323 - val_mae: 13.8666\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 300.9968 - mae: 14.0222 - val_loss: 291.0326 - val_mae: 13.8768\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 300.6882 - mae: 13.9982 - val_loss: 289.8831 - val_mae: 13.8047\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.1700 - mae: 13.9645 - val_loss: 289.2183 - val_mae: 13.8016\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 299.5305 - mae: 13.9625 - val_loss: 289.1262 - val_mae: 13.7591\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 299.4024 - mae: 13.9267 - val_loss: 288.5111 - val_mae: 13.7502\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.7300 - mae: 13.9194 - val_loss: 288.0359 - val_mae: 13.7210\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 298.3134 - mae: 13.9133 - val_loss: 287.9776 - val_mae: 13.6927\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 297.7922 - mae: 13.8587 - val_loss: 287.3040 - val_mae: 13.7066\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 297.6525 - mae: 13.8761 - val_loss: 287.1043 - val_mae: 13.6891\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 297.2736 - mae: 13.8755 - val_loss: 286.6105 - val_mae: 13.6287\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.7688 - mae: 13.8230 - val_loss: 286.8573 - val_mae: 13.6772\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 296.5357 - mae: 13.8369 - val_loss: 286.0110 - val_mae: 13.6130\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.9239 - mae: 13.8179 - val_loss: 285.3189 - val_mae: 13.5861\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.8256 - mae: 13.8036 - val_loss: 284.8015 - val_mae: 13.5587\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.4710 - mae: 13.7841 - val_loss: 284.8071 - val_mae: 13.5468\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.0341 - mae: 13.7464 - val_loss: 285.0610 - val_mae: 13.5901\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 294.3372 - mae: 13.7572 - val_loss: 284.4634 - val_mae: 13.5322\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.9394 - mae: 13.7171 - val_loss: 284.2715 - val_mae: 13.5221\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 293.2532 - mae: 13.6736 - val_loss: 282.8037 - val_mae: 13.4768\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 292.9542 - mae: 13.6885 - val_loss: 283.3666 - val_mae: 13.4664\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 292.6706 - mae: 13.6651 - val_loss: 282.3520 - val_mae: 13.4305\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.6796 - mae: 13.6066 - val_loss: 281.6958 - val_mae: 13.4645\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.2430 - mae: 13.6140 - val_loss: 281.1550 - val_mae: 13.4087\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.2288 - mae: 13.5834 - val_loss: 281.2061 - val_mae: 13.4497\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.6474 - mae: 13.5898 - val_loss: 280.0262 - val_mae: 13.3617\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.5434 - mae: 13.5805 - val_loss: 279.5024 - val_mae: 13.3288\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 290.3796 - mae: 13.5601 - val_loss: 279.7178 - val_mae: 13.3720\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 289.7974 - mae: 13.5877 - val_loss: 279.3529 - val_mae: 13.3138\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 289.9986 - mae: 13.5246 - val_loss: 278.8803 - val_mae: 13.3468\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.3227 - mae: 13.5054 - val_loss: 279.5307 - val_mae: 13.4014\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 288.9801 - mae: 13.5956 - val_loss: 277.4870 - val_mae: 13.2415\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 288.0404 - mae: 13.4979 - val_loss: 276.8873 - val_mae: 13.2406\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 287.4399 - mae: 13.4933 - val_loss: 276.1249 - val_mae: 13.2211\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 286.8965 - mae: 13.4767 - val_loss: 276.2477 - val_mae: 13.2005\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 286.2801 - mae: 13.4179 - val_loss: 275.3341 - val_mae: 13.1845\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 286.5497 - mae: 13.4725 - val_loss: 274.5100 - val_mae: 13.1250\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 285.1869 - mae: 13.3784 - val_loss: 274.6625 - val_mae: 13.1059\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 284.8955 - mae: 13.3494 - val_loss: 274.6200 - val_mae: 13.1272\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 284.4664 - mae: 13.3702 - val_loss: 274.0983 - val_mae: 13.0726\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.0941 - mae: 13.3128 - val_loss: 274.3301 - val_mae: 13.1232\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.1359 - mae: 13.3454 - val_loss: 274.0367 - val_mae: 13.1136\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 283.6923 - mae: 13.3492 - val_loss: 273.2107 - val_mae: 13.0559\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284.0858 - mae: 13.3454 - val_loss: 273.4671 - val_mae: 13.0422\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283.6578 - mae: 13.3024 - val_loss: 273.1771 - val_mae: 13.0356\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283.0429 - mae: 13.2635 - val_loss: 271.9789 - val_mae: 13.0069\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.9518 - mae: 13.3019 - val_loss: 272.3163 - val_mae: 12.9978\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.5707 - mae: 13.2634 - val_loss: 271.8947 - val_mae: 12.9760\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.4478 - mae: 13.2485 - val_loss: 271.5897 - val_mae: 13.0079\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.1388 - mae: 13.2732 - val_loss: 271.5325 - val_mae: 12.9553\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.4373 - mae: 13.2483 - val_loss: 271.3436 - val_mae: 12.9571\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.5632 - mae: 13.2376 - val_loss: 271.7071 - val_mae: 12.9762\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.6194 - mae: 13.2242 - val_loss: 271.9789 - val_mae: 12.9994\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.3263 - mae: 13.2591 - val_loss: 270.6250 - val_mae: 12.9336\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.5753 - mae: 13.2489 - val_loss: 271.5776 - val_mae: 12.9426\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.0141 - mae: 13.1945 - val_loss: 270.7792 - val_mae: 12.9127\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.5741 - mae: 13.1847 - val_loss: 270.3951 - val_mae: 12.8948\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.4214 - mae: 13.1883 - val_loss: 270.7501 - val_mae: 12.9043\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.2831 - mae: 13.1625 - val_loss: 269.8965 - val_mae: 12.8874\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.8952 - mae: 13.1612 - val_loss: 269.9986 - val_mae: 12.8771\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.8887 - mae: 13.1757 - val_loss: 269.3292 - val_mae: 12.8401\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.8239 - mae: 13.1164 - val_loss: 270.9582 - val_mae: 12.9664\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.0113 - mae: 13.1679 - val_loss: 269.6465 - val_mae: 12.8486\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.0485 - mae: 13.1057 - val_loss: 269.0613 - val_mae: 12.8479\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 279.0127 - mae: 13.1041 - val_loss: 268.8557 - val_mae: 12.8409\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.2599 - mae: 13.1098 - val_loss: 268.1108 - val_mae: 12.8241\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.2102 - mae: 13.1028 - val_loss: 268.8810 - val_mae: 12.8425\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=25, model__optimizer=momentum; total time=   5.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2188 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23399.2188 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21701.8457 - mae: 70.9162"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 3812.0481 - mae: 42.4908 - val_loss: 3041.0378 - val_mae: 38.0425\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2732.5159 - mae: 37.7384 - val_loss: 2191.3479 - val_mae: 33.7235\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2017.0291 - mae: 33.9092 - val_loss: 1627.4204 - val_mae: 30.3245\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1541.1447 - mae: 30.9047 - val_loss: 1241.5193 - val_mae: 27.5745\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1215.1614 - mae: 28.4508 - val_loss: 983.5031 - val_mae: 25.3588\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 995.8273 - mae: 26.4931 - val_loss: 805.5513 - val_mae: 23.6211\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 844.1306 - mae: 24.8585 - val_loss: 683.6237 - val_mae: 22.1883\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 739.9083 - mae: 23.5716 - val_loss: 598.4737 - val_mae: 21.0553\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.2457 - mae: 22.5460 - val_loss: 538.5222 - val_mae: 20.1592\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5872 - mae: 21.7486 - val_loss: 495.5662 - val_mae: 19.4420\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.6385 - mae: 21.1348 - val_loss: 464.4953 - val_mae: 18.8853\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.8129 - mae: 20.6708 - val_loss: 441.4614 - val_mae: 18.4702\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 535.6317 - mae: 20.2985 - val_loss: 423.9427 - val_mae: 18.1366\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 521.1893 - mae: 20.0009 - val_loss: 410.4879 - val_mae: 17.8604\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.2280 - mae: 19.7516 - val_loss: 399.4241 - val_mae: 17.6331\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.4258 - mae: 19.5538 - val_loss: 391.1855 - val_mae: 17.4613\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.6716 - mae: 19.3971 - val_loss: 383.9865 - val_mae: 17.3151\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.9350 - mae: 19.2658 - val_loss: 378.2409 - val_mae: 17.1861\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.3221 - mae: 19.1517 - val_loss: 373.4642 - val_mae: 17.0742\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.4911 - mae: 19.0555 - val_loss: 369.4643 - val_mae: 16.9788\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 477.2037 - mae: 18.9720 - val_loss: 366.0744 - val_mae: 16.8943\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.3665 - mae: 18.8928 - val_loss: 363.3223 - val_mae: 16.8240\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 472.0239 - mae: 18.8254 - val_loss: 360.8662 - val_mae: 16.7610\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.9802 - mae: 18.7698 - val_loss: 358.6251 - val_mae: 16.7011\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.1190 - mae: 18.7149 - val_loss: 356.6572 - val_mae: 16.6463\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.5204 - mae: 18.6713 - val_loss: 354.9094 - val_mae: 16.5991\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.1313 - mae: 18.6300 - val_loss: 353.4484 - val_mae: 16.5588\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.8961 - mae: 18.5943 - val_loss: 352.1216 - val_mae: 16.5249\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.7618 - mae: 18.5632 - val_loss: 350.8527 - val_mae: 16.4971\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 461.7508 - mae: 18.5396 - val_loss: 349.7196 - val_mae: 16.4719\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.8791 - mae: 18.5171 - val_loss: 348.7209 - val_mae: 16.4521\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.0297 - mae: 18.4990 - val_loss: 347.8316 - val_mae: 16.4343\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.2842 - mae: 18.4832 - val_loss: 346.9391 - val_mae: 16.4164\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 458.6034 - mae: 18.4661 - val_loss: 346.1081 - val_mae: 16.3991\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.9994 - mae: 18.4511 - val_loss: 345.4119 - val_mae: 16.3831\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.3525 - mae: 18.4384 - val_loss: 344.6731 - val_mae: 16.3671\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.7656 - mae: 18.4254 - val_loss: 344.0669 - val_mae: 16.3516\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 456.2566 - mae: 18.4155 - val_loss: 343.3285 - val_mae: 16.3352\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 455.6841 - mae: 18.4039 - val_loss: 342.7220 - val_mae: 16.3213\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 455.1977 - mae: 18.3932 - val_loss: 342.1337 - val_mae: 16.3088\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.7398 - mae: 18.3844 - val_loss: 341.4278 - val_mae: 16.2934\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.2323 - mae: 18.3727 - val_loss: 340.8660 - val_mae: 16.2813\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.7984 - mae: 18.3635 - val_loss: 340.3416 - val_mae: 16.2700\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.3857 - mae: 18.3550 - val_loss: 339.8064 - val_mae: 16.2574\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.9539 - mae: 18.3460 - val_loss: 339.3405 - val_mae: 16.2462\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.5605 - mae: 18.3374 - val_loss: 338.8617 - val_mae: 16.2343\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.1665 - mae: 18.3288 - val_loss: 338.3676 - val_mae: 16.2226\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 451.7725 - mae: 18.3189 - val_loss: 337.8983 - val_mae: 16.2115\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 451.3916 - mae: 18.3115 - val_loss: 337.4336 - val_mae: 16.1996\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 451.0215 - mae: 18.3029 - val_loss: 337.0331 - val_mae: 16.1890\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 450.6641 - mae: 18.2948 - val_loss: 336.6360 - val_mae: 16.1782\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 450.2851 - mae: 18.2865 - val_loss: 336.2166 - val_mae: 16.1673\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.9586 - mae: 18.2783 - val_loss: 335.8667 - val_mae: 16.1574\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 449.6216 - mae: 18.2703 - val_loss: 335.4537 - val_mae: 16.1463\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.2677 - mae: 18.2620 - val_loss: 335.0943 - val_mae: 16.1363\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.9185 - mae: 18.2547 - val_loss: 334.7285 - val_mae: 16.1258\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.5894 - mae: 18.2459 - val_loss: 334.3156 - val_mae: 16.1140\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.2581 - mae: 18.2374 - val_loss: 333.8842 - val_mae: 16.1024\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 447.9238 - mae: 18.2307 - val_loss: 333.5608 - val_mae: 16.0925\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.5931 - mae: 18.2223 - val_loss: 333.1810 - val_mae: 16.0811\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 447.2747 - mae: 18.2144 - val_loss: 332.8485 - val_mae: 16.0708\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.9706 - mae: 18.2065 - val_loss: 332.4775 - val_mae: 16.0593\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.6494 - mae: 18.1983 - val_loss: 332.0836 - val_mae: 16.0478\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 446.3537 - mae: 18.1903 - val_loss: 331.7039 - val_mae: 16.0362\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.0513 - mae: 18.1831 - val_loss: 331.3727 - val_mae: 16.0254\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 445.7714 - mae: 18.1750 - val_loss: 331.0292 - val_mae: 16.0141\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.4706 - mae: 18.1687 - val_loss: 330.6875 - val_mae: 16.0035\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 445.1650 - mae: 18.1618 - val_loss: 330.3195 - val_mae: 15.9928\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.8636 - mae: 18.1539 - val_loss: 329.9520 - val_mae: 15.9828\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.5490 - mae: 18.1456 - val_loss: 329.5950 - val_mae: 15.9726\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.2835 - mae: 18.1403 - val_loss: 329.2141 - val_mae: 15.9613\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.9704 - mae: 18.1319 - val_loss: 328.9175 - val_mae: 15.9521\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.6441 - mae: 18.1247 - val_loss: 328.5732 - val_mae: 15.9415\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.3957 - mae: 18.1176 - val_loss: 328.2560 - val_mae: 15.9323\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.0933 - mae: 18.1103 - val_loss: 327.9639 - val_mae: 15.9228\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.8143 - mae: 18.1025 - val_loss: 327.6738 - val_mae: 15.9146\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.5500 - mae: 18.0970 - val_loss: 327.3232 - val_mae: 15.9027\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.2839 - mae: 18.0872 - val_loss: 327.0256 - val_mae: 15.8940\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.9962 - mae: 18.0815 - val_loss: 326.7759 - val_mae: 15.8858\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.7321 - mae: 18.0755 - val_loss: 326.4114 - val_mae: 15.8751\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 441.4538 - mae: 18.0673 - val_loss: 326.0731 - val_mae: 15.8642\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 441.1678 - mae: 18.0592 - val_loss: 325.7707 - val_mae: 15.8545\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.8888 - mae: 18.0540 - val_loss: 325.4199 - val_mae: 15.8436\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.5910 - mae: 18.0443 - val_loss: 325.0285 - val_mae: 15.8324\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.2433 - mae: 18.0352 - val_loss: 324.6537 - val_mae: 15.8221\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 439.9264 - mae: 18.0277 - val_loss: 324.2479 - val_mae: 15.8119\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.5504 - mae: 18.0177 - val_loss: 323.8424 - val_mae: 15.8021\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.1598 - mae: 18.0098 - val_loss: 323.4557 - val_mae: 15.7913\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.7387 - mae: 18.0005 - val_loss: 323.0590 - val_mae: 15.7800\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 438.2703 - mae: 17.9895 - val_loss: 322.6338 - val_mae: 15.7673\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.8808 - mae: 17.9808 - val_loss: 322.2603 - val_mae: 15.7551\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.4999 - mae: 17.9700 - val_loss: 321.9238 - val_mae: 15.7444\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.1022 - mae: 17.9611 - val_loss: 321.5725 - val_mae: 15.7343\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 436.7557 - mae: 17.9519 - val_loss: 321.2619 - val_mae: 15.7250\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 436.3903 - mae: 17.9431 - val_loss: 320.9242 - val_mae: 15.7155\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 436.0567 - mae: 17.9333 - val_loss: 320.5857 - val_mae: 15.7052\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 435.7327 - mae: 17.9264 - val_loss: 320.2798 - val_mae: 15.6955\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.3984 - mae: 17.9177 - val_loss: 319.9700 - val_mae: 15.6857\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.0872 - mae: 17.9080 - val_loss: 319.6572 - val_mae: 15.6752\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 434.8028 - mae: 17.9011 - val_loss: 319.3762 - val_mae: 15.6660\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 2810.2332 - mae: 39.0439 - val_loss: 2443.4756 - val_mae: 35.9440\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2166.6824 - mae: 35.5518 - val_loss: 1884.5023 - val_mae: 32.6909\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1719.1833 - mae: 32.6622 - val_loss: 1496.8452 - val_mae: 30.0224\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1410.6019 - mae: 30.2957 - val_loss: 1227.8907 - val_mae: 27.8226\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1198.3809 - mae: 28.3936 - val_loss: 1038.6924 - val_mae: 26.0447\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1050.5107 - mae: 26.8544 - val_loss: 902.9508 - val_mae: 24.5864\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 944.9144 - mae: 25.6786 - val_loss: 806.1202 - val_mae: 23.4356\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 870.9960 - mae: 24.7916 - val_loss: 733.2968 - val_mae: 22.5410\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 816.1692 - mae: 24.1123 - val_loss: 679.3163 - val_mae: 21.9011\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 775.7369 - mae: 23.5884 - val_loss: 639.5778 - val_mae: 21.4397\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 745.9195 - mae: 23.2024 - val_loss: 609.1191 - val_mae: 21.0677\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 723.0540 - mae: 22.8922 - val_loss: 585.4222 - val_mae: 20.7740\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 705.4595 - mae: 22.6618 - val_loss: 565.0565 - val_mae: 20.5273\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 690.6672 - mae: 22.4708 - val_loss: 549.4316 - val_mae: 20.3237\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 679.0306 - mae: 22.3037 - val_loss: 535.3718 - val_mae: 20.1348\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.7049 - mae: 22.1638 - val_loss: 523.8360 - val_mae: 19.9674\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.9933 - mae: 22.0418 - val_loss: 513.6753 - val_mae: 19.8162\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.7614 - mae: 21.9349 - val_loss: 504.8069 - val_mae: 19.6819\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 646.0980 - mae: 21.8413 - val_loss: 496.7513 - val_mae: 19.5560\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 640.1915 - mae: 21.7596 - val_loss: 489.1324 - val_mae: 19.4419\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 634.8078 - mae: 21.6827 - val_loss: 482.1067 - val_mae: 19.3435\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 629.5452 - mae: 21.6138 - val_loss: 475.4354 - val_mae: 19.2515\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 624.7421 - mae: 21.5538 - val_loss: 469.6236 - val_mae: 19.1698\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 620.4383 - mae: 21.4995 - val_loss: 463.8097 - val_mae: 19.0924\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 616.0544 - mae: 21.4478 - val_loss: 458.6005 - val_mae: 19.0226\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 612.1662 - mae: 21.4026 - val_loss: 453.9716 - val_mae: 18.9579\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 608.5962 - mae: 21.3605 - val_loss: 449.2642 - val_mae: 18.8923\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 604.9869 - mae: 21.3206 - val_loss: 445.0604 - val_mae: 18.8334\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 601.6411 - mae: 21.2814 - val_loss: 441.0729 - val_mae: 18.7797\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.4257 - mae: 21.2429 - val_loss: 437.3238 - val_mae: 18.7260\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 595.4175 - mae: 21.2040 - val_loss: 433.9881 - val_mae: 18.6767\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.5643 - mae: 21.1682 - val_loss: 430.8521 - val_mae: 18.6282\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 589.7941 - mae: 21.1283 - val_loss: 427.6677 - val_mae: 18.5830\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 587.0195 - mae: 21.0911 - val_loss: 424.6530 - val_mae: 18.5386\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.4385 - mae: 21.0558 - val_loss: 421.5211 - val_mae: 18.4882\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 581.6443 - mae: 21.0151 - val_loss: 418.6566 - val_mae: 18.4398\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 579.0544 - mae: 20.9757 - val_loss: 415.9675 - val_mae: 18.3960\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.5481 - mae: 20.9390 - val_loss: 413.4824 - val_mae: 18.3541\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.1567 - mae: 20.9014 - val_loss: 411.0570 - val_mae: 18.3122\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.7866 - mae: 20.8636 - val_loss: 408.8016 - val_mae: 18.2727\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.5964 - mae: 20.8267 - val_loss: 406.6925 - val_mae: 18.2379\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.4971 - mae: 20.7916 - val_loss: 404.7102 - val_mae: 18.2043\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.4635 - mae: 20.7531 - val_loss: 402.6555 - val_mae: 18.1696\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 563.4354 - mae: 20.7184 - val_loss: 400.8364 - val_mae: 18.1367\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.4930 - mae: 20.6826 - val_loss: 399.0768 - val_mae: 18.1035\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 559.6866 - mae: 20.6504 - val_loss: 397.4665 - val_mae: 18.0728\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.8684 - mae: 20.6144 - val_loss: 395.7596 - val_mae: 18.0438\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.0370 - mae: 20.5785 - val_loss: 394.2503 - val_mae: 18.0178\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3741 - mae: 20.5466 - val_loss: 392.8775 - val_mae: 17.9949\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.7661 - mae: 20.5151 - val_loss: 391.4808 - val_mae: 17.9705\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 551.1528 - mae: 20.4828 - val_loss: 390.2301 - val_mae: 17.9471\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 549.6604 - mae: 20.4553 - val_loss: 389.0711 - val_mae: 17.9239\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2731 - mae: 20.4264 - val_loss: 387.8283 - val_mae: 17.8996\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7947 - mae: 20.3979 - val_loss: 386.7249 - val_mae: 17.8802\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.4543 - mae: 20.3725 - val_loss: 385.4789 - val_mae: 17.8557\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.1653 - mae: 20.3475 - val_loss: 384.2889 - val_mae: 17.8313\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 542.9152 - mae: 20.3241 - val_loss: 383.4051 - val_mae: 17.8142\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 541.8318 - mae: 20.3056 - val_loss: 382.4668 - val_mae: 17.7952\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.7959 - mae: 20.2839 - val_loss: 381.5709 - val_mae: 17.7773\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.7321 - mae: 20.2638 - val_loss: 380.6983 - val_mae: 17.7588\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 538.7118 - mae: 20.2432 - val_loss: 379.8889 - val_mae: 17.7407\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.7330 - mae: 20.2239 - val_loss: 378.9838 - val_mae: 17.7206\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.7335 - mae: 20.2046 - val_loss: 378.1791 - val_mae: 17.7014\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 535.7763 - mae: 20.1844 - val_loss: 377.4585 - val_mae: 17.6846\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.8507 - mae: 20.1657 - val_loss: 376.7179 - val_mae: 17.6658\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.9798 - mae: 20.1481 - val_loss: 376.0222 - val_mae: 17.6481\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 533.1228 - mae: 20.1299 - val_loss: 375.3993 - val_mae: 17.6316\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.2861 - mae: 20.1121 - val_loss: 374.8323 - val_mae: 17.6161\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.4662 - mae: 20.0934 - val_loss: 374.1891 - val_mae: 17.5977\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 530.6477 - mae: 20.0757 - val_loss: 373.6609 - val_mae: 17.5827\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 529.8558 - mae: 20.0584 - val_loss: 372.9588 - val_mae: 17.5630\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 529.0391 - mae: 20.0409 - val_loss: 372.3806 - val_mae: 17.5457\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.2547 - mae: 20.0221 - val_loss: 371.7165 - val_mae: 17.5259\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.4879 - mae: 20.0033 - val_loss: 371.0546 - val_mae: 17.5065\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.6498 - mae: 19.9836 - val_loss: 370.4563 - val_mae: 17.4891\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.8183 - mae: 19.9635 - val_loss: 369.7615 - val_mae: 17.4696\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 524.8934 - mae: 19.9389 - val_loss: 369.0698 - val_mae: 17.4504\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 523.9709 - mae: 19.9156 - val_loss: 368.4096 - val_mae: 17.4311\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 523.0291 - mae: 19.8912 - val_loss: 367.6290 - val_mae: 17.4082\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.9773 - mae: 19.8639 - val_loss: 366.7420 - val_mae: 17.3822\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.7843 - mae: 19.8303 - val_loss: 365.7495 - val_mae: 17.3532\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.5984 - mae: 19.7995 - val_loss: 364.5571 - val_mae: 17.3177\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.3788 - mae: 19.7634 - val_loss: 363.4364 - val_mae: 17.2836\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 517.2634 - mae: 19.7307 - val_loss: 362.4023 - val_mae: 17.2506\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 516.2524 - mae: 19.6973 - val_loss: 361.5154 - val_mae: 17.2211\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.2892 - mae: 19.6676 - val_loss: 360.5888 - val_mae: 17.1890\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.3702 - mae: 19.6381 - val_loss: 359.6047 - val_mae: 17.1551\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 513.3669 - mae: 19.6065 - val_loss: 358.7003 - val_mae: 17.1211\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 512.4207 - mae: 19.5727 - val_loss: 357.8697 - val_mae: 17.0878\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.5209 - mae: 19.5433 - val_loss: 357.1443 - val_mae: 17.0569\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.6977 - mae: 19.5158 - val_loss: 356.4973 - val_mae: 17.0273\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.9062 - mae: 19.4900 - val_loss: 355.8777 - val_mae: 16.9997\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.1702 - mae: 19.4674 - val_loss: 355.3129 - val_mae: 16.9764\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.5010 - mae: 19.4456 - val_loss: 354.6912 - val_mae: 16.9517\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.9133 - mae: 19.4246 - val_loss: 354.1920 - val_mae: 16.9302\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 507.4308 - mae: 19.4082 - val_loss: 353.8063 - val_mae: 16.9116\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.0102 - mae: 19.3958 - val_loss: 353.4055 - val_mae: 16.8939\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.6058 - mae: 19.3829 - val_loss: 353.0541 - val_mae: 16.8786\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.2473 - mae: 19.3706 - val_loss: 352.7166 - val_mae: 16.8640\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.9429 - mae: 19.3614 - val_loss: 352.4432 - val_mae: 16.8526\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 2682.8396 - mae: 35.2442 - val_loss: 2264.3643 - val_mae: 33.4708\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2032.0496 - mae: 32.0184 - val_loss: 1716.3882 - val_mae: 30.5342\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1588.8683 - mae: 29.4998 - val_loss: 1336.2123 - val_mae: 28.1050\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1280.2578 - mae: 27.4226 - val_loss: 1070.8369 - val_mae: 26.1538\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1064.0643 - mae: 25.7396 - val_loss: 889.6366 - val_mae: 24.5793\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 914.6989 - mae: 24.4073 - val_loss: 761.6188 - val_mae: 23.2891\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 808.2678 - mae: 23.3169 - val_loss: 671.2085 - val_mae: 22.2368\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 731.8409 - mae: 22.4284 - val_loss: 606.4391 - val_mae: 21.3790\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.6353 - mae: 21.7058 - val_loss: 560.5936 - val_mae: 20.7063\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.6052 - mae: 21.1480 - val_loss: 526.8892 - val_mae: 20.1543\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 603.3737 - mae: 20.7059 - val_loss: 502.4330 - val_mae: 19.7435\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 579.6307 - mae: 20.3767 - val_loss: 483.9158 - val_mae: 19.4177\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 560.7712 - mae: 20.1075 - val_loss: 470.3303 - val_mae: 19.1508\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.2047 - mae: 19.8930 - val_loss: 459.4709 - val_mae: 18.9387\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.7657 - mae: 19.7090 - val_loss: 451.7959 - val_mae: 18.7808\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.0078 - mae: 19.5553 - val_loss: 445.3273 - val_mae: 18.6515\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.4290 - mae: 19.4132 - val_loss: 440.2488 - val_mae: 18.5420\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.0895 - mae: 19.2918 - val_loss: 436.3364 - val_mae: 18.4552\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.8493 - mae: 19.1875 - val_loss: 432.8680 - val_mae: 18.3704\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.8286 - mae: 19.0929 - val_loss: 430.0700 - val_mae: 18.2969\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.8101 - mae: 19.0062 - val_loss: 427.9647 - val_mae: 18.2454\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.5971 - mae: 18.9399 - val_loss: 426.1342 - val_mae: 18.1979\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 482.7807 - mae: 18.8811 - val_loss: 424.7177 - val_mae: 18.1622\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.4625 - mae: 18.8315 - val_loss: 423.5391 - val_mae: 18.1311\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 476.4512 - mae: 18.7906 - val_loss: 422.5908 - val_mae: 18.1054\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 473.8596 - mae: 18.7562 - val_loss: 421.7613 - val_mae: 18.0785\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.3041 - mae: 18.7243 - val_loss: 421.0506 - val_mae: 18.0551\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.0417 - mae: 18.6984 - val_loss: 420.5339 - val_mae: 18.0393\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.0561 - mae: 18.6750 - val_loss: 420.0963 - val_mae: 18.0285\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.1470 - mae: 18.6523 - val_loss: 419.7526 - val_mae: 18.0219\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.3481 - mae: 18.6312 - val_loss: 419.4963 - val_mae: 18.0175\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.6564 - mae: 18.6115 - val_loss: 419.2805 - val_mae: 18.0121\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.1387 - mae: 18.5912 - val_loss: 419.1146 - val_mae: 18.0125\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.6180 - mae: 18.5722 - val_loss: 419.0530 - val_mae: 18.0154\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.1658 - mae: 18.5528 - val_loss: 418.8691 - val_mae: 18.0153\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 455.6125 - mae: 18.5340 - val_loss: 418.6348 - val_mae: 18.0155\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.1539 - mae: 18.5122 - val_loss: 418.4485 - val_mae: 18.0145\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.7748 - mae: 18.4918 - val_loss: 418.2868 - val_mae: 18.0150\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.4312 - mae: 18.4725 - val_loss: 418.1257 - val_mae: 18.0144\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.1236 - mae: 18.4542 - val_loss: 417.8758 - val_mae: 18.0104\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.9006 - mae: 18.4372 - val_loss: 417.6287 - val_mae: 18.0050\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.7704 - mae: 18.4185 - val_loss: 417.4387 - val_mae: 18.0025\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.6153 - mae: 18.4013 - val_loss: 417.2414 - val_mae: 17.9983\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.5318 - mae: 18.3845 - val_loss: 417.0639 - val_mae: 17.9947\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.4881 - mae: 18.3681 - val_loss: 416.9086 - val_mae: 17.9911\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4642 - mae: 18.3524 - val_loss: 416.7151 - val_mae: 17.9851\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.4567 - mae: 18.3351 - val_loss: 416.5508 - val_mae: 17.9803\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.4952 - mae: 18.3197 - val_loss: 416.3947 - val_mae: 17.9758\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.5537 - mae: 18.3044 - val_loss: 416.2334 - val_mae: 17.9701\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.6530 - mae: 18.2890 - val_loss: 415.9879 - val_mae: 17.9615\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.8020 - mae: 18.2748 - val_loss: 415.7295 - val_mae: 17.9527\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.9857 - mae: 18.2581 - val_loss: 415.4949 - val_mae: 17.9456\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.1840 - mae: 18.2441 - val_loss: 415.2385 - val_mae: 17.9380\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.3878 - mae: 18.2281 - val_loss: 414.9409 - val_mae: 17.9304\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.6259 - mae: 18.2112 - val_loss: 414.7192 - val_mae: 17.9263\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.8731 - mae: 18.1966 - val_loss: 414.4726 - val_mae: 17.9206\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.1382 - mae: 18.1806 - val_loss: 414.2394 - val_mae: 17.9143\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.4154 - mae: 18.1648 - val_loss: 414.0004 - val_mae: 17.9072\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.6919 - mae: 18.1476 - val_loss: 413.7868 - val_mae: 17.9013\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.9848 - mae: 18.1311 - val_loss: 413.5484 - val_mae: 17.8943\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 431.3069 - mae: 18.1148 - val_loss: 413.3437 - val_mae: 17.8880\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6541 - mae: 18.0988 - val_loss: 413.1317 - val_mae: 17.8811\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.0374 - mae: 18.0826 - val_loss: 412.9181 - val_mae: 17.8741\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.4615 - mae: 18.0677 - val_loss: 412.6620 - val_mae: 17.8667\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.8489 - mae: 18.0522 - val_loss: 412.4018 - val_mae: 17.8590\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.2537 - mae: 18.0374 - val_loss: 412.1137 - val_mae: 17.8512\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.6677 - mae: 18.0225 - val_loss: 411.8388 - val_mae: 17.8437\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 427.1004 - mae: 18.0071 - val_loss: 411.5221 - val_mae: 17.8339\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.5495 - mae: 17.9929 - val_loss: 411.1828 - val_mae: 17.8237\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.0034 - mae: 17.9780 - val_loss: 410.8532 - val_mae: 17.8140\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.4373 - mae: 17.9625 - val_loss: 410.5012 - val_mae: 17.8035\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.9211 - mae: 17.9485 - val_loss: 410.1302 - val_mae: 17.7933\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 424.3966 - mae: 17.9350 - val_loss: 409.7056 - val_mae: 17.7812\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.8901 - mae: 17.9205 - val_loss: 409.2786 - val_mae: 17.7680\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.3579 - mae: 17.9037 - val_loss: 408.9118 - val_mae: 17.7584\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 422.8683 - mae: 17.8905 - val_loss: 408.4747 - val_mae: 17.7462\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 422.3659 - mae: 17.8759 - val_loss: 408.0643 - val_mae: 17.7345\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.8915 - mae: 17.8622 - val_loss: 407.6480 - val_mae: 17.7227\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.4087 - mae: 17.8480 - val_loss: 407.2182 - val_mae: 17.7101\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.9041 - mae: 17.8335 - val_loss: 406.7455 - val_mae: 17.6959\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.4007 - mae: 17.8181 - val_loss: 406.2731 - val_mae: 17.6820\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.8990 - mae: 17.8036 - val_loss: 405.7572 - val_mae: 17.6671\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.3932 - mae: 17.7873 - val_loss: 405.2144 - val_mae: 17.6527\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.8621 - mae: 17.7725 - val_loss: 404.6831 - val_mae: 17.6379\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 418.3463 - mae: 17.7564 - val_loss: 404.1427 - val_mae: 17.6224\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 417.8215 - mae: 17.7404 - val_loss: 403.6511 - val_mae: 17.6100\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 417.3057 - mae: 17.7258 - val_loss: 403.1320 - val_mae: 17.5966\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.7988 - mae: 17.7098 - val_loss: 402.6357 - val_mae: 17.5834\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.2963 - mae: 17.6946 - val_loss: 402.1461 - val_mae: 17.5702\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 415.7975 - mae: 17.6794 - val_loss: 401.6527 - val_mae: 17.5571\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 415.2483 - mae: 17.6630 - val_loss: 401.1426 - val_mae: 17.5431\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.7042 - mae: 17.6460 - val_loss: 400.6188 - val_mae: 17.5284\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.1562 - mae: 17.6287 - val_loss: 400.0890 - val_mae: 17.5125\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.5799 - mae: 17.6113 - val_loss: 399.5635 - val_mae: 17.4966\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.9861 - mae: 17.5928 - val_loss: 399.0767 - val_mae: 17.4811\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.3945 - mae: 17.5739 - val_loss: 398.6027 - val_mae: 17.4659\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.8310 - mae: 17.5561 - val_loss: 398.1112 - val_mae: 17.4505\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.2251 - mae: 17.5368 - val_loss: 397.5771 - val_mae: 17.4325\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.6667 - mae: 17.5185 - val_loss: 397.0472 - val_mae: 17.4152\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.0391 - mae: 17.4989 - val_loss: 396.4827 - val_mae: 17.3944\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.1, model__n_hidden=1, model__n_neurons=25, model__optimizer=sgd; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 2049.6584 - mae: 22.0553 - val_loss: 241.4236 - val_mae: 13.4104\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.3658 - mae: 15.0181 - val_loss: 238.5188 - val_mae: 13.2068\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.3015 - mae: 14.8190 - val_loss: 237.2778 - val_mae: 13.0466\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 329.2434 - mae: 14.7352 - val_loss: 234.3910 - val_mae: 12.8675\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 327.3531 - mae: 14.6441 - val_loss: 232.3136 - val_mae: 12.8078\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 326.1478 - mae: 14.5662 - val_loss: 230.4376 - val_mae: 12.6768\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.9564 - mae: 14.5469 - val_loss: 229.7016 - val_mae: 12.7235\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.6854 - mae: 14.4994 - val_loss: 228.4053 - val_mae: 12.5144\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 322.2998 - mae: 14.4373 - val_loss: 228.3639 - val_mae: 12.4311\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 322.0462 - mae: 14.4209 - val_loss: 227.0773 - val_mae: 12.4562\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 320.4321 - mae: 14.3812 - val_loss: 226.1755 - val_mae: 12.4146\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.8698 - mae: 14.3993 - val_loss: 225.8431 - val_mae: 12.3795\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.3119 - mae: 14.3557 - val_loss: 225.2455 - val_mae: 12.3343\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.4582 - mae: 14.3330 - val_loss: 224.6446 - val_mae: 12.3087\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.0316 - mae: 14.2932 - val_loss: 224.4925 - val_mae: 12.2740\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.0778 - mae: 14.3131 - val_loss: 225.5115 - val_mae: 12.2264\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.1566 - mae: 14.2500 - val_loss: 225.5949 - val_mae: 12.2826\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 317.4146 - mae: 14.3076 - val_loss: 222.3765 - val_mae: 12.2495\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.4507 - mae: 14.2476 - val_loss: 222.7732 - val_mae: 12.4684\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.0260 - mae: 14.1758 - val_loss: 221.5384 - val_mae: 12.2433\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 314.8529 - mae: 14.1851 - val_loss: 221.2444 - val_mae: 12.3126\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 315.4777 - mae: 14.1466 - val_loss: 221.0509 - val_mae: 12.2182\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 314.4311 - mae: 14.1127 - val_loss: 221.3615 - val_mae: 12.1318\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.8737 - mae: 14.1358 - val_loss: 220.3998 - val_mae: 12.1474\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.2115 - mae: 14.0938 - val_loss: 220.0176 - val_mae: 12.1492\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 312.4940 - mae: 14.0970 - val_loss: 219.3682 - val_mae: 12.1034\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 312.5046 - mae: 14.0550 - val_loss: 218.7507 - val_mae: 12.1255\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 312.1474 - mae: 14.0201 - val_loss: 218.8086 - val_mae: 12.0285\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 311.2738 - mae: 13.9990 - val_loss: 219.0047 - val_mae: 12.0366\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 311.3729 - mae: 14.0210 - val_loss: 219.0301 - val_mae: 12.0025\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.4796 - mae: 14.0150 - val_loss: 218.4281 - val_mae: 11.9286\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.4704 - mae: 14.0302 - val_loss: 216.6342 - val_mae: 11.9888\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.1761 - mae: 13.9340 - val_loss: 216.4426 - val_mae: 11.9596\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.1003 - mae: 13.8847 - val_loss: 216.2547 - val_mae: 11.9161\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 307.9817 - mae: 13.8604 - val_loss: 216.5384 - val_mae: 11.9155\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 308.0062 - mae: 13.8884 - val_loss: 216.7697 - val_mae: 11.8896\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 307.8812 - mae: 13.8711 - val_loss: 218.0263 - val_mae: 11.9311\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.2317 - mae: 13.8848 - val_loss: 215.4640 - val_mae: 11.8868\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.5554 - mae: 13.7822 - val_loss: 216.6585 - val_mae: 11.8770\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 306.9945 - mae: 13.8658 - val_loss: 214.5478 - val_mae: 11.8598\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.9001 - mae: 13.8053 - val_loss: 214.4364 - val_mae: 11.8780\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.3326 - mae: 13.7731 - val_loss: 215.1566 - val_mae: 11.8024\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.5161 - mae: 13.7951 - val_loss: 214.2036 - val_mae: 11.7907\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 305.5415 - mae: 13.7362 - val_loss: 215.9056 - val_mae: 11.8420\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 305.5448 - mae: 13.8068 - val_loss: 213.7734 - val_mae: 11.7853\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 305.4312 - mae: 13.7592 - val_loss: 214.0875 - val_mae: 11.7447\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.8210 - mae: 13.7696 - val_loss: 213.1584 - val_mae: 11.7917\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.1327 - mae: 13.7454 - val_loss: 212.9760 - val_mae: 11.7841\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.1812 - mae: 13.7072 - val_loss: 212.6923 - val_mae: 11.7806\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.8155 - mae: 13.7348 - val_loss: 212.7417 - val_mae: 11.7650\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.1971 - mae: 13.6866 - val_loss: 213.0052 - val_mae: 11.7185\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.3477 - mae: 13.7053 - val_loss: 213.6811 - val_mae: 11.7489\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.5242 - mae: 13.7227 - val_loss: 212.5693 - val_mae: 11.7655\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.2920 - mae: 13.6520 - val_loss: 213.1570 - val_mae: 11.7432\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.2404 - mae: 13.6876 - val_loss: 212.0793 - val_mae: 11.7011\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.0369 - mae: 13.5958 - val_loss: 214.4523 - val_mae: 11.6991\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 302.8199 - mae: 13.6741 - val_loss: 212.3600 - val_mae: 11.6779\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 302.3712 - mae: 13.6118 - val_loss: 213.2924 - val_mae: 11.6741\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.5510 - mae: 13.7323 - val_loss: 211.8481 - val_mae: 11.6106\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 302.0073 - mae: 13.6186 - val_loss: 212.2154 - val_mae: 11.6069\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 301.9420 - mae: 13.5870 - val_loss: 214.1736 - val_mae: 11.6853\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.2354 - mae: 13.6443 - val_loss: 212.8280 - val_mae: 11.6390\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.8718 - mae: 13.6426 - val_loss: 211.6054 - val_mae: 11.5917\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.3508 - mae: 13.6212 - val_loss: 210.4787 - val_mae: 11.5911\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.2347 - mae: 13.5791 - val_loss: 210.3972 - val_mae: 11.5648\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.4951 - mae: 13.5735 - val_loss: 211.9778 - val_mae: 11.5879\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.2606 - mae: 13.5674 - val_loss: 213.4339 - val_mae: 11.6292\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.2132 - mae: 13.6272 - val_loss: 211.4613 - val_mae: 11.5952\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.7229 - mae: 13.6374 - val_loss: 209.4942 - val_mae: 11.5698\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.4476 - mae: 13.5805 - val_loss: 209.3230 - val_mae: 11.5657\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.4219 - mae: 13.5056 - val_loss: 211.0955 - val_mae: 11.6171\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.4113 - mae: 13.5358 - val_loss: 211.9761 - val_mae: 11.6056\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.2633 - mae: 13.5942 - val_loss: 208.7972 - val_mae: 11.5447\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.4071 - mae: 13.5087 - val_loss: 209.2215 - val_mae: 11.5180\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.1761 - mae: 13.5187 - val_loss: 209.8413 - val_mae: 11.5555\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.1874 - mae: 13.5548 - val_loss: 209.6581 - val_mae: 11.4965\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.2858 - mae: 13.5459 - val_loss: 209.1336 - val_mae: 11.4824\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.6245 - mae: 13.5349 - val_loss: 208.7616 - val_mae: 11.5051\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.9937 - mae: 13.4673 - val_loss: 210.5649 - val_mae: 11.4868\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.5848 - mae: 13.5081 - val_loss: 214.4465 - val_mae: 11.6837\n",
      "Epoch 80: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   3.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 326.9794 - mae: 14.3594 - val_loss: 200.2548 - val_mae: 12.1530\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.8797 - mae: 13.7098 - val_loss: 189.7202 - val_mae: 11.8917\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.4783 - mae: 13.3879 - val_loss: 179.9926 - val_mae: 11.4107\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.5240 - mae: 13.0641 - val_loss: 176.9847 - val_mae: 11.2260\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.5061 - mae: 12.8215 - val_loss: 170.3752 - val_mae: 10.9326\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.8647 - mae: 12.6168 - val_loss: 169.3728 - val_mae: 10.8301\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.9690 - mae: 12.4354 - val_loss: 162.4619 - val_mae: 10.4315\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.3905 - mae: 12.1762 - val_loss: 158.9509 - val_mae: 10.2923\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.6974 - mae: 12.1180 - val_loss: 153.2663 - val_mae: 9.9804\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.7171 - mae: 11.8585 - val_loss: 149.3372 - val_mae: 9.7207\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.8138 - mae: 11.7609 - val_loss: 146.0716 - val_mae: 9.5747\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 245.0291 - mae: 11.7508 - val_loss: 136.9837 - val_mae: 9.0623\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.2056 - mae: 11.4687 - val_loss: 128.8269 - val_mae: 8.6460\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.8130 - mae: 11.1942 - val_loss: 117.4276 - val_mae: 7.7863\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.4675 - mae: 10.7331 - val_loss: 115.0123 - val_mae: 7.7170\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.9284 - mae: 10.7125 - val_loss: 111.6754 - val_mae: 7.4264\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.3662 - mae: 10.3996 - val_loss: 135.1858 - val_mae: 9.1626\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.6760 - mae: 10.5934 - val_loss: 108.1005 - val_mae: 7.0955\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.2365 - mae: 10.2917 - val_loss: 118.7078 - val_mae: 7.9524\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.2255 - mae: 10.4322 - val_loss: 108.6137 - val_mae: 7.1222\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.0130 - mae: 10.2394 - val_loss: 106.6896 - val_mae: 6.9717\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.2180 - mae: 10.2632 - val_loss: 106.4982 - val_mae: 6.9480\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.1240 - mae: 10.2042 - val_loss: 106.1176 - val_mae: 6.9942\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.1580 - mae: 10.5487 - val_loss: 110.8663 - val_mae: 7.4632\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.3390 - mae: 10.2898 - val_loss: 107.0157 - val_mae: 6.9507\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.7664 - mae: 10.2625 - val_loss: 105.3294 - val_mae: 6.8639\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 198.5008 - mae: 10.1266 - val_loss: 111.5325 - val_mae: 7.3044\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.4894 - mae: 10.4003 - val_loss: 106.2406 - val_mae: 7.0576\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 200.3636 - mae: 10.0943 - val_loss: 112.6131 - val_mae: 7.3771\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.2496 - mae: 10.1869 - val_loss: 118.5483 - val_mae: 7.8354\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 198.8139 - mae: 10.3260 - val_loss: 113.2113 - val_mae: 7.3981\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.9670 - mae: 10.1405 - val_loss: 127.6857 - val_mae: 8.4849\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.2945 - mae: 10.2672 - val_loss: 133.5413 - val_mae: 8.9096\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.0013 - mae: 10.3860 - val_loss: 104.9956 - val_mae: 6.9366\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.2619 - mae: 10.1808 - val_loss: 111.2871 - val_mae: 7.2784\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.5791 - mae: 10.2578 - val_loss: 106.2299 - val_mae: 6.8656\n",
      "Epoch 36: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   1.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 383.7064 - mae: 16.1988 - val_loss: 325.4456 - val_mae: 15.1873\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.9444 - mae: 15.1010 - val_loss: 297.7621 - val_mae: 14.2736\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.1398 - mae: 14.2405 - val_loss: 279.5423 - val_mae: 13.8248\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.0135 - mae: 13.7414 - val_loss: 260.1976 - val_mae: 13.1056\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.4141 - mae: 13.1356 - val_loss: 246.4916 - val_mae: 12.7383\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.8615 - mae: 12.7067 - val_loss: 236.2883 - val_mae: 12.3294\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.2466 - mae: 12.3340 - val_loss: 225.4356 - val_mae: 12.0312\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.9299 - mae: 12.0275 - val_loss: 222.1036 - val_mae: 11.9047\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 223.3943 - mae: 11.8990 - val_loss: 211.0314 - val_mae: 11.4450\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 217.1454 - mae: 11.5612 - val_loss: 208.7196 - val_mae: 11.4181\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.9595 - mae: 11.5835 - val_loss: 202.0795 - val_mae: 11.1362\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 209.7708 - mae: 11.4147 - val_loss: 201.2351 - val_mae: 11.0466\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.9292 - mae: 11.2609 - val_loss: 195.4667 - val_mae: 10.9387\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.7687 - mae: 11.1340 - val_loss: 196.6713 - val_mae: 11.0558\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204.3176 - mae: 11.2194 - val_loss: 191.3866 - val_mae: 10.8000\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 202.0590 - mae: 11.1028 - val_loss: 189.5681 - val_mae: 10.7268\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.3789 - mae: 10.9662 - val_loss: 187.9219 - val_mae: 10.6828\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.8728 - mae: 10.9776 - val_loss: 186.6999 - val_mae: 10.6467\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 197.1259 - mae: 10.8305 - val_loss: 188.0607 - val_mae: 10.7153\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 196.8234 - mae: 10.8476 - val_loss: 184.6891 - val_mae: 10.5711\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.9420 - mae: 10.8197 - val_loss: 182.8365 - val_mae: 10.5028\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 195.5858 - mae: 10.8225 - val_loss: 182.2833 - val_mae: 10.4421\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 194.8364 - mae: 10.6990 - val_loss: 180.9029 - val_mae: 10.4297\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 193.4536 - mae: 10.7040 - val_loss: 179.8872 - val_mae: 10.3784\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 192.4054 - mae: 10.6132 - val_loss: 182.7023 - val_mae: 10.4762\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.1062 - mae: 10.6912 - val_loss: 178.9069 - val_mae: 10.3494\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.0998 - mae: 10.6441 - val_loss: 177.7087 - val_mae: 10.2598\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.0210 - mae: 10.5616 - val_loss: 176.8579 - val_mae: 10.2331\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.3278 - mae: 10.5416 - val_loss: 176.2382 - val_mae: 10.2195\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.2256 - mae: 10.4875 - val_loss: 176.9992 - val_mae: 10.2389\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.2610 - mae: 10.5058 - val_loss: 176.2864 - val_mae: 10.2035\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.2321 - mae: 10.4870 - val_loss: 175.6186 - val_mae: 10.1726\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.4732 - mae: 10.5423 - val_loss: 174.2481 - val_mae: 10.0933\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 189.2202 - mae: 10.4092 - val_loss: 173.6011 - val_mae: 10.0597\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.2949 - mae: 10.4180 - val_loss: 173.0043 - val_mae: 10.0479\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.4603 - mae: 10.3812 - val_loss: 172.3490 - val_mae: 10.0082\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 187.1437 - mae: 10.3897 - val_loss: 171.9667 - val_mae: 9.9904\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.6373 - mae: 10.3939 - val_loss: 171.3796 - val_mae: 9.9639\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.1377 - mae: 10.3398 - val_loss: 171.2166 - val_mae: 9.9454\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 185.7341 - mae: 10.2892 - val_loss: 170.4261 - val_mae: 9.9208\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.7921 - mae: 10.2074 - val_loss: 175.2129 - val_mae: 10.1666\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.2269 - mae: 10.4397 - val_loss: 169.9692 - val_mae: 9.9290\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.7248 - mae: 10.2660 - val_loss: 169.0464 - val_mae: 9.8672\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.3553 - mae: 10.2282 - val_loss: 169.0435 - val_mae: 9.8977\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.3285 - mae: 10.2213 - val_loss: 168.5599 - val_mae: 9.8702\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.2762 - mae: 10.1870 - val_loss: 168.1718 - val_mae: 9.8559\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.8303 - mae: 10.1702 - val_loss: 168.5605 - val_mae: 9.8828\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 182.9487 - mae: 10.2233 - val_loss: 167.2497 - val_mae: 9.8104\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 182.8292 - mae: 10.1505 - val_loss: 167.5363 - val_mae: 9.8415\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.7663 - mae: 10.1617 - val_loss: 166.6870 - val_mae: 9.8016\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.7685 - mae: 10.1114 - val_loss: 166.8670 - val_mae: 9.8105\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.2231 - mae: 10.1590 - val_loss: 166.0390 - val_mae: 9.7320\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.3942 - mae: 10.0620 - val_loss: 165.5994 - val_mae: 9.7419\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.9366 - mae: 10.0175 - val_loss: 166.3515 - val_mae: 9.7818\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 181.2679 - mae: 10.0771 - val_loss: 167.2799 - val_mae: 9.8197\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 181.5600 - mae: 10.2027 - val_loss: 164.8512 - val_mae: 9.6967\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 181.1015 - mae: 10.0935 - val_loss: 164.6499 - val_mae: 9.6790\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 180.9157 - mae: 10.0770 - val_loss: 164.5098 - val_mae: 9.6606\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 180.9192 - mae: 10.0331 - val_loss: 164.4793 - val_mae: 9.6411\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 180.1181 - mae: 10.0033 - val_loss: 164.2525 - val_mae: 9.6306\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 179.5110 - mae: 9.9009 - val_loss: 164.6320 - val_mae: 9.6989\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 179.1073 - mae: 10.0667 - val_loss: 163.5439 - val_mae: 9.6211\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 180.0784 - mae: 9.9369 - val_loss: 163.5556 - val_mae: 9.6616\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 178.9971 - mae: 9.9649 - val_loss: 163.5810 - val_mae: 9.6585\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 179.1423 - mae: 10.0094 - val_loss: 162.8132 - val_mae: 9.5977\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 179.0721 - mae: 9.9241 - val_loss: 162.5560 - val_mae: 9.6032\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 178.5903 - mae: 9.9296 - val_loss: 162.5151 - val_mae: 9.6021\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 178.1690 - mae: 9.9623 - val_loss: 162.2781 - val_mae: 9.5662\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 179.3683 - mae: 9.9117 - val_loss: 162.0473 - val_mae: 9.5727\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 177.9808 - mae: 9.8894 - val_loss: 161.9396 - val_mae: 9.5732\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 177.6806 - mae: 9.8236 - val_loss: 163.5141 - val_mae: 9.6328\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 178.1974 - mae: 9.9631 - val_loss: 161.9432 - val_mae: 9.5777\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 177.3531 - mae: 9.9160 - val_loss: 161.3055 - val_mae: 9.5527\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 177.8248 - mae: 9.8875 - val_loss: 161.0132 - val_mae: 9.5346\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 178.1627 - mae: 9.9000 - val_loss: 160.7965 - val_mae: 9.5173\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 177.2723 - mae: 9.8070 - val_loss: 161.0738 - val_mae: 9.5499\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 177.8230 - mae: 9.9335 - val_loss: 160.5126 - val_mae: 9.5228\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.7287 - mae: 9.8507 - val_loss: 160.3108 - val_mae: 9.5081\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 176.8928 - mae: 9.8564 - val_loss: 160.0621 - val_mae: 9.4979\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 176.4280 - mae: 9.7835 - val_loss: 159.9411 - val_mae: 9.5057\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.4541 - mae: 9.7959 - val_loss: 160.2190 - val_mae: 9.5116\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 177.0845 - mae: 9.8974 - val_loss: 159.6736 - val_mae: 9.4711\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.5053 - mae: 9.7791 - val_loss: 159.5245 - val_mae: 9.4771\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.1187 - mae: 9.8262 - val_loss: 159.4184 - val_mae: 9.4498\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 175.9885 - mae: 9.7501 - val_loss: 159.5082 - val_mae: 9.4703\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 175.8116 - mae: 9.8180 - val_loss: 159.1767 - val_mae: 9.4463\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 176.0019 - mae: 9.8255 - val_loss: 159.2554 - val_mae: 9.4115\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 175.9238 - mae: 9.7031 - val_loss: 159.1018 - val_mae: 9.4461\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.5627 - mae: 9.7706 - val_loss: 158.9716 - val_mae: 9.4379\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.6069 - mae: 9.7433 - val_loss: 159.0387 - val_mae: 9.4422\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.1684 - mae: 9.8103 - val_loss: 158.5423 - val_mae: 9.4036\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 175.5821 - mae: 9.7403 - val_loss: 158.6503 - val_mae: 9.4200\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.1690 - mae: 9.7667 - val_loss: 158.3154 - val_mae: 9.3888\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 175.3820 - mae: 9.6860 - val_loss: 158.1865 - val_mae: 9.4050\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.9387 - mae: 9.7634 - val_loss: 157.9920 - val_mae: 9.3800\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.9212 - mae: 9.6977 - val_loss: 157.8877 - val_mae: 9.3806\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.6777 - mae: 9.7778 - val_loss: 157.9860 - val_mae: 9.3496\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.8159 - mae: 9.6598 - val_loss: 157.7032 - val_mae: 9.3695\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.9327 - mae: 9.6891 - val_loss: 157.7988 - val_mae: 9.3750\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 174.8452 - mae: 9.7421 - val_loss: 157.7259 - val_mae: 9.3695\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 1181.9099 - mae: 26.5312 - val_loss: 957.1658 - val_mae: 23.8596\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 883.2164 - mae: 23.7372 - val_loss: 745.3308 - val_mae: 21.7149\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 719.0979 - mae: 21.9172 - val_loss: 615.5346 - val_mae: 20.1850\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 617.5560 - mae: 20.5767 - val_loss: 533.4113 - val_mae: 19.0873\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 553.2616 - mae: 19.6305 - val_loss: 476.8878 - val_mae: 18.2404\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 508.9470 - mae: 18.9240 - val_loss: 436.0382 - val_mae: 17.5769\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 476.8576 - mae: 18.3486 - val_loss: 405.5515 - val_mae: 17.0326\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 452.6465 - mae: 17.8900 - val_loss: 381.9478 - val_mae: 16.5579\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.8261 - mae: 17.4943 - val_loss: 362.9683 - val_mae: 16.1476\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.4463 - mae: 17.1602 - val_loss: 347.0772 - val_mae: 15.7801\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 405.5357 - mae: 16.8486 - val_loss: 334.1330 - val_mae: 15.4578\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 394.7376 - mae: 16.5712 - val_loss: 322.6864 - val_mae: 15.1590\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.2119 - mae: 16.3167 - val_loss: 312.8063 - val_mae: 14.8951\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.8290 - mae: 16.0876 - val_loss: 304.3260 - val_mae: 14.6579\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.5171 - mae: 15.8757 - val_loss: 296.4872 - val_mae: 14.4329\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.9784 - mae: 15.6827 - val_loss: 289.5023 - val_mae: 14.2266\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 357.0746 - mae: 15.5058 - val_loss: 283.0662 - val_mae: 14.0359\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.7205 - mae: 15.3417 - val_loss: 277.1675 - val_mae: 13.8585\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.8462 - mae: 15.1943 - val_loss: 271.8665 - val_mae: 13.6932\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 342.5050 - mae: 15.0602 - val_loss: 267.1266 - val_mae: 13.5430\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 338.6079 - mae: 14.9454 - val_loss: 262.7299 - val_mae: 13.4094\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.9105 - mae: 14.8375 - val_loss: 258.8119 - val_mae: 13.2914\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.4622 - mae: 14.7340 - val_loss: 255.1603 - val_mae: 13.1827\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 328.1393 - mae: 14.6356 - val_loss: 251.4280 - val_mae: 13.0757\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 324.8560 - mae: 14.5432 - val_loss: 247.9595 - val_mae: 12.9749\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 321.8520 - mae: 14.4622 - val_loss: 244.7691 - val_mae: 12.8841\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 319.1898 - mae: 14.3868 - val_loss: 241.7890 - val_mae: 12.7927\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 316.7627 - mae: 14.3197 - val_loss: 239.1024 - val_mae: 12.7097\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 314.5278 - mae: 14.2633 - val_loss: 236.4558 - val_mae: 12.6243\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 312.2956 - mae: 14.1932 - val_loss: 233.9268 - val_mae: 12.5426\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.2444 - mae: 14.1359 - val_loss: 231.5925 - val_mae: 12.4648\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 308.3813 - mae: 14.0773 - val_loss: 229.3685 - val_mae: 12.3873\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.5634 - mae: 14.0220 - val_loss: 227.1918 - val_mae: 12.3113\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.8098 - mae: 13.9636 - val_loss: 225.4018 - val_mae: 12.2475\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.2326 - mae: 13.9119 - val_loss: 223.6495 - val_mae: 12.1867\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 301.7680 - mae: 13.8624 - val_loss: 222.1698 - val_mae: 12.1310\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.3885 - mae: 13.8131 - val_loss: 220.8412 - val_mae: 12.0799\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 299.2388 - mae: 13.7725 - val_loss: 219.6812 - val_mae: 12.0337\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 298.2322 - mae: 13.7307 - val_loss: 218.6404 - val_mae: 11.9919\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 297.3065 - mae: 13.7014 - val_loss: 217.5450 - val_mae: 11.9459\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 296.4788 - mae: 13.6617 - val_loss: 216.6187 - val_mae: 11.9074\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.7317 - mae: 13.6307 - val_loss: 215.8971 - val_mae: 11.8775\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 295.0576 - mae: 13.6048 - val_loss: 215.0254 - val_mae: 11.8417\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 294.4201 - mae: 13.5824 - val_loss: 214.2632 - val_mae: 11.8112\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.8326 - mae: 13.5521 - val_loss: 213.5134 - val_mae: 11.7819\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.2880 - mae: 13.5288 - val_loss: 212.8066 - val_mae: 11.7550\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 292.7569 - mae: 13.5061 - val_loss: 212.0973 - val_mae: 11.7273\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 292.2594 - mae: 13.4871 - val_loss: 211.4565 - val_mae: 11.7020\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.7578 - mae: 13.4603 - val_loss: 210.9373 - val_mae: 11.6844\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.3255 - mae: 13.4452 - val_loss: 210.4688 - val_mae: 11.6695\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.8850 - mae: 13.4336 - val_loss: 209.8764 - val_mae: 11.6482\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.4076 - mae: 13.4164 - val_loss: 209.3280 - val_mae: 11.6276\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.9448 - mae: 13.3965 - val_loss: 208.7681 - val_mae: 11.6073\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.5224 - mae: 13.3836 - val_loss: 208.2143 - val_mae: 11.5883\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.0329 - mae: 13.3651 - val_loss: 207.6292 - val_mae: 11.5665\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.5727 - mae: 13.3408 - val_loss: 207.1551 - val_mae: 11.5503\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.0678 - mae: 13.3288 - val_loss: 206.6627 - val_mae: 11.5319\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.5773 - mae: 13.3141 - val_loss: 206.2051 - val_mae: 11.5150\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.1380 - mae: 13.2996 - val_loss: 205.7788 - val_mae: 11.5017\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286.6268 - mae: 13.2806 - val_loss: 205.2626 - val_mae: 11.4840\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 286.1107 - mae: 13.2640 - val_loss: 204.7864 - val_mae: 11.4678\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.6098 - mae: 13.2499 - val_loss: 204.2812 - val_mae: 11.4506\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.0727 - mae: 13.2321 - val_loss: 203.8004 - val_mae: 11.4350\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.5567 - mae: 13.2152 - val_loss: 203.3585 - val_mae: 11.4219\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.0671 - mae: 13.2019 - val_loss: 202.8700 - val_mae: 11.4061\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.5340 - mae: 13.1853 - val_loss: 202.3978 - val_mae: 11.3902\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.9639 - mae: 13.1679 - val_loss: 201.9212 - val_mae: 11.3733\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.4014 - mae: 13.1481 - val_loss: 201.4334 - val_mae: 11.3575\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.8236 - mae: 13.1310 - val_loss: 200.9330 - val_mae: 11.3405\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.2402 - mae: 13.1160 - val_loss: 200.4218 - val_mae: 11.3230\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.6484 - mae: 13.0927 - val_loss: 199.9297 - val_mae: 11.3058\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.1042 - mae: 13.0766 - val_loss: 199.4299 - val_mae: 11.2870\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.5400 - mae: 13.0582 - val_loss: 198.9585 - val_mae: 11.2691\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.0349 - mae: 13.0373 - val_loss: 198.5414 - val_mae: 11.2533\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.5224 - mae: 13.0219 - val_loss: 198.1015 - val_mae: 11.2355\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.0202 - mae: 13.0078 - val_loss: 197.6336 - val_mae: 11.2151\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.5219 - mae: 12.9863 - val_loss: 197.2184 - val_mae: 11.1970\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.0413 - mae: 12.9671 - val_loss: 196.8581 - val_mae: 11.1819\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.5790 - mae: 12.9507 - val_loss: 196.4970 - val_mae: 11.1669\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.0955 - mae: 12.9399 - val_loss: 196.0378 - val_mae: 11.1462\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.5992 - mae: 12.9191 - val_loss: 195.6168 - val_mae: 11.1267\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 275.1532 - mae: 12.9004 - val_loss: 195.2251 - val_mae: 11.1087\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 274.6846 - mae: 12.8839 - val_loss: 194.8112 - val_mae: 11.0897\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.1938 - mae: 12.8653 - val_loss: 194.4011 - val_mae: 11.0701\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.6746 - mae: 12.8429 - val_loss: 194.0752 - val_mae: 11.0559\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.1357 - mae: 12.8254 - val_loss: 193.7524 - val_mae: 11.0412\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 272.6004 - mae: 12.8091 - val_loss: 193.2888 - val_mae: 11.0192\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 272.0841 - mae: 12.7880 - val_loss: 192.8727 - val_mae: 10.9993\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.5800 - mae: 12.7702 - val_loss: 192.4831 - val_mae: 10.9794\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.0543 - mae: 12.7478 - val_loss: 192.0551 - val_mae: 10.9579\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270.5790 - mae: 12.7294 - val_loss: 191.6601 - val_mae: 10.9380\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.1180 - mae: 12.7107 - val_loss: 191.2906 - val_mae: 10.9193\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.6707 - mae: 12.6907 - val_loss: 190.9308 - val_mae: 10.9016\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 269.2441 - mae: 12.6712 - val_loss: 190.5952 - val_mae: 10.8854\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 268.8438 - mae: 12.6572 - val_loss: 190.2374 - val_mae: 10.8673\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 268.4315 - mae: 12.6391 - val_loss: 189.8589 - val_mae: 10.8475\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 268.0457 - mae: 12.6231 - val_loss: 189.5409 - val_mae: 10.8313\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.6638 - mae: 12.6035 - val_loss: 189.2115 - val_mae: 10.8144\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.3134 - mae: 12.5857 - val_loss: 188.9813 - val_mae: 10.8046\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.9611 - mae: 12.5764 - val_loss: 188.7725 - val_mae: 10.7950\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=nesterov; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 22ms/step - loss: 933.7532 - mae: 25.0144 - val_loss: 757.9430 - val_mae: 22.6826\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 792.2557 - mae: 23.4631 - val_loss: 638.6238 - val_mae: 21.2604\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 700.9519 - mae: 22.3354 - val_loss: 558.5434 - val_mae: 20.1863\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.7161 - mae: 21.4857 - val_loss: 501.7659 - val_mae: 19.3377\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.4800 - mae: 20.8068 - val_loss: 460.8317 - val_mae: 18.6682\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 562.2921 - mae: 20.2792 - val_loss: 429.7006 - val_mae: 18.1113\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 537.7670 - mae: 19.8333 - val_loss: 406.1212 - val_mae: 17.6531\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.2328 - mae: 19.4769 - val_loss: 387.5153 - val_mae: 17.2683\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.5506 - mae: 19.1805 - val_loss: 372.3601 - val_mae: 16.9396\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.7136 - mae: 18.9150 - val_loss: 360.5207 - val_mae: 16.6683\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.3334 - mae: 18.7128 - val_loss: 350.6653 - val_mae: 16.4295\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 475.4271 - mae: 18.5245 - val_loss: 342.4168 - val_mae: 16.2251\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.7018 - mae: 18.3651 - val_loss: 335.0852 - val_mae: 16.0416\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.6802 - mae: 18.2194 - val_loss: 328.2899 - val_mae: 15.8689\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.0555 - mae: 18.0778 - val_loss: 322.2398 - val_mae: 15.7055\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.9885 - mae: 17.9496 - val_loss: 316.6248 - val_mae: 15.5420\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.3140 - mae: 17.8210 - val_loss: 311.7702 - val_mae: 15.3908\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.0066 - mae: 17.7019 - val_loss: 307.0703 - val_mae: 15.2366\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.7719 - mae: 17.5765 - val_loss: 302.8553 - val_mae: 15.0881\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.8641 - mae: 17.4591 - val_loss: 298.9586 - val_mae: 14.9443\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.2587 - mae: 17.3529 - val_loss: 295.3489 - val_mae: 14.8093\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.8144 - mae: 17.2512 - val_loss: 292.2094 - val_mae: 14.6910\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.6566 - mae: 17.1553 - val_loss: 289.4325 - val_mae: 14.5836\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.7199 - mae: 17.0708 - val_loss: 286.8114 - val_mae: 14.4848\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.0597 - mae: 16.9918 - val_loss: 284.5160 - val_mae: 14.3991\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.6723 - mae: 16.9230 - val_loss: 282.3504 - val_mae: 14.3226\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.4302 - mae: 16.8557 - val_loss: 280.4113 - val_mae: 14.2576\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.3301 - mae: 16.7933 - val_loss: 278.6893 - val_mae: 14.2002\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.2600 - mae: 16.7330 - val_loss: 277.1265 - val_mae: 14.1455\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 408.2824 - mae: 16.6785 - val_loss: 275.4362 - val_mae: 14.0835\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 406.3299 - mae: 16.6179 - val_loss: 273.6684 - val_mae: 14.0209\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.1600 - mae: 16.5562 - val_loss: 271.7988 - val_mae: 13.9562\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.0511 - mae: 16.4956 - val_loss: 269.9688 - val_mae: 13.8895\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.9636 - mae: 16.4313 - val_loss: 268.2141 - val_mae: 13.8240\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.8778 - mae: 16.3688 - val_loss: 266.5150 - val_mae: 13.7568\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.8859 - mae: 16.3071 - val_loss: 265.0272 - val_mae: 13.6965\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.9397 - mae: 16.2455 - val_loss: 263.6463 - val_mae: 13.6402\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.1302 - mae: 16.1918 - val_loss: 262.2256 - val_mae: 13.5852\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.5224 - mae: 16.1399 - val_loss: 260.8762 - val_mae: 13.5333\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.9225 - mae: 16.0867 - val_loss: 259.6593 - val_mae: 13.4882\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.4834 - mae: 16.0414 - val_loss: 258.5757 - val_mae: 13.4450\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.1502 - mae: 15.9940 - val_loss: 257.5684 - val_mae: 13.4026\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.9402 - mae: 15.9570 - val_loss: 256.6522 - val_mae: 13.3649\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.8544 - mae: 15.9177 - val_loss: 255.9162 - val_mae: 13.3363\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.8098 - mae: 15.8854 - val_loss: 255.3195 - val_mae: 13.3128\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.8721 - mae: 15.8614 - val_loss: 254.6281 - val_mae: 13.2862\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.0113 - mae: 15.8294 - val_loss: 254.0992 - val_mae: 13.2654\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.2301 - mae: 15.8065 - val_loss: 253.5835 - val_mae: 13.2445\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.5430 - mae: 15.7867 - val_loss: 253.0473 - val_mae: 13.2228\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 378.8453 - mae: 15.7626 - val_loss: 252.6048 - val_mae: 13.2053\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 378.2546 - mae: 15.7448 - val_loss: 252.2031 - val_mae: 13.1893\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.6906 - mae: 15.7261 - val_loss: 251.6675 - val_mae: 13.1690\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.1935 - mae: 15.7064 - val_loss: 251.2390 - val_mae: 13.1522\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.6968 - mae: 15.6910 - val_loss: 250.8165 - val_mae: 13.1355\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 376.2140 - mae: 15.6729 - val_loss: 250.4867 - val_mae: 13.1223\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.7612 - mae: 15.6545 - val_loss: 250.2036 - val_mae: 13.1109\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.3499 - mae: 15.6401 - val_loss: 249.9028 - val_mae: 13.0984\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.9672 - mae: 15.6284 - val_loss: 249.5858 - val_mae: 13.0848\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.5799 - mae: 15.6156 - val_loss: 249.3249 - val_mae: 13.0736\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.2259 - mae: 15.6029 - val_loss: 249.0366 - val_mae: 13.0616\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 373.9072 - mae: 15.5920 - val_loss: 248.8215 - val_mae: 13.0525\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.6252 - mae: 15.5794 - val_loss: 248.5741 - val_mae: 13.0419\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.3182 - mae: 15.5694 - val_loss: 248.3911 - val_mae: 13.0336\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.0291 - mae: 15.5636 - val_loss: 248.1386 - val_mae: 13.0225\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.7365 - mae: 15.5516 - val_loss: 247.7480 - val_mae: 13.0061\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.4509 - mae: 15.5328 - val_loss: 247.5569 - val_mae: 12.9973\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.2124 - mae: 15.5301 - val_loss: 247.2765 - val_mae: 12.9848\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.9409 - mae: 15.5172 - val_loss: 247.0873 - val_mae: 12.9758\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.7089 - mae: 15.5060 - val_loss: 246.9926 - val_mae: 12.9702\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.4608 - mae: 15.4970 - val_loss: 246.9452 - val_mae: 12.9666\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.2220 - mae: 15.4924 - val_loss: 246.7723 - val_mae: 12.9589\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 371.0081 - mae: 15.4821 - val_loss: 246.6505 - val_mae: 12.9533\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 370.7857 - mae: 15.4794 - val_loss: 246.4503 - val_mae: 12.9443\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 370.5812 - mae: 15.4683 - val_loss: 246.3729 - val_mae: 12.9402\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 370.3642 - mae: 15.4606 - val_loss: 246.2172 - val_mae: 12.9328\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 370.1541 - mae: 15.4561 - val_loss: 246.0558 - val_mae: 12.9252\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.9196 - mae: 15.4493 - val_loss: 245.8882 - val_mae: 12.9173\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 369.7063 - mae: 15.4394 - val_loss: 245.7247 - val_mae: 12.9095\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.5042 - mae: 15.4298 - val_loss: 245.6471 - val_mae: 12.9059\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.2928 - mae: 15.4260 - val_loss: 245.4799 - val_mae: 12.8981\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.1051 - mae: 15.4183 - val_loss: 245.3270 - val_mae: 12.8910\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.8860 - mae: 15.4156 - val_loss: 245.1640 - val_mae: 12.8834\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.6781 - mae: 15.4081 - val_loss: 244.9198 - val_mae: 12.8727\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.4686 - mae: 15.4028 - val_loss: 244.6897 - val_mae: 12.8628\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.2133 - mae: 15.3847 - val_loss: 244.5414 - val_mae: 12.8570\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.9871 - mae: 15.3806 - val_loss: 244.4440 - val_mae: 12.8541\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.7258 - mae: 15.3763 - val_loss: 244.2149 - val_mae: 12.8459\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.4067 - mae: 15.3672 - val_loss: 244.0034 - val_mae: 12.8398\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.0312 - mae: 15.3619 - val_loss: 243.7177 - val_mae: 12.8313\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 366.6718 - mae: 15.3555 - val_loss: 243.3679 - val_mae: 12.8215\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.1828 - mae: 15.3401 - val_loss: 243.0951 - val_mae: 12.8151\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.7213 - mae: 15.3325 - val_loss: 242.7871 - val_mae: 12.8077\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 365.1559 - mae: 15.3194 - val_loss: 242.3275 - val_mae: 12.7963\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 364.4887 - mae: 15.3079 - val_loss: 241.8078 - val_mae: 12.7846\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.6093 - mae: 15.2930 - val_loss: 241.0686 - val_mae: 12.7663\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.6719 - mae: 15.2745 - val_loss: 240.2667 - val_mae: 12.7454\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.7356 - mae: 15.2537 - val_loss: 239.4912 - val_mae: 12.7239\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.8420 - mae: 15.2302 - val_loss: 238.7459 - val_mae: 12.7025\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.0215 - mae: 15.2090 - val_loss: 238.1293 - val_mae: 12.6849\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.2437 - mae: 15.1915 - val_loss: 237.4450 - val_mae: 12.6631\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=nesterov; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 1006.7726 - mae: 24.9342 - val_loss: 850.7458 - val_mae: 23.5225\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 779.8514 - mae: 22.6761 - val_loss: 682.9810 - val_mae: 21.6496\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 653.8260 - mae: 21.1725 - val_loss: 583.7422 - val_mae: 20.3819\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 576.4263 - mae: 20.1277 - val_loss: 521.4993 - val_mae: 19.4674\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 526.5458 - mae: 19.3803 - val_loss: 480.3388 - val_mae: 18.7960\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 492.1689 - mae: 18.8191 - val_loss: 449.6834 - val_mae: 18.2566\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.1057 - mae: 18.3605 - val_loss: 427.2587 - val_mae: 17.8274\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 446.6582 - mae: 17.9995 - val_loss: 410.5965 - val_mae: 17.4835\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 431.4257 - mae: 17.7060 - val_loss: 397.3723 - val_mae: 17.1923\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 418.9111 - mae: 17.4491 - val_loss: 386.1243 - val_mae: 16.9267\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 408.3310 - mae: 17.2246 - val_loss: 376.5272 - val_mae: 16.6836\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 399.3430 - mae: 17.0271 - val_loss: 368.4292 - val_mae: 16.4748\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.6877 - mae: 16.8488 - val_loss: 361.2018 - val_mae: 16.2931\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 384.7941 - mae: 16.6830 - val_loss: 354.9959 - val_mae: 16.1373\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.6934 - mae: 16.5369 - val_loss: 349.4331 - val_mae: 15.9970\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.1896 - mae: 16.4005 - val_loss: 344.4963 - val_mae: 15.8667\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.2886 - mae: 16.2775 - val_loss: 339.9425 - val_mae: 15.7430\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.6664 - mae: 16.1606 - val_loss: 335.7804 - val_mae: 15.6271\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 359.4672 - mae: 16.0514 - val_loss: 331.9745 - val_mae: 15.5202\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 355.5327 - mae: 15.9481 - val_loss: 328.4524 - val_mae: 15.4198\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.9212 - mae: 15.8496 - val_loss: 325.1346 - val_mae: 15.3206\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 348.5628 - mae: 15.7549 - val_loss: 322.0461 - val_mae: 15.2276\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 345.4798 - mae: 15.6643 - val_loss: 319.2120 - val_mae: 15.1399\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 342.5846 - mae: 15.5801 - val_loss: 316.6242 - val_mae: 15.0571\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 339.9188 - mae: 15.4994 - val_loss: 314.2250 - val_mae: 14.9772\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 337.3762 - mae: 15.4235 - val_loss: 311.9875 - val_mae: 14.8999\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 334.9990 - mae: 15.3501 - val_loss: 309.8596 - val_mae: 14.8256\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.7152 - mae: 15.2776 - val_loss: 307.9553 - val_mae: 14.7586\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.6150 - mae: 15.2120 - val_loss: 306.0682 - val_mae: 14.6918\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 328.5947 - mae: 15.1483 - val_loss: 304.3217 - val_mae: 14.6313\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 326.6550 - mae: 15.0878 - val_loss: 302.6612 - val_mae: 14.5717\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.8456 - mae: 15.0321 - val_loss: 300.9999 - val_mae: 14.5114\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.0927 - mae: 14.9778 - val_loss: 299.3589 - val_mae: 14.4548\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 321.3770 - mae: 14.9219 - val_loss: 297.7592 - val_mae: 14.3999\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 319.7495 - mae: 14.8720 - val_loss: 296.2606 - val_mae: 14.3476\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.2008 - mae: 14.8232 - val_loss: 294.8261 - val_mae: 14.2973\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.7784 - mae: 14.7764 - val_loss: 293.4453 - val_mae: 14.2476\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 315.3769 - mae: 14.7322 - val_loss: 292.1444 - val_mae: 14.2022\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 314.0807 - mae: 14.6899 - val_loss: 290.9216 - val_mae: 14.1619\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 312.8066 - mae: 14.6479 - val_loss: 289.7511 - val_mae: 14.1227\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 311.6101 - mae: 14.6103 - val_loss: 288.6500 - val_mae: 14.0858\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.4500 - mae: 14.5734 - val_loss: 287.5219 - val_mae: 14.0469\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.2475 - mae: 14.5318 - val_loss: 286.3990 - val_mae: 14.0090\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 308.1167 - mae: 14.4955 - val_loss: 285.3255 - val_mae: 13.9719\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 306.9599 - mae: 14.4581 - val_loss: 284.2707 - val_mae: 13.9357\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 305.8502 - mae: 14.4219 - val_loss: 283.1624 - val_mae: 13.8979\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 304.6706 - mae: 14.3843 - val_loss: 282.0467 - val_mae: 13.8603\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.4867 - mae: 14.3478 - val_loss: 280.9546 - val_mae: 13.8247\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 302.3065 - mae: 14.3119 - val_loss: 279.8305 - val_mae: 13.7869\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 301.1515 - mae: 14.2733 - val_loss: 278.7437 - val_mae: 13.7520\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 299.9137 - mae: 14.2360 - val_loss: 277.7078 - val_mae: 13.7192\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 298.7334 - mae: 14.1999 - val_loss: 276.6728 - val_mae: 13.6860\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 297.5473 - mae: 14.1654 - val_loss: 275.6410 - val_mae: 13.6488\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 296.3498 - mae: 14.1260 - val_loss: 274.6035 - val_mae: 13.6152\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.1331 - mae: 14.0881 - val_loss: 273.6289 - val_mae: 13.5852\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.9782 - mae: 14.0552 - val_loss: 272.6991 - val_mae: 13.5543\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.8553 - mae: 14.0200 - val_loss: 271.7698 - val_mae: 13.5231\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.8348 - mae: 13.9859 - val_loss: 270.8785 - val_mae: 13.4950\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.7417 - mae: 13.9518 - val_loss: 270.0030 - val_mae: 13.4646\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.7281 - mae: 13.9182 - val_loss: 269.1967 - val_mae: 13.4374\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 288.7277 - mae: 13.8853 - val_loss: 268.3771 - val_mae: 13.4098\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.6945 - mae: 13.8517 - val_loss: 267.5179 - val_mae: 13.3794\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.6691 - mae: 13.8171 - val_loss: 266.6396 - val_mae: 13.3476\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.5382 - mae: 13.7787 - val_loss: 265.7231 - val_mae: 13.3141\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.4711 - mae: 13.7419 - val_loss: 264.8405 - val_mae: 13.2818\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.3993 - mae: 13.7072 - val_loss: 263.9396 - val_mae: 13.2486\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.3239 - mae: 13.6730 - val_loss: 263.0288 - val_mae: 13.2138\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.2912 - mae: 13.6375 - val_loss: 262.1237 - val_mae: 13.1774\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.2787 - mae: 13.6013 - val_loss: 261.2332 - val_mae: 13.1451\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.2867 - mae: 13.5684 - val_loss: 260.2980 - val_mae: 13.1108\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.3005 - mae: 13.5332 - val_loss: 259.3621 - val_mae: 13.0769\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.3300 - mae: 13.4996 - val_loss: 258.4642 - val_mae: 13.0475\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.3191 - mae: 13.4674 - val_loss: 257.5154 - val_mae: 13.0147\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.3280 - mae: 13.4321 - val_loss: 256.5783 - val_mae: 12.9819\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 274.2356 - mae: 13.3957 - val_loss: 255.5043 - val_mae: 12.9498\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.0118 - mae: 13.3581 - val_loss: 254.3707 - val_mae: 12.9110\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.7439 - mae: 13.3171 - val_loss: 253.1959 - val_mae: 12.8723\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.4114 - mae: 13.2754 - val_loss: 251.9489 - val_mae: 12.8380\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.0292 - mae: 13.2342 - val_loss: 250.6215 - val_mae: 12.7978\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.6318 - mae: 13.1900 - val_loss: 249.2602 - val_mae: 12.7573\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.2868 - mae: 13.1495 - val_loss: 247.9589 - val_mae: 12.7155\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 265.0121 - mae: 13.1022 - val_loss: 246.8010 - val_mae: 12.6816\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.8168 - mae: 13.0656 - val_loss: 245.6914 - val_mae: 12.6457\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.6553 - mae: 13.0280 - val_loss: 244.6312 - val_mae: 12.6075\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 261.5209 - mae: 12.9915 - val_loss: 243.5377 - val_mae: 12.5674\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.3781 - mae: 12.9464 - val_loss: 242.4735 - val_mae: 12.5346\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.2407 - mae: 12.9134 - val_loss: 241.4157 - val_mae: 12.4954\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.1369 - mae: 12.8727 - val_loss: 240.3274 - val_mae: 12.4579\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.9481 - mae: 12.8355 - val_loss: 239.2521 - val_mae: 12.4178\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.6317 - mae: 12.7896 - val_loss: 238.1230 - val_mae: 12.3765\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.2174 - mae: 12.7442 - val_loss: 236.8961 - val_mae: 12.3316\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.5247 - mae: 12.6887 - val_loss: 235.6298 - val_mae: 12.2880\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 250.7655 - mae: 12.6336 - val_loss: 234.1964 - val_mae: 12.2370\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.9673 - mae: 12.5753 - val_loss: 232.7841 - val_mae: 12.1857\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.3582 - mae: 12.5206 - val_loss: 231.4522 - val_mae: 12.1337\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.8901 - mae: 12.4674 - val_loss: 230.1511 - val_mae: 12.0794\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.4856 - mae: 12.4133 - val_loss: 228.9745 - val_mae: 12.0295\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.0572 - mae: 12.3618 - val_loss: 227.8199 - val_mae: 11.9750\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241.5587 - mae: 12.3047 - val_loss: 226.6705 - val_mae: 11.9248\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 240.1618 - mae: 12.2490 - val_loss: 225.5168 - val_mae: 11.8748\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=nesterov; total time=   4.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 599.2286 - mae: 21.3742 - val_loss: 362.8805 - val_mae: 17.4855\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.7529 - mae: 19.8432 - val_loss: 356.8748 - val_mae: 17.2601\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 487.9090 - mae: 19.5917 - val_loss: 353.8577 - val_mae: 16.9462\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.5026 - mae: 19.3565 - val_loss: 353.4836 - val_mae: 17.0424\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.8521 - mae: 19.3018 - val_loss: 359.4077 - val_mae: 17.3052\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.6484 - mae: 19.1961 - val_loss: 354.2792 - val_mae: 16.9968\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.0975 - mae: 19.1238 - val_loss: 354.6033 - val_mae: 17.0969\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.8185 - mae: 19.0658 - val_loss: 351.2447 - val_mae: 16.9145\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.3470 - mae: 18.9968 - val_loss: 349.8116 - val_mae: 16.9899\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.2829 - mae: 18.9706 - val_loss: 344.4490 - val_mae: 16.7018\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.5558 - mae: 18.8574 - val_loss: 342.2531 - val_mae: 16.6192\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.2778 - mae: 18.8520 - val_loss: 342.7004 - val_mae: 16.6574\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.5033 - mae: 18.8011 - val_loss: 341.9742 - val_mae: 16.6359\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.3406 - mae: 18.6964 - val_loss: 338.4904 - val_mae: 16.4980\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.9047 - mae: 18.5453 - val_loss: 335.4788 - val_mae: 16.3997\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.1799 - mae: 18.4516 - val_loss: 333.0945 - val_mae: 16.2441\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.4643 - mae: 18.3079 - val_loss: 327.5038 - val_mae: 16.1399\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.6669 - mae: 18.2090 - val_loss: 324.0773 - val_mae: 15.7768\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.6767 - mae: 17.9692 - val_loss: 322.2423 - val_mae: 15.6964\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.4821 - mae: 17.9415 - val_loss: 316.4909 - val_mae: 15.5457\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 432.3902 - mae: 17.8756 - val_loss: 315.6822 - val_mae: 15.6020\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.7031 - mae: 17.8602 - val_loss: 318.7805 - val_mae: 15.5594\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.3891 - mae: 17.7446 - val_loss: 311.7301 - val_mae: 15.3130\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.8430 - mae: 17.6803 - val_loss: 311.7386 - val_mae: 15.3120\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.7726 - mae: 17.5772 - val_loss: 308.0442 - val_mae: 15.1897\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.4175 - mae: 17.5784 - val_loss: 310.1581 - val_mae: 15.2267\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.8963 - mae: 17.4844 - val_loss: 305.9443 - val_mae: 15.2272\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.0267 - mae: 17.4259 - val_loss: 302.9445 - val_mae: 15.0197\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 416.0691 - mae: 17.3245 - val_loss: 301.9861 - val_mae: 14.9945\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 414.9084 - mae: 17.3126 - val_loss: 301.3727 - val_mae: 14.9424\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.4703 - mae: 17.3138 - val_loss: 301.4431 - val_mae: 14.9256\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.5246 - mae: 17.2551 - val_loss: 306.0726 - val_mae: 15.1052\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.0168 - mae: 17.1810 - val_loss: 297.0768 - val_mae: 14.6814\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.4989 - mae: 17.1285 - val_loss: 300.3869 - val_mae: 14.9048\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.7625 - mae: 17.1008 - val_loss: 296.9438 - val_mae: 14.7729\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.3383 - mae: 17.1140 - val_loss: 294.8676 - val_mae: 14.6168\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.4231 - mae: 17.0333 - val_loss: 295.5715 - val_mae: 14.7061\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.6410 - mae: 16.9929 - val_loss: 295.4829 - val_mae: 14.7062\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.6618 - mae: 17.0039 - val_loss: 293.3877 - val_mae: 14.5723\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.2044 - mae: 16.9131 - val_loss: 292.2375 - val_mae: 14.4739\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.9794 - mae: 16.8306 - val_loss: 288.1927 - val_mae: 14.2894\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.2205 - mae: 16.4841 - val_loss: 285.3807 - val_mae: 14.1669\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.2934 - mae: 16.4059 - val_loss: 284.0376 - val_mae: 14.0458\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.2130 - mae: 16.3813 - val_loss: 284.8181 - val_mae: 14.1307\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.3276 - mae: 16.3518 - val_loss: 288.6700 - val_mae: 14.4275\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.0077 - mae: 16.3516 - val_loss: 283.6349 - val_mae: 14.0802\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.1872 - mae: 16.3101 - val_loss: 283.9351 - val_mae: 14.1299\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.5302 - mae: 16.2886 - val_loss: 284.5173 - val_mae: 14.1912\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.1657 - mae: 16.2734 - val_loss: 283.3602 - val_mae: 14.0767\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.5160 - mae: 16.2534 - val_loss: 283.0520 - val_mae: 14.0590\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.5962 - mae: 16.2170 - val_loss: 285.5689 - val_mae: 14.2724\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.0997 - mae: 16.2317 - val_loss: 283.3096 - val_mae: 14.0914\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.8879 - mae: 16.2330 - val_loss: 281.7001 - val_mae: 13.9831\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.7527 - mae: 16.0920 - val_loss: 283.6277 - val_mae: 14.1132\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.6249 - mae: 16.1873 - val_loss: 281.5695 - val_mae: 13.9127\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.3137 - mae: 16.0997 - val_loss: 285.2228 - val_mae: 14.2308\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.1641 - mae: 16.1487 - val_loss: 281.4122 - val_mae: 13.9001\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.6040 - mae: 16.0858 - val_loss: 281.4095 - val_mae: 13.9402\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.2422 - mae: 16.0477 - val_loss: 282.7887 - val_mae: 13.9798\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.9580 - mae: 16.0486 - val_loss: 282.2321 - val_mae: 13.9261\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 383.1585 - mae: 16.0406 - val_loss: 281.7389 - val_mae: 13.8357\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.3549 - mae: 16.0290 - val_loss: 282.8916 - val_mae: 13.9556\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.5550 - mae: 16.0740 - val_loss: 280.0727 - val_mae: 13.8097\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.9029 - mae: 15.9713 - val_loss: 282.4778 - val_mae: 14.0223\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.4800 - mae: 16.0257 - val_loss: 280.3868 - val_mae: 13.8006\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.6127 - mae: 15.9578 - val_loss: 281.1891 - val_mae: 13.8408\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.3862 - mae: 15.9652 - val_loss: 281.9449 - val_mae: 13.9115\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.2408 - mae: 15.9549 - val_loss: 280.6405 - val_mae: 13.8366\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.0406 - mae: 15.9408 - val_loss: 281.9648 - val_mae: 13.9203\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.4892 - mae: 15.9502 - val_loss: 281.3332 - val_mae: 13.8634\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.3666 - mae: 15.8756 - val_loss: 282.6128 - val_mae: 14.0701\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.5054 - mae: 15.9651 - val_loss: 280.6849 - val_mae: 13.8439\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.0954 - mae: 15.9071 - val_loss: 281.5040 - val_mae: 13.9811\n",
      "Epoch 73: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=nesterov; total time=   3.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 880.9423 - mae: 24.2667 - val_loss: 444.8487 - val_mae: 18.1932\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.3928 - mae: 20.4812 - val_loss: 350.5330 - val_mae: 16.7581\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 483.8784 - mae: 18.9823 - val_loss: 321.4182 - val_mae: 16.0077\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 448.8721 - mae: 18.0039 - val_loss: 290.2824 - val_mae: 15.0273\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 427.3890 - mae: 17.4433 - val_loss: 284.7518 - val_mae: 14.8169\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.3338 - mae: 16.9836 - val_loss: 277.6676 - val_mae: 14.4836\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.5385 - mae: 16.6555 - val_loss: 265.9265 - val_mae: 13.9321\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.7536 - mae: 16.4481 - val_loss: 261.4773 - val_mae: 13.7191\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.2292 - mae: 16.2040 - val_loss: 268.9955 - val_mae: 14.1179\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.6175 - mae: 16.1934 - val_loss: 257.3665 - val_mae: 13.5547\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.5835 - mae: 16.0351 - val_loss: 259.1725 - val_mae: 13.6530\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.7724 - mae: 15.9438 - val_loss: 258.8351 - val_mae: 13.6409\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.4011 - mae: 15.9521 - val_loss: 258.8380 - val_mae: 13.7114\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 379.7000 - mae: 15.9455 - val_loss: 248.3131 - val_mae: 13.1749\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 378.5865 - mae: 15.8674 - val_loss: 248.8342 - val_mae: 13.2952\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.8988 - mae: 15.9145 - val_loss: 246.8695 - val_mae: 13.2476\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.4341 - mae: 15.8860 - val_loss: 244.8560 - val_mae: 13.1498\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.8057 - mae: 15.8240 - val_loss: 250.9945 - val_mae: 13.5208\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.5784 - mae: 15.7998 - val_loss: 248.8626 - val_mae: 13.4924\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.0010 - mae: 15.7888 - val_loss: 245.1973 - val_mae: 13.3287\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.4334 - mae: 15.7225 - val_loss: 239.6216 - val_mae: 13.1026\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.8769 - mae: 15.6042 - val_loss: 247.9890 - val_mae: 13.6511\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 356.1338 - mae: 15.4128 - val_loss: 227.5663 - val_mae: 12.6213\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 350.2773 - mae: 15.1919 - val_loss: 225.9974 - val_mae: 12.6429\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 346.2315 - mae: 15.0863 - val_loss: 222.9431 - val_mae: 12.4704\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.5526 - mae: 14.9504 - val_loss: 219.7262 - val_mae: 12.2399\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.1762 - mae: 14.8615 - val_loss: 220.2000 - val_mae: 12.3376\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.9745 - mae: 14.8437 - val_loss: 217.3530 - val_mae: 12.1356\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.1242 - mae: 14.7415 - val_loss: 217.3810 - val_mae: 12.1098\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.4668 - mae: 14.7028 - val_loss: 216.5018 - val_mae: 12.1266\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 332.6110 - mae: 14.6583 - val_loss: 216.3836 - val_mae: 12.1307\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 331.5515 - mae: 14.6132 - val_loss: 216.3837 - val_mae: 12.1577\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.6575 - mae: 14.6396 - val_loss: 216.1080 - val_mae: 12.1498\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 330.4063 - mae: 14.6338 - val_loss: 215.1487 - val_mae: 12.0622\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 328.8499 - mae: 14.5778 - val_loss: 214.1352 - val_mae: 11.9732\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 328.2910 - mae: 14.5090 - val_loss: 213.5917 - val_mae: 11.9272\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.4299 - mae: 14.4962 - val_loss: 213.1726 - val_mae: 11.8498\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 327.1341 - mae: 14.4976 - val_loss: 213.2956 - val_mae: 11.9385\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 326.4604 - mae: 14.4889 - val_loss: 212.5289 - val_mae: 11.8062\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.4600 - mae: 14.4187 - val_loss: 212.7757 - val_mae: 11.8362\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.1527 - mae: 14.4472 - val_loss: 211.8457 - val_mae: 11.8254\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.4189 - mae: 14.3969 - val_loss: 211.9114 - val_mae: 11.8502\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 324.0400 - mae: 14.4045 - val_loss: 209.2054 - val_mae: 11.7416\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 320.6786 - mae: 14.2749 - val_loss: 191.4462 - val_mae: 11.1711\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 287.4496 - mae: 13.3195 - val_loss: 139.7649 - val_mae: 9.0388\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 230.7718 - mae: 11.4510 - val_loss: 132.2710 - val_mae: 8.9112\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 221.3522 - mae: 11.3335 - val_loss: 133.1757 - val_mae: 9.0395\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 219.3567 - mae: 11.3729 - val_loss: 132.8336 - val_mae: 9.0337\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 218.8695 - mae: 11.3443 - val_loss: 132.8592 - val_mae: 9.0571\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 217.9101 - mae: 11.2933 - val_loss: 133.8339 - val_mae: 9.1636\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 218.2562 - mae: 11.3258 - val_loss: 133.4845 - val_mae: 9.1254\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 217.4282 - mae: 11.2868 - val_loss: 134.0636 - val_mae: 9.1665\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 217.3552 - mae: 11.3101 - val_loss: 135.8483 - val_mae: 9.2834\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 217.1706 - mae: 11.3532 - val_loss: 133.3161 - val_mae: 9.1279\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.7815 - mae: 11.3129 - val_loss: 131.4376 - val_mae: 9.0035\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.3307 - mae: 11.2888 - val_loss: 131.0612 - val_mae: 8.9943\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 216.3268 - mae: 11.1978 - val_loss: 131.2633 - val_mae: 8.9692\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 216.4792 - mae: 11.2417 - val_loss: 131.5864 - val_mae: 9.0382\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 215.8652 - mae: 11.2128 - val_loss: 131.1484 - val_mae: 9.0039\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 215.6088 - mae: 11.2237 - val_loss: 132.1799 - val_mae: 9.0454\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 215.3739 - mae: 11.2557 - val_loss: 130.5584 - val_mae: 8.9543\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 215.0044 - mae: 11.1735 - val_loss: 130.9276 - val_mae: 9.0231\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 215.0935 - mae: 11.2275 - val_loss: 131.1124 - val_mae: 8.9956\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.4634 - mae: 11.2149 - val_loss: 129.0700 - val_mae: 8.8397\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.5320 - mae: 11.1375 - val_loss: 129.7910 - val_mae: 8.8774\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.5501 - mae: 11.1910 - val_loss: 130.3038 - val_mae: 8.9192\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214.3845 - mae: 11.1759 - val_loss: 131.4050 - val_mae: 9.0271\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 213.7852 - mae: 11.2635 - val_loss: 127.6927 - val_mae: 8.7190\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 214.0226 - mae: 11.1467 - val_loss: 127.1763 - val_mae: 8.7185\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 213.7672 - mae: 11.0667 - val_loss: 127.7503 - val_mae: 8.7782\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 213.2764 - mae: 11.0804 - val_loss: 128.8553 - val_mae: 8.8232\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 213.4503 - mae: 11.0834 - val_loss: 132.3325 - val_mae: 9.0985\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 213.5781 - mae: 11.2419 - val_loss: 128.3067 - val_mae: 8.8016\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 213.0772 - mae: 11.0966 - val_loss: 127.1820 - val_mae: 8.7009\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 213.1369 - mae: 11.1332 - val_loss: 126.8496 - val_mae: 8.7004\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212.3044 - mae: 11.0050 - val_loss: 129.6303 - val_mae: 8.8993\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212.1951 - mae: 11.1402 - val_loss: 126.5337 - val_mae: 8.6735\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 212.2903 - mae: 11.0241 - val_loss: 128.0769 - val_mae: 8.7806\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212.3494 - mae: 11.0629 - val_loss: 127.8216 - val_mae: 8.7633\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212.0337 - mae: 11.0488 - val_loss: 128.6647 - val_mae: 8.8341\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 211.8833 - mae: 11.1174 - val_loss: 126.8252 - val_mae: 8.7107\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 211.3157 - mae: 11.0425 - val_loss: 126.0145 - val_mae: 8.6629\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 211.5611 - mae: 10.9657 - val_loss: 128.8009 - val_mae: 8.8288\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 211.2904 - mae: 11.0367 - val_loss: 128.1267 - val_mae: 8.7900\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 210.9071 - mae: 11.0131 - val_loss: 128.2045 - val_mae: 8.8089\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 211.5996 - mae: 11.0774 - val_loss: 126.9499 - val_mae: 8.7216\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 210.8789 - mae: 11.0444 - val_loss: 127.2362 - val_mae: 8.7048\n",
      "Epoch 87: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=nesterov; total time=   4.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1729.1713 - mae: 26.4117 - val_loss: 545.7122 - val_mae: 21.7516\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 558.1027 - mae: 21.8981 - val_loss: 546.6027 - val_mae: 21.7792\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.7610 - mae: 21.8565 - val_loss: 544.7440 - val_mae: 21.7223\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 555.1003 - mae: 21.8093 - val_loss: 536.9631 - val_mae: 21.3276\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 551.1924 - mae: 21.6407 - val_loss: 535.5777 - val_mae: 21.1167\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 549.5294 - mae: 21.5383 - val_loss: 535.7333 - val_mae: 21.1509\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2720 - mae: 21.5145 - val_loss: 535.5911 - val_mae: 21.1413\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 546.6140 - mae: 21.4656 - val_loss: 535.7807 - val_mae: 21.1949\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 544.8099 - mae: 21.4559 - val_loss: 534.2610 - val_mae: 21.2348\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 541.0209 - mae: 21.3926 - val_loss: 532.8973 - val_mae: 21.3988\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.6288 - mae: 21.1319 - val_loss: 519.3703 - val_mae: 20.9959\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 510.3253 - mae: 20.5108 - val_loss: 502.8680 - val_mae: 20.4551\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 498.2643 - mae: 20.0866 - val_loss: 495.6741 - val_mae: 20.1321\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.4980 - mae: 19.8290 - val_loss: 487.8068 - val_mae: 19.9078\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 484.9283 - mae: 19.6227 - val_loss: 481.7746 - val_mae: 19.7990\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 482.2300 - mae: 19.5496 - val_loss: 477.0042 - val_mae: 19.6543\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 479.1487 - mae: 19.4501 - val_loss: 475.7835 - val_mae: 19.6598\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.3914 - mae: 19.4080 - val_loss: 472.4547 - val_mae: 19.4515\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.6218 - mae: 19.3498 - val_loss: 468.3321 - val_mae: 19.3717\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.2468 - mae: 19.3404 - val_loss: 466.8305 - val_mae: 19.3317\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.0606 - mae: 19.2950 - val_loss: 465.6797 - val_mae: 19.3005\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.4081 - mae: 19.2744 - val_loss: 464.6211 - val_mae: 19.2704\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 472.5725 - mae: 19.2857 - val_loss: 463.7363 - val_mae: 19.2400\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.3152 - mae: 19.2586 - val_loss: 463.3714 - val_mae: 19.2385\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.0368 - mae: 19.2521 - val_loss: 463.9709 - val_mae: 19.2546\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 470.4719 - mae: 19.2364 - val_loss: 462.0319 - val_mae: 19.1858\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.9966 - mae: 19.2243 - val_loss: 460.7809 - val_mae: 19.1438\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.6249 - mae: 19.1968 - val_loss: 460.2806 - val_mae: 19.1314\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.3838 - mae: 19.1976 - val_loss: 460.7423 - val_mae: 19.1272\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.8796 - mae: 19.1594 - val_loss: 459.3615 - val_mae: 19.1059\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.6559 - mae: 19.1624 - val_loss: 459.7274 - val_mae: 19.0838\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.7202 - mae: 19.1496 - val_loss: 458.8599 - val_mae: 19.0629\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.1381 - mae: 19.1283 - val_loss: 458.1760 - val_mae: 19.0613\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.0550 - mae: 19.1299 - val_loss: 457.9524 - val_mae: 19.0376\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.9299 - mae: 19.1168 - val_loss: 457.5431 - val_mae: 19.0282\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.2458 - mae: 19.1445 - val_loss: 457.4623 - val_mae: 19.0135\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.3540 - mae: 19.0997 - val_loss: 458.2322 - val_mae: 19.0239\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.1811 - mae: 19.0848 - val_loss: 457.9586 - val_mae: 19.0136\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.3351 - mae: 19.0840 - val_loss: 457.3615 - val_mae: 19.0002\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.7637 - mae: 19.0531 - val_loss: 456.3434 - val_mae: 19.0020\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.0875 - mae: 19.0845 - val_loss: 456.7962 - val_mae: 18.9848\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.4920 - mae: 19.0485 - val_loss: 458.6621 - val_mae: 19.0122\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.4863 - mae: 19.0379 - val_loss: 456.2113 - val_mae: 18.9697\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.3733 - mae: 19.0428 - val_loss: 455.8615 - val_mae: 18.9602\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.4299 - mae: 19.0432 - val_loss: 455.7461 - val_mae: 18.9556\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.3343 - mae: 19.0382 - val_loss: 456.4662 - val_mae: 18.9569\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.1839 - mae: 19.0313 - val_loss: 456.2285 - val_mae: 18.9509\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.1396 - mae: 19.0257 - val_loss: 456.0431 - val_mae: 18.9451\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.9194 - mae: 19.0186 - val_loss: 455.7890 - val_mae: 18.9398\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.8242 - mae: 19.0135 - val_loss: 455.9900 - val_mae: 18.9345\n",
      "Epoch 50: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=nesterov; total time=   2.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 608.9960 - mae: 22.2362 - val_loss: 525.1969 - val_mae: 21.3014\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.9370 - mae: 22.2351 - val_loss: 525.1339 - val_mae: 21.3001\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.8806 - mae: 22.2340 - val_loss: 525.0705 - val_mae: 21.2988\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.8235 - mae: 22.2329 - val_loss: 525.0082 - val_mae: 21.2976\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 608.7648 - mae: 22.2317 - val_loss: 524.9471 - val_mae: 21.2963\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.7076 - mae: 22.2306 - val_loss: 524.8860 - val_mae: 21.2951\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.6519 - mae: 22.2296 - val_loss: 524.8241 - val_mae: 21.2938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.5936 - mae: 22.2284 - val_loss: 524.7630 - val_mae: 21.2926\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 608.5367 - mae: 22.2274 - val_loss: 524.7008 - val_mae: 21.2913\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.4793 - mae: 22.2262 - val_loss: 524.6382 - val_mae: 21.2901\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 608.4207 - mae: 22.2251 - val_loss: 524.5762 - val_mae: 21.2888\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   0.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 1951.0583 - mae: 32.0276 - val_loss: 1927.8170 - val_mae: 30.7506\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1950.7666 - mae: 32.0262 - val_loss: 1927.4750 - val_mae: 30.7486\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1950.4695 - mae: 32.0248 - val_loss: 1927.1382 - val_mae: 30.7466\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1950.1823 - mae: 32.0234 - val_loss: 1926.7998 - val_mae: 30.7446\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1949.8760 - mae: 32.0218 - val_loss: 1926.4722 - val_mae: 30.7427\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1949.5958 - mae: 32.0204 - val_loss: 1926.1338 - val_mae: 30.7407\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1949.2977 - mae: 32.0190 - val_loss: 1925.8018 - val_mae: 30.7387\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1949.0101 - mae: 32.0176 - val_loss: 1925.4686 - val_mae: 30.7367\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1948.7090 - mae: 32.0161 - val_loss: 1925.1450 - val_mae: 30.7348\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1948.4388 - mae: 32.0148 - val_loss: 1924.8080 - val_mae: 30.7328\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1948.1343 - mae: 32.0133 - val_loss: 1924.4904 - val_mae: 30.7308\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1947.8623 - mae: 32.0119 - val_loss: 1924.1572 - val_mae: 30.7288\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1947.5676 - mae: 32.0104 - val_loss: 1923.8302 - val_mae: 30.7269\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1947.2922 - mae: 32.0091 - val_loss: 1923.4950 - val_mae: 30.7249\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1946.9861 - mae: 32.0076 - val_loss: 1923.1752 - val_mae: 30.7229\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1946.7100 - mae: 32.0061 - val_loss: 1922.8458 - val_mae: 30.7210\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1946.4131 - mae: 32.0047 - val_loss: 1922.5197 - val_mae: 30.7190\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1946.1362 - mae: 32.0034 - val_loss: 1922.1813 - val_mae: 30.7170\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1945.8357 - mae: 32.0019 - val_loss: 1921.8566 - val_mae: 30.7151\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1945.5549 - mae: 32.0004 - val_loss: 1921.5258 - val_mae: 30.7131\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1945.2594 - mae: 31.9990 - val_loss: 1921.2017 - val_mae: 30.7111\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1944.9795 - mae: 31.9976 - val_loss: 1920.8669 - val_mae: 30.7092\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1944.6750 - mae: 31.9960 - val_loss: 1920.5415 - val_mae: 30.7072\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1944.3911 - mae: 31.9946 - val_loss: 1920.2091 - val_mae: 30.7052\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1944.1014 - mae: 31.9932 - val_loss: 1919.8760 - val_mae: 30.7032\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1943.8121 - mae: 31.9917 - val_loss: 1919.5428 - val_mae: 30.7012\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1943.5170 - mae: 31.9903 - val_loss: 1919.2186 - val_mae: 30.6993\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1943.2271 - mae: 31.9888 - val_loss: 1918.8932 - val_mae: 30.6973\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1942.9332 - mae: 31.9873 - val_loss: 1918.5664 - val_mae: 30.6953\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1942.6560 - mae: 31.9859 - val_loss: 1918.2286 - val_mae: 30.6933\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1942.3507 - mae: 31.9844 - val_loss: 1917.9095 - val_mae: 30.6914\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1942.0723 - mae: 31.9830 - val_loss: 1917.5791 - val_mae: 30.6894\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1941.7771 - mae: 31.9815 - val_loss: 1917.2467 - val_mae: 30.6874\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1941.4851 - mae: 31.9800 - val_loss: 1916.9147 - val_mae: 30.6854\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1941.1962 - mae: 31.9786 - val_loss: 1916.5889 - val_mae: 30.6835\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1940.9066 - mae: 31.9771 - val_loss: 1916.2609 - val_mae: 30.6815\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1940.6250 - mae: 31.9756 - val_loss: 1915.9280 - val_mae: 30.6795\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1940.3354 - mae: 31.9741 - val_loss: 1915.6010 - val_mae: 30.6775\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1940.0464 - mae: 31.9727 - val_loss: 1915.2709 - val_mae: 30.6755\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1939.7572 - mae: 31.9712 - val_loss: 1914.9463 - val_mae: 30.6736\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1939.4800 - mae: 31.9699 - val_loss: 1914.6119 - val_mae: 30.6716\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1939.1764 - mae: 31.9683 - val_loss: 1914.2959 - val_mae: 30.6696\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1938.9009 - mae: 31.9669 - val_loss: 1913.9681 - val_mae: 30.6677\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1938.6161 - mae: 31.9655 - val_loss: 1913.6357 - val_mae: 30.6657\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1938.3201 - mae: 31.9640 - val_loss: 1913.3140 - val_mae: 30.6637\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1938.0343 - mae: 31.9625 - val_loss: 1912.9891 - val_mae: 30.6618\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1937.7532 - mae: 31.9611 - val_loss: 1912.6586 - val_mae: 30.6598\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1937.4570 - mae: 31.9596 - val_loss: 1912.3383 - val_mae: 30.6578\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1937.1763 - mae: 31.9582 - val_loss: 1912.0099 - val_mae: 30.6559\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1936.8857 - mae: 31.9566 - val_loss: 1911.6857 - val_mae: 30.6539\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1936.5995 - mae: 31.9552 - val_loss: 1911.3634 - val_mae: 30.6519\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1936.3094 - mae: 31.9537 - val_loss: 1911.0375 - val_mae: 30.6500\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1936.0321 - mae: 31.9523 - val_loss: 1910.7069 - val_mae: 30.6480\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1935.7405 - mae: 31.9508 - val_loss: 1910.3817 - val_mae: 30.6460\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1935.4519 - mae: 31.9494 - val_loss: 1910.0631 - val_mae: 30.6441\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1935.1676 - mae: 31.9479 - val_loss: 1909.7413 - val_mae: 30.6422\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1934.8853 - mae: 31.9465 - val_loss: 1909.4138 - val_mae: 30.6402\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1934.6001 - mae: 31.9451 - val_loss: 1909.0883 - val_mae: 30.6382\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1934.3110 - mae: 31.9436 - val_loss: 1908.7626 - val_mae: 30.6362\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 1934.0221 - mae: 31.9421 - val_loss: 1908.4382 - val_mae: 30.6343\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1933.7350 - mae: 31.9407 - val_loss: 1908.1080 - val_mae: 30.6323\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1933.4515 - mae: 31.9393 - val_loss: 1907.7759 - val_mae: 30.6303\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1933.1570 - mae: 31.9378 - val_loss: 1907.4530 - val_mae: 30.6284\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1932.8662 - mae: 31.9363 - val_loss: 1907.1326 - val_mae: 30.6264\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1932.5853 - mae: 31.9348 - val_loss: 1906.8037 - val_mae: 30.6244\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1932.3053 - mae: 31.9335 - val_loss: 1906.4728 - val_mae: 30.6224\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1932.0122 - mae: 31.9320 - val_loss: 1906.1492 - val_mae: 30.6205\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1931.7206 - mae: 31.9305 - val_loss: 1905.8291 - val_mae: 30.6185\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1931.4446 - mae: 31.9290 - val_loss: 1905.4972 - val_mae: 30.6165\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1931.1486 - mae: 31.9276 - val_loss: 1905.1682 - val_mae: 30.6146\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1930.8599 - mae: 31.9262 - val_loss: 1904.8362 - val_mae: 30.6126\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1930.5668 - mae: 31.9248 - val_loss: 1904.5033 - val_mae: 30.6106\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1930.2803 - mae: 31.9233 - val_loss: 1904.1704 - val_mae: 30.6086\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1929.9882 - mae: 31.9219 - val_loss: 1903.8452 - val_mae: 30.6066\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1929.7026 - mae: 31.9204 - val_loss: 1903.5170 - val_mae: 30.6046\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1929.4183 - mae: 31.9190 - val_loss: 1903.1938 - val_mae: 30.6027\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1929.1288 - mae: 31.9175 - val_loss: 1902.8784 - val_mae: 30.6007\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1928.8472 - mae: 31.9161 - val_loss: 1902.5618 - val_mae: 30.5988\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1928.5656 - mae: 31.9146 - val_loss: 1902.2421 - val_mae: 30.5969\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1928.2916 - mae: 31.9133 - val_loss: 1901.9130 - val_mae: 30.5949\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1928.0007 - mae: 31.9118 - val_loss: 1901.5909 - val_mae: 30.5929\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1927.7129 - mae: 31.9104 - val_loss: 1901.2639 - val_mae: 30.5909\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1927.4332 - mae: 31.9090 - val_loss: 1900.9294 - val_mae: 30.5889\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1927.1329 - mae: 31.9075 - val_loss: 1900.6091 - val_mae: 30.5870\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1926.8567 - mae: 31.9061 - val_loss: 1900.2794 - val_mae: 30.5850\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1926.5630 - mae: 31.9047 - val_loss: 1899.9591 - val_mae: 30.5831\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1926.2863 - mae: 31.9032 - val_loss: 1899.6294 - val_mae: 30.5811\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1925.9868 - mae: 31.9018 - val_loss: 1899.3149 - val_mae: 30.5791\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1925.7174 - mae: 31.9004 - val_loss: 1898.9844 - val_mae: 30.5771\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1925.4229 - mae: 31.8989 - val_loss: 1898.6652 - val_mae: 30.5752\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1925.1398 - mae: 31.8975 - val_loss: 1898.3452 - val_mae: 30.5732\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1924.8646 - mae: 31.8961 - val_loss: 1898.0182 - val_mae: 30.5713\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1924.5728 - mae: 31.8946 - val_loss: 1897.6942 - val_mae: 30.5693\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1924.2836 - mae: 31.8932 - val_loss: 1897.3719 - val_mae: 30.5673\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1924.0001 - mae: 31.8917 - val_loss: 1897.0513 - val_mae: 30.5654\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1923.7235 - mae: 31.8903 - val_loss: 1896.7245 - val_mae: 30.5634\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1923.4329 - mae: 31.8888 - val_loss: 1896.4048 - val_mae: 30.5614\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1923.1538 - mae: 31.8875 - val_loss: 1896.0760 - val_mae: 30.5595\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1922.8655 - mae: 31.8861 - val_loss: 1895.7518 - val_mae: 30.5575\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1922.5720 - mae: 31.8846 - val_loss: 1895.4358 - val_mae: 30.5556\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   4.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 9792.5059 - mae: 70.4175 - val_loss: 10279.6113 - val_mae: 72.0469\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9791.1162 - mae: 70.4130 - val_loss: 10278.1416 - val_mae: 72.0422\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9789.7559 - mae: 70.4086 - val_loss: 10276.6602 - val_mae: 72.0374\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9788.3906 - mae: 70.4041 - val_loss: 10275.1807 - val_mae: 72.0327\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9787.0010 - mae: 70.3995 - val_loss: 10273.7129 - val_mae: 72.0280\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9785.6484 - mae: 70.3950 - val_loss: 10272.2373 - val_mae: 72.0232\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9784.2617 - mae: 70.3905 - val_loss: 10270.7773 - val_mae: 72.0185\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9782.9033 - mae: 70.3860 - val_loss: 10269.3086 - val_mae: 72.0137\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9781.5264 - mae: 70.3815 - val_loss: 10267.8369 - val_mae: 72.0090\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9780.1582 - mae: 70.3770 - val_loss: 10266.3633 - val_mae: 72.0043\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9778.8076 - mae: 70.3725 - val_loss: 10264.8818 - val_mae: 71.9995\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9777.4121 - mae: 70.3680 - val_loss: 10263.4355 - val_mae: 71.9948\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9776.0557 - mae: 70.3635 - val_loss: 10261.9766 - val_mae: 71.9901\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9774.6875 - mae: 70.3590 - val_loss: 10260.5166 - val_mae: 71.9854\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9773.3428 - mae: 70.3545 - val_loss: 10259.0371 - val_mae: 71.9806\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9771.9629 - mae: 70.3500 - val_loss: 10257.5566 - val_mae: 71.9758\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9770.5967 - mae: 70.3454 - val_loss: 10256.0820 - val_mae: 71.9711\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9769.2314 - mae: 70.3409 - val_loss: 10254.6064 - val_mae: 71.9663\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9767.8535 - mae: 70.3364 - val_loss: 10253.1562 - val_mae: 71.9617\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9766.4834 - mae: 70.3320 - val_loss: 10251.7139 - val_mae: 71.9570\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9765.1338 - mae: 70.3275 - val_loss: 10250.2539 - val_mae: 71.9523\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9763.7861 - mae: 70.3230 - val_loss: 10248.7744 - val_mae: 71.9475\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9762.4141 - mae: 70.3185 - val_loss: 10247.3018 - val_mae: 71.9428\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9761.0410 - mae: 70.3140 - val_loss: 10245.8379 - val_mae: 71.9381\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9759.6758 - mae: 70.3095 - val_loss: 10244.3711 - val_mae: 71.9334\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9758.3066 - mae: 70.3050 - val_loss: 10242.9062 - val_mae: 71.9286\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9756.9434 - mae: 70.3005 - val_loss: 10241.4395 - val_mae: 71.9239\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9755.5771 - mae: 70.2960 - val_loss: 10239.9697 - val_mae: 71.9192\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9754.2041 - mae: 70.2915 - val_loss: 10238.5020 - val_mae: 71.9144\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9752.8467 - mae: 70.2869 - val_loss: 10237.0273 - val_mae: 71.9096\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9751.4775 - mae: 70.2824 - val_loss: 10235.5693 - val_mae: 71.9050\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9750.1104 - mae: 70.2780 - val_loss: 10234.1162 - val_mae: 71.9003\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9748.7451 - mae: 70.2735 - val_loss: 10232.6631 - val_mae: 71.8956\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9747.3926 - mae: 70.2690 - val_loss: 10231.1914 - val_mae: 71.8908\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9746.0234 - mae: 70.2645 - val_loss: 10229.7295 - val_mae: 71.8861\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9744.6553 - mae: 70.2600 - val_loss: 10228.2676 - val_mae: 71.8814\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9743.3066 - mae: 70.2555 - val_loss: 10226.7871 - val_mae: 71.8766\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9741.9336 - mae: 70.2510 - val_loss: 10225.3125 - val_mae: 71.8719\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9740.5566 - mae: 70.2465 - val_loss: 10223.8516 - val_mae: 71.8671\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9739.2012 - mae: 70.2420 - val_loss: 10222.3818 - val_mae: 71.8624\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9737.8184 - mae: 70.2374 - val_loss: 10220.9395 - val_mae: 71.8577\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9736.4697 - mae: 70.2330 - val_loss: 10219.4766 - val_mae: 71.8530\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9735.1094 - mae: 70.2285 - val_loss: 10218.0078 - val_mae: 71.8483\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9733.7559 - mae: 70.2240 - val_loss: 10216.5391 - val_mae: 71.8435\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9732.3906 - mae: 70.2195 - val_loss: 10215.0791 - val_mae: 71.8388\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9731.0283 - mae: 70.2150 - val_loss: 10213.6162 - val_mae: 71.8341\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9729.6680 - mae: 70.2105 - val_loss: 10212.1553 - val_mae: 71.8293\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9728.3125 - mae: 70.2060 - val_loss: 10210.6875 - val_mae: 71.8246\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9726.9365 - mae: 70.2015 - val_loss: 10209.2256 - val_mae: 71.8199\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9725.5859 - mae: 70.1970 - val_loss: 10207.7549 - val_mae: 71.8151\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9724.2070 - mae: 70.1925 - val_loss: 10206.3018 - val_mae: 71.8104\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9722.8525 - mae: 70.1880 - val_loss: 10204.8438 - val_mae: 71.8057\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9721.5000 - mae: 70.1835 - val_loss: 10203.3750 - val_mae: 71.8010\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9720.1309 - mae: 70.1790 - val_loss: 10201.9131 - val_mae: 71.7962\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9718.7715 - mae: 70.1745 - val_loss: 10200.4453 - val_mae: 71.7915\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9717.4150 - mae: 70.1700 - val_loss: 10198.9854 - val_mae: 71.7868\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9716.0498 - mae: 70.1655 - val_loss: 10197.5371 - val_mae: 71.7821\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9714.6865 - mae: 70.1610 - val_loss: 10196.0898 - val_mae: 71.7774\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9713.3291 - mae: 70.1566 - val_loss: 10194.6357 - val_mae: 71.7727\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 9711.9844 - mae: 70.1521 - val_loss: 10193.1611 - val_mae: 71.7680\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9710.6211 - mae: 70.1476 - val_loss: 10191.6982 - val_mae: 71.7633\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9709.2568 - mae: 70.1431 - val_loss: 10190.2432 - val_mae: 71.7586\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9707.8994 - mae: 70.1386 - val_loss: 10188.7822 - val_mae: 71.7539\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9706.5488 - mae: 70.1341 - val_loss: 10187.3145 - val_mae: 71.7491\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9705.1729 - mae: 70.1296 - val_loss: 10185.8623 - val_mae: 71.7444\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9703.8213 - mae: 70.1251 - val_loss: 10184.3984 - val_mae: 71.7397\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9702.4492 - mae: 70.1206 - val_loss: 10182.9512 - val_mae: 71.7350\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9701.1035 - mae: 70.1162 - val_loss: 10181.4814 - val_mae: 71.7303\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9699.7529 - mae: 70.1117 - val_loss: 10180.0137 - val_mae: 71.7255\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9698.3809 - mae: 70.1072 - val_loss: 10178.5635 - val_mae: 71.7209\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9697.0215 - mae: 70.1027 - val_loss: 10177.1123 - val_mae: 71.7162\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9695.6602 - mae: 70.0982 - val_loss: 10175.6631 - val_mae: 71.7115\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9694.3154 - mae: 70.0938 - val_loss: 10174.2070 - val_mae: 71.7068\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9692.9609 - mae: 70.0893 - val_loss: 10172.7500 - val_mae: 71.7021\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9691.6221 - mae: 70.0848 - val_loss: 10171.2822 - val_mae: 71.6973\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9690.2451 - mae: 70.0803 - val_loss: 10169.8330 - val_mae: 71.6926\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9688.8799 - mae: 70.0758 - val_loss: 10168.4014 - val_mae: 71.6880\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9687.5400 - mae: 70.0714 - val_loss: 10166.9365 - val_mae: 71.6832\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9686.1846 - mae: 70.0668 - val_loss: 10165.4707 - val_mae: 71.6785\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9684.8350 - mae: 70.0624 - val_loss: 10164.0068 - val_mae: 71.6738\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9683.4824 - mae: 70.0578 - val_loss: 10162.5498 - val_mae: 71.6690\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9682.1260 - mae: 70.0533 - val_loss: 10161.0977 - val_mae: 71.6642\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9680.7715 - mae: 70.0488 - val_loss: 10159.6514 - val_mae: 71.6596\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9679.4219 - mae: 70.0444 - val_loss: 10158.2061 - val_mae: 71.6549\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9678.0654 - mae: 70.0399 - val_loss: 10156.7578 - val_mae: 71.6503\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9676.7168 - mae: 70.0355 - val_loss: 10155.3057 - val_mae: 71.6456\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9675.3604 - mae: 70.0310 - val_loss: 10153.8584 - val_mae: 71.6409\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9674.0078 - mae: 70.0266 - val_loss: 10152.4189 - val_mae: 71.6362\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9672.6748 - mae: 70.0221 - val_loss: 10150.9619 - val_mae: 71.6315\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9671.3145 - mae: 70.0177 - val_loss: 10149.5078 - val_mae: 71.6268\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9669.9727 - mae: 70.0132 - val_loss: 10148.0439 - val_mae: 71.6221\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9668.5977 - mae: 70.0086 - val_loss: 10146.5996 - val_mae: 71.6174\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9667.2588 - mae: 70.0041 - val_loss: 10145.1357 - val_mae: 71.6126\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9665.8906 - mae: 69.9996 - val_loss: 10143.6943 - val_mae: 71.6079\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9664.5586 - mae: 69.9952 - val_loss: 10142.2363 - val_mae: 71.6032\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9663.1885 - mae: 69.9907 - val_loss: 10140.7998 - val_mae: 71.5985\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 9661.8564 - mae: 69.9862 - val_loss: 10139.3398 - val_mae: 71.5938\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 9660.4961 - mae: 69.9818 - val_loss: 10137.8896 - val_mae: 71.5892\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 9659.1309 - mae: 69.9773 - val_loss: 10136.4541 - val_mae: 71.5845\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9657.7930 - mae: 69.9729 - val_loss: 10134.9951 - val_mae: 71.5798\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 74ms/step - loss: 1041.2563 - mae: 23.7499 - val_loss: 543.9662 - val_mae: 18.1699\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.3665 - mae: 17.8893 - val_loss: 349.3001 - val_mae: 15.2618\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.8358 - mae: 15.9649 - val_loss: 285.9542 - val_mae: 13.8993\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 344.8662 - mae: 14.9916 - val_loss: 256.9022 - val_mae: 13.1363\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.7986 - mae: 14.4230 - val_loss: 241.2735 - val_mae: 12.6704\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.3958 - mae: 14.0605 - val_loss: 231.3796 - val_mae: 12.3506\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 306.0506 - mae: 13.8139 - val_loss: 224.9398 - val_mae: 12.1256\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.8542 - mae: 13.6359 - val_loss: 219.9957 - val_mae: 11.9472\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 296.8747 - mae: 13.4804 - val_loss: 216.6841 - val_mae: 11.8256\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 293.3942 - mae: 13.3871 - val_loss: 212.9529 - val_mae: 11.6853\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 290.3341 - mae: 13.2747 - val_loss: 209.6147 - val_mae: 11.5693\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 287.2119 - mae: 13.1682 - val_loss: 207.1469 - val_mae: 11.4861\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.0034 - mae: 13.1083 - val_loss: 204.9005 - val_mae: 11.3987\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283.1153 - mae: 13.0269 - val_loss: 203.1494 - val_mae: 11.3338\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 281.5714 - mae: 12.9752 - val_loss: 201.6931 - val_mae: 11.2836\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 280.1953 - mae: 12.9368 - val_loss: 200.1242 - val_mae: 11.2204\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 278.9572 - mae: 12.8972 - val_loss: 198.6788 - val_mae: 11.1658\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 277.7960 - mae: 12.8500 - val_loss: 197.2184 - val_mae: 11.1055\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 276.5429 - mae: 12.7933 - val_loss: 196.2993 - val_mae: 11.0753\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 275.4794 - mae: 12.7796 - val_loss: 195.1227 - val_mae: 11.0289\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 274.5788 - mae: 12.7357 - val_loss: 194.1817 - val_mae: 10.9947\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 273.5897 - mae: 12.7198 - val_loss: 192.9118 - val_mae: 10.9351\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 272.6037 - mae: 12.6586 - val_loss: 191.9489 - val_mae: 10.8996\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 271.8059 - mae: 12.6361 - val_loss: 191.0659 - val_mae: 10.8626\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 270.9709 - mae: 12.5998 - val_loss: 190.1105 - val_mae: 10.8196\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 270.1400 - mae: 12.5692 - val_loss: 189.3303 - val_mae: 10.7926\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 269.4714 - mae: 12.5697 - val_loss: 188.3255 - val_mae: 10.7514\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.6108 - mae: 12.5189 - val_loss: 187.5175 - val_mae: 10.7263\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 267.6552 - mae: 12.5071 - val_loss: 186.3107 - val_mae: 10.6715\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 266.7671 - mae: 12.4522 - val_loss: 185.3532 - val_mae: 10.6318\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 265.9242 - mae: 12.4150 - val_loss: 184.9204 - val_mae: 10.6226\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 265.1970 - mae: 12.3970 - val_loss: 184.3614 - val_mae: 10.6026\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 264.5725 - mae: 12.3992 - val_loss: 183.3781 - val_mae: 10.5496\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 264.1040 - mae: 12.3644 - val_loss: 182.6143 - val_mae: 10.5143\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.4758 - mae: 12.3230 - val_loss: 182.0979 - val_mae: 10.4918\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.0635 - mae: 12.3110 - val_loss: 181.6420 - val_mae: 10.4695\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 262.4920 - mae: 12.2821 - val_loss: 181.2310 - val_mae: 10.4532\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 262.0773 - mae: 12.2589 - val_loss: 181.0703 - val_mae: 10.4511\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 261.6909 - mae: 12.2706 - val_loss: 180.6076 - val_mae: 10.4290\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 261.2279 - mae: 12.2631 - val_loss: 179.9879 - val_mae: 10.3901\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 260.8257 - mae: 12.2035 - val_loss: 180.1408 - val_mae: 10.4128\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 260.5736 - mae: 12.2596 - val_loss: 179.2522 - val_mae: 10.3587\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 260.1334 - mae: 12.2021 - val_loss: 178.8703 - val_mae: 10.3454\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 259.6880 - mae: 12.1786 - val_loss: 178.8114 - val_mae: 10.3516\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.4192 - mae: 12.2109 - val_loss: 178.1859 - val_mae: 10.3133\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.9792 - mae: 12.1732 - val_loss: 177.7876 - val_mae: 10.2915\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.6845 - mae: 12.1777 - val_loss: 177.0833 - val_mae: 10.2486\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.2822 - mae: 12.1226 - val_loss: 176.9249 - val_mae: 10.2508\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.7798 - mae: 12.1223 - val_loss: 176.5415 - val_mae: 10.2367\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.3040 - mae: 12.1211 - val_loss: 175.7999 - val_mae: 10.2108\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 256.2831 - mae: 12.0945 - val_loss: 174.7645 - val_mae: 10.1774\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 255.1464 - mae: 12.0582 - val_loss: 173.3876 - val_mae: 10.1353\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 253.5812 - mae: 12.0188 - val_loss: 172.0578 - val_mae: 10.0772\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 252.2658 - mae: 11.9644 - val_loss: 170.9255 - val_mae: 10.0268\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 251.0747 - mae: 11.9265 - val_loss: 169.9737 - val_mae: 9.9745\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 250.1655 - mae: 11.8715 - val_loss: 169.3297 - val_mae: 9.9379\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 249.3313 - mae: 11.8392 - val_loss: 168.7389 - val_mae: 9.9065\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 248.6952 - mae: 11.8105 - val_loss: 168.4066 - val_mae: 9.8880\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 248.3196 - mae: 11.7930 - val_loss: 168.4303 - val_mae: 9.8928\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 247.9441 - mae: 11.8051 - val_loss: 168.1135 - val_mae: 9.8700\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 247.7623 - mae: 11.7895 - val_loss: 167.7349 - val_mae: 9.8440\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 247.5941 - mae: 11.7713 - val_loss: 167.5709 - val_mae: 9.8337\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 247.2586 - mae: 11.7544 - val_loss: 167.4049 - val_mae: 9.8237\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 247.0949 - mae: 11.7595 - val_loss: 167.0271 - val_mae: 9.7969\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 247.0038 - mae: 11.7318 - val_loss: 167.1635 - val_mae: 9.8121\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 246.9423 - mae: 11.7580 - val_loss: 166.9578 - val_mae: 9.7984\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 246.7542 - mae: 11.7386 - val_loss: 166.9842 - val_mae: 9.8038\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.5062 - mae: 11.7611 - val_loss: 166.5082 - val_mae: 9.7659\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.3199 - mae: 11.7166 - val_loss: 166.4185 - val_mae: 9.7621\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 246.2945 - mae: 11.7279 - val_loss: 165.9805 - val_mae: 9.7289\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246.1542 - mae: 11.6953 - val_loss: 165.8149 - val_mae: 9.7195\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 246.0601 - mae: 11.7026 - val_loss: 165.7365 - val_mae: 9.7168\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 245.8332 - mae: 11.7010 - val_loss: 165.5224 - val_mae: 9.7007\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 245.6998 - mae: 11.6633 - val_loss: 165.7226 - val_mae: 9.7201\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 245.6151 - mae: 11.7204 - val_loss: 165.2624 - val_mae: 9.6844\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 245.4646 - mae: 11.6457 - val_loss: 165.5633 - val_mae: 9.7128\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 245.2951 - mae: 11.6915 - val_loss: 165.4388 - val_mae: 9.7044\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 245.2086 - mae: 11.6820 - val_loss: 165.3909 - val_mae: 9.7015\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 245.2608 - mae: 11.6759 - val_loss: 165.4347 - val_mae: 9.7081\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 244.9366 - mae: 11.6806 - val_loss: 165.1776 - val_mae: 9.6878\n",
      "Epoch 80: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=momentum; total time=   6.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 848.1819 - mae: 23.3255 - val_loss: 543.4207 - val_mae: 19.4533\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 589.9753 - mae: 20.4628 - val_loss: 412.1355 - val_mae: 17.5078\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 511.3488 - mae: 19.1842 - val_loss: 361.2292 - val_mae: 16.5322\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.0673 - mae: 18.5018 - val_loss: 336.3303 - val_mae: 15.9501\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.3119 - mae: 18.0677 - val_loss: 322.1194 - val_mae: 15.5558\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.9505 - mae: 17.7339 - val_loss: 311.6447 - val_mae: 15.2352\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.4669 - mae: 17.4538 - val_loss: 302.7781 - val_mae: 14.9630\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.2704 - mae: 17.1981 - val_loss: 294.9439 - val_mae: 14.7195\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 419.9467 - mae: 16.9697 - val_loss: 288.0578 - val_mae: 14.4926\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 412.7149 - mae: 16.7548 - val_loss: 283.0368 - val_mae: 14.3148\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.0623 - mae: 16.5896 - val_loss: 278.6520 - val_mae: 14.1582\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 402.5827 - mae: 16.4492 - val_loss: 274.9219 - val_mae: 14.0255\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 398.8275 - mae: 16.3393 - val_loss: 271.7415 - val_mae: 13.9097\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.7589 - mae: 16.2459 - val_loss: 269.1704 - val_mae: 13.8159\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.0078 - mae: 16.1665 - val_loss: 266.9467 - val_mae: 13.7302\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.0137 - mae: 16.1164 - val_loss: 264.6392 - val_mae: 13.6430\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.7779 - mae: 16.0246 - val_loss: 262.9946 - val_mae: 13.5818\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.0080 - mae: 15.9734 - val_loss: 261.2913 - val_mae: 13.5188\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.3323 - mae: 15.9164 - val_loss: 259.9378 - val_mae: 13.4699\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 383.7751 - mae: 15.8752 - val_loss: 258.7613 - val_mae: 13.4236\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 382.3041 - mae: 15.8356 - val_loss: 257.5735 - val_mae: 13.3762\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 380.9891 - mae: 15.8015 - val_loss: 256.1245 - val_mae: 13.3105\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 379.7362 - mae: 15.7483 - val_loss: 255.1611 - val_mae: 13.2702\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 378.4962 - mae: 15.7157 - val_loss: 254.0209 - val_mae: 13.2254\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.2662 - mae: 15.6721 - val_loss: 253.0143 - val_mae: 13.1797\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.9889 - mae: 15.6483 - val_loss: 251.6819 - val_mae: 13.1218\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 374.6768 - mae: 15.5945 - val_loss: 250.6453 - val_mae: 13.0777\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 373.2972 - mae: 15.5557 - val_loss: 249.3844 - val_mae: 13.0256\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.0217 - mae: 15.5138 - val_loss: 248.4658 - val_mae: 12.9906\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.6665 - mae: 15.4818 - val_loss: 247.3286 - val_mae: 12.9404\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.4936 - mae: 15.4314 - val_loss: 246.2703 - val_mae: 12.8892\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 368.5494 - mae: 15.4034 - val_loss: 245.2290 - val_mae: 12.8377\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367.5772 - mae: 15.3567 - val_loss: 244.4885 - val_mae: 12.8031\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.7212 - mae: 15.3275 - val_loss: 243.7641 - val_mae: 12.7701\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.8895 - mae: 15.2895 - val_loss: 243.2307 - val_mae: 12.7490\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 365.1523 - mae: 15.2692 - val_loss: 242.7528 - val_mae: 12.7284\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.3379 - mae: 15.2546 - val_loss: 242.0458 - val_mae: 12.6921\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.5422 - mae: 15.2333 - val_loss: 241.1259 - val_mae: 12.6512\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.7079 - mae: 15.1992 - val_loss: 240.3930 - val_mae: 12.6284\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.7115 - mae: 15.1648 - val_loss: 239.7360 - val_mae: 12.6027\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.8403 - mae: 15.1466 - val_loss: 238.6660 - val_mae: 12.5512\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 359.5058 - mae: 15.1086 - val_loss: 236.3670 - val_mae: 12.4551\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 357.0746 - mae: 15.0100 - val_loss: 234.7857 - val_mae: 12.3869\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 355.5390 - mae: 14.9564 - val_loss: 234.0512 - val_mae: 12.3534\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 354.4860 - mae: 14.9198 - val_loss: 233.7254 - val_mae: 12.3399\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.9064 - mae: 14.9159 - val_loss: 233.3980 - val_mae: 12.3212\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 353.4874 - mae: 14.9086 - val_loss: 232.9198 - val_mae: 12.2899\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.9159 - mae: 14.8763 - val_loss: 232.4811 - val_mae: 12.2643\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.4954 - mae: 14.8612 - val_loss: 231.9051 - val_mae: 12.2326\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 352.1220 - mae: 14.8361 - val_loss: 231.4743 - val_mae: 12.2110\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.5083 - mae: 14.7998 - val_loss: 231.3679 - val_mae: 12.2099\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.1328 - mae: 14.8229 - val_loss: 230.8967 - val_mae: 12.1818\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.7333 - mae: 14.7859 - val_loss: 230.7304 - val_mae: 12.1726\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.2837 - mae: 14.7762 - val_loss: 230.5639 - val_mae: 12.1651\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 350.0183 - mae: 14.7860 - val_loss: 230.2167 - val_mae: 12.1453\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.5959 - mae: 14.7624 - val_loss: 229.8371 - val_mae: 12.1256\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.2648 - mae: 14.7434 - val_loss: 229.5419 - val_mae: 12.1099\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.9157 - mae: 14.7365 - val_loss: 229.2298 - val_mae: 12.0925\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.4362 - mae: 14.7250 - val_loss: 229.0289 - val_mae: 12.0836\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 348.1586 - mae: 14.6986 - val_loss: 229.4432 - val_mae: 12.1168\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 347.6132 - mae: 14.7322 - val_loss: 229.1197 - val_mae: 12.0988\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 347.2449 - mae: 14.6954 - val_loss: 228.8378 - val_mae: 12.0873\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.6634 - mae: 14.6841 - val_loss: 228.5406 - val_mae: 12.0736\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 346.1546 - mae: 14.6738 - val_loss: 228.2938 - val_mae: 12.0680\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.6644 - mae: 14.6853 - val_loss: 227.6609 - val_mae: 12.0324\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 345.1288 - mae: 14.6417 - val_loss: 227.3051 - val_mae: 12.0164\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 344.6183 - mae: 14.6241 - val_loss: 226.8371 - val_mae: 11.9952\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 344.2530 - mae: 14.6336 - val_loss: 225.9966 - val_mae: 11.9443\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.8633 - mae: 14.5737 - val_loss: 225.9038 - val_mae: 11.9489\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.2951 - mae: 14.5649 - val_loss: 225.7667 - val_mae: 11.9480\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.9591 - mae: 14.5771 - val_loss: 225.2859 - val_mae: 11.9233\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.4536 - mae: 14.5406 - val_loss: 224.9564 - val_mae: 11.9064\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.9743 - mae: 14.5219 - val_loss: 224.7942 - val_mae: 11.9040\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.5655 - mae: 14.5206 - val_loss: 224.4404 - val_mae: 11.8914\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.1812 - mae: 14.5191 - val_loss: 224.0311 - val_mae: 11.8751\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.7169 - mae: 14.4942 - val_loss: 223.7415 - val_mae: 11.8684\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.3098 - mae: 14.4822 - val_loss: 223.7104 - val_mae: 11.8778\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.9037 - mae: 14.4969 - val_loss: 223.1310 - val_mae: 11.8454\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.5118 - mae: 14.4732 - val_loss: 222.5004 - val_mae: 11.8128\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.0828 - mae: 14.4403 - val_loss: 222.1336 - val_mae: 11.7961\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.7116 - mae: 14.4365 - val_loss: 221.7105 - val_mae: 11.7738\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.4081 - mae: 14.4154 - val_loss: 221.5183 - val_mae: 11.7698\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.0927 - mae: 14.4030 - val_loss: 221.4519 - val_mae: 11.7794\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.7115 - mae: 14.3966 - val_loss: 221.4737 - val_mae: 11.7902\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 337.3957 - mae: 14.4135 - val_loss: 221.1614 - val_mae: 11.7769\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.0598 - mae: 14.4117 - val_loss: 220.6802 - val_mae: 11.7505\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.6986 - mae: 14.3904 - val_loss: 220.2066 - val_mae: 11.7226\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.4839 - mae: 14.3812 - val_loss: 219.9717 - val_mae: 11.7165\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.1323 - mae: 14.3680 - val_loss: 219.8390 - val_mae: 11.7158\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.7913 - mae: 14.3517 - val_loss: 219.7589 - val_mae: 11.7171\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.5197 - mae: 14.3501 - val_loss: 219.5106 - val_mae: 11.7059\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.1867 - mae: 14.3449 - val_loss: 219.3898 - val_mae: 11.7029\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.8997 - mae: 14.3342 - val_loss: 219.1951 - val_mae: 11.6924\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.4686 - mae: 14.3270 - val_loss: 218.9720 - val_mae: 11.6902\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.1126 - mae: 14.3339 - val_loss: 218.5317 - val_mae: 11.6691\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.6389 - mae: 14.3186 - val_loss: 217.8475 - val_mae: 11.6311\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.2155 - mae: 14.2688 - val_loss: 217.7468 - val_mae: 11.6346\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.8433 - mae: 14.2784 - val_loss: 217.4966 - val_mae: 11.6244\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.5774 - mae: 14.2623 - val_loss: 217.2979 - val_mae: 11.6180\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.3943 - mae: 14.2629 - val_loss: 216.9866 - val_mae: 11.5990\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=momentum; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 696.8715 - mae: 21.4755 - val_loss: 518.0411 - val_mae: 19.0218\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.7145 - mae: 18.1800 - val_loss: 409.3952 - val_mae: 17.0129\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 399.4519 - mae: 16.7369 - val_loss: 365.0881 - val_mae: 15.9618\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 366.7935 - mae: 15.8972 - val_loss: 343.2085 - val_mae: 15.3545\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.3218 - mae: 15.3817 - val_loss: 330.7573 - val_mae: 14.9715\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.3838 - mae: 15.0409 - val_loss: 322.6385 - val_mae: 14.7113\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 330.8299 - mae: 14.8028 - val_loss: 316.8217 - val_mae: 14.5190\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.9049 - mae: 14.6179 - val_loss: 312.1538 - val_mae: 14.3594\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 319.9295 - mae: 14.4584 - val_loss: 308.3835 - val_mae: 14.2262\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.9723 - mae: 14.3309 - val_loss: 304.5202 - val_mae: 14.0922\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 311.8510 - mae: 14.1916 - val_loss: 300.8240 - val_mae: 13.9575\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 308.4178 - mae: 14.0753 - val_loss: 297.8907 - val_mae: 13.8463\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.4500 - mae: 13.9715 - val_loss: 295.5582 - val_mae: 13.7597\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.0926 - mae: 13.8859 - val_loss: 293.7577 - val_mae: 13.6965\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 301.2613 - mae: 13.8301 - val_loss: 292.1372 - val_mae: 13.6350\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.6101 - mae: 13.7654 - val_loss: 290.7612 - val_mae: 13.5854\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.1752 - mae: 13.7144 - val_loss: 289.5522 - val_mae: 13.5428\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.7639 - mae: 13.6609 - val_loss: 288.4446 - val_mae: 13.5081\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.5318 - mae: 13.6295 - val_loss: 287.3445 - val_mae: 13.4623\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.3275 - mae: 13.5773 - val_loss: 286.3035 - val_mae: 13.4209\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.1546 - mae: 13.5299 - val_loss: 285.2385 - val_mae: 13.3810\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.0784 - mae: 13.4913 - val_loss: 284.1652 - val_mae: 13.3407\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.0590 - mae: 13.4474 - val_loss: 283.1831 - val_mae: 13.3047\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.1089 - mae: 13.4124 - val_loss: 282.3062 - val_mae: 13.2743\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.1115 - mae: 13.3710 - val_loss: 281.4787 - val_mae: 13.2463\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 288.3958 - mae: 13.3516 - val_loss: 280.7076 - val_mae: 13.2206\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 287.5316 - mae: 13.3229 - val_loss: 279.9374 - val_mae: 13.1917\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286.7502 - mae: 13.2842 - val_loss: 279.1871 - val_mae: 13.1638\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 286.0674 - mae: 13.2581 - val_loss: 278.5674 - val_mae: 13.1427\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 285.2632 - mae: 13.2373 - val_loss: 277.5748 - val_mae: 13.1008\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 284.2692 - mae: 13.1875 - val_loss: 276.5441 - val_mae: 13.0736\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 283.1900 - mae: 13.1690 - val_loss: 275.5944 - val_mae: 13.0395\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282.2832 - mae: 13.1325 - val_loss: 274.8400 - val_mae: 13.0126\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.6008 - mae: 13.1017 - val_loss: 274.2194 - val_mae: 12.9913\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 280.9977 - mae: 13.0837 - val_loss: 273.6891 - val_mae: 12.9693\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.4898 - mae: 13.0600 - val_loss: 273.2143 - val_mae: 12.9546\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 279.8806 - mae: 13.0531 - val_loss: 272.6150 - val_mae: 12.9233\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.3952 - mae: 13.0103 - val_loss: 272.1632 - val_mae: 12.9081\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.9235 - mae: 12.9991 - val_loss: 271.7942 - val_mae: 12.8988\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.4839 - mae: 12.9893 - val_loss: 271.3081 - val_mae: 12.8781\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.0841 - mae: 12.9741 - val_loss: 270.7966 - val_mae: 12.8524\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.6797 - mae: 12.9422 - val_loss: 270.4955 - val_mae: 12.8489\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 277.2712 - mae: 12.9396 - val_loss: 270.1190 - val_mae: 12.8346\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.9115 - mae: 12.9233 - val_loss: 269.7812 - val_mae: 12.8245\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 276.5717 - mae: 12.9094 - val_loss: 269.4604 - val_mae: 12.8143\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.2347 - mae: 12.9037 - val_loss: 269.0565 - val_mae: 12.7933\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.0062 - mae: 12.8905 - val_loss: 268.7033 - val_mae: 12.7799\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 275.6038 - mae: 12.8743 - val_loss: 268.3437 - val_mae: 12.7671\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 275.2667 - mae: 12.8548 - val_loss: 268.0480 - val_mae: 12.7557\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 275.0565 - mae: 12.8469 - val_loss: 267.7570 - val_mae: 12.7437\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.7921 - mae: 12.8442 - val_loss: 267.2761 - val_mae: 12.7204\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.3908 - mae: 12.8173 - val_loss: 266.9210 - val_mae: 12.7136\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 274.0325 - mae: 12.8097 - val_loss: 266.4021 - val_mae: 12.7003\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 273.4584 - mae: 12.7982 - val_loss: 265.3502 - val_mae: 12.6673\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 272.2792 - mae: 12.7656 - val_loss: 263.8928 - val_mae: 12.6215\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 271.1725 - mae: 12.7303 - val_loss: 262.9890 - val_mae: 12.5838\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 270.5123 - mae: 12.6925 - val_loss: 262.4731 - val_mae: 12.5652\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 269.9736 - mae: 12.6818 - val_loss: 262.0760 - val_mae: 12.5464\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 269.7014 - mae: 12.6654 - val_loss: 261.7394 - val_mae: 12.5319\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 269.3579 - mae: 12.6535 - val_loss: 261.3967 - val_mae: 12.5132\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 269.1616 - mae: 12.6427 - val_loss: 261.0845 - val_mae: 12.4963\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.8274 - mae: 12.6275 - val_loss: 260.8432 - val_mae: 12.4851\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.6111 - mae: 12.6072 - val_loss: 260.6010 - val_mae: 12.4763\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 268.4340 - mae: 12.6005 - val_loss: 260.3383 - val_mae: 12.4646\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 268.1843 - mae: 12.6020 - val_loss: 259.9250 - val_mae: 12.4418\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 267.6972 - mae: 12.5716 - val_loss: 258.9397 - val_mae: 12.4139\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 266.4190 - mae: 12.5312 - val_loss: 257.5526 - val_mae: 12.3704\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 265.2508 - mae: 12.4918 - val_loss: 256.7422 - val_mae: 12.3422\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 264.5964 - mae: 12.4708 - val_loss: 256.1404 - val_mae: 12.3138\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 264.1690 - mae: 12.4567 - val_loss: 255.7589 - val_mae: 12.3000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.8063 - mae: 12.4452 - val_loss: 255.4053 - val_mae: 12.2840\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.5550 - mae: 12.4233 - val_loss: 255.1815 - val_mae: 12.2769\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.3066 - mae: 12.4268 - val_loss: 254.9117 - val_mae: 12.2685\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.1188 - mae: 12.4128 - val_loss: 254.6249 - val_mae: 12.2555\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 262.9387 - mae: 12.4145 - val_loss: 254.3552 - val_mae: 12.2392\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 262.6830 - mae: 12.3853 - val_loss: 254.1763 - val_mae: 12.2361\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 262.5104 - mae: 12.3828 - val_loss: 253.9188 - val_mae: 12.2262\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 262.3168 - mae: 12.3804 - val_loss: 253.6807 - val_mae: 12.2170\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 262.0485 - mae: 12.3643 - val_loss: 253.3473 - val_mae: 12.2018\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 261.6875 - mae: 12.3433 - val_loss: 252.9560 - val_mae: 12.1924\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 261.1760 - mae: 12.3347 - val_loss: 252.5015 - val_mae: 12.1819\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.6865 - mae: 12.3309 - val_loss: 252.0543 - val_mae: 12.1631\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.3677 - mae: 12.3157 - val_loss: 251.7471 - val_mae: 12.1526\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.0172 - mae: 12.3063 - val_loss: 251.4533 - val_mae: 12.1454\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.7845 - mae: 12.2846 - val_loss: 251.2296 - val_mae: 12.1423\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 259.5390 - mae: 12.2888 - val_loss: 250.9874 - val_mae: 12.1357\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 259.2910 - mae: 12.2823 - val_loss: 250.7792 - val_mae: 12.1279\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 259.1160 - mae: 12.2693 - val_loss: 250.6218 - val_mae: 12.1288\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 258.8686 - mae: 12.2601 - val_loss: 250.4628 - val_mae: 12.1254\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 258.7006 - mae: 12.2570 - val_loss: 250.3068 - val_mae: 12.1217\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.5532 - mae: 12.2521 - val_loss: 250.1727 - val_mae: 12.1220\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.5242 - mae: 12.2738 - val_loss: 249.8747 - val_mae: 12.0964\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 258.2525 - mae: 12.2366 - val_loss: 249.6913 - val_mae: 12.0898\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 258.1024 - mae: 12.2316 - val_loss: 249.5331 - val_mae: 12.0834\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.9966 - mae: 12.2441 - val_loss: 249.3286 - val_mae: 12.0659\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.8380 - mae: 12.2141 - val_loss: 249.1712 - val_mae: 12.0579\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 257.6958 - mae: 12.2046 - val_loss: 249.0302 - val_mae: 12.0558\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.5287 - mae: 12.2035 - val_loss: 248.9040 - val_mae: 12.0547\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.4022 - mae: 12.2073 - val_loss: 248.7820 - val_mae: 12.0536\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 257.2173 - mae: 12.1957 - val_loss: 248.6112 - val_mae: 12.0462\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=125, model__optimizer=momentum; total time=   4.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 24ms/step - loss: 632.1788 - mae: 21.8327 - val_loss: 449.2878 - val_mae: 20.2775\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.5833 - mae: 22.6998 - val_loss: 449.2487 - val_mae: 20.2765\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.6338 - mae: 22.7015 - val_loss: 449.1983 - val_mae: 20.2752\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.5745 - mae: 22.7002 - val_loss: 449.1435 - val_mae: 20.2739\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.5112 - mae: 22.6988 - val_loss: 449.0867 - val_mae: 20.2725\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.4471 - mae: 22.6974 - val_loss: 449.0282 - val_mae: 20.2710\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.3815 - mae: 22.6960 - val_loss: 448.9691 - val_mae: 20.2696\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.3154 - mae: 22.6945 - val_loss: 448.9102 - val_mae: 20.2681\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.2496 - mae: 22.6931 - val_loss: 448.8514 - val_mae: 20.2667\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.1833 - mae: 22.6916 - val_loss: 448.7929 - val_mae: 20.2652\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 598.1180 - mae: 22.6902 - val_loss: 448.7339 - val_mae: 20.2638\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 989us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   1.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 5177.4546 - mae: 35.2379 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   0.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 1193.4458 - mae: 23.0958 - val_loss: 385.9015 - val_mae: 16.7700\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.4190 - mae: 16.8195 - val_loss: 380.4547 - val_mae: 16.6825\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.6701 - mae: 16.3919 - val_loss: 366.9644 - val_mae: 16.0567\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.1510 - mae: 16.2519 - val_loss: 366.3365 - val_mae: 15.9703\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.7712 - mae: 16.0528 - val_loss: 364.6163 - val_mae: 15.9812\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.3809 - mae: 16.0000 - val_loss: 363.1992 - val_mae: 15.9022\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.7039 - mae: 15.9361 - val_loss: 362.6812 - val_mae: 15.8792\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.2032 - mae: 15.9414 - val_loss: 362.0800 - val_mae: 15.8372\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.5162 - mae: 15.8821 - val_loss: 361.4543 - val_mae: 15.7961\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.4729 - mae: 15.9082 - val_loss: 360.4710 - val_mae: 15.7321\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.3073 - mae: 15.8155 - val_loss: 360.8575 - val_mae: 15.7703\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.3902 - mae: 15.9149 - val_loss: 359.9574 - val_mae: 15.7046\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.3648 - mae: 15.7793 - val_loss: 359.0254 - val_mae: 15.6432\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.4696 - mae: 15.8217 - val_loss: 359.0289 - val_mae: 15.6754\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.9488 - mae: 15.7968 - val_loss: 358.4442 - val_mae: 15.6246\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.2163 - mae: 15.7719 - val_loss: 360.0591 - val_mae: 15.7567\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 366.5453 - mae: 15.9508 - val_loss: 358.3268 - val_mae: 15.5663\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.7492 - mae: 15.7373 - val_loss: 358.6187 - val_mae: 15.6626\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 367.5675 - mae: 15.9715 - val_loss: 358.0142 - val_mae: 15.5044\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 366.3892 - mae: 15.7235 - val_loss: 357.8131 - val_mae: 15.6057\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 365.6688 - mae: 15.8191 - val_loss: 357.9983 - val_mae: 15.6137\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 364.8072 - mae: 15.6753 - val_loss: 357.5288 - val_mae: 15.5237\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.9515 - mae: 15.7057 - val_loss: 358.8806 - val_mae: 15.7283\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.6928 - mae: 15.7763 - val_loss: 356.5012 - val_mae: 15.5188\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.5685 - mae: 15.6703 - val_loss: 357.0661 - val_mae: 15.6070\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.6342 - mae: 15.8149 - val_loss: 356.2280 - val_mae: 15.5465\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.6547 - mae: 15.7499 - val_loss: 355.9181 - val_mae: 15.4997\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.1201 - mae: 15.6845 - val_loss: 356.3183 - val_mae: 15.5561\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.0987 - mae: 15.8450 - val_loss: 355.8811 - val_mae: 15.5093\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.4084 - mae: 15.7091 - val_loss: 355.7881 - val_mae: 15.4927\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.7823 - mae: 15.6678 - val_loss: 356.2189 - val_mae: 15.5537\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.0680 - mae: 15.8677 - val_loss: 355.2998 - val_mae: 15.4637\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.3172 - mae: 15.6332 - val_loss: 355.6897 - val_mae: 15.5024\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.1237 - mae: 15.8043 - val_loss: 355.9641 - val_mae: 15.5365\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 364.0711 - mae: 15.6626 - val_loss: 354.8951 - val_mae: 15.4079\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 365.1567 - mae: 15.8418 - val_loss: 354.9356 - val_mae: 15.4771\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 363.4872 - mae: 15.6017 - val_loss: 354.2440 - val_mae: 15.4150\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.2159 - mae: 15.6644 - val_loss: 354.5783 - val_mae: 15.4631\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.0691 - mae: 15.6468 - val_loss: 354.7052 - val_mae: 15.4764\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.7939 - mae: 15.6420 - val_loss: 354.3804 - val_mae: 15.4179\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.6591 - mae: 15.5759 - val_loss: 354.0679 - val_mae: 15.4037\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.5725 - mae: 15.6227 - val_loss: 354.1861 - val_mae: 15.4399\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.3772 - mae: 15.6049 - val_loss: 353.7523 - val_mae: 15.3987\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.4421 - mae: 15.6303 - val_loss: 354.3886 - val_mae: 15.4478\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.1708 - mae: 15.5779 - val_loss: 353.3734 - val_mae: 15.3359\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.0935 - mae: 15.5551 - val_loss: 354.7261 - val_mae: 15.4711\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2029 - mae: 15.6648 - val_loss: 352.6520 - val_mae: 15.3082\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.9768 - mae: 15.5610 - val_loss: 353.6699 - val_mae: 15.4185\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 363.0228 - mae: 15.7346 - val_loss: 353.0909 - val_mae: 15.3536\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2355 - mae: 15.5299 - val_loss: 353.8636 - val_mae: 15.4117\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.9355 - mae: 15.6384 - val_loss: 353.2544 - val_mae: 15.3730\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.4402 - mae: 15.5868 - val_loss: 352.2500 - val_mae: 15.2990\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.5556 - mae: 15.5443 - val_loss: 351.8240 - val_mae: 15.2680\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.7101 - mae: 15.5830 - val_loss: 351.9834 - val_mae: 15.3057\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.5038 - mae: 15.5023 - val_loss: 351.8035 - val_mae: 15.2795\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 361.0208 - mae: 15.5670 - val_loss: 352.3736 - val_mae: 15.3308\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.8468 - mae: 15.5369 - val_loss: 350.7543 - val_mae: 15.2021\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.8541 - mae: 15.5068 - val_loss: 351.4065 - val_mae: 15.2728\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.6767 - mae: 15.5667 - val_loss: 351.1889 - val_mae: 15.2378\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.9993 - mae: 15.5414 - val_loss: 351.1280 - val_mae: 15.1788\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 360.9661 - mae: 15.4679 - val_loss: 351.5908 - val_mae: 15.2493\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.7933 - mae: 15.5418 - val_loss: 350.4279 - val_mae: 15.1749\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.5296 - mae: 15.4518 - val_loss: 352.1506 - val_mae: 15.2873\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.6908 - mae: 15.5718 - val_loss: 350.3264 - val_mae: 15.1407\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.8907 - mae: 15.4678 - val_loss: 352.7799 - val_mae: 15.3063\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.6226 - mae: 15.6014 - val_loss: 349.6522 - val_mae: 15.1311\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.0889 - mae: 15.4536 - val_loss: 353.6629 - val_mae: 15.3704\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.8146 - mae: 15.6196 - val_loss: 349.5449 - val_mae: 15.1100\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.5344 - mae: 15.4689 - val_loss: 353.4181 - val_mae: 15.3451\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.4928 - mae: 15.5978 - val_loss: 349.4886 - val_mae: 15.0953\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 359.9720 - mae: 15.5158 - val_loss: 352.4377 - val_mae: 15.2769\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.4089 - mae: 15.4481 - val_loss: 348.8185 - val_mae: 15.0904\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.6241 - mae: 15.4381 - val_loss: 353.9536 - val_mae: 15.3851\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 360.6074 - mae: 15.4956 - val_loss: 349.2943 - val_mae: 15.0633\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.5413 - mae: 15.4750 - val_loss: 350.5209 - val_mae: 15.1526\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 359.5829 - mae: 15.4302 - val_loss: 349.4978 - val_mae: 15.0784\n",
      "Epoch 76: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=2, model__n_neurons=5, model__optimizer=momentum; total time=   3.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 4031.1765 - mae: 46.1682 - val_loss: 4193.0254 - val_mae: 46.7891\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4029.5242 - mae: 46.1577 - val_loss: 4191.2681 - val_mae: 46.7781\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4027.8259 - mae: 46.1471 - val_loss: 4189.5337 - val_mae: 46.7671\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4026.1560 - mae: 46.1365 - val_loss: 4187.7959 - val_mae: 46.7562\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4024.4680 - mae: 46.1261 - val_loss: 4186.0591 - val_mae: 46.7453\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4022.8196 - mae: 46.1155 - val_loss: 4184.2959 - val_mae: 46.7341\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4021.1448 - mae: 46.1049 - val_loss: 4182.5371 - val_mae: 46.7231\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4019.4556 - mae: 46.0943 - val_loss: 4180.8008 - val_mae: 46.7121\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4017.7629 - mae: 46.0839 - val_loss: 4179.0811 - val_mae: 46.7013\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4016.1060 - mae: 46.0733 - val_loss: 4177.3262 - val_mae: 46.6902\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4014.4558 - mae: 46.0628 - val_loss: 4175.5537 - val_mae: 46.6790\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4012.7454 - mae: 46.0521 - val_loss: 4173.8311 - val_mae: 46.6681\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4011.0957 - mae: 46.0417 - val_loss: 4172.0854 - val_mae: 46.6571\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4009.4231 - mae: 46.0312 - val_loss: 4170.3525 - val_mae: 46.6461\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4007.7644 - mae: 46.0207 - val_loss: 4168.6265 - val_mae: 46.6351\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4006.1121 - mae: 46.0103 - val_loss: 4166.8940 - val_mae: 46.6242\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4004.4426 - mae: 45.9998 - val_loss: 4165.1660 - val_mae: 46.6132\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4002.7866 - mae: 45.9893 - val_loss: 4163.4214 - val_mae: 46.6021\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4001.1401 - mae: 45.9787 - val_loss: 4161.6753 - val_mae: 46.5911\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3999.4358 - mae: 45.9681 - val_loss: 4159.9634 - val_mae: 46.5802\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3997.8040 - mae: 45.9577 - val_loss: 4158.2334 - val_mae: 46.5692\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3996.1460 - mae: 45.9473 - val_loss: 4156.5151 - val_mae: 46.5583\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3994.5103 - mae: 45.9370 - val_loss: 4154.7949 - val_mae: 46.5474\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3992.8401 - mae: 45.9265 - val_loss: 4153.0933 - val_mae: 46.5366\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3991.2175 - mae: 45.9162 - val_loss: 4151.3599 - val_mae: 46.5256\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3989.5508 - mae: 45.9056 - val_loss: 4149.6348 - val_mae: 46.5146\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3987.8860 - mae: 45.8951 - val_loss: 4147.9155 - val_mae: 46.5037\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3986.2219 - mae: 45.8846 - val_loss: 4146.1909 - val_mae: 46.4927\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3984.5779 - mae: 45.8742 - val_loss: 4144.4541 - val_mae: 46.4817\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3982.9204 - mae: 45.8637 - val_loss: 4142.7134 - val_mae: 46.4706\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3981.2646 - mae: 45.8531 - val_loss: 4140.9805 - val_mae: 46.4596\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3979.6074 - mae: 45.8426 - val_loss: 4139.2661 - val_mae: 46.4487\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3977.9507 - mae: 45.8322 - val_loss: 4137.5571 - val_mae: 46.4378\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3976.3069 - mae: 45.8218 - val_loss: 4135.8281 - val_mae: 46.4268\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3974.6577 - mae: 45.8113 - val_loss: 4134.1079 - val_mae: 46.4158\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3973.0063 - mae: 45.8009 - val_loss: 4132.3975 - val_mae: 46.4049\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3971.3491 - mae: 45.7905 - val_loss: 4130.6909 - val_mae: 46.3941\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3969.7168 - mae: 45.7801 - val_loss: 4128.9565 - val_mae: 46.3830\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3968.0796 - mae: 45.7696 - val_loss: 4127.2275 - val_mae: 46.3720\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3966.4360 - mae: 45.7591 - val_loss: 4125.5068 - val_mae: 46.3610\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3964.7549 - mae: 45.7487 - val_loss: 4123.8384 - val_mae: 46.3504\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3963.1499 - mae: 45.7385 - val_loss: 4122.1411 - val_mae: 46.3396\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3961.5044 - mae: 45.7282 - val_loss: 4120.4312 - val_mae: 46.3287\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3959.8755 - mae: 45.7177 - val_loss: 4118.6919 - val_mae: 46.3176\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3958.2207 - mae: 45.7073 - val_loss: 4116.9707 - val_mae: 46.3065\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3956.5569 - mae: 45.6968 - val_loss: 4115.2759 - val_mae: 46.2957\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3954.9338 - mae: 45.6864 - val_loss: 4113.5679 - val_mae: 46.2848\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3953.2932 - mae: 45.6760 - val_loss: 4111.8618 - val_mae: 46.2739\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3951.6387 - mae: 45.6656 - val_loss: 4110.1646 - val_mae: 46.2630\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3950.0266 - mae: 45.6552 - val_loss: 4108.4414 - val_mae: 46.2520\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3948.3672 - mae: 45.6448 - val_loss: 4106.7339 - val_mae: 46.2411\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3946.7070 - mae: 45.6343 - val_loss: 4105.0293 - val_mae: 46.2302\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3945.0820 - mae: 45.6239 - val_loss: 4103.2959 - val_mae: 46.2191\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3943.4385 - mae: 45.6135 - val_loss: 4101.5649 - val_mae: 46.2080\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3941.7793 - mae: 45.6029 - val_loss: 4099.8589 - val_mae: 46.1971\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3940.1526 - mae: 45.5926 - val_loss: 4098.1528 - val_mae: 46.1862\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3938.5220 - mae: 45.5822 - val_loss: 4096.4604 - val_mae: 46.1755\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3936.8967 - mae: 45.5718 - val_loss: 4094.7703 - val_mae: 46.1647\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3935.2671 - mae: 45.5615 - val_loss: 4093.0825 - val_mae: 46.1539\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 3933.6631 - mae: 45.5512 - val_loss: 4091.3640 - val_mae: 46.1430\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3932.0039 - mae: 45.5407 - val_loss: 4089.6765 - val_mae: 46.1322\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3930.3967 - mae: 45.5304 - val_loss: 4087.9829 - val_mae: 46.1214\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3928.7468 - mae: 45.5201 - val_loss: 4086.2974 - val_mae: 46.1106\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3927.1309 - mae: 45.5097 - val_loss: 4084.5920 - val_mae: 46.0998\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3925.4812 - mae: 45.4993 - val_loss: 4082.9075 - val_mae: 46.0891\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3923.8787 - mae: 45.4890 - val_loss: 4081.2053 - val_mae: 46.0783\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3922.2607 - mae: 45.4786 - val_loss: 4079.5017 - val_mae: 46.0675\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3920.6172 - mae: 45.4682 - val_loss: 4077.8240 - val_mae: 46.0568\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3919.0020 - mae: 45.4580 - val_loss: 4076.1406 - val_mae: 46.0461\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3917.3970 - mae: 45.4477 - val_loss: 4074.4402 - val_mae: 46.0353\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3915.7454 - mae: 45.4374 - val_loss: 4072.7668 - val_mae: 46.0247\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3914.1689 - mae: 45.4272 - val_loss: 4071.0674 - val_mae: 46.0139\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3912.5239 - mae: 45.4167 - val_loss: 4069.3918 - val_mae: 46.0033\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3910.9045 - mae: 45.4065 - val_loss: 4067.7126 - val_mae: 45.9926\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3909.3130 - mae: 45.3962 - val_loss: 4066.0022 - val_mae: 45.9817\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3907.6860 - mae: 45.3858 - val_loss: 4064.3037 - val_mae: 45.9708\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3906.0330 - mae: 45.3754 - val_loss: 4062.6265 - val_mae: 45.9601\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3904.4255 - mae: 45.3651 - val_loss: 4060.9348 - val_mae: 45.9494\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3902.8193 - mae: 45.3548 - val_loss: 4059.2314 - val_mae: 45.9385\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3901.1797 - mae: 45.3444 - val_loss: 4057.5535 - val_mae: 45.9278\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3899.5686 - mae: 45.3342 - val_loss: 4055.8894 - val_mae: 45.9171\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3897.9497 - mae: 45.3240 - val_loss: 4054.2312 - val_mae: 45.9066\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3896.3608 - mae: 45.3138 - val_loss: 4052.5413 - val_mae: 45.8958\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3894.7717 - mae: 45.3034 - val_loss: 4050.8184 - val_mae: 45.8848\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3893.1145 - mae: 45.2929 - val_loss: 4049.1282 - val_mae: 45.8740\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3891.5037 - mae: 45.2825 - val_loss: 4047.4434 - val_mae: 45.8632\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3889.8887 - mae: 45.2723 - val_loss: 4045.7690 - val_mae: 45.8525\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3888.2930 - mae: 45.2620 - val_loss: 4044.0959 - val_mae: 45.8418\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3886.6912 - mae: 45.2518 - val_loss: 4042.4150 - val_mae: 45.8310\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3885.0601 - mae: 45.2414 - val_loss: 4040.7473 - val_mae: 45.8203\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3883.4697 - mae: 45.2311 - val_loss: 4039.0703 - val_mae: 45.8096\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3881.8518 - mae: 45.2209 - val_loss: 4037.4153 - val_mae: 45.7990\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3880.2627 - mae: 45.2107 - val_loss: 4035.7344 - val_mae: 45.7882\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3878.6375 - mae: 45.2004 - val_loss: 4034.0579 - val_mae: 45.7775\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3877.0300 - mae: 45.1902 - val_loss: 4032.3875 - val_mae: 45.7668\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3875.4324 - mae: 45.1799 - val_loss: 4030.7029 - val_mae: 45.7560\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3873.8384 - mae: 45.1696 - val_loss: 4029.0234 - val_mae: 45.7452\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3872.2092 - mae: 45.1594 - val_loss: 4027.3640 - val_mae: 45.7346\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3870.6514 - mae: 45.1491 - val_loss: 4025.6702 - val_mae: 45.7237\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3869.0061 - mae: 45.1389 - val_loss: 4024.0222 - val_mae: 45.7131\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=adam; total time=   5.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 28ms/step - loss: 1772.2866 - mae: 31.5856 - val_loss: 1816.6544 - val_mae: 31.1759\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1771.8251 - mae: 31.5817 - val_loss: 1816.1409 - val_mae: 31.1716\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1771.3558 - mae: 31.5777 - val_loss: 1815.6310 - val_mae: 31.1673\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1770.8956 - mae: 31.5738 - val_loss: 1815.1227 - val_mae: 31.1630\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1770.4268 - mae: 31.5699 - val_loss: 1814.6163 - val_mae: 31.1587\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1769.9658 - mae: 31.5659 - val_loss: 1814.1101 - val_mae: 31.1544\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1769.4973 - mae: 31.5620 - val_loss: 1813.6047 - val_mae: 31.1501\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1769.0333 - mae: 31.5580 - val_loss: 1813.0978 - val_mae: 31.1458\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1768.5844 - mae: 31.5542 - val_loss: 1812.5811 - val_mae: 31.1414\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1768.1089 - mae: 31.5502 - val_loss: 1812.0782 - val_mae: 31.1371\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1767.6364 - mae: 31.5462 - val_loss: 1811.5829 - val_mae: 31.1329\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1767.1877 - mae: 31.5423 - val_loss: 1811.0718 - val_mae: 31.1286\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1766.7150 - mae: 31.5384 - val_loss: 1810.5682 - val_mae: 31.1243\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1766.2616 - mae: 31.5344 - val_loss: 1810.0503 - val_mae: 31.1199\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1765.7875 - mae: 31.5305 - val_loss: 1809.5406 - val_mae: 31.1156\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1765.3239 - mae: 31.5265 - val_loss: 1809.0305 - val_mae: 31.1113\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1764.8593 - mae: 31.5226 - val_loss: 1808.5255 - val_mae: 31.1070\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1764.3964 - mae: 31.5187 - val_loss: 1808.0193 - val_mae: 31.1027\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1763.9421 - mae: 31.5148 - val_loss: 1807.5088 - val_mae: 31.0984\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1763.4728 - mae: 31.5108 - val_loss: 1807.0117 - val_mae: 31.0942\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1763.0170 - mae: 31.5069 - val_loss: 1806.5126 - val_mae: 31.0900\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1762.5548 - mae: 31.5030 - val_loss: 1806.0156 - val_mae: 31.0857\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1762.1027 - mae: 31.4991 - val_loss: 1805.5116 - val_mae: 31.0814\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1761.6420 - mae: 31.4952 - val_loss: 1805.0073 - val_mae: 31.0772\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1761.1874 - mae: 31.4913 - val_loss: 1804.5017 - val_mae: 31.0729\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1760.7263 - mae: 31.4874 - val_loss: 1803.9999 - val_mae: 31.0686\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1760.2684 - mae: 31.4835 - val_loss: 1803.5010 - val_mae: 31.0644\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1759.8052 - mae: 31.4796 - val_loss: 1803.0049 - val_mae: 31.0602\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1759.3615 - mae: 31.4757 - val_loss: 1802.4978 - val_mae: 31.0559\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1758.8826 - mae: 31.4717 - val_loss: 1802.0095 - val_mae: 31.0517\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1758.4371 - mae: 31.4679 - val_loss: 1801.4991 - val_mae: 31.0474\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1757.9669 - mae: 31.4639 - val_loss: 1800.9938 - val_mae: 31.0431\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1757.5104 - mae: 31.4600 - val_loss: 1800.4799 - val_mae: 31.0387\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1757.0465 - mae: 31.4561 - val_loss: 1799.9706 - val_mae: 31.0344\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1756.5780 - mae: 31.4522 - val_loss: 1799.4705 - val_mae: 31.0302\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1756.1238 - mae: 31.4483 - val_loss: 1798.9642 - val_mae: 31.0259\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1755.6613 - mae: 31.4443 - val_loss: 1798.4604 - val_mae: 31.0216\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1755.2065 - mae: 31.4405 - val_loss: 1797.9572 - val_mae: 31.0173\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1754.7434 - mae: 31.4365 - val_loss: 1797.4628 - val_mae: 31.0131\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1754.2947 - mae: 31.4327 - val_loss: 1796.9520 - val_mae: 31.0088\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1753.8206 - mae: 31.4287 - val_loss: 1796.4553 - val_mae: 31.0046\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1753.3750 - mae: 31.4248 - val_loss: 1795.9437 - val_mae: 31.0002\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1752.9038 - mae: 31.4209 - val_loss: 1795.4429 - val_mae: 30.9960\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1752.4530 - mae: 31.4170 - val_loss: 1794.9323 - val_mae: 30.9917\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1751.9829 - mae: 31.4131 - val_loss: 1794.4336 - val_mae: 30.9874\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1751.5251 - mae: 31.4092 - val_loss: 1793.9358 - val_mae: 30.9832\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1751.0634 - mae: 31.4053 - val_loss: 1793.4388 - val_mae: 30.9789\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1750.6112 - mae: 31.4014 - val_loss: 1792.9357 - val_mae: 30.9746\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1750.1560 - mae: 31.3975 - val_loss: 1792.4304 - val_mae: 30.9704\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1749.6921 - mae: 31.3936 - val_loss: 1791.9280 - val_mae: 30.9661\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1749.2393 - mae: 31.3897 - val_loss: 1791.4203 - val_mae: 30.9618\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1748.7806 - mae: 31.3858 - val_loss: 1790.9155 - val_mae: 30.9575\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1748.3215 - mae: 31.3819 - val_loss: 1790.4178 - val_mae: 30.9533\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1747.8663 - mae: 31.3780 - val_loss: 1789.9205 - val_mae: 30.9490\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1747.4067 - mae: 31.3741 - val_loss: 1789.4291 - val_mae: 30.9448\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1746.9648 - mae: 31.3703 - val_loss: 1788.9248 - val_mae: 30.9405\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1746.4990 - mae: 31.3664 - val_loss: 1788.4315 - val_mae: 30.9363\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1746.0416 - mae: 31.3625 - val_loss: 1787.9386 - val_mae: 30.9321\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1745.5933 - mae: 31.3586 - val_loss: 1787.4408 - val_mae: 30.9279\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 1745.1353 - mae: 31.3547 - val_loss: 1786.9474 - val_mae: 30.9236\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1744.6877 - mae: 31.3509 - val_loss: 1786.4498 - val_mae: 30.9194\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1744.2339 - mae: 31.3471 - val_loss: 1785.9500 - val_mae: 30.9151\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1743.7761 - mae: 31.3431 - val_loss: 1785.4493 - val_mae: 30.9109\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1743.3207 - mae: 31.3393 - val_loss: 1784.9491 - val_mae: 30.9066\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1742.8666 - mae: 31.3354 - val_loss: 1784.4495 - val_mae: 30.9024\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1742.4180 - mae: 31.3315 - val_loss: 1783.9506 - val_mae: 30.8981\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1741.9543 - mae: 31.3276 - val_loss: 1783.4633 - val_mae: 30.8940\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1741.5186 - mae: 31.3238 - val_loss: 1782.9592 - val_mae: 30.8897\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1741.0570 - mae: 31.3199 - val_loss: 1782.4713 - val_mae: 30.8856\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1740.5992 - mae: 31.3161 - val_loss: 1781.9905 - val_mae: 30.8814\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1740.1630 - mae: 31.3123 - val_loss: 1781.4921 - val_mae: 30.8772\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1739.7135 - mae: 31.3084 - val_loss: 1780.9928 - val_mae: 30.8730\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1739.2607 - mae: 31.3045 - val_loss: 1780.5016 - val_mae: 30.8688\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1738.8086 - mae: 31.3007 - val_loss: 1780.0142 - val_mae: 30.8646\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1738.3685 - mae: 31.2969 - val_loss: 1779.5250 - val_mae: 30.8604\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1737.9180 - mae: 31.2930 - val_loss: 1779.0421 - val_mae: 30.8563\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1737.4783 - mae: 31.2892 - val_loss: 1778.5526 - val_mae: 30.8521\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1737.0205 - mae: 31.2854 - val_loss: 1778.0717 - val_mae: 30.8480\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1736.5807 - mae: 31.2816 - val_loss: 1777.5756 - val_mae: 30.8438\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1736.1278 - mae: 31.2777 - val_loss: 1777.0813 - val_mae: 30.8396\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1735.6812 - mae: 31.2739 - val_loss: 1776.5828 - val_mae: 30.8353\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1735.2201 - mae: 31.2700 - val_loss: 1776.0992 - val_mae: 30.8312\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1734.7904 - mae: 31.2662 - val_loss: 1775.5975 - val_mae: 30.8269\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1734.3345 - mae: 31.2623 - val_loss: 1775.1078 - val_mae: 30.8227\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1733.8815 - mae: 31.2585 - val_loss: 1774.6310 - val_mae: 30.8186\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1733.4508 - mae: 31.2547 - val_loss: 1774.1404 - val_mae: 30.8145\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1732.9933 - mae: 31.2508 - val_loss: 1773.6636 - val_mae: 30.8103\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1732.5582 - mae: 31.2470 - val_loss: 1773.1727 - val_mae: 30.8062\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1732.1039 - mae: 31.2432 - val_loss: 1772.6869 - val_mae: 30.8020\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1731.6621 - mae: 31.2394 - val_loss: 1772.1952 - val_mae: 30.7978\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1731.2113 - mae: 31.2355 - val_loss: 1771.7094 - val_mae: 30.7936\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1730.7660 - mae: 31.2317 - val_loss: 1771.2190 - val_mae: 30.7894\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1730.3115 - mae: 31.2278 - val_loss: 1770.7303 - val_mae: 30.7853\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1729.8667 - mae: 31.2240 - val_loss: 1770.2333 - val_mae: 30.7810\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1729.4194 - mae: 31.2202 - val_loss: 1769.7380 - val_mae: 30.7768\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1728.9679 - mae: 31.2163 - val_loss: 1769.2458 - val_mae: 30.7726\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1728.5188 - mae: 31.2125 - val_loss: 1768.7563 - val_mae: 30.7684\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1728.0709 - mae: 31.2087 - val_loss: 1768.2723 - val_mae: 30.7642\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1727.6353 - mae: 31.2049 - val_loss: 1767.7783 - val_mae: 30.7600\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1727.1755 - mae: 31.2010 - val_loss: 1767.2992 - val_mae: 30.7559\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=adam; total time=   5.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 20ms/step - loss: 3466.8872 - mae: 40.3958 - val_loss: 3314.1733 - val_mae: 40.1280\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3465.5657 - mae: 40.3883 - val_loss: 3312.8245 - val_mae: 40.1202\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3464.2961 - mae: 40.3810 - val_loss: 3311.4683 - val_mae: 40.1124\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3462.9426 - mae: 40.3735 - val_loss: 3310.1421 - val_mae: 40.1047\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3461.6470 - mae: 40.3662 - val_loss: 3308.8059 - val_mae: 40.0970\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3460.3228 - mae: 40.3587 - val_loss: 3307.4795 - val_mae: 40.0893\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3459.0471 - mae: 40.3514 - val_loss: 3306.1250 - val_mae: 40.0814\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3457.7432 - mae: 40.3440 - val_loss: 3304.7800 - val_mae: 40.0736\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3456.4314 - mae: 40.3366 - val_loss: 3303.4404 - val_mae: 40.0659\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3455.1545 - mae: 40.3292 - val_loss: 3302.0815 - val_mae: 40.0581\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3453.8079 - mae: 40.3216 - val_loss: 3300.7483 - val_mae: 40.0504\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3452.4985 - mae: 40.3143 - val_loss: 3299.4155 - val_mae: 40.0427\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3451.2212 - mae: 40.3069 - val_loss: 3298.0659 - val_mae: 40.0349\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3449.9082 - mae: 40.2995 - val_loss: 3296.7334 - val_mae: 40.0272\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3448.6013 - mae: 40.2921 - val_loss: 3295.4089 - val_mae: 40.0196\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3447.3257 - mae: 40.2848 - val_loss: 3294.0754 - val_mae: 40.0118\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3446.0149 - mae: 40.2774 - val_loss: 3292.7544 - val_mae: 40.0042\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3444.7544 - mae: 40.2702 - val_loss: 3291.4202 - val_mae: 39.9965\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3443.4590 - mae: 40.2628 - val_loss: 3290.0845 - val_mae: 39.9888\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3442.1689 - mae: 40.2555 - val_loss: 3288.7490 - val_mae: 39.9811\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3440.8569 - mae: 40.2482 - val_loss: 3287.4380 - val_mae: 39.9736\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3439.5920 - mae: 40.2409 - val_loss: 3286.1113 - val_mae: 39.9659\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3438.2769 - mae: 40.2336 - val_loss: 3284.7986 - val_mae: 39.9584\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3436.9897 - mae: 40.2263 - val_loss: 3283.4829 - val_mae: 39.9508\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3435.7383 - mae: 40.2190 - val_loss: 3282.1287 - val_mae: 39.9430\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3434.4429 - mae: 40.2117 - val_loss: 3280.7927 - val_mae: 39.9353\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3433.1284 - mae: 40.2043 - val_loss: 3279.4768 - val_mae: 39.9277\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3431.8425 - mae: 40.1970 - val_loss: 3278.1560 - val_mae: 39.9201\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3430.5593 - mae: 40.1897 - val_loss: 3276.8237 - val_mae: 39.9124\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3429.2761 - mae: 40.1824 - val_loss: 3275.4824 - val_mae: 39.9047\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3427.9768 - mae: 40.1752 - val_loss: 3274.1670 - val_mae: 39.8971\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3426.7053 - mae: 40.1679 - val_loss: 3272.8604 - val_mae: 39.8895\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3425.4321 - mae: 40.1607 - val_loss: 3271.5579 - val_mae: 39.8820\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3424.1792 - mae: 40.1535 - val_loss: 3270.2361 - val_mae: 39.8744\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3422.8821 - mae: 40.1462 - val_loss: 3268.9434 - val_mae: 39.8669\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3421.6147 - mae: 40.1391 - val_loss: 3267.6389 - val_mae: 39.8594\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3420.3491 - mae: 40.1319 - val_loss: 3266.3059 - val_mae: 39.8517\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3419.0466 - mae: 40.1245 - val_loss: 3264.9907 - val_mae: 39.8441\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3417.7546 - mae: 40.1173 - val_loss: 3263.6799 - val_mae: 39.8365\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3416.5015 - mae: 40.1101 - val_loss: 3262.3450 - val_mae: 39.8288\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3415.1990 - mae: 40.1028 - val_loss: 3261.0359 - val_mae: 39.8212\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3413.9189 - mae: 40.0956 - val_loss: 3259.7236 - val_mae: 39.8136\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3412.6423 - mae: 40.0884 - val_loss: 3258.4006 - val_mae: 39.8060\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3411.3645 - mae: 40.0811 - val_loss: 3257.0708 - val_mae: 39.7984\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3410.0757 - mae: 40.0739 - val_loss: 3255.7534 - val_mae: 39.7908\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3408.7744 - mae: 40.0666 - val_loss: 3254.4543 - val_mae: 39.7833\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3407.5371 - mae: 40.0595 - val_loss: 3253.1135 - val_mae: 39.7756\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3406.2244 - mae: 40.0522 - val_loss: 3251.8076 - val_mae: 39.7680\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3404.9719 - mae: 40.0451 - val_loss: 3250.4744 - val_mae: 39.7603\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3403.6768 - mae: 40.0378 - val_loss: 3249.1650 - val_mae: 39.7528\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3402.3914 - mae: 40.0306 - val_loss: 3247.8770 - val_mae: 39.7453\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3401.1545 - mae: 40.0235 - val_loss: 3246.5574 - val_mae: 39.7377\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3399.8457 - mae: 40.0162 - val_loss: 3245.2551 - val_mae: 39.7302\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3398.5930 - mae: 40.0091 - val_loss: 3243.9241 - val_mae: 39.7225\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3397.2871 - mae: 40.0018 - val_loss: 3242.6252 - val_mae: 39.7150\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3396.0352 - mae: 39.9947 - val_loss: 3241.2964 - val_mae: 39.7073\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3394.7419 - mae: 39.9874 - val_loss: 3239.9817 - val_mae: 39.6997\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3393.4629 - mae: 39.9802 - val_loss: 3238.6719 - val_mae: 39.6921\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3392.2031 - mae: 39.9730 - val_loss: 3237.3635 - val_mae: 39.6846\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 3390.9307 - mae: 39.9659 - val_loss: 3236.0562 - val_mae: 39.6770\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3389.6384 - mae: 39.9586 - val_loss: 3234.7610 - val_mae: 39.6695\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3388.3943 - mae: 39.9515 - val_loss: 3233.4404 - val_mae: 39.6618\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3387.1155 - mae: 39.9443 - val_loss: 3232.1208 - val_mae: 39.6542\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3385.8062 - mae: 39.9370 - val_loss: 3230.8328 - val_mae: 39.6467\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3384.5510 - mae: 39.9298 - val_loss: 3229.5225 - val_mae: 39.6391\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3383.2874 - mae: 39.9227 - val_loss: 3228.2100 - val_mae: 39.6315\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3382.0017 - mae: 39.9154 - val_loss: 3226.9033 - val_mae: 39.6240\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3380.7571 - mae: 39.9083 - val_loss: 3225.5745 - val_mae: 39.6163\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3379.4382 - mae: 39.9009 - val_loss: 3224.2825 - val_mae: 39.6088\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3378.1836 - mae: 39.8938 - val_loss: 3222.9807 - val_mae: 39.6013\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3376.9092 - mae: 39.8866 - val_loss: 3221.6731 - val_mae: 39.5938\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3375.6367 - mae: 39.8794 - val_loss: 3220.3713 - val_mae: 39.5862\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3374.3828 - mae: 39.8723 - val_loss: 3219.0659 - val_mae: 39.5787\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3373.1096 - mae: 39.8651 - val_loss: 3217.7739 - val_mae: 39.5712\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3371.8738 - mae: 39.8580 - val_loss: 3216.4653 - val_mae: 39.5636\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3370.5779 - mae: 39.8508 - val_loss: 3215.1814 - val_mae: 39.5562\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3369.3372 - mae: 39.8438 - val_loss: 3213.8733 - val_mae: 39.5486\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3368.0679 - mae: 39.8366 - val_loss: 3212.5808 - val_mae: 39.5411\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3366.8291 - mae: 39.8295 - val_loss: 3211.2715 - val_mae: 39.5335\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3365.5322 - mae: 39.8222 - val_loss: 3209.9871 - val_mae: 39.5261\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3364.2925 - mae: 39.8152 - val_loss: 3208.6968 - val_mae: 39.5186\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3363.0503 - mae: 39.8081 - val_loss: 3207.4026 - val_mae: 39.5110\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3361.7827 - mae: 39.8010 - val_loss: 3206.1309 - val_mae: 39.5036\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3360.5405 - mae: 39.7940 - val_loss: 3204.8464 - val_mae: 39.4961\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3359.3013 - mae: 39.7869 - val_loss: 3203.5547 - val_mae: 39.4886\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3358.0286 - mae: 39.7797 - val_loss: 3202.2634 - val_mae: 39.4811\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3356.7700 - mae: 39.7726 - val_loss: 3200.9878 - val_mae: 39.4737\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3355.5764 - mae: 39.7657 - val_loss: 3199.6685 - val_mae: 39.4661\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 3354.2646 - mae: 39.7585 - val_loss: 3198.4084 - val_mae: 39.4587\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3353.0220 - mae: 39.7514 - val_loss: 3197.1421 - val_mae: 39.4514\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3351.7712 - mae: 39.7444 - val_loss: 3195.8645 - val_mae: 39.4439\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3350.5295 - mae: 39.7374 - val_loss: 3194.5688 - val_mae: 39.4364\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3349.2581 - mae: 39.7302 - val_loss: 3193.2822 - val_mae: 39.4289\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3348.0242 - mae: 39.7231 - val_loss: 3191.9705 - val_mae: 39.4213\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3346.7395 - mae: 39.7159 - val_loss: 3190.6763 - val_mae: 39.4137\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3345.4878 - mae: 39.7088 - val_loss: 3189.3767 - val_mae: 39.4061\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3344.2009 - mae: 39.7016 - val_loss: 3188.0908 - val_mae: 39.3986\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3342.9707 - mae: 39.6945 - val_loss: 3186.7920 - val_mae: 39.3910\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3341.6768 - mae: 39.6874 - val_loss: 3185.5293 - val_mae: 39.3836\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3340.4480 - mae: 39.6804 - val_loss: 3184.2332 - val_mae: 39.3760\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=adam; total time=   5.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 26ms/step - loss: 1249.5839 - mae: 28.9565 - val_loss: 1121.9581 - val_mae: 26.5605\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1029.9309 - mae: 26.5943 - val_loss: 945.5564 - val_mae: 24.5830\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 891.0668 - mae: 24.9105 - val_loss: 825.5341 - val_mae: 23.1396\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 795.6767 - mae: 23.6691 - val_loss: 741.4438 - val_mae: 22.1142\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 728.8942 - mae: 22.7814 - val_loss: 678.4922 - val_mae: 21.3755\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.4271 - mae: 22.0957 - val_loss: 630.8765 - val_mae: 20.8270\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 642.6131 - mae: 21.5771 - val_loss: 594.0407 - val_mae: 20.3807\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 614.2845 - mae: 21.1739 - val_loss: 565.0784 - val_mae: 19.9861\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.1762 - mae: 20.8391 - val_loss: 540.7615 - val_mae: 19.6481\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.2321 - mae: 20.5625 - val_loss: 520.7380 - val_mae: 19.3684\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.4178 - mae: 20.3130 - val_loss: 503.8546 - val_mae: 19.1168\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.0049 - mae: 20.0983 - val_loss: 489.6805 - val_mae: 18.8979\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 536.5143 - mae: 19.9102 - val_loss: 477.4137 - val_mae: 18.7041\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.6127 - mae: 19.7459 - val_loss: 466.4919 - val_mae: 18.5230\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.7155 - mae: 19.5946 - val_loss: 456.5074 - val_mae: 18.3484\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 512.6437 - mae: 19.4586 - val_loss: 447.8678 - val_mae: 18.1890\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.7056 - mae: 19.3367 - val_loss: 440.1678 - val_mae: 18.0405\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 501.4162 - mae: 19.2260 - val_loss: 433.0367 - val_mae: 17.9023\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 496.6783 - mae: 19.1234 - val_loss: 426.8872 - val_mae: 17.7732\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.4209 - mae: 19.0240 - val_loss: 421.1729 - val_mae: 17.6578\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488.4521 - mae: 18.9317 - val_loss: 415.7666 - val_mae: 17.5384\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 484.5839 - mae: 18.8388 - val_loss: 410.3959 - val_mae: 17.4209\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.8004 - mae: 18.7501 - val_loss: 405.8860 - val_mae: 17.3174\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 477.4402 - mae: 18.6684 - val_loss: 402.0533 - val_mae: 17.2274\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.5242 - mae: 18.5939 - val_loss: 398.3041 - val_mae: 17.1417\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.8018 - mae: 18.5268 - val_loss: 395.0545 - val_mae: 17.0673\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 469.4498 - mae: 18.4668 - val_loss: 392.2404 - val_mae: 17.0004\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 467.3300 - mae: 18.4155 - val_loss: 389.6603 - val_mae: 16.9430\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.5157 - mae: 18.3703 - val_loss: 387.3523 - val_mae: 16.8919\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 463.8620 - mae: 18.3261 - val_loss: 385.0298 - val_mae: 16.8464\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.2552 - mae: 18.2857 - val_loss: 382.6320 - val_mae: 16.8063\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.6164 - mae: 18.2503 - val_loss: 380.8489 - val_mae: 16.7753\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 459.3319 - mae: 18.2181 - val_loss: 379.1792 - val_mae: 16.7456\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 458.0414 - mae: 18.1857 - val_loss: 377.4597 - val_mae: 16.7199\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.7890 - mae: 18.1562 - val_loss: 375.9330 - val_mae: 16.6968\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 455.6479 - mae: 18.1267 - val_loss: 374.3481 - val_mae: 16.6739\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 454.5455 - mae: 18.1007 - val_loss: 372.9205 - val_mae: 16.6517\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.4774 - mae: 18.0763 - val_loss: 371.6205 - val_mae: 16.6277\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.5386 - mae: 18.0523 - val_loss: 370.3326 - val_mae: 16.6028\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 451.6226 - mae: 18.0291 - val_loss: 368.9836 - val_mae: 16.5800\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.7483 - mae: 18.0081 - val_loss: 367.8353 - val_mae: 16.5588\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.9342 - mae: 17.9880 - val_loss: 366.5647 - val_mae: 16.5351\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.1524 - mae: 17.9695 - val_loss: 365.6021 - val_mae: 16.5149\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.4129 - mae: 17.9513 - val_loss: 364.5292 - val_mae: 16.4936\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 447.6643 - mae: 17.9323 - val_loss: 363.4909 - val_mae: 16.4712\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.9283 - mae: 17.9133 - val_loss: 362.5290 - val_mae: 16.4508\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.2254 - mae: 17.8976 - val_loss: 361.5471 - val_mae: 16.4312\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 445.5221 - mae: 17.8792 - val_loss: 360.6394 - val_mae: 16.4110\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 444.8407 - mae: 17.8609 - val_loss: 359.7764 - val_mae: 16.3941\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.1620 - mae: 17.8444 - val_loss: 358.8151 - val_mae: 16.3733\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4814 - mae: 17.8243 - val_loss: 358.0059 - val_mae: 16.3580\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.8347 - mae: 17.8091 - val_loss: 357.1981 - val_mae: 16.3395\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.2432 - mae: 17.7936 - val_loss: 356.3899 - val_mae: 16.3211\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 441.6025 - mae: 17.7768 - val_loss: 355.4856 - val_mae: 16.3024\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 440.9260 - mae: 17.7601 - val_loss: 354.6909 - val_mae: 16.2840\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 440.3335 - mae: 17.7426 - val_loss: 353.8598 - val_mae: 16.2658\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.7411 - mae: 17.7296 - val_loss: 352.9456 - val_mae: 16.2454\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.1513 - mae: 17.7129 - val_loss: 352.0417 - val_mae: 16.2269\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 438.5815 - mae: 17.7002 - val_loss: 351.2771 - val_mae: 16.2108\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.9830 - mae: 17.6869 - val_loss: 350.5046 - val_mae: 16.1931\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 437.4343 - mae: 17.6712 - val_loss: 349.7529 - val_mae: 16.1765\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.9079 - mae: 17.6575 - val_loss: 348.8051 - val_mae: 16.1585\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 436.3034 - mae: 17.6447 - val_loss: 348.0949 - val_mae: 16.1434\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.7697 - mae: 17.6318 - val_loss: 347.3602 - val_mae: 16.1274\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.2515 - mae: 17.6181 - val_loss: 346.6013 - val_mae: 16.1124\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.7338 - mae: 17.6063 - val_loss: 345.8941 - val_mae: 16.0981\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.1615 - mae: 17.5948 - val_loss: 345.1076 - val_mae: 16.0796\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.6835 - mae: 17.5787 - val_loss: 344.4359 - val_mae: 16.0668\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.0869 - mae: 17.5666 - val_loss: 343.7016 - val_mae: 16.0516\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.5860 - mae: 17.5552 - val_loss: 343.0282 - val_mae: 16.0375\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.0571 - mae: 17.5433 - val_loss: 342.1429 - val_mae: 16.0173\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.5740 - mae: 17.5290 - val_loss: 341.3644 - val_mae: 16.0007\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 431.0662 - mae: 17.5166 - val_loss: 340.6636 - val_mae: 15.9864\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 430.5691 - mae: 17.5054 - val_loss: 339.8605 - val_mae: 15.9697\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 430.0986 - mae: 17.4953 - val_loss: 339.2156 - val_mae: 15.9572\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.6135 - mae: 17.4851 - val_loss: 338.5181 - val_mae: 15.9451\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.1084 - mae: 17.4755 - val_loss: 337.8221 - val_mae: 15.9296\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.6523 - mae: 17.4658 - val_loss: 336.9565 - val_mae: 15.9105\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.1508 - mae: 17.4527 - val_loss: 336.2153 - val_mae: 15.8944\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 427.6795 - mae: 17.4433 - val_loss: 335.4820 - val_mae: 15.8787\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.2150 - mae: 17.4338 - val_loss: 334.7438 - val_mae: 15.8633\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.7310 - mae: 17.4224 - val_loss: 333.9864 - val_mae: 15.8471\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.2263 - mae: 17.4109 - val_loss: 333.1836 - val_mae: 15.8309\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.7517 - mae: 17.4019 - val_loss: 332.4208 - val_mae: 15.8146\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.2339 - mae: 17.3913 - val_loss: 331.7199 - val_mae: 15.8019\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.7312 - mae: 17.3841 - val_loss: 330.8243 - val_mae: 15.7840\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 424.1855 - mae: 17.3689 - val_loss: 330.1459 - val_mae: 15.7746\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 423.6706 - mae: 17.3612 - val_loss: 329.4398 - val_mae: 15.7608\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 423.1721 - mae: 17.3511 - val_loss: 328.6972 - val_mae: 15.7447\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.6787 - mae: 17.3403 - val_loss: 327.8878 - val_mae: 15.7266\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.1602 - mae: 17.3277 - val_loss: 327.1748 - val_mae: 15.7126\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.6697 - mae: 17.3169 - val_loss: 326.4148 - val_mae: 15.6956\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.1272 - mae: 17.3018 - val_loss: 325.6681 - val_mae: 15.6814\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.6178 - mae: 17.2922 - val_loss: 324.8149 - val_mae: 15.6607\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.0676 - mae: 17.2771 - val_loss: 324.0721 - val_mae: 15.6439\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.5501 - mae: 17.2642 - val_loss: 323.3097 - val_mae: 15.6253\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 419.0576 - mae: 17.2541 - val_loss: 322.6392 - val_mae: 15.6082\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.5661 - mae: 17.2397 - val_loss: 321.9772 - val_mae: 15.5924\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 418.1048 - mae: 17.2281 - val_loss: 321.3376 - val_mae: 15.5782\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.6521 - mae: 17.2176 - val_loss: 320.7226 - val_mae: 15.5611\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 1074.3511 - mae: 25.2503 - val_loss: 923.0980 - val_mae: 23.3809\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 888.1924 - mae: 23.5968 - val_loss: 770.1329 - val_mae: 21.9533\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 775.9810 - mae: 22.4502 - val_loss: 670.1450 - val_mae: 20.8585\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 699.7902 - mae: 21.5465 - val_loss: 597.5792 - val_mae: 19.9493\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 644.1368 - mae: 20.8208 - val_loss: 543.9774 - val_mae: 19.1857\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 603.0219 - mae: 20.2308 - val_loss: 502.2430 - val_mae: 18.5465\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.0504 - mae: 19.7546 - val_loss: 469.8150 - val_mae: 18.0246\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.3417 - mae: 19.3596 - val_loss: 444.2605 - val_mae: 17.5913\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.9930 - mae: 19.0340 - val_loss: 423.7906 - val_mae: 17.2221\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 511.6109 - mae: 18.7663 - val_loss: 406.8922 - val_mae: 16.9195\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 499.0943 - mae: 18.5488 - val_loss: 392.9500 - val_mae: 16.6697\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 488.6813 - mae: 18.3653 - val_loss: 381.0297 - val_mae: 16.4632\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.9349 - mae: 18.2047 - val_loss: 371.0791 - val_mae: 16.2864\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 472.5185 - mae: 18.0607 - val_loss: 362.5994 - val_mae: 16.1326\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.2670 - mae: 17.9436 - val_loss: 355.1594 - val_mae: 15.9931\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.8423 - mae: 17.8359 - val_loss: 348.6865 - val_mae: 15.8681\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.1476 - mae: 17.7405 - val_loss: 342.8958 - val_mae: 15.7506\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.0535 - mae: 17.6618 - val_loss: 338.0446 - val_mae: 15.6456\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 448.5309 - mae: 17.5882 - val_loss: 333.6750 - val_mae: 15.5489\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 445.4103 - mae: 17.5256 - val_loss: 329.7360 - val_mae: 15.4571\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.5647 - mae: 17.4614 - val_loss: 326.3229 - val_mae: 15.3746\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 440.0888 - mae: 17.4027 - val_loss: 323.1745 - val_mae: 15.2968\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.8188 - mae: 17.3512 - val_loss: 320.0556 - val_mae: 15.2196\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.6381 - mae: 17.3014 - val_loss: 317.3505 - val_mae: 15.1488\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 433.7444 - mae: 17.2573 - val_loss: 314.9955 - val_mae: 15.0867\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 432.0482 - mae: 17.2166 - val_loss: 312.8908 - val_mae: 15.0306\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 430.5097 - mae: 17.1770 - val_loss: 310.7384 - val_mae: 14.9730\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.9581 - mae: 17.1385 - val_loss: 308.8193 - val_mae: 14.9206\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 427.5608 - mae: 17.1018 - val_loss: 307.0707 - val_mae: 14.8719\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 426.3014 - mae: 17.0697 - val_loss: 305.5131 - val_mae: 14.8276\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 425.1017 - mae: 17.0384 - val_loss: 303.9258 - val_mae: 14.7829\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 423.9987 - mae: 17.0073 - val_loss: 302.5410 - val_mae: 14.7427\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 422.8720 - mae: 16.9776 - val_loss: 301.1761 - val_mae: 14.7047\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 421.8514 - mae: 16.9477 - val_loss: 299.8285 - val_mae: 14.6666\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 420.9126 - mae: 16.9236 - val_loss: 298.5269 - val_mae: 14.6290\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 419.9254 - mae: 16.8955 - val_loss: 297.4135 - val_mae: 14.5945\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 419.0170 - mae: 16.8708 - val_loss: 296.3598 - val_mae: 14.5618\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 418.0732 - mae: 16.8427 - val_loss: 295.2023 - val_mae: 14.5276\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 417.2099 - mae: 16.8207 - val_loss: 294.2507 - val_mae: 14.4960\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.3870 - mae: 16.7975 - val_loss: 293.2905 - val_mae: 14.4635\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 415.5964 - mae: 16.7710 - val_loss: 292.3000 - val_mae: 14.4331\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 414.7759 - mae: 16.7508 - val_loss: 291.3812 - val_mae: 14.4018\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 414.0001 - mae: 16.7284 - val_loss: 290.6121 - val_mae: 14.3733\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 413.2502 - mae: 16.7056 - val_loss: 289.8403 - val_mae: 14.3469\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.5474 - mae: 16.6870 - val_loss: 288.9962 - val_mae: 14.3175\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.8453 - mae: 16.6664 - val_loss: 288.2563 - val_mae: 14.2917\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 411.1396 - mae: 16.6463 - val_loss: 287.3915 - val_mae: 14.2622\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.4555 - mae: 16.6233 - val_loss: 286.6105 - val_mae: 14.2356\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.7554 - mae: 16.6037 - val_loss: 285.7880 - val_mae: 14.2080\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.0558 - mae: 16.5852 - val_loss: 284.9677 - val_mae: 14.1804\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 408.3510 - mae: 16.5626 - val_loss: 284.1364 - val_mae: 14.1527\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 407.6280 - mae: 16.5401 - val_loss: 283.3731 - val_mae: 14.1260\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 406.9229 - mae: 16.5186 - val_loss: 282.6442 - val_mae: 14.1029\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 406.2801 - mae: 16.5017 - val_loss: 281.9695 - val_mae: 14.0785\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 405.5936 - mae: 16.4813 - val_loss: 281.2568 - val_mae: 14.0541\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 404.9703 - mae: 16.4602 - val_loss: 280.5742 - val_mae: 14.0326\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 404.3456 - mae: 16.4392 - val_loss: 279.8738 - val_mae: 14.0122\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.7140 - mae: 16.4249 - val_loss: 279.1534 - val_mae: 13.9912\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.0663 - mae: 16.4041 - val_loss: 278.5591 - val_mae: 13.9713\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.4847 - mae: 16.3871 - val_loss: 277.8778 - val_mae: 13.9498\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 401.8480 - mae: 16.3684 - val_loss: 277.2256 - val_mae: 13.9278\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.2461 - mae: 16.3474 - val_loss: 276.6087 - val_mae: 13.9071\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.6385 - mae: 16.3300 - val_loss: 276.0134 - val_mae: 13.8861\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.0461 - mae: 16.3111 - val_loss: 275.4362 - val_mae: 13.8659\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.4772 - mae: 16.2930 - val_loss: 274.8104 - val_mae: 13.8435\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.9023 - mae: 16.2771 - val_loss: 274.2434 - val_mae: 13.8227\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.3194 - mae: 16.2589 - val_loss: 273.6634 - val_mae: 13.7995\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 397.7873 - mae: 16.2398 - val_loss: 273.0540 - val_mae: 13.7772\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 397.2853 - mae: 16.2198 - val_loss: 272.5847 - val_mae: 13.7586\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.6929 - mae: 16.2027 - val_loss: 272.1149 - val_mae: 13.7402\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.2068 - mae: 16.1864 - val_loss: 271.6604 - val_mae: 13.7217\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.6740 - mae: 16.1702 - val_loss: 271.1296 - val_mae: 13.7022\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.1725 - mae: 16.1545 - val_loss: 270.6767 - val_mae: 13.6848\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 394.6924 - mae: 16.1372 - val_loss: 270.2581 - val_mae: 13.6678\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 394.2195 - mae: 16.1216 - val_loss: 269.8848 - val_mae: 13.6527\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 393.7162 - mae: 16.1069 - val_loss: 269.4529 - val_mae: 13.6360\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 393.2653 - mae: 16.0916 - val_loss: 269.0202 - val_mae: 13.6179\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.8134 - mae: 16.0758 - val_loss: 268.5755 - val_mae: 13.6011\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.3943 - mae: 16.0623 - val_loss: 268.1459 - val_mae: 13.5834\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.9983 - mae: 16.0469 - val_loss: 267.8495 - val_mae: 13.5712\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.5865 - mae: 16.0380 - val_loss: 267.4361 - val_mae: 13.5542\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.1860 - mae: 16.0237 - val_loss: 267.1004 - val_mae: 13.5403\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.7982 - mae: 16.0114 - val_loss: 266.7283 - val_mae: 13.5266\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.4247 - mae: 15.9992 - val_loss: 266.3639 - val_mae: 13.5130\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.0412 - mae: 15.9868 - val_loss: 266.0264 - val_mae: 13.5014\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.6782 - mae: 15.9771 - val_loss: 265.7041 - val_mae: 13.4888\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.3179 - mae: 15.9642 - val_loss: 265.4036 - val_mae: 13.4788\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.9601 - mae: 15.9570 - val_loss: 265.0286 - val_mae: 13.4639\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.6466 - mae: 15.9456 - val_loss: 264.7007 - val_mae: 13.4500\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.3271 - mae: 15.9320 - val_loss: 264.3374 - val_mae: 13.4367\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.0598 - mae: 15.9235 - val_loss: 264.0258 - val_mae: 13.4247\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.7099 - mae: 15.9107 - val_loss: 263.8202 - val_mae: 13.4173\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.4112 - mae: 15.9038 - val_loss: 263.6008 - val_mae: 13.4101\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 387.1204 - mae: 15.8993 - val_loss: 263.3152 - val_mae: 13.3991\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 386.8255 - mae: 15.8870 - val_loss: 263.0689 - val_mae: 13.3905\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.5281 - mae: 15.8766 - val_loss: 262.8066 - val_mae: 13.3803\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.2439 - mae: 15.8680 - val_loss: 262.5369 - val_mae: 13.3697\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.9744 - mae: 15.8591 - val_loss: 262.2370 - val_mae: 13.3585\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.7106 - mae: 15.8504 - val_loss: 262.0199 - val_mae: 13.3527\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.4586 - mae: 15.8430 - val_loss: 261.7715 - val_mae: 13.3441\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   4.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 21ms/step - loss: 1780.1410 - mae: 32.0726 - val_loss: 1518.8522 - val_mae: 29.7201\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1348.4447 - mae: 28.4707 - val_loss: 1187.7113 - val_mae: 26.7015\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1081.2198 - mae: 25.9053 - val_loss: 966.6612 - val_mae: 24.4153\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 899.2005 - mae: 23.9416 - val_loss: 814.7528 - val_mae: 22.6619\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 772.4178 - mae: 22.4379 - val_loss: 706.9454 - val_mae: 21.3257\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.9276 - mae: 21.2406 - val_loss: 628.0511 - val_mae: 20.2925\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 613.1710 - mae: 20.3073 - val_loss: 569.0283 - val_mae: 19.4820\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.8920 - mae: 19.5545 - val_loss: 523.6348 - val_mae: 18.8187\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 522.1078 - mae: 18.9330 - val_loss: 488.3445 - val_mae: 18.2763\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 490.8220 - mae: 18.4149 - val_loss: 460.3079 - val_mae: 17.8267\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 465.6946 - mae: 17.9834 - val_loss: 437.3795 - val_mae: 17.4394\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 444.9654 - mae: 17.6082 - val_loss: 418.2583 - val_mae: 17.0969\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.6129 - mae: 17.2785 - val_loss: 402.3174 - val_mae: 16.8016\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.0044 - mae: 16.9879 - val_loss: 389.0302 - val_mae: 16.5442\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.6515 - mae: 16.7307 - val_loss: 377.8072 - val_mae: 16.3210\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.0633 - mae: 16.5083 - val_loss: 367.9514 - val_mae: 16.1120\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 380.7265 - mae: 16.3022 - val_loss: 359.3906 - val_mae: 15.9216\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.5367 - mae: 16.1117 - val_loss: 351.9126 - val_mae: 15.7542\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.3661 - mae: 15.9438 - val_loss: 345.1915 - val_mae: 15.6017\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.8803 - mae: 15.7821 - val_loss: 339.1669 - val_mae: 15.4562\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.9943 - mae: 15.6369 - val_loss: 333.6351 - val_mae: 15.3198\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.5328 - mae: 15.4992 - val_loss: 328.5930 - val_mae: 15.1901\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.5907 - mae: 15.3658 - val_loss: 323.9849 - val_mae: 15.0718\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.1563 - mae: 15.2474 - val_loss: 319.7604 - val_mae: 14.9601\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 334.0753 - mae: 15.1337 - val_loss: 315.9201 - val_mae: 14.8545\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.3293 - mae: 15.0288 - val_loss: 312.4396 - val_mae: 14.7554\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 326.8854 - mae: 14.9301 - val_loss: 309.3017 - val_mae: 14.6642\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.7890 - mae: 14.8421 - val_loss: 306.3881 - val_mae: 14.5799\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.8720 - mae: 14.7573 - val_loss: 303.7850 - val_mae: 14.5035\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.1870 - mae: 14.6771 - val_loss: 301.3784 - val_mae: 14.4325\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.6667 - mae: 14.6015 - val_loss: 299.1430 - val_mae: 14.3683\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.3109 - mae: 14.5304 - val_loss: 297.0460 - val_mae: 14.3082\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 311.1409 - mae: 14.4668 - val_loss: 295.0443 - val_mae: 14.2490\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.1122 - mae: 14.4023 - val_loss: 293.2200 - val_mae: 14.1942\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.2069 - mae: 14.3445 - val_loss: 291.5201 - val_mae: 14.1417\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.4352 - mae: 14.2900 - val_loss: 289.8873 - val_mae: 14.0910\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 303.7054 - mae: 14.2368 - val_loss: 288.3825 - val_mae: 14.0439\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 302.1125 - mae: 14.1867 - val_loss: 286.9509 - val_mae: 13.9996\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 300.5457 - mae: 14.1379 - val_loss: 285.6034 - val_mae: 13.9579\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.1161 - mae: 14.0939 - val_loss: 284.3037 - val_mae: 13.9180\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 297.6737 - mae: 14.0483 - val_loss: 283.0522 - val_mae: 13.8788\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.3236 - mae: 14.0077 - val_loss: 281.8497 - val_mae: 13.8410\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.0212 - mae: 13.9673 - val_loss: 280.7415 - val_mae: 13.8061\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.7612 - mae: 13.9282 - val_loss: 279.6403 - val_mae: 13.7709\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.5477 - mae: 13.8920 - val_loss: 278.5559 - val_mae: 13.7364\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.3448 - mae: 13.8552 - val_loss: 277.4918 - val_mae: 13.7021\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.2186 - mae: 13.8181 - val_loss: 276.4335 - val_mae: 13.6688\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.1030 - mae: 13.7849 - val_loss: 275.4405 - val_mae: 13.6366\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 288.0690 - mae: 13.7528 - val_loss: 274.4308 - val_mae: 13.6047\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 287.0129 - mae: 13.7217 - val_loss: 273.4590 - val_mae: 13.5747\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 285.9955 - mae: 13.6915 - val_loss: 272.5094 - val_mae: 13.5449\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 284.9923 - mae: 13.6606 - val_loss: 271.5870 - val_mae: 13.5164\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 284.0294 - mae: 13.6309 - val_loss: 270.6818 - val_mae: 13.4879\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 283.1038 - mae: 13.6009 - val_loss: 269.7818 - val_mae: 13.4598\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 282.1565 - mae: 13.5744 - val_loss: 268.9080 - val_mae: 13.4320\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 281.2148 - mae: 13.5474 - val_loss: 268.0448 - val_mae: 13.4058\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 280.3181 - mae: 13.5188 - val_loss: 267.2133 - val_mae: 13.3797\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 279.4541 - mae: 13.4891 - val_loss: 266.3575 - val_mae: 13.3535\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 278.5850 - mae: 13.4638 - val_loss: 265.5068 - val_mae: 13.3289\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 277.7146 - mae: 13.4393 - val_loss: 264.7123 - val_mae: 13.3047\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 276.8537 - mae: 13.4118 - val_loss: 263.8811 - val_mae: 13.2803\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 276.0338 - mae: 13.3869 - val_loss: 263.0660 - val_mae: 13.2575\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 275.1987 - mae: 13.3648 - val_loss: 262.3000 - val_mae: 13.2365\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 274.3977 - mae: 13.3377 - val_loss: 261.5188 - val_mae: 13.2134\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 273.5911 - mae: 13.3148 - val_loss: 260.7912 - val_mae: 13.1916\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 272.8001 - mae: 13.2888 - val_loss: 260.0337 - val_mae: 13.1695\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 272.0461 - mae: 13.2692 - val_loss: 259.3241 - val_mae: 13.1478\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 271.2982 - mae: 13.2436 - val_loss: 258.6033 - val_mae: 13.1258\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 270.5460 - mae: 13.2203 - val_loss: 257.9238 - val_mae: 13.1049\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.8110 - mae: 13.1962 - val_loss: 257.2622 - val_mae: 13.0840\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.0818 - mae: 13.1716 - val_loss: 256.6074 - val_mae: 13.0637\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.3426 - mae: 13.1480 - val_loss: 255.9706 - val_mae: 13.0438\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.6599 - mae: 13.1255 - val_loss: 255.3553 - val_mae: 13.0238\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.9137 - mae: 13.1012 - val_loss: 254.7431 - val_mae: 13.0052\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.2093 - mae: 13.0782 - val_loss: 254.1474 - val_mae: 12.9852\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 265.5334 - mae: 13.0569 - val_loss: 253.5752 - val_mae: 12.9655\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.8347 - mae: 13.0313 - val_loss: 252.9928 - val_mae: 12.9469\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.1609 - mae: 13.0094 - val_loss: 252.4227 - val_mae: 12.9283\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.5147 - mae: 12.9883 - val_loss: 251.8497 - val_mae: 12.9093\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.8342 - mae: 12.9638 - val_loss: 251.2626 - val_mae: 12.8901\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.2019 - mae: 12.9424 - val_loss: 250.6851 - val_mae: 12.8715\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 261.5473 - mae: 12.9206 - val_loss: 250.1248 - val_mae: 12.8529\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 260.8995 - mae: 12.8984 - val_loss: 249.5800 - val_mae: 12.8346\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.2666 - mae: 12.8776 - val_loss: 249.0145 - val_mae: 12.8157\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.6185 - mae: 12.8556 - val_loss: 248.4505 - val_mae: 12.7961\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.0008 - mae: 12.8345 - val_loss: 247.8866 - val_mae: 12.7765\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.3948 - mae: 12.8147 - val_loss: 247.3192 - val_mae: 12.7576\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.7553 - mae: 12.7952 - val_loss: 246.7540 - val_mae: 12.7389\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.1266 - mae: 12.7709 - val_loss: 246.1917 - val_mae: 12.7207\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 256.4828 - mae: 12.7510 - val_loss: 245.6174 - val_mae: 12.7010\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.8365 - mae: 12.7295 - val_loss: 245.0639 - val_mae: 12.6821\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.2028 - mae: 12.7061 - val_loss: 244.4926 - val_mae: 12.6637\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 254.5858 - mae: 12.6847 - val_loss: 243.9382 - val_mae: 12.6454\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.9934 - mae: 12.6654 - val_loss: 243.3862 - val_mae: 12.6268\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.3107 - mae: 12.6439 - val_loss: 242.8712 - val_mae: 12.6085\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.6655 - mae: 12.6217 - val_loss: 242.3007 - val_mae: 12.5890\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.0241 - mae: 12.6022 - val_loss: 241.7167 - val_mae: 12.5686\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.3742 - mae: 12.5786 - val_loss: 241.1098 - val_mae: 12.5477\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 250.7226 - mae: 12.5577 - val_loss: 240.4686 - val_mae: 12.5260\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 250.0195 - mae: 12.5329 - val_loss: 239.8180 - val_mae: 12.5039\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=2, model__n_neurons=25, model__optimizer=sgd; total time=   6.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 58ms/step - loss: 1332.1272 - mae: 27.3337 - val_loss: 1344.5388 - val_mae: 26.8057\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1330.1229 - mae: 27.3128 - val_loss: 1342.4111 - val_mae: 26.7843\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1328.1614 - mae: 27.2922 - val_loss: 1340.2633 - val_mae: 26.7628\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1326.1599 - mae: 27.2714 - val_loss: 1338.1185 - val_mae: 26.7411\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1324.1801 - mae: 27.2507 - val_loss: 1335.9772 - val_mae: 26.7195\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1322.1863 - mae: 27.2300 - val_loss: 1333.8448 - val_mae: 26.6980\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1320.2113 - mae: 27.2093 - val_loss: 1331.6810 - val_mae: 26.6761\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1318.2362 - mae: 27.1887 - val_loss: 1329.5178 - val_mae: 26.6543\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1316.2393 - mae: 27.1680 - val_loss: 1327.3898 - val_mae: 26.6329\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1314.3204 - mae: 27.1478 - val_loss: 1325.2231 - val_mae: 26.6111\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1312.3141 - mae: 27.1270 - val_loss: 1323.1268 - val_mae: 26.5898\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1310.3558 - mae: 27.1066 - val_loss: 1321.0217 - val_mae: 26.5684\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1308.4460 - mae: 27.0864 - val_loss: 1318.8964 - val_mae: 26.5469\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1306.4949 - mae: 27.0660 - val_loss: 1316.7902 - val_mae: 26.5254\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1304.5485 - mae: 27.0457 - val_loss: 1314.7013 - val_mae: 26.5041\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1302.6710 - mae: 27.0257 - val_loss: 1312.5674 - val_mae: 26.4824\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1300.6748 - mae: 27.0051 - val_loss: 1310.5126 - val_mae: 26.4612\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1298.8301 - mae: 26.9854 - val_loss: 1308.3813 - val_mae: 26.4395\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1296.8684 - mae: 26.9649 - val_loss: 1306.3062 - val_mae: 26.4183\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1294.9742 - mae: 26.9449 - val_loss: 1304.2125 - val_mae: 26.3969\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1293.0378 - mae: 26.9247 - val_loss: 1302.1630 - val_mae: 26.3758\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1291.1577 - mae: 26.9047 - val_loss: 1300.1034 - val_mae: 26.3547\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1289.2416 - mae: 26.8846 - val_loss: 1298.0431 - val_mae: 26.3336\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1287.3539 - mae: 26.8647 - val_loss: 1295.9692 - val_mae: 26.3123\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1285.4220 - mae: 26.8445 - val_loss: 1293.9404 - val_mae: 26.2915\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1283.5491 - mae: 26.8246 - val_loss: 1291.8943 - val_mae: 26.2706\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1281.6844 - mae: 26.8046 - val_loss: 1289.8148 - val_mae: 26.2493\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1279.7545 - mae: 26.7845 - val_loss: 1287.7682 - val_mae: 26.2284\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1277.8630 - mae: 26.7645 - val_loss: 1285.7258 - val_mae: 26.2073\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1275.9823 - mae: 26.7445 - val_loss: 1283.6790 - val_mae: 26.1864\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1274.1208 - mae: 26.7246 - val_loss: 1281.6202 - val_mae: 26.1654\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1272.2146 - mae: 26.7045 - val_loss: 1279.5927 - val_mae: 26.1445\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1270.3597 - mae: 26.6848 - val_loss: 1277.5687 - val_mae: 26.1237\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1268.4752 - mae: 26.6649 - val_loss: 1275.5679 - val_mae: 26.1030\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1266.6337 - mae: 26.6452 - val_loss: 1273.5389 - val_mae: 26.0820\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1264.7810 - mae: 26.6255 - val_loss: 1271.5205 - val_mae: 26.0611\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1262.9125 - mae: 26.6056 - val_loss: 1269.5331 - val_mae: 26.0406\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1261.0758 - mae: 26.5860 - val_loss: 1267.5328 - val_mae: 26.0198\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1259.2325 - mae: 26.5663 - val_loss: 1265.5421 - val_mae: 25.9991\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1257.3831 - mae: 26.5468 - val_loss: 1263.5480 - val_mae: 25.9784\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1255.5507 - mae: 26.5271 - val_loss: 1261.5530 - val_mae: 25.9576\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1253.7195 - mae: 26.5076 - val_loss: 1259.5747 - val_mae: 25.9371\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1251.8915 - mae: 26.4881 - val_loss: 1257.6050 - val_mae: 25.9164\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1250.0861 - mae: 26.4686 - val_loss: 1255.6443 - val_mae: 25.8959\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1248.2588 - mae: 26.4490 - val_loss: 1253.6877 - val_mae: 25.8755\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1246.4225 - mae: 26.4296 - val_loss: 1251.7499 - val_mae: 25.8553\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1244.6516 - mae: 26.4105 - val_loss: 1249.7736 - val_mae: 25.8348\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1242.8390 - mae: 26.3911 - val_loss: 1247.8270 - val_mae: 25.8146\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1241.0165 - mae: 26.3717 - val_loss: 1245.9115 - val_mae: 25.7945\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1239.2581 - mae: 26.3525 - val_loss: 1243.9347 - val_mae: 25.7740\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1237.4473 - mae: 26.3333 - val_loss: 1241.9952 - val_mae: 25.7537\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1235.6154 - mae: 26.3139 - val_loss: 1240.0844 - val_mae: 25.7336\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1233.8705 - mae: 26.2947 - val_loss: 1238.1069 - val_mae: 25.7131\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1232.0399 - mae: 26.2752 - val_loss: 1236.1721 - val_mae: 25.6929\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1230.2524 - mae: 26.2559 - val_loss: 1234.2483 - val_mae: 25.6728\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1228.4747 - mae: 26.2368 - val_loss: 1232.3251 - val_mae: 25.6527\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1226.7054 - mae: 26.2177 - val_loss: 1230.3928 - val_mae: 25.6325\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1224.9421 - mae: 26.1986 - val_loss: 1228.4659 - val_mae: 25.6124\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1223.1591 - mae: 26.1794 - val_loss: 1226.5579 - val_mae: 25.5925\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 1221.3752 - mae: 26.1603 - val_loss: 1224.6764 - val_mae: 25.5727\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1219.6345 - mae: 26.1414 - val_loss: 1222.7719 - val_mae: 25.5526\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1217.9135 - mae: 26.1226 - val_loss: 1220.8370 - val_mae: 25.5324\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1216.1184 - mae: 26.1034 - val_loss: 1218.9485 - val_mae: 25.5126\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1214.3560 - mae: 26.0845 - val_loss: 1217.0828 - val_mae: 25.4930\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1212.6132 - mae: 26.0657 - val_loss: 1215.2291 - val_mae: 25.4735\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1210.9021 - mae: 26.0470 - val_loss: 1213.3217 - val_mae: 25.4536\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1209.1556 - mae: 26.0283 - val_loss: 1211.4255 - val_mae: 25.4338\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1207.4299 - mae: 26.0095 - val_loss: 1209.5403 - val_mae: 25.4141\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1205.6833 - mae: 25.9907 - val_loss: 1207.6709 - val_mae: 25.3946\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1203.9664 - mae: 25.9721 - val_loss: 1205.8013 - val_mae: 25.3750\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1202.2350 - mae: 25.9533 - val_loss: 1203.9286 - val_mae: 25.3554\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1200.5146 - mae: 25.9348 - val_loss: 1202.0591 - val_mae: 25.3358\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1198.7933 - mae: 25.9161 - val_loss: 1200.1924 - val_mae: 25.3162\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1197.0925 - mae: 25.8977 - val_loss: 1198.3307 - val_mae: 25.2966\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1195.3776 - mae: 25.8792 - val_loss: 1196.4667 - val_mae: 25.2771\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1193.6725 - mae: 25.8606 - val_loss: 1194.6073 - val_mae: 25.2576\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1191.9519 - mae: 25.8420 - val_loss: 1192.7798 - val_mae: 25.2383\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1190.2662 - mae: 25.8236 - val_loss: 1190.9491 - val_mae: 25.2190\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1188.5746 - mae: 25.8052 - val_loss: 1189.1359 - val_mae: 25.1999\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1186.9067 - mae: 25.7869 - val_loss: 1187.3085 - val_mae: 25.1808\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1185.2567 - mae: 25.7687 - val_loss: 1185.4640 - val_mae: 25.1614\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1183.5435 - mae: 25.7503 - val_loss: 1183.6569 - val_mae: 25.1423\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1181.8986 - mae: 25.7322 - val_loss: 1181.8448 - val_mae: 25.1231\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1180.2017 - mae: 25.7139 - val_loss: 1180.0760 - val_mae: 25.1042\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1178.5568 - mae: 25.6958 - val_loss: 1178.2511 - val_mae: 25.0848\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1176.8787 - mae: 25.6774 - val_loss: 1176.4081 - val_mae: 25.0653\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1175.2208 - mae: 25.6592 - val_loss: 1174.5645 - val_mae: 25.0459\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1173.5182 - mae: 25.6409 - val_loss: 1172.7869 - val_mae: 25.0269\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1171.8698 - mae: 25.6226 - val_loss: 1170.9825 - val_mae: 25.0078\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1170.2153 - mae: 25.6046 - val_loss: 1169.1740 - val_mae: 24.9887\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1168.5432 - mae: 25.5863 - val_loss: 1167.3971 - val_mae: 24.9698\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1166.8824 - mae: 25.5681 - val_loss: 1165.6326 - val_mae: 24.9509\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1165.2632 - mae: 25.5502 - val_loss: 1163.8059 - val_mae: 24.9316\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1163.5825 - mae: 25.5318 - val_loss: 1162.0049 - val_mae: 24.9124\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1161.9293 - mae: 25.5135 - val_loss: 1160.2050 - val_mae: 24.8933\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1160.2775 - mae: 25.4954 - val_loss: 1158.4153 - val_mae: 24.8741\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1158.6404 - mae: 25.4772 - val_loss: 1156.6365 - val_mae: 24.8550\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1156.9895 - mae: 25.4591 - val_loss: 1154.8739 - val_mae: 24.8360\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1155.3704 - mae: 25.4412 - val_loss: 1153.0919 - val_mae: 24.8168\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1153.7104 - mae: 25.4229 - val_loss: 1151.3484 - val_mae: 24.7979\n",
      "5/5 [==============================] - 0s 989us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=125, model__optimizer=adam; total time=   5.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 1860.4277 - mae: 32.6917 - val_loss: 1922.3508 - val_mae: 32.5174\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1857.4454 - mae: 32.6652 - val_loss: 1919.0675 - val_mae: 32.4892\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1854.4365 - mae: 32.6385 - val_loss: 1915.8014 - val_mae: 32.4613\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1851.5316 - mae: 32.6124 - val_loss: 1912.4928 - val_mae: 32.4330\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1848.5077 - mae: 32.5857 - val_loss: 1909.2739 - val_mae: 32.4053\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1845.6445 - mae: 32.5598 - val_loss: 1905.9888 - val_mae: 32.3771\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1842.6857 - mae: 32.5334 - val_loss: 1902.7640 - val_mae: 32.3494\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1839.7648 - mae: 32.5074 - val_loss: 1899.5560 - val_mae: 32.3217\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1836.8634 - mae: 32.4813 - val_loss: 1896.3657 - val_mae: 32.2941\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1833.9896 - mae: 32.4555 - val_loss: 1893.1398 - val_mae: 32.2662\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1831.0275 - mae: 32.4291 - val_loss: 1889.9576 - val_mae: 32.2386\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1828.2117 - mae: 32.4036 - val_loss: 1886.7075 - val_mae: 32.2105\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1825.2515 - mae: 32.3771 - val_loss: 1883.5109 - val_mae: 32.1827\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1822.3231 - mae: 32.3509 - val_loss: 1880.3256 - val_mae: 32.1550\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1819.4291 - mae: 32.3249 - val_loss: 1877.1313 - val_mae: 32.1272\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1816.5811 - mae: 32.2991 - val_loss: 1873.9052 - val_mae: 32.0991\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1813.6453 - mae: 32.2729 - val_loss: 1870.7478 - val_mae: 32.0715\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1810.8097 - mae: 32.2472 - val_loss: 1867.5690 - val_mae: 32.0437\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1807.9359 - mae: 32.2213 - val_loss: 1864.4196 - val_mae: 32.0162\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1805.1183 - mae: 32.1956 - val_loss: 1861.2170 - val_mae: 31.9883\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1802.1523 - mae: 32.1694 - val_loss: 1858.1144 - val_mae: 31.9612\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1799.3607 - mae: 32.1438 - val_loss: 1854.9031 - val_mae: 31.9332\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1796.4863 - mae: 32.1179 - val_loss: 1851.7640 - val_mae: 31.9057\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1793.6693 - mae: 32.0923 - val_loss: 1848.6399 - val_mae: 31.8784\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1790.8137 - mae: 32.0665 - val_loss: 1845.5538 - val_mae: 31.8514\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1788.0122 - mae: 32.0411 - val_loss: 1842.4463 - val_mae: 31.8242\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1785.1925 - mae: 32.0154 - val_loss: 1839.3353 - val_mae: 31.7970\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1782.3838 - mae: 31.9899 - val_loss: 1836.2203 - val_mae: 31.7695\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1779.5754 - mae: 31.9641 - val_loss: 1833.0575 - val_mae: 31.7418\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1776.6790 - mae: 31.9380 - val_loss: 1829.9688 - val_mae: 31.7147\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1773.9299 - mae: 31.9128 - val_loss: 1826.8291 - val_mae: 31.6872\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1771.0940 - mae: 31.8872 - val_loss: 1823.7645 - val_mae: 31.6603\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1768.3064 - mae: 31.8617 - val_loss: 1820.7179 - val_mae: 31.6335\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1765.5985 - mae: 31.8368 - val_loss: 1817.6143 - val_mae: 31.6062\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1762.7688 - mae: 31.8111 - val_loss: 1814.5646 - val_mae: 31.5793\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1760.0331 - mae: 31.7858 - val_loss: 1811.5026 - val_mae: 31.5522\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1757.2363 - mae: 31.7604 - val_loss: 1808.4908 - val_mae: 31.5256\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1754.5306 - mae: 31.7355 - val_loss: 1805.4296 - val_mae: 31.4985\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1751.7640 - mae: 31.7100 - val_loss: 1802.4259 - val_mae: 31.4720\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1749.0607 - mae: 31.6851 - val_loss: 1799.3711 - val_mae: 31.4450\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1746.2496 - mae: 31.6597 - val_loss: 1796.3862 - val_mae: 31.4185\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1743.5963 - mae: 31.6350 - val_loss: 1793.3175 - val_mae: 31.3914\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1740.7880 - mae: 31.6094 - val_loss: 1790.3380 - val_mae: 31.3649\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1738.1028 - mae: 31.5846 - val_loss: 1787.3263 - val_mae: 31.3382\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1735.4060 - mae: 31.5596 - val_loss: 1784.3008 - val_mae: 31.3112\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1732.6534 - mae: 31.5343 - val_loss: 1781.3174 - val_mae: 31.2847\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1729.9595 - mae: 31.5095 - val_loss: 1778.3320 - val_mae: 31.2580\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1727.2513 - mae: 31.4845 - val_loss: 1775.3531 - val_mae: 31.2314\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1724.5427 - mae: 31.4594 - val_loss: 1772.3800 - val_mae: 31.2048\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1721.8899 - mae: 31.4347 - val_loss: 1769.3849 - val_mae: 31.1780\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1719.1580 - mae: 31.4096 - val_loss: 1766.4569 - val_mae: 31.1517\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1716.5052 - mae: 31.3850 - val_loss: 1763.4993 - val_mae: 31.1253\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1713.8528 - mae: 31.3602 - val_loss: 1760.5205 - val_mae: 31.0986\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1711.1516 - mae: 31.3352 - val_loss: 1757.5892 - val_mae: 31.0723\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1708.4917 - mae: 31.3105 - val_loss: 1754.6603 - val_mae: 31.0461\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1705.8517 - mae: 31.2859 - val_loss: 1751.7179 - val_mae: 31.0196\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1703.2046 - mae: 31.2612 - val_loss: 1748.8069 - val_mae: 30.9934\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1700.5522 - mae: 31.2364 - val_loss: 1745.9297 - val_mae: 30.9676\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1697.9302 - mae: 31.2119 - val_loss: 1743.0049 - val_mae: 30.9414\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 1695.2975 - mae: 31.1873 - val_loss: 1740.0834 - val_mae: 30.9152\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1692.6356 - mae: 31.1627 - val_loss: 1737.1860 - val_mae: 30.8892\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1690.0073 - mae: 31.1381 - val_loss: 1734.2563 - val_mae: 30.8628\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1687.3602 - mae: 31.1135 - val_loss: 1731.3492 - val_mae: 30.8368\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1684.7660 - mae: 31.0892 - val_loss: 1728.4164 - val_mae: 30.8104\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1682.1315 - mae: 31.0646 - val_loss: 1725.5243 - val_mae: 30.7844\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1679.4871 - mae: 31.0399 - val_loss: 1722.6672 - val_mae: 30.7586\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1676.8936 - mae: 31.0155 - val_loss: 1719.7985 - val_mae: 30.7326\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1674.3022 - mae: 30.9911 - val_loss: 1716.9174 - val_mae: 30.7066\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1671.7416 - mae: 30.9670 - val_loss: 1714.0135 - val_mae: 30.6804\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1669.0984 - mae: 30.9424 - val_loss: 1711.1704 - val_mae: 30.6545\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1666.5297 - mae: 30.9182 - val_loss: 1708.3447 - val_mae: 30.6290\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1663.9703 - mae: 30.8942 - val_loss: 1705.4999 - val_mae: 30.6032\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1661.3907 - mae: 30.8698 - val_loss: 1702.6611 - val_mae: 30.5773\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1658.8096 - mae: 30.8456 - val_loss: 1699.8264 - val_mae: 30.5515\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1656.2517 - mae: 30.8213 - val_loss: 1696.9708 - val_mae: 30.5254\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1653.6915 - mae: 30.7972 - val_loss: 1694.1204 - val_mae: 30.4994\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1651.0710 - mae: 30.7727 - val_loss: 1691.3479 - val_mae: 30.4740\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1648.5710 - mae: 30.7488 - val_loss: 1688.5245 - val_mae: 30.4481\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1646.0251 - mae: 30.7246 - val_loss: 1685.6874 - val_mae: 30.4222\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1643.4648 - mae: 30.7004 - val_loss: 1682.8669 - val_mae: 30.3964\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1640.9296 - mae: 30.6763 - val_loss: 1680.0815 - val_mae: 30.3708\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1638.3760 - mae: 30.6522 - val_loss: 1677.3290 - val_mae: 30.3456\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1635.8534 - mae: 30.6282 - val_loss: 1674.5308 - val_mae: 30.3199\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1633.3329 - mae: 30.6041 - val_loss: 1671.7098 - val_mae: 30.2941\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1630.8390 - mae: 30.5803 - val_loss: 1668.8759 - val_mae: 30.2682\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1628.2488 - mae: 30.5560 - val_loss: 1666.1337 - val_mae: 30.2430\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1625.7523 - mae: 30.5322 - val_loss: 1663.3934 - val_mae: 30.2179\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1623.2661 - mae: 30.5085 - val_loss: 1660.6228 - val_mae: 30.1926\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1620.7523 - mae: 30.4846 - val_loss: 1657.8497 - val_mae: 30.1672\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1618.2330 - mae: 30.4607 - val_loss: 1655.0933 - val_mae: 30.1418\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1615.7692 - mae: 30.4370 - val_loss: 1652.3240 - val_mae: 30.1164\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1613.2781 - mae: 30.4132 - val_loss: 1649.5607 - val_mae: 30.0911\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1610.8005 - mae: 30.3896 - val_loss: 1646.7952 - val_mae: 30.0657\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1608.2878 - mae: 30.3657 - val_loss: 1644.0878 - val_mae: 30.0407\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1605.8435 - mae: 30.3421 - val_loss: 1641.3734 - val_mae: 30.0158\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1603.4088 - mae: 30.3189 - val_loss: 1638.6686 - val_mae: 29.9909\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1600.9153 - mae: 30.2952 - val_loss: 1636.0083 - val_mae: 29.9662\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1598.4879 - mae: 30.2719 - val_loss: 1633.3339 - val_mae: 29.9414\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1596.0820 - mae: 30.2486 - val_loss: 1630.6177 - val_mae: 29.9162\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1593.6216 - mae: 30.2251 - val_loss: 1627.9415 - val_mae: 29.8914\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=125, model__optimizer=adam; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 20ms/step - loss: 1630.9443 - mae: 30.1766 - val_loss: 1675.3810 - val_mae: 30.3609\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1628.3235 - mae: 30.1520 - val_loss: 1672.5703 - val_mae: 30.3353\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1625.6875 - mae: 30.1273 - val_loss: 1669.7856 - val_mae: 30.3100\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1623.0963 - mae: 30.1029 - val_loss: 1667.0172 - val_mae: 30.2847\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1620.4652 - mae: 30.0784 - val_loss: 1664.2539 - val_mae: 30.2595\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1617.8853 - mae: 30.0541 - val_loss: 1661.4705 - val_mae: 30.2342\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1615.2877 - mae: 30.0296 - val_loss: 1658.6680 - val_mae: 30.2087\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1612.6451 - mae: 30.0050 - val_loss: 1655.9048 - val_mae: 30.1834\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1610.0718 - mae: 29.9807 - val_loss: 1653.1292 - val_mae: 30.1581\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1607.4465 - mae: 29.9562 - val_loss: 1650.3772 - val_mae: 30.1329\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1604.8455 - mae: 29.9319 - val_loss: 1647.6095 - val_mae: 30.1076\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1602.2819 - mae: 29.9076 - val_loss: 1644.8245 - val_mae: 30.0821\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1599.6636 - mae: 29.8831 - val_loss: 1642.0680 - val_mae: 30.0570\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1597.0449 - mae: 29.8587 - val_loss: 1639.3313 - val_mae: 30.0319\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1594.5114 - mae: 29.8345 - val_loss: 1636.5541 - val_mae: 30.0066\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1591.9247 - mae: 29.8103 - val_loss: 1633.7948 - val_mae: 29.9815\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1589.3475 - mae: 29.7861 - val_loss: 1631.0549 - val_mae: 29.9564\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1586.7848 - mae: 29.7619 - val_loss: 1628.3326 - val_mae: 29.9315\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1584.2155 - mae: 29.7378 - val_loss: 1625.6334 - val_mae: 29.9067\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1581.7140 - mae: 29.7140 - val_loss: 1622.8925 - val_mae: 29.8817\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1579.1221 - mae: 29.6898 - val_loss: 1620.2142 - val_mae: 29.8570\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1576.5906 - mae: 29.6659 - val_loss: 1617.5220 - val_mae: 29.8322\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1574.0863 - mae: 29.6421 - val_loss: 1614.7992 - val_mae: 29.8073\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1571.5443 - mae: 29.6180 - val_loss: 1612.0972 - val_mae: 29.7825\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1569.0377 - mae: 29.5942 - val_loss: 1609.3853 - val_mae: 29.7575\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1566.4727 - mae: 29.5702 - val_loss: 1606.7283 - val_mae: 29.7330\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1563.9828 - mae: 29.5466 - val_loss: 1604.0454 - val_mae: 29.7083\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1561.4889 - mae: 29.5231 - val_loss: 1601.3867 - val_mae: 29.6838\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1558.9894 - mae: 29.4994 - val_loss: 1598.7510 - val_mae: 29.6593\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1556.5439 - mae: 29.4761 - val_loss: 1596.1005 - val_mae: 29.6349\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1554.0503 - mae: 29.4525 - val_loss: 1593.4575 - val_mae: 29.6104\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1551.5718 - mae: 29.4291 - val_loss: 1590.8258 - val_mae: 29.5860\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1549.1378 - mae: 29.4057 - val_loss: 1588.1764 - val_mae: 29.5614\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1546.6492 - mae: 29.3822 - val_loss: 1585.5596 - val_mae: 29.5372\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1544.2036 - mae: 29.3589 - val_loss: 1582.9323 - val_mae: 29.5128\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1541.7646 - mae: 29.3356 - val_loss: 1580.2937 - val_mae: 29.4884\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1539.2668 - mae: 29.3121 - val_loss: 1577.7134 - val_mae: 29.4644\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1536.8387 - mae: 29.2888 - val_loss: 1575.1040 - val_mae: 29.4401\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1534.3804 - mae: 29.2654 - val_loss: 1572.5061 - val_mae: 29.4158\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1531.9384 - mae: 29.2422 - val_loss: 1569.9252 - val_mae: 29.3916\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1529.5544 - mae: 29.2191 - val_loss: 1567.2947 - val_mae: 29.3671\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1527.1224 - mae: 29.1958 - val_loss: 1564.7075 - val_mae: 29.3430\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1524.7328 - mae: 29.1728 - val_loss: 1562.1200 - val_mae: 29.3188\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1522.2910 - mae: 29.1495 - val_loss: 1559.5709 - val_mae: 29.2950\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1519.8920 - mae: 29.1266 - val_loss: 1557.0280 - val_mae: 29.2712\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1517.4847 - mae: 29.1035 - val_loss: 1554.4657 - val_mae: 29.2471\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1515.1450 - mae: 29.0808 - val_loss: 1551.8727 - val_mae: 29.2229\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1512.7047 - mae: 29.0575 - val_loss: 1549.3253 - val_mae: 29.1990\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1510.3217 - mae: 29.0346 - val_loss: 1546.7852 - val_mae: 29.1752\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1507.9388 - mae: 29.0117 - val_loss: 1544.2467 - val_mae: 29.1514\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1505.5150 - mae: 28.9888 - val_loss: 1541.7391 - val_mae: 29.1277\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1503.1969 - mae: 28.9661 - val_loss: 1539.1847 - val_mae: 29.1037\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1500.8153 - mae: 28.9432 - val_loss: 1536.6383 - val_mae: 29.0798\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1498.4481 - mae: 28.9203 - val_loss: 1534.1050 - val_mae: 29.0560\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1496.0857 - mae: 28.8976 - val_loss: 1531.6062 - val_mae: 29.0325\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1493.7401 - mae: 28.8749 - val_loss: 1529.0916 - val_mae: 29.0088\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1491.3875 - mae: 28.8522 - val_loss: 1526.5853 - val_mae: 28.9852\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1489.0510 - mae: 28.8296 - val_loss: 1524.0804 - val_mae: 28.9616\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1486.7244 - mae: 28.8070 - val_loss: 1521.5725 - val_mae: 28.9380\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 1484.3511 - mae: 28.7843 - val_loss: 1519.0999 - val_mae: 28.9147\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1482.0145 - mae: 28.7620 - val_loss: 1516.6509 - val_mae: 28.8915\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1479.7507 - mae: 28.7397 - val_loss: 1514.1522 - val_mae: 28.8680\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1477.3881 - mae: 28.7169 - val_loss: 1511.6960 - val_mae: 28.8448\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1475.0989 - mae: 28.6948 - val_loss: 1509.2170 - val_mae: 28.8214\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1472.7991 - mae: 28.6724 - val_loss: 1506.7430 - val_mae: 28.7979\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1470.4890 - mae: 28.6500 - val_loss: 1504.2798 - val_mae: 28.7747\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1468.1456 - mae: 28.6277 - val_loss: 1501.8674 - val_mae: 28.7518\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1465.8878 - mae: 28.6056 - val_loss: 1499.4156 - val_mae: 28.7285\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1463.6343 - mae: 28.5835 - val_loss: 1496.9546 - val_mae: 28.7052\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1461.2815 - mae: 28.5611 - val_loss: 1494.5330 - val_mae: 28.6822\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1459.0186 - mae: 28.5390 - val_loss: 1492.0869 - val_mae: 28.6589\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1456.7122 - mae: 28.5169 - val_loss: 1489.6547 - val_mae: 28.6358\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1454.4407 - mae: 28.4947 - val_loss: 1487.2147 - val_mae: 28.6125\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1452.1790 - mae: 28.4727 - val_loss: 1484.7888 - val_mae: 28.5893\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1449.8973 - mae: 28.4506 - val_loss: 1482.3721 - val_mae: 28.5662\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1447.6278 - mae: 28.4286 - val_loss: 1479.9497 - val_mae: 28.5430\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1445.3506 - mae: 28.4066 - val_loss: 1477.5424 - val_mae: 28.5199\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1443.1121 - mae: 28.3848 - val_loss: 1475.1251 - val_mae: 28.4967\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1440.8441 - mae: 28.3628 - val_loss: 1472.7025 - val_mae: 28.4734\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1438.5770 - mae: 28.3408 - val_loss: 1470.2885 - val_mae: 28.4503\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1436.3153 - mae: 28.3189 - val_loss: 1467.8875 - val_mae: 28.4272\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1434.0590 - mae: 28.2970 - val_loss: 1465.5028 - val_mae: 28.4043\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1431.8370 - mae: 28.2753 - val_loss: 1463.0933 - val_mae: 28.3812\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1429.5643 - mae: 28.2533 - val_loss: 1460.7125 - val_mae: 28.3584\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1427.3665 - mae: 28.2317 - val_loss: 1458.3213 - val_mae: 28.3355\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1425.1614 - mae: 28.2101 - val_loss: 1455.9320 - val_mae: 28.3125\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1422.8943 - mae: 28.1882 - val_loss: 1453.5826 - val_mae: 28.2899\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1420.6833 - mae: 28.1667 - val_loss: 1451.2245 - val_mae: 28.2673\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1418.5051 - mae: 28.1451 - val_loss: 1448.8318 - val_mae: 28.2444\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1416.2806 - mae: 28.1235 - val_loss: 1446.4585 - val_mae: 28.2217\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1414.0129 - mae: 28.1017 - val_loss: 1444.1483 - val_mae: 28.1996\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1411.8365 - mae: 28.0803 - val_loss: 1441.8136 - val_mae: 28.1772\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1409.6952 - mae: 28.0591 - val_loss: 1439.4208 - val_mae: 28.1544\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1407.4312 - mae: 28.0373 - val_loss: 1437.0881 - val_mae: 28.1321\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1405.2406 - mae: 28.0158 - val_loss: 1434.7555 - val_mae: 28.1097\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1403.0918 - mae: 27.9947 - val_loss: 1432.4032 - val_mae: 28.0871\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1400.8844 - mae: 27.9733 - val_loss: 1430.0948 - val_mae: 28.0649\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1398.7107 - mae: 27.9520 - val_loss: 1427.8062 - val_mae: 28.0429\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1396.5887 - mae: 27.9310 - val_loss: 1425.4634 - val_mae: 28.0204\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1394.3729 - mae: 27.9097 - val_loss: 1423.1453 - val_mae: 27.9982\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.9, model__n_hidden=1, model__n_neurons=125, model__optimizer=adam; total time=   6.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 18ms/step - loss: 669.8224 - mae: 22.4368 - val_loss: 585.2186 - val_mae: 20.9403\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.5709 - mae: 22.4328 - val_loss: 584.9470 - val_mae: 20.9359\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.3188 - mae: 22.4289 - val_loss: 584.6755 - val_mae: 20.9316\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.0633 - mae: 22.4249 - val_loss: 584.4079 - val_mae: 20.9273\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.8102 - mae: 22.4209 - val_loss: 584.1407 - val_mae: 20.9230\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.5649 - mae: 22.4170 - val_loss: 583.8710 - val_mae: 20.9187\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.3139 - mae: 22.4131 - val_loss: 583.6022 - val_mae: 20.9145\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.0650 - mae: 22.4092 - val_loss: 583.3345 - val_mae: 20.9102\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.8135 - mae: 22.4052 - val_loss: 583.0673 - val_mae: 20.9060\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.5652 - mae: 22.4013 - val_loss: 582.7980 - val_mae: 20.9017\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.3159 - mae: 22.3974 - val_loss: 582.5317 - val_mae: 20.8975\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.0671 - mae: 22.3934 - val_loss: 582.2676 - val_mae: 20.8933\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.8185 - mae: 22.3895 - val_loss: 582.0045 - val_mae: 20.8891\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.5754 - mae: 22.3856 - val_loss: 581.7404 - val_mae: 20.8849\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.3264 - mae: 22.3817 - val_loss: 581.4797 - val_mae: 20.8808\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 666.0796 - mae: 22.3778 - val_loss: 581.2187 - val_mae: 20.8766\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.8328 - mae: 22.3739 - val_loss: 580.9547 - val_mae: 20.8724\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.5891 - mae: 22.3700 - val_loss: 580.6871 - val_mae: 20.8682\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.3405 - mae: 22.3661 - val_loss: 580.4250 - val_mae: 20.8640\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.0970 - mae: 22.3622 - val_loss: 580.1591 - val_mae: 20.8598\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 664.8484 - mae: 22.3583 - val_loss: 579.8976 - val_mae: 20.8557\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 664.6044 - mae: 22.3544 - val_loss: 579.6333 - val_mae: 20.8515\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.3594 - mae: 22.3505 - val_loss: 579.3669 - val_mae: 20.8472\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.1129 - mae: 22.3466 - val_loss: 579.1019 - val_mae: 20.8430\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.8670 - mae: 22.3427 - val_loss: 578.8350 - val_mae: 20.8388\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.6207 - mae: 22.3388 - val_loss: 578.5702 - val_mae: 20.8345\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.3748 - mae: 22.3349 - val_loss: 578.3065 - val_mae: 20.8303\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.1274 - mae: 22.3310 - val_loss: 578.0464 - val_mae: 20.8261\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.8832 - mae: 22.3271 - val_loss: 577.7829 - val_mae: 20.8219\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.6389 - mae: 22.3232 - val_loss: 577.5180 - val_mae: 20.8177\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.3922 - mae: 22.3193 - val_loss: 577.2562 - val_mae: 20.8135\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.1488 - mae: 22.3154 - val_loss: 576.9915 - val_mae: 20.8093\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.9038 - mae: 22.3115 - val_loss: 576.7268 - val_mae: 20.8051\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.6586 - mae: 22.3076 - val_loss: 576.4637 - val_mae: 20.8008\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.4126 - mae: 22.3037 - val_loss: 576.2020 - val_mae: 20.7966\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.1709 - mae: 22.2999 - val_loss: 575.9374 - val_mae: 20.7924\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.9263 - mae: 22.2960 - val_loss: 575.6737 - val_mae: 20.7882\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.6794 - mae: 22.2921 - val_loss: 575.4112 - val_mae: 20.7840\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4422 - mae: 22.2882 - val_loss: 575.1444 - val_mae: 20.7797\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.1890 - mae: 22.2843 - val_loss: 574.8899 - val_mae: 20.7756\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.9538 - mae: 22.2805 - val_loss: 574.6301 - val_mae: 20.7715\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.7158 - mae: 22.2766 - val_loss: 574.3684 - val_mae: 20.7673\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.4727 - mae: 22.2728 - val_loss: 574.1110 - val_mae: 20.7631\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.2307 - mae: 22.2689 - val_loss: 573.8552 - val_mae: 20.7589\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.9907 - mae: 22.2651 - val_loss: 573.5982 - val_mae: 20.7548\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.7527 - mae: 22.2612 - val_loss: 573.3408 - val_mae: 20.7506\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.5118 - mae: 22.2574 - val_loss: 573.0833 - val_mae: 20.7464\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.2735 - mae: 22.2535 - val_loss: 572.8234 - val_mae: 20.7422\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.0347 - mae: 22.2497 - val_loss: 572.5638 - val_mae: 20.7380\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.7928 - mae: 22.2458 - val_loss: 572.3078 - val_mae: 20.7339\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.5555 - mae: 22.2420 - val_loss: 572.0483 - val_mae: 20.7297\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.3131 - mae: 22.2381 - val_loss: 571.7919 - val_mae: 20.7255\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 657.0738 - mae: 22.2343 - val_loss: 571.5339 - val_mae: 20.7213\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 656.8348 - mae: 22.2305 - val_loss: 571.2745 - val_mae: 20.7171\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.5979 - mae: 22.2267 - val_loss: 571.0134 - val_mae: 20.7129\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.3604 - mae: 22.2228 - val_loss: 570.7537 - val_mae: 20.7087\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1177 - mae: 22.2190 - val_loss: 570.4989 - val_mae: 20.7046\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.8771 - mae: 22.2151 - val_loss: 570.2461 - val_mae: 20.7004\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 655.6429 - mae: 22.2113 - val_loss: 569.9883 - val_mae: 20.6962\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 655.4048 - mae: 22.2075 - val_loss: 569.7318 - val_mae: 20.6921\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 655.1661 - mae: 22.2036 - val_loss: 569.4756 - val_mae: 20.6879\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.9290 - mae: 22.1998 - val_loss: 569.2186 - val_mae: 20.6837\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6898 - mae: 22.1960 - val_loss: 568.9637 - val_mae: 20.6795\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.4541 - mae: 22.1921 - val_loss: 568.7056 - val_mae: 20.6753\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.2164 - mae: 22.1883 - val_loss: 568.4479 - val_mae: 20.6711\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9780 - mae: 22.1844 - val_loss: 568.1933 - val_mae: 20.6669\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 653.7389 - mae: 22.1806 - val_loss: 567.9418 - val_mae: 20.6628\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 653.5038 - mae: 22.1768 - val_loss: 567.6876 - val_mae: 20.6586\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.2665 - mae: 22.1729 - val_loss: 567.4351 - val_mae: 20.6544\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.0312 - mae: 22.1691 - val_loss: 567.1786 - val_mae: 20.6502\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.7928 - mae: 22.1652 - val_loss: 566.9222 - val_mae: 20.6461\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.5557 - mae: 22.1614 - val_loss: 566.6646 - val_mae: 20.6418\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.3204 - mae: 22.1575 - val_loss: 566.4077 - val_mae: 20.6376\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.0807 - mae: 22.1537 - val_loss: 566.1547 - val_mae: 20.6335\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.8484 - mae: 22.1499 - val_loss: 565.9017 - val_mae: 20.6293\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.6115 - mae: 22.1460 - val_loss: 565.6497 - val_mae: 20.6251\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.3762 - mae: 22.1422 - val_loss: 565.3989 - val_mae: 20.6210\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.1393 - mae: 22.1384 - val_loss: 565.1484 - val_mae: 20.6169\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.9055 - mae: 22.1345 - val_loss: 564.8986 - val_mae: 20.6127\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 650.6760 - mae: 22.1307 - val_loss: 564.6403 - val_mae: 20.6085\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 650.4351 - mae: 22.1268 - val_loss: 564.3865 - val_mae: 20.6043\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 650.1965 - mae: 22.1230 - val_loss: 564.1379 - val_mae: 20.6002\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.9650 - mae: 22.1192 - val_loss: 563.8848 - val_mae: 20.5960\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.7333 - mae: 22.1154 - val_loss: 563.6280 - val_mae: 20.5917\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.4944 - mae: 22.1115 - val_loss: 563.3790 - val_mae: 20.5876\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2669 - mae: 22.1078 - val_loss: 563.1237 - val_mae: 20.5834\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.0309 - mae: 22.1039 - val_loss: 562.8718 - val_mae: 20.5792\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 648.7979 - mae: 22.1001 - val_loss: 562.6198 - val_mae: 20.5750\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 648.5663 - mae: 22.0963 - val_loss: 562.3690 - val_mae: 20.5709\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.3299 - mae: 22.0925 - val_loss: 562.1251 - val_mae: 20.5668\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.1050 - mae: 22.0888 - val_loss: 561.8730 - val_mae: 20.5626\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 647.8696 - mae: 22.0850 - val_loss: 561.6261 - val_mae: 20.5585\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 647.6441 - mae: 22.0812 - val_loss: 561.3745 - val_mae: 20.5543\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 647.4078 - mae: 22.0774 - val_loss: 561.1265 - val_mae: 20.5502\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 647.1795 - mae: 22.0736 - val_loss: 560.8735 - val_mae: 20.5459\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 646.9446 - mae: 22.0697 - val_loss: 560.6237 - val_mae: 20.5418\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 646.7141 - mae: 22.0660 - val_loss: 560.3749 - val_mae: 20.5376\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.4820 - mae: 22.0622 - val_loss: 560.1274 - val_mae: 20.5335\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2542 - mae: 22.0584 - val_loss: 559.8747 - val_mae: 20.5293\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.0198 - mae: 22.0546 - val_loss: 559.6277 - val_mae: 20.5251\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=adam; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 42ms/step - loss: 561.2100 - mae: 20.8775 - val_loss: 414.0535 - val_mae: 18.5197\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 561.1436 - mae: 20.8761 - val_loss: 413.9816 - val_mae: 18.5185\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 561.0701 - mae: 20.8747 - val_loss: 413.9131 - val_mae: 18.5173\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 561.0001 - mae: 20.8733 - val_loss: 413.8470 - val_mae: 18.5161\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 560.9296 - mae: 20.8719 - val_loss: 413.7808 - val_mae: 18.5149\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 560.8603 - mae: 20.8705 - val_loss: 413.7130 - val_mae: 18.5137\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 560.7910 - mae: 20.8692 - val_loss: 413.6436 - val_mae: 18.5124\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 560.7183 - mae: 20.8678 - val_loss: 413.5757 - val_mae: 18.5112\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 560.6478 - mae: 20.8664 - val_loss: 413.5081 - val_mae: 18.5100\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 560.5778 - mae: 20.8650 - val_loss: 413.4389 - val_mae: 18.5088\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 560.5051 - mae: 20.8636 - val_loss: 413.3725 - val_mae: 18.5076\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=adam; total time=   1.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 39ms/step - loss: 494.3637 - mae: 19.8727 - val_loss: 475.8064 - val_mae: 19.5287\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 494.2754 - mae: 19.8706 - val_loss: 475.7191 - val_mae: 19.5262\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 494.1899 - mae: 19.8684 - val_loss: 475.6325 - val_mae: 19.5238\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 494.1032 - mae: 19.8663 - val_loss: 475.5466 - val_mae: 19.5214\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 494.0169 - mae: 19.8642 - val_loss: 475.4604 - val_mae: 19.5190\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 493.9298 - mae: 19.8621 - val_loss: 475.3750 - val_mae: 19.5166\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 493.8445 - mae: 19.8600 - val_loss: 475.2896 - val_mae: 19.5142\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 493.7573 - mae: 19.8579 - val_loss: 475.2040 - val_mae: 19.5118\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 493.6703 - mae: 19.8558 - val_loss: 475.1187 - val_mae: 19.5094\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 493.5827 - mae: 19.8536 - val_loss: 475.0326 - val_mae: 19.5070\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 493.4952 - mae: 19.8515 - val_loss: 474.9464 - val_mae: 19.5046\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=3, model__n_neurons=25, model__optimizer=adam; total time=   1.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 23ms/step - loss: 11509.0029 - mae: 77.8787 - val_loss: 11307.5645 - val_mae: 77.0534\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11507.9951 - mae: 77.8750 - val_loss: 11306.5625 - val_mae: 77.0497\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11507.0000 - mae: 77.8713 - val_loss: 11305.5576 - val_mae: 77.0460\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11506.0010 - mae: 77.8677 - val_loss: 11304.5547 - val_mae: 77.0423\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11504.9814 - mae: 77.8640 - val_loss: 11303.5645 - val_mae: 77.0386\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11503.9961 - mae: 77.8604 - val_loss: 11302.5625 - val_mae: 77.0350\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11502.9883 - mae: 77.8567 - val_loss: 11301.5693 - val_mae: 77.0313\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 11501.9941 - mae: 77.8531 - val_loss: 11300.5732 - val_mae: 77.0276\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11500.9971 - mae: 77.8494 - val_loss: 11299.5742 - val_mae: 77.0239\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11500.0000 - mae: 77.8458 - val_loss: 11298.5674 - val_mae: 77.0202\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11498.9775 - mae: 77.8420 - val_loss: 11297.5742 - val_mae: 77.0165\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11497.9824 - mae: 77.8384 - val_loss: 11296.5703 - val_mae: 77.0128\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11496.9814 - mae: 77.8347 - val_loss: 11295.5664 - val_mae: 77.0091\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11495.9717 - mae: 77.8310 - val_loss: 11294.5674 - val_mae: 77.0055\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11494.9697 - mae: 77.8273 - val_loss: 11293.5635 - val_mae: 77.0018\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11493.9639 - mae: 77.8237 - val_loss: 11292.5664 - val_mae: 76.9981\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11492.9609 - mae: 77.8200 - val_loss: 11291.5684 - val_mae: 76.9944\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11491.9717 - mae: 77.8163 - val_loss: 11290.5684 - val_mae: 76.9907\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11490.9658 - mae: 77.8126 - val_loss: 11289.5752 - val_mae: 76.9870\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11489.9648 - mae: 77.8090 - val_loss: 11288.5752 - val_mae: 76.9833\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11488.9648 - mae: 77.8053 - val_loss: 11287.5674 - val_mae: 76.9796\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11487.9541 - mae: 77.8016 - val_loss: 11286.5625 - val_mae: 76.9759\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11486.9443 - mae: 77.7979 - val_loss: 11285.5664 - val_mae: 76.9722\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11485.9521 - mae: 77.7942 - val_loss: 11284.5605 - val_mae: 76.9685\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11484.9463 - mae: 77.7905 - val_loss: 11283.5615 - val_mae: 76.9648\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11483.9473 - mae: 77.7869 - val_loss: 11282.5703 - val_mae: 76.9611\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 11482.9521 - mae: 77.7832 - val_loss: 11281.5820 - val_mae: 76.9575\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11481.9570 - mae: 77.7796 - val_loss: 11280.5889 - val_mae: 76.9538\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11480.9629 - mae: 77.7759 - val_loss: 11279.5850 - val_mae: 76.9501\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11479.9521 - mae: 77.7722 - val_loss: 11278.5879 - val_mae: 76.9464\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11478.9531 - mae: 77.7686 - val_loss: 11277.5898 - val_mae: 76.9427\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11477.9434 - mae: 77.7649 - val_loss: 11276.6045 - val_mae: 76.9390\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11476.9512 - mae: 77.7612 - val_loss: 11275.6045 - val_mae: 76.9354\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11475.9648 - mae: 77.7576 - val_loss: 11274.5957 - val_mae: 76.9316\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11474.9521 - mae: 77.7539 - val_loss: 11273.6113 - val_mae: 76.9280\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11473.9639 - mae: 77.7502 - val_loss: 11272.6133 - val_mae: 76.9243\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11472.9561 - mae: 77.7466 - val_loss: 11271.6201 - val_mae: 76.9206\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11471.9639 - mae: 77.7429 - val_loss: 11270.6123 - val_mae: 76.9169\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11470.9648 - mae: 77.7392 - val_loss: 11269.6143 - val_mae: 76.9132\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11469.9619 - mae: 77.7355 - val_loss: 11268.6182 - val_mae: 76.9095\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11468.9561 - mae: 77.7319 - val_loss: 11267.6250 - val_mae: 76.9059\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11467.9561 - mae: 77.7282 - val_loss: 11266.6309 - val_mae: 76.9022\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11466.9639 - mae: 77.7245 - val_loss: 11265.6367 - val_mae: 76.8985\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11465.9688 - mae: 77.7208 - val_loss: 11264.6357 - val_mae: 76.8948\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11464.9639 - mae: 77.7172 - val_loss: 11263.6338 - val_mae: 76.8911\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11463.9629 - mae: 77.7135 - val_loss: 11262.6387 - val_mae: 76.8874\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11462.9668 - mae: 77.7098 - val_loss: 11261.6436 - val_mae: 76.8837\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11461.9629 - mae: 77.7061 - val_loss: 11260.6504 - val_mae: 76.8800\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11460.9648 - mae: 77.7025 - val_loss: 11259.6572 - val_mae: 76.8764\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11459.9814 - mae: 77.6988 - val_loss: 11258.6572 - val_mae: 76.8727\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11458.9600 - mae: 77.6951 - val_loss: 11257.6748 - val_mae: 76.8690\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11457.9814 - mae: 77.6915 - val_loss: 11256.6738 - val_mae: 76.8653\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11456.9727 - mae: 77.6878 - val_loss: 11255.6816 - val_mae: 76.8616\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11455.9814 - mae: 77.6841 - val_loss: 11254.6826 - val_mae: 76.8579\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11454.9824 - mae: 77.6804 - val_loss: 11253.6826 - val_mae: 76.8542\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11453.9814 - mae: 77.6767 - val_loss: 11252.6924 - val_mae: 76.8506\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11452.9814 - mae: 77.6730 - val_loss: 11251.7021 - val_mae: 76.8469\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11451.9922 - mae: 77.6694 - val_loss: 11250.7080 - val_mae: 76.8432\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 11450.9990 - mae: 77.6657 - val_loss: 11249.7178 - val_mae: 76.8395\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11450.0010 - mae: 77.6620 - val_loss: 11248.7266 - val_mae: 76.8359\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11449.0078 - mae: 77.6584 - val_loss: 11247.7354 - val_mae: 76.8322\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11448.0146 - mae: 77.6547 - val_loss: 11246.7432 - val_mae: 76.8285\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11447.0156 - mae: 77.6510 - val_loss: 11245.7520 - val_mae: 76.8248\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11446.0186 - mae: 77.6473 - val_loss: 11244.7578 - val_mae: 76.8211\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11445.0361 - mae: 77.6437 - val_loss: 11243.7500 - val_mae: 76.8174\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11444.0166 - mae: 77.6400 - val_loss: 11242.7646 - val_mae: 76.8138\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11443.0283 - mae: 77.6363 - val_loss: 11241.7725 - val_mae: 76.8101\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11442.0352 - mae: 77.6326 - val_loss: 11240.7793 - val_mae: 76.8064\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11441.0391 - mae: 77.6289 - val_loss: 11239.7881 - val_mae: 76.8027\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11440.0508 - mae: 77.6253 - val_loss: 11238.7920 - val_mae: 76.7990\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11439.0488 - mae: 77.6216 - val_loss: 11237.7998 - val_mae: 76.7953\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11438.0498 - mae: 77.6179 - val_loss: 11236.8057 - val_mae: 76.7917\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11437.0479 - mae: 77.6142 - val_loss: 11235.8105 - val_mae: 76.7880\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11436.0576 - mae: 77.6106 - val_loss: 11234.8164 - val_mae: 76.7843\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11435.0498 - mae: 77.6069 - val_loss: 11233.8271 - val_mae: 76.7806\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11434.0605 - mae: 77.6032 - val_loss: 11232.8262 - val_mae: 76.7769\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11433.0654 - mae: 77.5995 - val_loss: 11231.8311 - val_mae: 76.7732\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11432.0547 - mae: 77.5958 - val_loss: 11230.8389 - val_mae: 76.7695\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11431.0596 - mae: 77.5921 - val_loss: 11229.8438 - val_mae: 76.7659\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11430.0596 - mae: 77.5885 - val_loss: 11228.8486 - val_mae: 76.7621\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11429.0654 - mae: 77.5848 - val_loss: 11227.8555 - val_mae: 76.7585\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11428.0771 - mae: 77.5811 - val_loss: 11226.8506 - val_mae: 76.7547\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11427.0635 - mae: 77.5774 - val_loss: 11225.8564 - val_mae: 76.7511\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11426.0732 - mae: 77.5737 - val_loss: 11224.8506 - val_mae: 76.7474\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11425.0693 - mae: 77.5700 - val_loss: 11223.8564 - val_mae: 76.7437\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11424.0732 - mae: 77.5663 - val_loss: 11222.8643 - val_mae: 76.7400\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11423.0684 - mae: 77.5626 - val_loss: 11221.8789 - val_mae: 76.7363\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11422.0830 - mae: 77.5590 - val_loss: 11220.8809 - val_mae: 76.7326\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11421.0811 - mae: 77.5553 - val_loss: 11219.8887 - val_mae: 76.7290\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11420.0771 - mae: 77.5516 - val_loss: 11218.9043 - val_mae: 76.7253\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11419.0859 - mae: 77.5480 - val_loss: 11217.9111 - val_mae: 76.7216\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11418.0967 - mae: 77.5443 - val_loss: 11216.9082 - val_mae: 76.7179\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11417.0977 - mae: 77.5406 - val_loss: 11215.9062 - val_mae: 76.7142\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11416.0908 - mae: 77.5369 - val_loss: 11214.9102 - val_mae: 76.7105\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11415.0928 - mae: 77.5332 - val_loss: 11213.9170 - val_mae: 76.7068\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11414.0918 - mae: 77.5296 - val_loss: 11212.9307 - val_mae: 76.7032\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11413.1104 - mae: 77.5259 - val_loss: 11211.9316 - val_mae: 76.6995\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 11412.1084 - mae: 77.5222 - val_loss: 11210.9463 - val_mae: 76.6958\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11411.1143 - mae: 77.5185 - val_loss: 11209.9580 - val_mae: 76.6922\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11410.1182 - mae: 77.5149 - val_loss: 11208.9746 - val_mae: 76.6885\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   5.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 58277.9570 - mae: 190.0000 - val_loss: 60377.0508 - val_mae: 192.9834\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58275.2383 - mae: 189.9955 - val_loss: 60374.2422 - val_mae: 192.9789\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58272.5078 - mae: 189.9910 - val_loss: 60371.4414 - val_mae: 192.9745\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58269.7891 - mae: 189.9865 - val_loss: 60368.6289 - val_mae: 192.9700\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58267.0703 - mae: 189.9820 - val_loss: 60365.8281 - val_mae: 192.9656\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58264.3633 - mae: 189.9776 - val_loss: 60363.0234 - val_mae: 192.9611\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58261.6367 - mae: 189.9730 - val_loss: 60360.2266 - val_mae: 192.9566\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58258.9492 - mae: 189.9686 - val_loss: 60357.4180 - val_mae: 192.9522\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58256.1836 - mae: 189.9641 - val_loss: 60354.6250 - val_mae: 192.9478\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58253.4883 - mae: 189.9595 - val_loss: 60351.7969 - val_mae: 192.9433\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58250.7461 - mae: 189.9550 - val_loss: 60349.0000 - val_mae: 192.9388\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58248.0312 - mae: 189.9505 - val_loss: 60346.2148 - val_mae: 192.9344\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58245.3047 - mae: 189.9461 - val_loss: 60343.4180 - val_mae: 192.9299\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58242.6016 - mae: 189.9416 - val_loss: 60340.6250 - val_mae: 192.9255\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58239.9023 - mae: 189.9371 - val_loss: 60337.8281 - val_mae: 192.9211\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58237.1875 - mae: 189.9326 - val_loss: 60335.0195 - val_mae: 192.9166\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58234.4570 - mae: 189.9281 - val_loss: 60332.2344 - val_mae: 192.9121\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58231.7422 - mae: 189.9236 - val_loss: 60329.4336 - val_mae: 192.9077\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58229.0195 - mae: 189.9191 - val_loss: 60326.6523 - val_mae: 192.9033\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58226.3320 - mae: 189.9147 - val_loss: 60323.8516 - val_mae: 192.8988\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58223.6016 - mae: 189.9102 - val_loss: 60321.0664 - val_mae: 192.8944\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58220.9336 - mae: 189.9057 - val_loss: 60318.2266 - val_mae: 192.8899\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58218.1445 - mae: 189.9012 - val_loss: 60315.4570 - val_mae: 192.8855\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58215.4609 - mae: 189.8967 - val_loss: 60312.6523 - val_mae: 192.8810\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 58212.7266 - mae: 189.8922 - val_loss: 60309.8672 - val_mae: 192.8766\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 58210.0156 - mae: 189.8877 - val_loss: 60307.0352 - val_mae: 192.8721\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58207.2891 - mae: 189.8832 - val_loss: 60304.2305 - val_mae: 192.8676\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58204.5469 - mae: 189.8787 - val_loss: 60301.4531 - val_mae: 192.8632\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58201.8672 - mae: 189.8742 - val_loss: 60298.6055 - val_mae: 192.8587\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58199.1016 - mae: 189.8697 - val_loss: 60295.8203 - val_mae: 192.8542\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58196.4258 - mae: 189.8652 - val_loss: 60292.9844 - val_mae: 192.8497\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58193.6836 - mae: 189.8607 - val_loss: 60290.2148 - val_mae: 192.8453\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58190.9492 - mae: 189.8562 - val_loss: 60287.4297 - val_mae: 192.8409\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58188.2734 - mae: 189.8517 - val_loss: 60284.6328 - val_mae: 192.8365\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58185.5469 - mae: 189.8473 - val_loss: 60281.8320 - val_mae: 192.8320\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58182.8086 - mae: 189.8427 - val_loss: 60279.0469 - val_mae: 192.8276\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58180.1094 - mae: 189.8383 - val_loss: 60276.2305 - val_mae: 192.8231\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58177.3984 - mae: 189.8338 - val_loss: 60273.4414 - val_mae: 192.8186\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58174.7109 - mae: 189.8293 - val_loss: 60270.6172 - val_mae: 192.8142\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58172.0000 - mae: 189.8248 - val_loss: 60267.8203 - val_mae: 192.8097\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58169.2461 - mae: 189.8203 - val_loss: 60265.0312 - val_mae: 192.8053\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58166.5625 - mae: 189.8158 - val_loss: 60262.2500 - val_mae: 192.8008\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58163.8711 - mae: 189.8113 - val_loss: 60259.4688 - val_mae: 192.7964\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58161.1484 - mae: 189.8069 - val_loss: 60256.6992 - val_mae: 192.7920\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58158.4297 - mae: 189.8024 - val_loss: 60253.9180 - val_mae: 192.7876\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58155.7305 - mae: 189.7979 - val_loss: 60251.0977 - val_mae: 192.7831\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58153.0117 - mae: 189.7934 - val_loss: 60248.3047 - val_mae: 192.7787\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58150.2773 - mae: 189.7889 - val_loss: 60245.5078 - val_mae: 192.7742\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58147.5938 - mae: 189.7845 - val_loss: 60242.7070 - val_mae: 192.7698\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58144.8672 - mae: 189.7800 - val_loss: 60239.9297 - val_mae: 192.7653\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58142.1562 - mae: 189.7755 - val_loss: 60237.1328 - val_mae: 192.7609\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58139.4609 - mae: 189.7710 - val_loss: 60234.3086 - val_mae: 192.7564\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58136.7109 - mae: 189.7665 - val_loss: 60231.5078 - val_mae: 192.7519\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58134.0078 - mae: 189.7620 - val_loss: 60228.7148 - val_mae: 192.7475\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58131.2930 - mae: 189.7575 - val_loss: 60225.9062 - val_mae: 192.7430\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58128.5703 - mae: 189.7530 - val_loss: 60223.1016 - val_mae: 192.7385\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58125.8164 - mae: 189.7485 - val_loss: 60220.3242 - val_mae: 192.7341\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58123.1133 - mae: 189.7440 - val_loss: 60217.5430 - val_mae: 192.7297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58120.4414 - mae: 189.7395 - val_loss: 60214.7188 - val_mae: 192.7252\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58117.6875 - mae: 189.7350 - val_loss: 60211.9219 - val_mae: 192.7208\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58114.9922 - mae: 189.7305 - val_loss: 60209.1211 - val_mae: 192.7163\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58112.2734 - mae: 189.7261 - val_loss: 60206.3281 - val_mae: 192.7119\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58109.5508 - mae: 189.7216 - val_loss: 60203.5469 - val_mae: 192.7074\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58106.8750 - mae: 189.7171 - val_loss: 60200.7305 - val_mae: 192.7029\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58104.1367 - mae: 189.7126 - val_loss: 60197.9492 - val_mae: 192.6985\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58101.4219 - mae: 189.7081 - val_loss: 60195.1523 - val_mae: 192.6941\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58098.7266 - mae: 189.7037 - val_loss: 60192.3594 - val_mae: 192.6896\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58095.9727 - mae: 189.6991 - val_loss: 60189.5781 - val_mae: 192.6852\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58093.2891 - mae: 189.6947 - val_loss: 60186.7695 - val_mae: 192.6807\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58090.5938 - mae: 189.6902 - val_loss: 60183.9453 - val_mae: 192.6762\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58087.8398 - mae: 189.6857 - val_loss: 60181.1562 - val_mae: 192.6718\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58085.1133 - mae: 189.6811 - val_loss: 60178.3828 - val_mae: 192.6674\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58082.4336 - mae: 189.6767 - val_loss: 60175.6016 - val_mae: 192.6629\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58079.7422 - mae: 189.6722 - val_loss: 60172.8164 - val_mae: 192.6585\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58077.0156 - mae: 189.6678 - val_loss: 60170.0078 - val_mae: 192.6540\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58074.2812 - mae: 189.6633 - val_loss: 60167.2148 - val_mae: 192.6496\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58071.6016 - mae: 189.6588 - val_loss: 60164.4023 - val_mae: 192.6451\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58068.8594 - mae: 189.6543 - val_loss: 60161.6055 - val_mae: 192.6407\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58066.1445 - mae: 189.6498 - val_loss: 60158.7930 - val_mae: 192.6362\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58063.4180 - mae: 189.6453 - val_loss: 60156.0078 - val_mae: 192.6318\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58060.7188 - mae: 189.6408 - val_loss: 60153.2227 - val_mae: 192.6273\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58058.0234 - mae: 189.6364 - val_loss: 60150.4336 - val_mae: 192.6229\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58055.3125 - mae: 189.6319 - val_loss: 60147.6211 - val_mae: 192.6184\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58052.5781 - mae: 189.6273 - val_loss: 60144.8477 - val_mae: 192.6140\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58049.8750 - mae: 189.6229 - val_loss: 60142.0547 - val_mae: 192.6096\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58047.1758 - mae: 189.6184 - val_loss: 60139.2227 - val_mae: 192.6051\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58044.4258 - mae: 189.6139 - val_loss: 60136.4336 - val_mae: 192.6006\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58041.7148 - mae: 189.6094 - val_loss: 60133.6289 - val_mae: 192.5962\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58039.0117 - mae: 189.6049 - val_loss: 60130.8555 - val_mae: 192.5917\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 58036.3125 - mae: 189.6005 - val_loss: 60128.0430 - val_mae: 192.5873\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58033.5898 - mae: 189.5959 - val_loss: 60125.2695 - val_mae: 192.5828\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58030.8906 - mae: 189.5915 - val_loss: 60122.4805 - val_mae: 192.5784\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58028.1719 - mae: 189.5870 - val_loss: 60119.7070 - val_mae: 192.5740\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 58025.4961 - mae: 189.5826 - val_loss: 60116.8945 - val_mae: 192.5695\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58022.7305 - mae: 189.5781 - val_loss: 60114.1250 - val_mae: 192.5651\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58020.0820 - mae: 189.5736 - val_loss: 60111.2734 - val_mae: 192.5606\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58017.2969 - mae: 189.5690 - val_loss: 60108.4727 - val_mae: 192.5561\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 58014.5977 - mae: 189.5646 - val_loss: 60105.6602 - val_mae: 192.5517\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 58011.8906 - mae: 189.5601 - val_loss: 60102.8750 - val_mae: 192.5472\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 58009.1523 - mae: 189.5556 - val_loss: 60100.1016 - val_mae: 192.5428\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   5.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 29ms/step - loss: 8957.0586 - mae: 72.5339 - val_loss: 8200.8672 - val_mae: 70.7191\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8956.0791 - mae: 72.5288 - val_loss: 8199.8672 - val_mae: 70.7136\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8955.1084 - mae: 72.5237 - val_loss: 8198.8633 - val_mae: 70.7081\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8954.1162 - mae: 72.5185 - val_loss: 8197.8701 - val_mae: 70.7027\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8953.1416 - mae: 72.5135 - val_loss: 8196.8721 - val_mae: 70.6972\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8952.1650 - mae: 72.5083 - val_loss: 8195.8730 - val_mae: 70.6918\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8951.1865 - mae: 72.5032 - val_loss: 8194.8750 - val_mae: 70.6863\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8950.2031 - mae: 72.4981 - val_loss: 8193.8789 - val_mae: 70.6808\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8949.2354 - mae: 72.4930 - val_loss: 8192.8760 - val_mae: 70.6754\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8948.2510 - mae: 72.4879 - val_loss: 8191.8789 - val_mae: 70.6699\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8947.2705 - mae: 72.4827 - val_loss: 8190.8862 - val_mae: 70.6645\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8946.2930 - mae: 72.4777 - val_loss: 8189.8872 - val_mae: 70.6590\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8945.3242 - mae: 72.4725 - val_loss: 8188.8833 - val_mae: 70.6535\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8944.3379 - mae: 72.4674 - val_loss: 8187.8867 - val_mae: 70.6481\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8943.3633 - mae: 72.4623 - val_loss: 8186.8896 - val_mae: 70.6426\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8942.3809 - mae: 72.4572 - val_loss: 8185.8989 - val_mae: 70.6372\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8941.4111 - mae: 72.4521 - val_loss: 8184.8989 - val_mae: 70.6317\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8940.4307 - mae: 72.4469 - val_loss: 8183.9009 - val_mae: 70.6262\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8939.4463 - mae: 72.4418 - val_loss: 8182.9136 - val_mae: 70.6208\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8938.4863 - mae: 72.4368 - val_loss: 8181.9146 - val_mae: 70.6153\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8937.5068 - mae: 72.4317 - val_loss: 8180.9180 - val_mae: 70.6099\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8936.5225 - mae: 72.4265 - val_loss: 8179.9248 - val_mae: 70.6045\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8935.5498 - mae: 72.4215 - val_loss: 8178.9316 - val_mae: 70.5990\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8934.5801 - mae: 72.4163 - val_loss: 8177.9346 - val_mae: 70.5935\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8933.6016 - mae: 72.4112 - val_loss: 8176.9443 - val_mae: 70.5881\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8932.6299 - mae: 72.4062 - val_loss: 8175.9541 - val_mae: 70.5827\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8931.6572 - mae: 72.4010 - val_loss: 8174.9624 - val_mae: 70.5772\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8930.6914 - mae: 72.3959 - val_loss: 8173.9624 - val_mae: 70.5718\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8929.7041 - mae: 72.3908 - val_loss: 8172.9717 - val_mae: 70.5663\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8928.7344 - mae: 72.3857 - val_loss: 8171.9746 - val_mae: 70.5609\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8927.7578 - mae: 72.3806 - val_loss: 8170.9834 - val_mae: 70.5554\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8926.7891 - mae: 72.3755 - val_loss: 8169.9878 - val_mae: 70.5500\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8925.8184 - mae: 72.3705 - val_loss: 8168.9932 - val_mae: 70.5445\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8924.8389 - mae: 72.3653 - val_loss: 8168.0000 - val_mae: 70.5391\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8923.8643 - mae: 72.3602 - val_loss: 8167.0103 - val_mae: 70.5336\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8922.9004 - mae: 72.3552 - val_loss: 8166.0132 - val_mae: 70.5282\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8921.9150 - mae: 72.3500 - val_loss: 8165.0293 - val_mae: 70.5228\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8920.9512 - mae: 72.3450 - val_loss: 8164.0352 - val_mae: 70.5173\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8919.9824 - mae: 72.3399 - val_loss: 8163.0381 - val_mae: 70.5118\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8918.9990 - mae: 72.3347 - val_loss: 8162.0498 - val_mae: 70.5064\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8918.0244 - mae: 72.3296 - val_loss: 8161.0542 - val_mae: 70.5009\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8917.0527 - mae: 72.3245 - val_loss: 8160.0620 - val_mae: 70.4955\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8916.0801 - mae: 72.3194 - val_loss: 8159.0679 - val_mae: 70.4900\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8915.0996 - mae: 72.3143 - val_loss: 8158.0786 - val_mae: 70.4846\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8914.1328 - mae: 72.3092 - val_loss: 8157.0840 - val_mae: 70.4791\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8913.1621 - mae: 72.3041 - val_loss: 8156.0938 - val_mae: 70.4737\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8912.1924 - mae: 72.2990 - val_loss: 8155.1094 - val_mae: 70.4682\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8911.2275 - mae: 72.2939 - val_loss: 8154.1245 - val_mae: 70.4629\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8910.2578 - mae: 72.2889 - val_loss: 8153.1367 - val_mae: 70.4574\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8909.2852 - mae: 72.2837 - val_loss: 8152.1504 - val_mae: 70.4520\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8908.3242 - mae: 72.2787 - val_loss: 8151.1572 - val_mae: 70.4465\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8907.3486 - mae: 72.2735 - val_loss: 8150.1709 - val_mae: 70.4411\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8906.3818 - mae: 72.2685 - val_loss: 8149.1743 - val_mae: 70.4356\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8905.4004 - mae: 72.2634 - val_loss: 8148.1841 - val_mae: 70.4302\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8904.4355 - mae: 72.2583 - val_loss: 8147.1909 - val_mae: 70.4247\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8903.4658 - mae: 72.2532 - val_loss: 8146.1919 - val_mae: 70.4192\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8902.4873 - mae: 72.2480 - val_loss: 8145.2070 - val_mae: 70.4138\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8901.5176 - mae: 72.2430 - val_loss: 8144.2251 - val_mae: 70.4084\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8900.5420 - mae: 72.2378 - val_loss: 8143.2397 - val_mae: 70.4030\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 8899.5840 - mae: 72.2328 - val_loss: 8142.2466 - val_mae: 70.3975\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8898.6074 - mae: 72.2276 - val_loss: 8141.2617 - val_mae: 70.3921\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8897.6455 - mae: 72.2226 - val_loss: 8140.2715 - val_mae: 70.3867\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8896.6738 - mae: 72.2175 - val_loss: 8139.2817 - val_mae: 70.3812\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8895.7002 - mae: 72.2124 - val_loss: 8138.2964 - val_mae: 70.3758\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8894.7412 - mae: 72.2074 - val_loss: 8137.3032 - val_mae: 70.3703\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8893.7646 - mae: 72.2022 - val_loss: 8136.3179 - val_mae: 70.3649\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8892.8018 - mae: 72.1971 - val_loss: 8135.3247 - val_mae: 70.3594\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8891.8184 - mae: 72.1920 - val_loss: 8134.3408 - val_mae: 70.3540\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8890.8564 - mae: 72.1869 - val_loss: 8133.3506 - val_mae: 70.3486\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8889.8857 - mae: 72.1818 - val_loss: 8132.3633 - val_mae: 70.3431\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8888.9180 - mae: 72.1767 - val_loss: 8131.3740 - val_mae: 70.3377\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8887.9404 - mae: 72.1716 - val_loss: 8130.3965 - val_mae: 70.3323\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8886.9814 - mae: 72.1666 - val_loss: 8129.4062 - val_mae: 70.3269\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8886.0117 - mae: 72.1615 - val_loss: 8128.4155 - val_mae: 70.3214\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8885.0459 - mae: 72.1564 - val_loss: 8127.4243 - val_mae: 70.3160\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8884.0684 - mae: 72.1513 - val_loss: 8126.4375 - val_mae: 70.3105\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8883.1045 - mae: 72.1461 - val_loss: 8125.4468 - val_mae: 70.3051\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8882.1299 - mae: 72.1411 - val_loss: 8124.4629 - val_mae: 70.2996\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8881.1689 - mae: 72.1360 - val_loss: 8123.4722 - val_mae: 70.2943\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8880.2051 - mae: 72.1309 - val_loss: 8122.4849 - val_mae: 70.2890\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8879.2266 - mae: 72.1258 - val_loss: 8121.5054 - val_mae: 70.2836\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8878.2617 - mae: 72.1207 - val_loss: 8120.5200 - val_mae: 70.2783\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8877.2881 - mae: 72.1156 - val_loss: 8119.5376 - val_mae: 70.2730\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8876.3340 - mae: 72.1106 - val_loss: 8118.5356 - val_mae: 70.2675\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8875.3496 - mae: 72.1054 - val_loss: 8117.5479 - val_mae: 70.2622\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8874.3789 - mae: 72.1003 - val_loss: 8116.5625 - val_mae: 70.2569\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8873.4189 - mae: 72.0952 - val_loss: 8115.5728 - val_mae: 70.2515\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8872.4482 - mae: 72.0902 - val_loss: 8114.5806 - val_mae: 70.2461\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8871.4736 - mae: 72.0850 - val_loss: 8113.5972 - val_mae: 70.2408\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8870.5059 - mae: 72.0799 - val_loss: 8112.6138 - val_mae: 70.2354\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8869.5430 - mae: 72.0749 - val_loss: 8111.6245 - val_mae: 70.2301\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8868.5771 - mae: 72.0699 - val_loss: 8110.6367 - val_mae: 70.2247\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8867.6104 - mae: 72.0648 - val_loss: 8109.6567 - val_mae: 70.2194\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8866.6396 - mae: 72.0597 - val_loss: 8108.6821 - val_mae: 70.2141\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8865.6816 - mae: 72.0546 - val_loss: 8107.6948 - val_mae: 70.2088\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8864.7197 - mae: 72.0496 - val_loss: 8106.7031 - val_mae: 70.2034\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8863.7441 - mae: 72.0444 - val_loss: 8105.7212 - val_mae: 70.1981\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8862.7773 - mae: 72.0394 - val_loss: 8104.7378 - val_mae: 70.1927\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8861.8105 - mae: 72.0343 - val_loss: 8103.7529 - val_mae: 70.1874\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8860.8477 - mae: 72.0292 - val_loss: 8102.7676 - val_mae: 70.1820\n",
      "5/5 [==============================] - 0s 988us/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.5, model__n_hidden=1, model__n_neurons=5, model__optimizer=adam; total time=   4.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step - loss: 1044.1785 - mae: 25.1715 - val_loss: 984.9810 - val_mae: 24.0320\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 969.7498 - mae: 24.5218 - val_loss: 910.8102 - val_mae: 23.3868\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 905.2531 - mae: 23.9402 - val_loss: 846.8570 - val_mae: 22.8012\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 849.8774 - mae: 23.4034 - val_loss: 792.3781 - val_mae: 22.2760\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 802.7289 - mae: 22.9269 - val_loss: 744.3714 - val_mae: 21.7901\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 761.2217 - mae: 22.4833 - val_loss: 702.3217 - val_mae: 21.3453\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 725.0283 - mae: 22.0797 - val_loss: 665.1138 - val_mae: 20.9321\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 693.1331 - mae: 21.7060 - val_loss: 633.8317 - val_mae: 20.5709\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.3212 - mae: 21.3822 - val_loss: 605.9688 - val_mae: 20.2363\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.4874 - mae: 21.0822 - val_loss: 581.3926 - val_mae: 19.9268\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 621.4248 - mae: 20.8107 - val_loss: 559.3070 - val_mae: 19.6393\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 602.6580 - mae: 20.5617 - val_loss: 539.7023 - val_mae: 19.3764\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 585.9333 - mae: 20.3251 - val_loss: 521.9119 - val_mae: 19.1294\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 570.9507 - mae: 20.1090 - val_loss: 505.9491 - val_mae: 18.8989\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.4719 - mae: 19.9103 - val_loss: 491.9348 - val_mae: 18.6889\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.6226 - mae: 19.7300 - val_loss: 478.8448 - val_mae: 18.4898\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.6835 - mae: 19.5580 - val_loss: 467.1025 - val_mae: 18.3075\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 524.8729 - mae: 19.4008 - val_loss: 456.3014 - val_mae: 18.1361\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 515.8963 - mae: 19.2536 - val_loss: 446.5941 - val_mae: 17.9771\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.8539 - mae: 19.1180 - val_loss: 437.9012 - val_mae: 17.8319\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 500.6729 - mae: 18.9932 - val_loss: 430.0276 - val_mae: 17.6969\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 494.1600 - mae: 18.8775 - val_loss: 422.3402 - val_mae: 17.5644\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 487.8950 - mae: 18.7649 - val_loss: 415.5196 - val_mae: 17.4437\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.2998 - mae: 18.6618 - val_loss: 409.2514 - val_mae: 17.3305\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.1674 - mae: 18.5637 - val_loss: 403.5698 - val_mae: 17.2247\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 472.5154 - mae: 18.4730 - val_loss: 398.1719 - val_mae: 17.1228\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.1335 - mae: 18.3862 - val_loss: 393.1890 - val_mae: 17.0271\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464.0657 - mae: 18.3046 - val_loss: 388.4419 - val_mae: 16.9344\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.2406 - mae: 18.2260 - val_loss: 384.1957 - val_mae: 16.8494\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.8132 - mae: 18.1535 - val_loss: 380.2735 - val_mae: 16.7692\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 453.5640 - mae: 18.0822 - val_loss: 376.4297 - val_mae: 16.6903\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.4537 - mae: 18.0139 - val_loss: 372.9607 - val_mae: 16.6169\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.5929 - mae: 17.9496 - val_loss: 369.5520 - val_mae: 16.5441\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.7986 - mae: 17.8866 - val_loss: 366.3961 - val_mae: 16.4750\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.1812 - mae: 17.8254 - val_loss: 363.4312 - val_mae: 16.4086\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.7266 - mae: 17.7678 - val_loss: 360.6100 - val_mae: 16.3446\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.3863 - mae: 17.7120 - val_loss: 357.7932 - val_mae: 16.2825\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 435.0979 - mae: 17.6579 - val_loss: 355.2261 - val_mae: 16.2240\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 432.9784 - mae: 17.6067 - val_loss: 352.8813 - val_mae: 16.1695\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.9979 - mae: 17.5577 - val_loss: 350.5524 - val_mae: 16.1156\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.0742 - mae: 17.5089 - val_loss: 348.3929 - val_mae: 16.0641\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.2716 - mae: 17.4633 - val_loss: 346.2791 - val_mae: 16.0135\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.5255 - mae: 17.4188 - val_loss: 344.3197 - val_mae: 15.9655\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.8790 - mae: 17.3767 - val_loss: 342.4490 - val_mae: 15.9187\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.2982 - mae: 17.3350 - val_loss: 340.6400 - val_mae: 15.8733\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.7674 - mae: 17.2945 - val_loss: 338.9504 - val_mae: 15.8304\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.3046 - mae: 17.2549 - val_loss: 337.2361 - val_mae: 15.7879\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.8745 - mae: 17.2170 - val_loss: 335.5982 - val_mae: 15.7467\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.4906 - mae: 17.1795 - val_loss: 333.9467 - val_mae: 15.7056\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 415.1318 - mae: 17.1432 - val_loss: 332.3975 - val_mae: 15.6667\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.8236 - mae: 17.1073 - val_loss: 330.8340 - val_mae: 15.6280\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.5616 - mae: 17.0724 - val_loss: 329.3773 - val_mae: 15.5910\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.3220 - mae: 17.0383 - val_loss: 327.9657 - val_mae: 15.5551\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.1106 - mae: 17.0048 - val_loss: 326.5258 - val_mae: 15.5191\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.8985 - mae: 16.9713 - val_loss: 325.2393 - val_mae: 15.4860\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.7493 - mae: 16.9393 - val_loss: 323.9334 - val_mae: 15.4526\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.6254 - mae: 16.9077 - val_loss: 322.6397 - val_mae: 15.4194\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 405.5185 - mae: 16.8767 - val_loss: 321.3789 - val_mae: 15.3865\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.4520 - mae: 16.8464 - val_loss: 320.2162 - val_mae: 15.3554\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.4391 - mae: 16.8173 - val_loss: 319.0370 - val_mae: 15.3239\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 402.4398 - mae: 16.7876 - val_loss: 317.9595 - val_mae: 15.2946\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.4995 - mae: 16.7602 - val_loss: 316.9004 - val_mae: 15.2655\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.5796 - mae: 16.7324 - val_loss: 315.8619 - val_mae: 15.2370\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.7055 - mae: 16.7064 - val_loss: 314.8231 - val_mae: 15.2088\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.8199 - mae: 16.6798 - val_loss: 313.8675 - val_mae: 15.1819\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.9810 - mae: 16.6546 - val_loss: 312.9026 - val_mae: 15.1554\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.1477 - mae: 16.6296 - val_loss: 311.9792 - val_mae: 15.1298\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.3552 - mae: 16.6062 - val_loss: 311.0899 - val_mae: 15.1046\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.5847 - mae: 16.5827 - val_loss: 310.2621 - val_mae: 15.0804\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.8359 - mae: 16.5593 - val_loss: 309.3733 - val_mae: 15.0556\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.0975 - mae: 16.5372 - val_loss: 308.5594 - val_mae: 15.0320\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.3973 - mae: 16.5153 - val_loss: 307.7234 - val_mae: 15.0084\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.6927 - mae: 16.4941 - val_loss: 306.9374 - val_mae: 14.9857\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.0016 - mae: 16.4726 - val_loss: 306.1837 - val_mae: 14.9635\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 391.3528 - mae: 16.4529 - val_loss: 305.4249 - val_mae: 14.9416\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.6997 - mae: 16.4329 - val_loss: 304.6813 - val_mae: 14.9201\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 390.0685 - mae: 16.4134 - val_loss: 303.9482 - val_mae: 14.8988\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 389.4515 - mae: 16.3942 - val_loss: 303.2630 - val_mae: 14.8787\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.8373 - mae: 16.3756 - val_loss: 302.5439 - val_mae: 14.8582\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.2549 - mae: 16.3574 - val_loss: 301.8708 - val_mae: 14.8388\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 387.6457 - mae: 16.3387 - val_loss: 301.1964 - val_mae: 14.8195\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 387.0701 - mae: 16.3215 - val_loss: 300.5428 - val_mae: 14.8003\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 386.5087 - mae: 16.3037 - val_loss: 299.8756 - val_mae: 14.7812\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 385.9605 - mae: 16.2868 - val_loss: 299.2530 - val_mae: 14.7629\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.4113 - mae: 16.2697 - val_loss: 298.6641 - val_mae: 14.7452\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.8980 - mae: 16.2535 - val_loss: 298.0395 - val_mae: 14.7270\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.3481 - mae: 16.2364 - val_loss: 297.4453 - val_mae: 14.7093\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.8273 - mae: 16.2201 - val_loss: 296.8369 - val_mae: 14.6915\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 383.3133 - mae: 16.2044 - val_loss: 296.2561 - val_mae: 14.6740\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.8220 - mae: 16.1887 - val_loss: 295.6999 - val_mae: 14.6572\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.3083 - mae: 16.1728 - val_loss: 295.1032 - val_mae: 14.6396\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 381.8004 - mae: 16.1570 - val_loss: 294.5417 - val_mae: 14.6225\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 381.3099 - mae: 16.1418 - val_loss: 293.9667 - val_mae: 14.6053\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 380.8171 - mae: 16.1262 - val_loss: 293.4309 - val_mae: 14.5888\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 380.3420 - mae: 16.1116 - val_loss: 292.8844 - val_mae: 14.5723\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.8534 - mae: 16.0961 - val_loss: 292.3528 - val_mae: 14.5561\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.3854 - mae: 16.0814 - val_loss: 291.8105 - val_mae: 14.5397\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.8961 - mae: 16.0666 - val_loss: 291.2744 - val_mae: 14.5233\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 378.4273 - mae: 16.0520 - val_loss: 290.7550 - val_mae: 14.5072\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 377.9432 - mae: 16.0369 - val_loss: 290.2383 - val_mae: 14.4913\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 22ms/step - loss: 1386.4917 - mae: 27.5835 - val_loss: 1259.5494 - val_mae: 25.7435\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1240.5638 - mae: 26.5683 - val_loss: 1121.9467 - val_mae: 24.7699\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1122.6882 - mae: 25.6994 - val_loss: 1006.0792 - val_mae: 23.8812\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1023.8328 - mae: 24.9058 - val_loss: 912.6074 - val_mae: 23.1113\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 943.7173 - mae: 24.2162 - val_loss: 834.6265 - val_mae: 22.4263\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 876.7654 - mae: 23.6010 - val_loss: 769.0004 - val_mae: 21.8133\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 820.2624 - mae: 23.0512 - val_loss: 712.2712 - val_mae: 21.2511\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 771.7827 - mae: 22.5486 - val_loss: 665.0093 - val_mae: 20.7564\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 731.2141 - mae: 22.1052 - val_loss: 624.0707 - val_mae: 20.3054\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 696.1994 - mae: 21.7044 - val_loss: 588.6492 - val_mae: 19.8969\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.0413 - mae: 21.3381 - val_loss: 558.1857 - val_mae: 19.5277\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 640.0863 - mae: 21.0116 - val_loss: 531.9351 - val_mae: 19.1928\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 617.7692 - mae: 20.7142 - val_loss: 508.9002 - val_mae: 18.8863\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 598.1839 - mae: 20.4423 - val_loss: 489.0467 - val_mae: 18.6080\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 581.2626 - mae: 20.1968 - val_loss: 471.1767 - val_mae: 18.3458\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 566.1857 - mae: 19.9709 - val_loss: 455.8121 - val_mae: 18.1090\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 553.0914 - mae: 19.7645 - val_loss: 442.1343 - val_mae: 17.8888\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 541.4371 - mae: 19.5756 - val_loss: 429.4088 - val_mae: 17.6781\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 530.7318 - mae: 19.3959 - val_loss: 418.0670 - val_mae: 17.4838\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 521.2257 - mae: 19.2334 - val_loss: 408.2437 - val_mae: 17.3067\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 512.9175 - mae: 19.0831 - val_loss: 399.3479 - val_mae: 17.1419\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 505.4434 - mae: 18.9470 - val_loss: 391.5038 - val_mae: 16.9890\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 498.7272 - mae: 18.8159 - val_loss: 384.0713 - val_mae: 16.8425\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 492.4968 - mae: 18.6953 - val_loss: 377.2203 - val_mae: 16.7020\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 486.7943 - mae: 18.5814 - val_loss: 371.0602 - val_mae: 16.5713\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 481.6253 - mae: 18.4741 - val_loss: 365.4313 - val_mae: 16.4476\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 476.8796 - mae: 18.3742 - val_loss: 360.2062 - val_mae: 16.3297\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 472.5303 - mae: 18.2803 - val_loss: 355.4871 - val_mae: 16.2193\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 468.5479 - mae: 18.1914 - val_loss: 351.1521 - val_mae: 16.1163\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 464.9007 - mae: 18.1080 - val_loss: 346.9879 - val_mae: 16.0178\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 461.4262 - mae: 18.0284 - val_loss: 343.3213 - val_mae: 15.9277\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 458.3013 - mae: 17.9537 - val_loss: 339.8886 - val_mae: 15.8424\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 455.3494 - mae: 17.8830 - val_loss: 336.6044 - val_mae: 15.7604\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 452.5630 - mae: 17.8154 - val_loss: 333.4793 - val_mae: 15.6815\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 449.9517 - mae: 17.7517 - val_loss: 330.6177 - val_mae: 15.6076\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 447.5389 - mae: 17.6919 - val_loss: 328.0079 - val_mae: 15.5381\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 445.2329 - mae: 17.6335 - val_loss: 325.5645 - val_mae: 15.4722\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 443.0911 - mae: 17.5776 - val_loss: 323.1858 - val_mae: 15.4092\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 441.0488 - mae: 17.5256 - val_loss: 320.9758 - val_mae: 15.3498\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 439.1575 - mae: 17.4764 - val_loss: 318.9594 - val_mae: 15.2943\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 437.3589 - mae: 17.4293 - val_loss: 317.0336 - val_mae: 15.2404\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 435.6683 - mae: 17.3835 - val_loss: 315.1132 - val_mae: 15.1877\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 434.0306 - mae: 17.3406 - val_loss: 313.3824 - val_mae: 15.1407\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 432.4738 - mae: 17.3001 - val_loss: 311.6830 - val_mae: 15.0948\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 430.9932 - mae: 17.2623 - val_loss: 310.1035 - val_mae: 15.0513\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 429.5595 - mae: 17.2238 - val_loss: 308.6070 - val_mae: 15.0093\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 428.2092 - mae: 17.1880 - val_loss: 307.1284 - val_mae: 14.9684\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 426.8802 - mae: 17.1533 - val_loss: 305.6512 - val_mae: 14.9273\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 425.5925 - mae: 17.1194 - val_loss: 304.3132 - val_mae: 14.8894\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 424.3785 - mae: 17.0884 - val_loss: 302.9095 - val_mae: 14.8503\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 423.1571 - mae: 17.0557 - val_loss: 301.6725 - val_mae: 14.8146\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 422.0329 - mae: 17.0261 - val_loss: 300.4655 - val_mae: 14.7798\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 420.9253 - mae: 16.9955 - val_loss: 299.2610 - val_mae: 14.7451\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 419.8443 - mae: 16.9663 - val_loss: 298.0475 - val_mae: 14.7112\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 418.7690 - mae: 16.9372 - val_loss: 296.9634 - val_mae: 14.6794\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 417.7933 - mae: 16.9114 - val_loss: 295.9149 - val_mae: 14.6483\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 416.8118 - mae: 16.8846 - val_loss: 294.8415 - val_mae: 14.6169\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 415.8427 - mae: 16.8579 - val_loss: 293.8628 - val_mae: 14.5874\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 414.9079 - mae: 16.8324 - val_loss: 292.8834 - val_mae: 14.5581\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 413.9897 - mae: 16.8073 - val_loss: 291.9058 - val_mae: 14.5281\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 413.0906 - mae: 16.7822 - val_loss: 290.9690 - val_mae: 14.4999\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 412.2066 - mae: 16.7595 - val_loss: 290.0553 - val_mae: 14.4717\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 411.3243 - mae: 16.7356 - val_loss: 289.1156 - val_mae: 14.4432\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 410.4507 - mae: 16.7119 - val_loss: 288.2226 - val_mae: 14.4157\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 409.6053 - mae: 16.6892 - val_loss: 287.3767 - val_mae: 14.3890\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 408.7880 - mae: 16.6671 - val_loss: 286.4567 - val_mae: 14.3614\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 407.9703 - mae: 16.6442 - val_loss: 285.6253 - val_mae: 14.3360\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 407.1684 - mae: 16.6234 - val_loss: 284.8165 - val_mae: 14.3104\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 406.4236 - mae: 16.6031 - val_loss: 284.0237 - val_mae: 14.2850\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 405.6300 - mae: 16.5799 - val_loss: 283.2463 - val_mae: 14.2604\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 404.8969 - mae: 16.5599 - val_loss: 282.5081 - val_mae: 14.2360\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 404.1652 - mae: 16.5385 - val_loss: 281.8147 - val_mae: 14.2132\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 403.4604 - mae: 16.5197 - val_loss: 281.1079 - val_mae: 14.1902\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 402.7506 - mae: 16.5001 - val_loss: 280.4143 - val_mae: 14.1672\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 402.0766 - mae: 16.4815 - val_loss: 279.7152 - val_mae: 14.1447\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 401.3946 - mae: 16.4632 - val_loss: 279.0598 - val_mae: 14.1224\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 400.7372 - mae: 16.4441 - val_loss: 278.4040 - val_mae: 14.1005\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 400.0986 - mae: 16.4256 - val_loss: 277.7740 - val_mae: 14.0795\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 399.4677 - mae: 16.4084 - val_loss: 277.1672 - val_mae: 14.0588\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 398.8465 - mae: 16.3897 - val_loss: 276.5298 - val_mae: 14.0378\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 398.2348 - mae: 16.3728 - val_loss: 275.9291 - val_mae: 14.0173\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 397.6357 - mae: 16.3551 - val_loss: 275.3937 - val_mae: 13.9987\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 397.0512 - mae: 16.3386 - val_loss: 274.8615 - val_mae: 13.9801\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.4764 - mae: 16.3223 - val_loss: 274.3321 - val_mae: 13.9619\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.9186 - mae: 16.3062 - val_loss: 273.7811 - val_mae: 13.9433\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.3730 - mae: 16.2910 - val_loss: 273.2308 - val_mae: 13.9247\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 394.8428 - mae: 16.2771 - val_loss: 272.7019 - val_mae: 13.9062\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 394.2759 - mae: 16.2592 - val_loss: 272.1940 - val_mae: 13.8887\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 393.7443 - mae: 16.2440 - val_loss: 271.6912 - val_mae: 13.8719\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 393.2333 - mae: 16.2293 - val_loss: 271.1600 - val_mae: 13.8538\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.7099 - mae: 16.2143 - val_loss: 270.6836 - val_mae: 13.8376\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 392.2052 - mae: 16.1995 - val_loss: 270.2349 - val_mae: 13.8223\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.6781 - mae: 16.1857 - val_loss: 269.7255 - val_mae: 13.8048\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 391.1905 - mae: 16.1716 - val_loss: 269.2721 - val_mae: 13.7888\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 390.6768 - mae: 16.1568 - val_loss: 268.7795 - val_mae: 13.7717\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 390.1842 - mae: 16.1413 - val_loss: 268.2829 - val_mae: 13.7558\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 389.6812 - mae: 16.1287 - val_loss: 267.7662 - val_mae: 13.7392\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 389.1734 - mae: 16.1141 - val_loss: 267.2942 - val_mae: 13.7230\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.6781 - mae: 16.0997 - val_loss: 266.8126 - val_mae: 13.7065\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 388.1881 - mae: 16.0856 - val_loss: 266.3601 - val_mae: 13.6910\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   6.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 982.4732 - mae: 24.9882 - val_loss: 958.5351 - val_mae: 24.7673\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 902.9341 - mae: 24.1933 - val_loss: 882.3786 - val_mae: 24.0041\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 836.2206 - mae: 23.4845 - val_loss: 817.4799 - val_mae: 23.3128\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 779.2160 - mae: 22.8520 - val_loss: 762.3839 - val_mae: 22.6912\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 730.7105 - mae: 22.2655 - val_loss: 715.1163 - val_mae: 22.1259\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.8686 - mae: 21.7411 - val_loss: 673.8962 - val_mae: 21.6016\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.4418 - mae: 21.2574 - val_loss: 638.9003 - val_mae: 21.1312\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3372 - mae: 20.8199 - val_loss: 608.2179 - val_mae: 20.6996\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 594.0638 - mae: 20.4266 - val_loss: 580.9557 - val_mae: 20.3015\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.7132 - mae: 20.0527 - val_loss: 556.5132 - val_mae: 19.9267\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.9058 - mae: 19.7076 - val_loss: 534.8177 - val_mae: 19.5770\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.5297 - mae: 19.3805 - val_loss: 515.9768 - val_mae: 19.2607\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.6566 - mae: 19.0846 - val_loss: 499.1669 - val_mae: 18.9677\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 496.5581 - mae: 18.8108 - val_loss: 484.4224 - val_mae: 18.7026\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 483.2896 - mae: 18.5628 - val_loss: 471.1835 - val_mae: 18.4570\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 471.3432 - mae: 18.3346 - val_loss: 459.2148 - val_mae: 18.2296\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.5682 - mae: 18.1194 - val_loss: 448.3928 - val_mae: 18.0172\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 450.7905 - mae: 17.9240 - val_loss: 438.7068 - val_mae: 17.8205\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.0368 - mae: 17.7373 - val_loss: 430.0899 - val_mae: 17.6402\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 434.2498 - mae: 17.5710 - val_loss: 422.1250 - val_mae: 17.4698\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 427.0063 - mae: 17.4123 - val_loss: 415.0428 - val_mae: 17.3131\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 420.5914 - mae: 17.2627 - val_loss: 408.6703 - val_mae: 17.1687\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 414.7649 - mae: 17.1302 - val_loss: 402.7959 - val_mae: 17.0334\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.3687 - mae: 17.0011 - val_loss: 397.3857 - val_mae: 16.9075\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 404.4031 - mae: 16.8819 - val_loss: 392.4826 - val_mae: 16.7911\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 399.8740 - mae: 16.7715 - val_loss: 387.9860 - val_mae: 16.6835\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 395.7075 - mae: 16.6684 - val_loss: 383.8666 - val_mae: 16.5824\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 391.8674 - mae: 16.5701 - val_loss: 380.0328 - val_mae: 16.4861\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 388.3245 - mae: 16.4785 - val_loss: 376.5344 - val_mae: 16.3973\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 385.0360 - mae: 16.3908 - val_loss: 373.2687 - val_mae: 16.3125\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 381.9708 - mae: 16.3083 - val_loss: 370.2924 - val_mae: 16.2340\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 379.1566 - mae: 16.2337 - val_loss: 367.4428 - val_mae: 16.1572\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 376.4664 - mae: 16.1600 - val_loss: 364.8256 - val_mae: 16.0848\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 373.9750 - mae: 16.0927 - val_loss: 362.3197 - val_mae: 16.0144\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.6039 - mae: 16.0266 - val_loss: 360.0931 - val_mae: 15.9510\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 369.4440 - mae: 15.9657 - val_loss: 357.9443 - val_mae: 15.8893\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 367.3896 - mae: 15.9060 - val_loss: 355.9030 - val_mae: 15.8307\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 365.4147 - mae: 15.8510 - val_loss: 353.9242 - val_mae: 15.7732\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 363.5339 - mae: 15.7962 - val_loss: 352.0710 - val_mae: 15.7186\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 361.7649 - mae: 15.7445 - val_loss: 350.2984 - val_mae: 15.6662\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 360.0247 - mae: 15.6956 - val_loss: 348.6082 - val_mae: 15.6151\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 358.3868 - mae: 15.6461 - val_loss: 346.9102 - val_mae: 15.5640\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 356.7133 - mae: 15.5992 - val_loss: 345.3114 - val_mae: 15.5155\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 355.1425 - mae: 15.5524 - val_loss: 343.7418 - val_mae: 15.4675\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 353.5854 - mae: 15.5066 - val_loss: 342.1981 - val_mae: 15.4199\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 352.0502 - mae: 15.4613 - val_loss: 340.6863 - val_mae: 15.3730\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 350.5359 - mae: 15.4169 - val_loss: 339.1975 - val_mae: 15.3263\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 349.0529 - mae: 15.3733 - val_loss: 337.7640 - val_mae: 15.2813\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 347.6436 - mae: 15.3309 - val_loss: 336.3684 - val_mae: 15.2376\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 346.2337 - mae: 15.2888 - val_loss: 335.0322 - val_mae: 15.1952\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 344.8986 - mae: 15.2495 - val_loss: 333.7150 - val_mae: 15.1525\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 343.5603 - mae: 15.2093 - val_loss: 332.4471 - val_mae: 15.1102\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 342.2856 - mae: 15.1701 - val_loss: 331.2128 - val_mae: 15.0689\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 341.0377 - mae: 15.1317 - val_loss: 330.0143 - val_mae: 15.0280\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 339.8424 - mae: 15.0949 - val_loss: 328.8410 - val_mae: 14.9880\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 338.6515 - mae: 15.0580 - val_loss: 327.7164 - val_mae: 14.9499\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 337.5000 - mae: 15.0219 - val_loss: 326.6184 - val_mae: 14.9126\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 336.3855 - mae: 14.9873 - val_loss: 325.5156 - val_mae: 14.8754\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 335.2670 - mae: 14.9532 - val_loss: 324.4349 - val_mae: 14.8392\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 334.1615 - mae: 14.9190 - val_loss: 323.4071 - val_mae: 14.8041\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 333.1353 - mae: 14.8862 - val_loss: 322.4055 - val_mae: 14.7703\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 332.0948 - mae: 14.8527 - val_loss: 321.4483 - val_mae: 14.7378\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 331.1140 - mae: 14.8219 - val_loss: 320.5100 - val_mae: 14.7066\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 330.1695 - mae: 14.7922 - val_loss: 319.6078 - val_mae: 14.6759\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 329.2474 - mae: 14.7621 - val_loss: 318.7513 - val_mae: 14.6468\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 328.3498 - mae: 14.7339 - val_loss: 317.9160 - val_mae: 14.6183\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 327.4942 - mae: 14.7059 - val_loss: 317.1221 - val_mae: 14.5909\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 326.6711 - mae: 14.6789 - val_loss: 316.3472 - val_mae: 14.5642\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 325.8549 - mae: 14.6521 - val_loss: 315.5957 - val_mae: 14.5383\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 325.0820 - mae: 14.6268 - val_loss: 314.8560 - val_mae: 14.5128\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 324.3263 - mae: 14.6024 - val_loss: 314.1458 - val_mae: 14.4879\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 323.6062 - mae: 14.5788 - val_loss: 313.4709 - val_mae: 14.4641\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 322.9052 - mae: 14.5558 - val_loss: 312.8059 - val_mae: 14.4402\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 322.2223 - mae: 14.5337 - val_loss: 312.1848 - val_mae: 14.4180\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 321.5759 - mae: 14.5123 - val_loss: 311.5962 - val_mae: 14.3969\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 320.9652 - mae: 14.4919 - val_loss: 311.0303 - val_mae: 14.3762\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 320.3736 - mae: 14.4720 - val_loss: 310.4729 - val_mae: 14.3557\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 319.8093 - mae: 14.4536 - val_loss: 309.9299 - val_mae: 14.3358\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 319.2363 - mae: 14.4341 - val_loss: 309.4165 - val_mae: 14.3168\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 318.7053 - mae: 14.4157 - val_loss: 308.9217 - val_mae: 14.2988\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 318.1838 - mae: 14.3983 - val_loss: 308.4575 - val_mae: 14.2818\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 317.6858 - mae: 14.3804 - val_loss: 308.0126 - val_mae: 14.2658\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 317.1986 - mae: 14.3641 - val_loss: 307.5845 - val_mae: 14.2506\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 316.7211 - mae: 14.3492 - val_loss: 307.1592 - val_mae: 14.2347\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 316.2571 - mae: 14.3334 - val_loss: 306.7502 - val_mae: 14.2195\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 315.8145 - mae: 14.3180 - val_loss: 306.3615 - val_mae: 14.2050\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 315.3853 - mae: 14.3047 - val_loss: 305.9856 - val_mae: 14.1905\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 314.9693 - mae: 14.2897 - val_loss: 305.6190 - val_mae: 14.1768\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 314.5641 - mae: 14.2759 - val_loss: 305.2664 - val_mae: 14.1640\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 314.1740 - mae: 14.2634 - val_loss: 304.9262 - val_mae: 14.1516\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 313.7950 - mae: 14.2496 - val_loss: 304.5992 - val_mae: 14.1401\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.4077 - mae: 14.2376 - val_loss: 304.2869 - val_mae: 14.1293\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 313.0451 - mae: 14.2261 - val_loss: 303.9541 - val_mae: 14.1171\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 312.6717 - mae: 14.2135 - val_loss: 303.6387 - val_mae: 14.1059\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 312.3206 - mae: 14.2012 - val_loss: 303.3326 - val_mae: 14.0954\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 311.9765 - mae: 14.1907 - val_loss: 303.0221 - val_mae: 14.0843\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 311.6533 - mae: 14.1789 - val_loss: 302.7278 - val_mae: 14.0739\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 311.3234 - mae: 14.1686 - val_loss: 302.4359 - val_mae: 14.0635\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.9901 - mae: 14.1578 - val_loss: 302.1440 - val_mae: 14.0532\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 310.6693 - mae: 14.1472 - val_loss: 301.8653 - val_mae: 14.0435\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=1e-06, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=sgd; total time=   5.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 789, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 94, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 332, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\users\\szymo\\p\\emotion-recognition\\er\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 17ms/step - loss: 9229.3516 - mae: 57.8331 - val_loss: 8749.9873 - val_mae: 56.2039\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9228.4258 - mae: 57.8309 - val_loss: 8749.1045 - val_mae: 56.2016\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9227.5107 - mae: 57.8286 - val_loss: 8748.2256 - val_mae: 56.1993\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9226.5850 - mae: 57.8264 - val_loss: 8747.3604 - val_mae: 56.1971\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9225.6680 - mae: 57.8242 - val_loss: 8746.4912 - val_mae: 56.1948\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9224.7549 - mae: 57.8220 - val_loss: 8745.6230 - val_mae: 56.1926\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9223.8320 - mae: 57.8198 - val_loss: 8744.7500 - val_mae: 56.1903\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9222.9102 - mae: 57.8176 - val_loss: 8743.8643 - val_mae: 56.1881\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9221.9736 - mae: 57.8154 - val_loss: 8742.9893 - val_mae: 56.1858\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9221.0527 - mae: 57.8132 - val_loss: 8742.1055 - val_mae: 56.1835\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9220.1230 - mae: 57.8109 - val_loss: 8741.2217 - val_mae: 56.1812\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9219.1904 - mae: 57.8087 - val_loss: 8740.3428 - val_mae: 56.1789\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9218.2676 - mae: 57.8065 - val_loss: 8739.4551 - val_mae: 56.1767\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9217.3379 - mae: 57.8042 - val_loss: 8738.5859 - val_mae: 56.1744\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9216.4189 - mae: 57.8020 - val_loss: 8737.7148 - val_mae: 56.1721\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9215.4990 - mae: 57.7998 - val_loss: 8736.8291 - val_mae: 56.1698\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9214.5684 - mae: 57.7976 - val_loss: 8735.9590 - val_mae: 56.1676\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9213.6543 - mae: 57.7954 - val_loss: 8735.0742 - val_mae: 56.1653\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9212.7227 - mae: 57.7931 - val_loss: 8734.2021 - val_mae: 56.1631\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9211.8057 - mae: 57.7909 - val_loss: 8733.3262 - val_mae: 56.1608\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9210.8818 - mae: 57.7887 - val_loss: 8732.4600 - val_mae: 56.1585\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9209.9678 - mae: 57.7865 - val_loss: 8731.5869 - val_mae: 56.1563\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9209.0420 - mae: 57.7843 - val_loss: 8730.7080 - val_mae: 56.1540\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9208.1143 - mae: 57.7820 - val_loss: 8729.8311 - val_mae: 56.1517\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9207.1953 - mae: 57.7798 - val_loss: 8728.9551 - val_mae: 56.1494\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9206.2656 - mae: 57.7776 - val_loss: 8728.0869 - val_mae: 56.1472\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9205.3516 - mae: 57.7754 - val_loss: 8727.2031 - val_mae: 56.1449\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9204.4238 - mae: 57.7732 - val_loss: 8726.3213 - val_mae: 56.1426\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9203.4922 - mae: 57.7710 - val_loss: 8725.4395 - val_mae: 56.1403\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9202.5703 - mae: 57.7687 - val_loss: 8724.5674 - val_mae: 56.1381\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9201.6553 - mae: 57.7665 - val_loss: 8723.7012 - val_mae: 56.1359\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9200.7324 - mae: 57.7643 - val_loss: 8722.8291 - val_mae: 56.1336\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9199.8164 - mae: 57.7621 - val_loss: 8721.9463 - val_mae: 56.1313\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9198.8916 - mae: 57.7599 - val_loss: 8721.0713 - val_mae: 56.1290\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9197.9756 - mae: 57.7576 - val_loss: 8720.1963 - val_mae: 56.1267\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9197.0527 - mae: 57.7554 - val_loss: 8719.3232 - val_mae: 56.1244\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9196.1270 - mae: 57.7532 - val_loss: 8718.4580 - val_mae: 56.1222\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9195.2070 - mae: 57.7510 - val_loss: 8717.5713 - val_mae: 56.1199\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9194.2793 - mae: 57.7488 - val_loss: 8716.6953 - val_mae: 56.1176\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9193.3633 - mae: 57.7465 - val_loss: 8715.8213 - val_mae: 56.1154\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9192.4355 - mae: 57.7443 - val_loss: 8714.9463 - val_mae: 56.1130\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9191.5225 - mae: 57.7421 - val_loss: 8714.0586 - val_mae: 56.1107\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9190.5889 - mae: 57.7398 - val_loss: 8713.1904 - val_mae: 56.1084\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9189.6729 - mae: 57.7376 - val_loss: 8712.3135 - val_mae: 56.1062\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9188.7500 - mae: 57.7354 - val_loss: 8711.4385 - val_mae: 56.1039\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9187.8301 - mae: 57.7332 - val_loss: 8710.5742 - val_mae: 56.1016\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9186.9189 - mae: 57.7310 - val_loss: 8709.7031 - val_mae: 56.0993\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9185.9990 - mae: 57.7288 - val_loss: 8708.8291 - val_mae: 56.0970\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9185.0762 - mae: 57.7265 - val_loss: 8707.9512 - val_mae: 56.0947\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9184.1592 - mae: 57.7243 - val_loss: 8707.0742 - val_mae: 56.0925\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9183.2363 - mae: 57.7221 - val_loss: 8706.2070 - val_mae: 56.0903\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9182.3154 - mae: 57.7199 - val_loss: 8705.3379 - val_mae: 56.0880\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9181.3984 - mae: 57.7177 - val_loss: 8704.4541 - val_mae: 56.0857\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9180.4717 - mae: 57.7154 - val_loss: 8703.5820 - val_mae: 56.0835\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9179.5547 - mae: 57.7132 - val_loss: 8702.7139 - val_mae: 56.0812\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9178.6436 - mae: 57.7110 - val_loss: 8701.8379 - val_mae: 56.0789\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9177.7227 - mae: 57.7088 - val_loss: 8700.9746 - val_mae: 56.0766\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9176.8076 - mae: 57.7066 - val_loss: 8700.1025 - val_mae: 56.0743\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 9175.8887 - mae: 57.7044 - val_loss: 8699.2354 - val_mae: 56.0720\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9174.9805 - mae: 57.7021 - val_loss: 8698.3506 - val_mae: 56.0698\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9174.0479 - mae: 57.6999 - val_loss: 8697.4785 - val_mae: 56.0675\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9173.1270 - mae: 57.6977 - val_loss: 8696.6133 - val_mae: 56.0653\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9172.2090 - mae: 57.6955 - val_loss: 8695.7422 - val_mae: 56.0630\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9171.2930 - mae: 57.6932 - val_loss: 8694.8604 - val_mae: 56.0607\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9170.3662 - mae: 57.6910 - val_loss: 8693.9844 - val_mae: 56.0584\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9169.4404 - mae: 57.6888 - val_loss: 8693.1094 - val_mae: 56.0561\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9168.5264 - mae: 57.6866 - val_loss: 8692.2422 - val_mae: 56.0538\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9167.6182 - mae: 57.6844 - val_loss: 8691.3779 - val_mae: 56.0516\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9166.7021 - mae: 57.6821 - val_loss: 8690.5059 - val_mae: 56.0494\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9165.7783 - mae: 57.6799 - val_loss: 8689.6367 - val_mae: 56.0471\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9164.8574 - mae: 57.6777 - val_loss: 8688.7549 - val_mae: 56.0448\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9163.9326 - mae: 57.6755 - val_loss: 8687.8799 - val_mae: 56.0425\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9163.0078 - mae: 57.6732 - val_loss: 8687.0020 - val_mae: 56.0403\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9162.0850 - mae: 57.6710 - val_loss: 8686.1221 - val_mae: 56.0380\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9161.1553 - mae: 57.6688 - val_loss: 8685.2480 - val_mae: 56.0357\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9160.2324 - mae: 57.6665 - val_loss: 8684.3750 - val_mae: 56.0334\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9159.3213 - mae: 57.6643 - val_loss: 8683.4980 - val_mae: 56.0311\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9158.3945 - mae: 57.6621 - val_loss: 8682.6201 - val_mae: 56.0288\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9157.4727 - mae: 57.6598 - val_loss: 8681.7363 - val_mae: 56.0265\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9156.5459 - mae: 57.6576 - val_loss: 8680.8730 - val_mae: 56.0243\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9155.6289 - mae: 57.6554 - val_loss: 8680.0068 - val_mae: 56.0221\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9154.7168 - mae: 57.6532 - val_loss: 8679.1338 - val_mae: 56.0198\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9153.7959 - mae: 57.6510 - val_loss: 8678.2676 - val_mae: 56.0175\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9152.8877 - mae: 57.6487 - val_loss: 8677.3857 - val_mae: 56.0152\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9151.9570 - mae: 57.6465 - val_loss: 8676.5156 - val_mae: 56.0129\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9151.0479 - mae: 57.6442 - val_loss: 8675.6396 - val_mae: 56.0106\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9150.1230 - mae: 57.6420 - val_loss: 8674.7773 - val_mae: 56.0083\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9149.2090 - mae: 57.6398 - val_loss: 8673.9189 - val_mae: 56.0061\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9148.2988 - mae: 57.6376 - val_loss: 8673.0400 - val_mae: 56.0038\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9147.3818 - mae: 57.6354 - val_loss: 8672.1670 - val_mae: 56.0015\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9146.4658 - mae: 57.6331 - val_loss: 8671.2852 - val_mae: 55.9991\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9145.5361 - mae: 57.6309 - val_loss: 8670.4238 - val_mae: 55.9968\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9144.6270 - mae: 57.6287 - val_loss: 8669.5518 - val_mae: 55.9945\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9143.7148 - mae: 57.6264 - val_loss: 8668.6787 - val_mae: 55.9922\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9142.7910 - mae: 57.6242 - val_loss: 8667.8135 - val_mae: 55.9900\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9141.8867 - mae: 57.6220 - val_loss: 8666.9443 - val_mae: 55.9877\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9140.9688 - mae: 57.6198 - val_loss: 8666.0850 - val_mae: 55.9855\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9140.0547 - mae: 57.6176 - val_loss: 8665.2217 - val_mae: 55.9832\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9139.1387 - mae: 57.6154 - val_loss: 8664.3447 - val_mae: 55.9809\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9138.2178 - mae: 57.6131 - val_loss: 8663.4678 - val_mae: 55.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x000001B73A342CA0>], model=<function build_model at 0x000001B704E52CA0>),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'model__learning_rate': [0.0001, 1e-05,\n",
       "                                                                 1e-06],\n",
       "                                        'model__momentum': [0.1, 0.5, 0.9],\n",
       "                                        'model__n_hidden': [0, 1, 2, 3],\n",
       "                                        'model__n_neurons': [5, 25, 125],\n",
       "                                        'model__optimizer': ['sgd', 'nesterov',\n",
       "                                                             'momentum',\n",
       "                                                             'adam']},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg,\n",
    "param_distribs,\n",
    "n_iter=30,\n",
    "cv=3,\n",
    "verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396c44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__optimizer': 'adam', 'model__n_neurons': 5, 'model__n_hidden': 1, 'model__momentum': 0.1, 'model__learning_rate': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8353fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rnd_search.pkl', 'wb') as fp:\n",
    "    pickle.dump(rnd_search_cv.best_params_, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24235465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f2a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da5a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}