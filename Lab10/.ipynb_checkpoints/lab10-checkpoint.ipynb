{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baac4ce6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() \n",
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f21ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd7ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(X_train[142], cmap=\"binary\") \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c158357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"koszulka\", \"spodnie\", \"pulower\", \"sukienka\", \"kurtka\",\n",
    "               \"sanda≈Ç\", \"koszula\", \"but\", \"torba\", \"kozak\"]\n",
    "class_names[y_train[142]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6a9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b5a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#tf.keras.utils.plot_model(model, \"fashion_mnist.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77072239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"image_logs\")\n",
    "def get_run_logdir(): \n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5e51f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.7209 - accuracy: 0.7638 - val_loss: 0.5753 - val_accuracy: 0.7872\n",
      "Epoch 2/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4862 - accuracy: 0.8316 - val_loss: 0.4528 - val_accuracy: 0.8403\n",
      "Epoch 3/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4410 - accuracy: 0.8455 - val_loss: 0.4229 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4140 - accuracy: 0.8553 - val_loss: 0.4246 - val_accuracy: 0.8475\n",
      "Epoch 5/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.3935 - accuracy: 0.8619 - val_loss: 0.4450 - val_accuracy: 0.8463\n",
      "Epoch 6/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3774 - accuracy: 0.8683 - val_loss: 0.4101 - val_accuracy: 0.8525\n",
      "Epoch 7/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3644 - accuracy: 0.8708 - val_loss: 0.3813 - val_accuracy: 0.8622\n",
      "Epoch 8/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3523 - accuracy: 0.8743 - val_loss: 0.3859 - val_accuracy: 0.8635\n",
      "Epoch 9/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3422 - accuracy: 0.8778 - val_loss: 0.3599 - val_accuracy: 0.8687\n",
      "Epoch 10/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3328 - accuracy: 0.8814 - val_loss: 0.3760 - val_accuracy: 0.8647\n",
      "Epoch 11/20\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3250 - accuracy: 0.8834 - val_loss: 0.3501 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3159 - accuracy: 0.8877 - val_loss: 0.3479 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3094 - accuracy: 0.8891 - val_loss: 0.3566 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3025 - accuracy: 0.8915 - val_loss: 0.3655 - val_accuracy: 0.8705\n",
      "Epoch 15/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2948 - accuracy: 0.8945 - val_loss: 0.3336 - val_accuracy: 0.8807\n",
      "Epoch 16/20\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2889 - accuracy: 0.8970 - val_loss: 0.3346 - val_accuracy: 0.8802\n",
      "Epoch 17/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2838 - accuracy: 0.8974 - val_loss: 0.3340 - val_accuracy: 0.8777\n",
      "Epoch 18/20\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2780 - accuracy: 0.9007 - val_loss: 0.3427 - val_accuracy: 0.8758\n",
      "Epoch 19/20\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2729 - accuracy: 0.9031 - val_loss: 0.3319 - val_accuracy: 0.8825\n",
      "Epoch 20/20\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2675 - accuracy: 0.9042 - val_loss: 0.3359 - val_accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_split=0.1, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acefc0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: torba\n",
      "Confidence: 0.9986545\n",
      "Truth: torba\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_index = np.random.randint(len(X_test))\n",
    "image = np.array([X_test[image_index]])\n",
    "confidences = model.predict(image)\n",
    "confidence = np.max(confidences[0])\n",
    "prediction = np.argmax(confidences[0])\n",
    "print(\"Prediction:\", class_names[prediction])\n",
    "print(\"Confidence:\", confidence)\n",
    "print(\"Truth:\", class_names[y_test[image_index]])\n",
    "plt.imshow(image[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54648cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fashion_clf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27945d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7415dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b108be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f93ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_housing1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model_housing1.compile(loss=\"mean_squared_error\", optimizer='SGD')\n",
    "\n",
    "model_housing1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ab2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=5,\n",
    "                                      min_delta=0.01, \n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05aca6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"housing_logs\")\n",
    "def get_run_logdir(): \n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5591b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9250 - val_loss: 1.0820\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 4.4895\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 1.3487\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4281 - val_loss: 0.4025\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.3794\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4048 - val_loss: 0.4113\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.3698\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4022\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3581\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3878\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.3531\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.3621\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.4081\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3815\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_housing1.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74be54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_housing1.save(\"reg_housing_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "431da8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_housing2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(90, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(90, activation=\"relu\"),\n",
    "    keras.layers.Dense(90, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0643ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 90)                810       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 91        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_housing2.compile(loss=\"mean_squared_error\", optimizer='SGD')\n",
    "\n",
    "model_housing2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67776813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7283 - val_loss: 1.3855\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.3702\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3654 - val_loss: 0.7449\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3662 - val_loss: 5.5340\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3595 - val_loss: 3.2197\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 1.2730\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3379 - val_loss: 1.1877\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_housing2.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa00936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_housing2.save(\"reg_housing_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6ee5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_housing3 = keras.models.Sequential([\n",
    "    keras.layers.Dense(80, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a34c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 80)                720       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,001\n",
      "Trainable params: 5,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_housing3.compile(loss=\"mean_squared_error\", optimizer='SGD')\n",
    "\n",
    "model_housing3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59378a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7434 - val_loss: 0.5861\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4194 - val_loss: 1.3042\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3851 - val_loss: 0.5688\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.7772\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 1.2631\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 1.0458\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.3245\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3376\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3278 - val_loss: 0.3820\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3159 - val_loss: 1.0216\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3483 - val_loss: 0.4987\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_housing3.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87f4936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_housing3.save(\"reg_housing_3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
